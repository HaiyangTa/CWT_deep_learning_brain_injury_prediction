{"cells":[{"cell_type":"code","execution_count":1,"id":"8f5a4f5b-bad9-49e3-8dd6-7304666df443","metadata":{"id":"8f5a4f5b-bad9-49e3-8dd6-7304666df443","executionInfo":{"status":"ok","timestamp":1760499951156,"user_tz":300,"elapsed":10553,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","import torchvision\n","import torchvision.transforms as transforms\n","import os\n","import argparse\n","from pathlib import Path\n","import re\n","import random\n","import math\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"id":"dr2Fm7p5mAAN","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19614,"status":"ok","timestamp":1760499970764,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"},"user_tz":300},"id":"dr2Fm7p5mAAN","outputId":"46aeaba8-b47a-4bbb-fba2-bface8262e39"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":[],"metadata":{"id":"gUHWAH8qdC05","executionInfo":{"status":"ok","timestamp":1760499970772,"user_tz":300,"elapsed":10,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"gUHWAH8qdC05","execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L2wH-XagdC3h","executionInfo":{"status":"ok","timestamp":1760499970781,"user_tz":300,"elapsed":4,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"L2wH-XagdC3h","execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### Reading the BF data"],"metadata":{"id":"51Qe0XC1X2Ju"},"id":"51Qe0XC1X2Ju"},{"cell_type":"code","source":["bf_path = '/content/drive/MyDrive/ALL_CLEAN_DEIDEN_NAME AND ECMO DATA(Sheet1) (1) (version 2).csv'\n","cols = ['ID', 'age_days', 'weight', 'study_height', 'Diagnosis']\n","df = pd.read_csv(bf_path, usecols=cols)\n","\n","for col in ['weight', 'study_height', 'age_days']:\n","    s = pd.to_numeric(df[col], errors='coerce')\n","    mx = s.max(skipna=True)\n","    if pd.notna(mx) and mx != 0:\n","        df[col] = s / mx\n","    else:\n","        df[col] = s\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eI4st7P3X51D","executionInfo":{"status":"ok","timestamp":1760499972280,"user_tz":300,"elapsed":1491,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"outputId":"6927453b-68f9-438f-a113-af1652c9768f"},"id":"eI4st7P3X51D","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["   ID  age_days            Diagnosis    weight  study_height\n","0   1  0.018213       Cardiac Arrest  0.042214      0.344538\n","1   2  0.072852       Cardiac Arrest  0.070000      0.431373\n","2   3  0.793776               Sepsis  0.403571      0.896359\n","3   4  0.000287  Respiratory Failure  0.022786      0.268908\n","4   5  0.000287  Respiratory Failure  0.023571      0.285714\n"]}]},{"cell_type":"code","source":["diag_clean = (\n","    df['Diagnosis']\n","      .astype('string')\n","      .str.strip()\n","      .str.replace(r'\\s+', ' ', regex=True)\n","      .fillna('Unknown')\n",")\n","\n","codes, uniques = pd.factorize(diag_clean, sort=True)\n","df['Diagnosis'] = codes.astype('int64')\n","diagnosis_mapping = {cat: int(i) for i, cat in enumerate(uniques)}\n","print(\"Diagnosis mapping (category -> code):\", diagnosis_mapping)\n","# Peek\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6KRSpwpSX53j","executionInfo":{"status":"ok","timestamp":1760499972310,"user_tz":300,"elapsed":23,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"outputId":"4ef0fd65-16a5-4380-f44b-9d84e8437a88"},"id":"6KRSpwpSX53j","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Diagnosis mapping (category -> code): {'Cardiac Arrest': 0, 'Cardiogenic Shock': 1, 'Respiratory Failure': 2, 'Respiratory Failure, Cardiac Arrest': 3, 'Sepsis': 4, 'Septic shock': 5}\n","   ID  age_days  Diagnosis    weight  study_height\n","0   1  0.018213          0  0.042214      0.344538\n","1   2  0.072852          0  0.070000      0.431373\n","2   3  0.793776          4  0.403571      0.896359\n","3   4  0.000287          2  0.022786      0.268908\n","4   5  0.000287          2  0.023571      0.285714\n"]}]},{"cell_type":"code","source":["df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5Jnj3X_X5_P","executionInfo":{"status":"ok","timestamp":1760499972328,"user_tz":300,"elapsed":15,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"outputId":"d857c778-d2e5-400f-f86c-1cf26c1ef404"},"id":"Z5Jnj3X_X5_P","execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(73, 5)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":[],"metadata":{"id":"Z-Q3ZaH-X6EY","executionInfo":{"status":"ok","timestamp":1760499972337,"user_tz":300,"elapsed":6,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"Z-Q3ZaH-X6EY","execution_count":5,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"REn1fKi1pHMT","executionInfo":{"status":"ok","timestamp":1760499972345,"user_tz":300,"elapsed":4,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"REn1fKi1pHMT","execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### No normalization!"],"metadata":{"id":"vCi0eO54p2NW"},"id":"vCi0eO54p2NW"},{"cell_type":"code","source":["from pathlib import Path\n","import re, random, math, os\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.metrics import roc_auc_score\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# =========================\n","# Config\n","# =========================\n","SPLIT_DIR = r\"/content/drive/MyDrive/CD/patient_data_clean_nozero_181920212223_1800\"\n","POS_PATIENTS = {1, 2, 16, 19, 21, 22, 25, 37, 39, 43, 44, 47, 50, 56, 58, 62, 65, 66, 73, 78}\n","\n","BATCH_SIZE       = 3\n","EPOCHS           = 100\n","LR               = 1e-4\n","SEED             = 1\n","\n","# =========================\n","# Repro\n","# =========================\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n","for g in tf.config.list_physical_devices('GPU'):\n","    try: tf.config.experimental.set_memory_growth(g, True)\n","    except Exception: pass\n","\n","# =========================\n","# Helpers\n","# =========================\n","PATIENT_NUM_RX = re.compile(r'^ID(\\d+)')  # e.g., \"ID76-2_...\" -> 76\n","\n","def patient_num_from_path(pathlike):\n","    stem = Path(pathlike).stem\n","    m = PATIENT_NUM_RX.match(stem)\n","    return int(m.group(1)) if m else None\n","\n","def label_for_file(p: Path) -> int:\n","    pnum = patient_num_from_path(p)\n","    return 1 if (pnum is not None and pnum in POS_PATIENTS) else 0\n","\n","# =========================\n","# Load pre-existing 4-feature DataFrame: df (must be in memory)\n","# Must contain column 'ID' + exactly 4 feature columns.\n","# =========================\n","feats_df = df.copy()  # <-- uses your in-memory DataFrame\n","if \"ID\" not in feats_df.columns:\n","    raise RuntimeError(\"Your features DataFrame must contain column 'ID'.\")\n","\n","FEAT_COLS = [c for c in feats_df.columns if c != \"ID\"]\n","#if len(FEAT_COLS) != 4:\n","#    raise RuntimeError(f\"Expected exactly 4 feature columns besides 'ID', found {len(FEAT_COLS)}: {FEAT_COLS}\")\n","\n","# Clean and index by ID; drop rows with missing any of the 4 features\n","feats_df[\"ID\"] = pd.to_numeric(feats_df[\"ID\"], errors=\"coerce\").astype(\"Int64\")\n","feats_df = feats_df.dropna(subset=[\"ID\"] + FEAT_COLS).copy()\n","feats_df[\"ID\"] = feats_df[\"ID\"].astype(int)\n","\n","ID_TO_FEAT = {\n","    int(row[\"ID\"]): row[FEAT_COLS].astype(\"float32\").to_numpy()\n","    for _, row in feats_df.iterrows()\n","}\n","FEAT_DIM = len(FEAT_COLS)\n","print('FEAT_DIM =', FEAT_DIM)\n","\n","# =========================\n","# List EEG files ONLY to define splits by patient ID (no EEG is loaded)\n","# =========================\n","split_dir = Path(SPLIT_DIR)\n","all_csvs = sorted(split_dir.glob(\"*.csv\"))\n","if not all_csvs:\n","    raise FileNotFoundError(f\"No CSV found in {SPLIT_DIR}\")\n","\n","# Map: id -> list of files for that patient\n","id_to_files = {}\n","for f in all_csvs:\n","    pid = patient_num_from_path(f)\n","    if pid is None:\n","        continue\n","    id_to_files.setdefault(pid, []).append(f)\n","\n","all_ids = sorted(id_to_files.keys())\n","\n","# Use only IDs that have the required 4 features\n","valid_ids = [pid for pid in all_ids if pid in ID_TO_FEAT]\n","if not valid_ids:\n","    raise RuntimeError(\"No overlapping patient IDs between files and the 4-feature table.\")\n","if len(valid_ids) < len(all_ids):\n","    print(f\"Dropping {len(all_ids)-len(valid_ids)} patient IDs without 4-feature rows.\")\n","\n","labels_all = np.array([1 if pid in POS_PATIENTS else 0 for pid in valid_ids], dtype=int)\n","\n","print(\"Total valid IDs:\", len(valid_ids),\n","      \"| Pos IDs:\", labels_all.sum(),\n","      \"| Neg IDs:\", (1 - labels_all).sum())\n","\n","# =========================\n","# Data Sequence (tab-only)\n","# Each file becomes one sample with that patient's 4 features.\n","# =========================\n","class TabSequence(keras.utils.Sequence):\n","    def __init__(self, files, batch_size=BATCH_SIZE, shuffle=True):\n","        super().__init__()\n","        # Keep only files whose patient ID has 4 features\n","        self.files = [f for f in files if patient_num_from_path(f) in ID_TO_FEAT]\n","        self.batch_size = int(batch_size)\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        return math.ceil(len(self.files) / self.batch_size)\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.files))\n","        if self.shuffle:\n","            np.random.shuffle(self.indexes)\n","\n","    def __getitem__(self, idx):\n","        idxs = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n","        batch_files = [self.files[i] for i in idxs]\n","        B = len(batch_files)\n","\n","        X_tab = np.empty((B, FEAT_DIM), dtype=np.float32)\n","        y     = np.empty((B,), dtype=np.int32)\n","\n","        for i, f in enumerate(batch_files):\n","            pid = patient_num_from_path(f)\n","            X_tab[i] = ID_TO_FEAT[pid]      # (4,)\n","            y[i] = label_for_file(f)\n","\n","        return {\"tab_input\": X_tab}, y\n","\n","# =========================\n","# Tab-only Model: 4 -> 8 -> 8 -> 1\n","# =========================\n","def build_model(tab_dim=FEAT_DIM, lr=LR, dropout=0.2):\n","    tab_in = keras.Input(shape=(tab_dim,), name=\"tab_input\")\n","    t = layers.Dense(8, activation=\"relu\")(tab_in)\n","    t = layers.Dense(8, activation=\"relu\")(t)\n","    t = layers.Dropout(dropout)(t)\n","    out = layers.Dense(1, activation=\"sigmoid\")(t)\n","\n","    model = keras.Model(inputs=tab_in, outputs=out)\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(learning_rate=lr),\n","        loss=\"binary_crossentropy\",\n","        metrics=[keras.metrics.BinaryAccuracy(name=\"acc\"),\n","                 keras.metrics.AUC(name=\"auc\")],\n","    )\n","    return model\n","\n","# =========================\n","# 10-fold Cross-Validation by patient ID (stratified)\n","# =========================\n","skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n","\n","fold_aucs = []\n","for fold_idx, (train_index, test_index) in enumerate(skf.split(valid_ids, labels_all), start=1):\n","    ids_train_full = [valid_ids[i] for i in train_index]\n","    ids_test       = [valid_ids[i] for i in test_index]\n","\n","    # small validation split from training IDs (stratified, by ID)\n","    train_labels_full = np.array([1 if pid in POS_PATIENTS else 0 for pid in ids_train_full], dtype=int)\n","    ids_tr, ids_val = train_test_split(\n","        ids_train_full, test_size=0.10, random_state=SEED,\n","        stratify=train_labels_full\n","    )\n","\n","    # Build file lists for this fold\n","    train_files = [f for pid in ids_tr  for f in id_to_files[pid]]\n","    val_files   = [f for pid in ids_val for f in id_to_files[pid]]\n","    test_files  = [f for pid in ids_test for f in id_to_files[pid]]\n","\n","    print(f\"\\n--- Fold {fold_idx}/10 ---\")\n","    def split_summary_by_ids(name, ids, files):\n","        ys = np.array([label_for_file(f) for f in files], dtype=int)\n","        print(f\"{name:>6} | ids: {len(ids):4d} | files: {len(files):4d} | pos: {(ys==1).sum():4d} | neg: {(ys==0).sum():4d}\")\n","    split_summary_by_ids(\"train\", ids_tr,  train_files)\n","    split_summary_by_ids(\"val\",   ids_val, val_files)\n","    split_summary_by_ids(\"test\",  ids_test, test_files)\n","\n","    # Generators\n","    train_gen = TabSequence(train_files, batch_size=BATCH_SIZE, shuffle=True)\n","    val_gen   = TabSequence(val_files,   batch_size=BATCH_SIZE, shuffle=False)\n","\n","    # Model + training\n","    model = build_model()\n","    best_path = f\"best_tab_only_fold{fold_idx}.h5\"\n","    ckpt = keras.callbacks.ModelCheckpoint(\n","        best_path, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1\n","    )\n","\n","    history = model.fit(\n","        train_gen,\n","        validation_data=val_gen,\n","        epochs=EPOCHS,\n","        callbacks=[ckpt],\n","        verbose=1,\n","    )\n","\n","    # Evaluate on this fold's test set\n","    best_model = keras.models.load_model(best_path)\n","\n","    test_files2 = [f for f in test_files if patient_num_from_path(f) in ID_TO_FEAT]\n","    X_tab_test = np.empty((len(test_files2), FEAT_DIM), dtype=np.float32)\n","    for i, f in enumerate(test_files2):\n","        X_tab_test[i] = ID_TO_FEAT[patient_num_from_path(f)]\n","    y_true = np.array([label_for_file(f) for f in test_files2], dtype=int)\n","\n","    probs1 = best_model.predict({\"tab_input\": X_tab_test}, verbose=0).ravel().astype(float)\n","    try:\n","        auc = roc_auc_score(y_true, probs1)\n","    except ValueError:\n","        auc = float('nan')\n","\n","    fold_aucs.append(float(auc))\n","    print(f\"Fold {fold_idx} AUC: {auc:.4f}\")\n","\n","# =========================\n","# Results across folds\n","# =========================\n","print(\"\\nAUCs per fold:\", fold_aucs)\n","if len([a for a in fold_aucs if not np.isnan(a)]) > 0:\n","    print(f\"Mean AUC: {np.nanmean(fold_aucs):.4f} ± {np.nanstd(fold_aucs):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lD7pVdaPpHPi","outputId":"cd059fa2-9a47-48c3-f692-9498c07cc438","executionInfo":{"status":"ok","timestamp":1760500813089,"user_tz":300,"elapsed":840738,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"lD7pVdaPpHPi","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["FEAT_DIM = 4\n","Total valid IDs: 44 | Pos IDs: 14 | Neg IDs: 30\n","\n","--- Fold 1/10 ---\n"," train | ids:   35 | files:  904 | pos:  318 | neg:  586\n","   val | ids:    4 | files:   42 | pos:    1 | neg:   41\n","  test | ids:    5 | files:  254 | pos:   86 | neg:  168\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m292/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.6055 - auc: 0.5565 - loss: 0.6612\n","Epoch 1: val_loss improved from inf to 0.47449, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - acc: 0.6060 - auc: 0.5567 - loss: 0.6611 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.4745\n","Epoch 2/100\n","\u001b[1m294/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6108 - auc: 0.5565 - loss: 0.6541\n","Epoch 2: val_loss improved from 0.47449 to 0.43209, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6114 - auc: 0.5577 - loss: 0.6538 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.4321\n","Epoch 3/100\n","\u001b[1m294/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6391 - auc: 0.6167 - loss: 0.6307\n","Epoch 3: val_loss improved from 0.43209 to 0.39838, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6388 - auc: 0.6170 - loss: 0.6307 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.3984\n","Epoch 4/100\n","\u001b[1m295/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6527 - auc: 0.6576 - loss: 0.6248\n","Epoch 4: val_loss improved from 0.39838 to 0.37234, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6525 - auc: 0.6583 - loss: 0.6246 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.3723\n","Epoch 5/100\n","\u001b[1m292/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6555 - auc: 0.7475 - loss: 0.5989\n","Epoch 5: val_loss improved from 0.37234 to 0.34894, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6553 - auc: 0.7466 - loss: 0.5991 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.3489\n","Epoch 6/100\n","\u001b[1m296/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6965 - auc: 0.8108 - loss: 0.5708\n","Epoch 6: val_loss improved from 0.34894 to 0.32477, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6959 - auc: 0.8102 - loss: 0.5712 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.3248\n","Epoch 7/100\n","\u001b[1m293/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6399 - auc: 0.7225 - loss: 0.6096\n","Epoch 7: val_loss improved from 0.32477 to 0.30728, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6405 - auc: 0.7238 - loss: 0.6089 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.3073\n","Epoch 8/100\n","\u001b[1m291/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6413 - auc: 0.7745 - loss: 0.5959\n","Epoch 8: val_loss improved from 0.30728 to 0.29061, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6423 - auc: 0.7754 - loss: 0.5950 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.2906\n","Epoch 9/100\n","\u001b[1m292/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6733 - auc: 0.7842 - loss: 0.5727\n","Epoch 9: val_loss improved from 0.29061 to 0.27531, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6735 - auc: 0.7844 - loss: 0.5725 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.2753\n","Epoch 10/100\n","\u001b[1m293/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6786 - auc: 0.7938 - loss: 0.5711\n","Epoch 10: val_loss improved from 0.27531 to 0.26277, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6796 - auc: 0.7940 - loss: 0.5707 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.2628\n","Epoch 11/100\n","\u001b[1m294/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7303 - auc: 0.7950 - loss: 0.5708\n","Epoch 11: val_loss improved from 0.26277 to 0.25475, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7311 - auc: 0.7951 - loss: 0.5703 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.2548\n","Epoch 12/100\n","\u001b[1m286/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7831 - auc: 0.8028 - loss: 0.5393\n","Epoch 12: val_loss improved from 0.25475 to 0.24450, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7834 - auc: 0.8032 - loss: 0.5394 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.2445\n","Epoch 13/100\n","\u001b[1m287/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8023 - auc: 0.8450 - loss: 0.5249\n","Epoch 13: val_loss improved from 0.24450 to 0.23692, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8025 - auc: 0.8429 - loss: 0.5256 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.2369\n","Epoch 14/100\n","\u001b[1m284/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8155 - auc: 0.8199 - loss: 0.5153\n","Epoch 14: val_loss improved from 0.23692 to 0.22737, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8158 - auc: 0.8200 - loss: 0.5155 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.2274\n","Epoch 15/100\n","\u001b[1m279/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8458 - auc: 0.7872 - loss: 0.5252\n","Epoch 15: val_loss improved from 0.22737 to 0.22332, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8451 - auc: 0.7888 - loss: 0.5249 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.2233\n","Epoch 16/100\n","\u001b[1m289/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8392 - auc: 0.7898 - loss: 0.5195\n","Epoch 16: val_loss improved from 0.22332 to 0.21739, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8392 - auc: 0.7908 - loss: 0.5192 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.2174\n","Epoch 17/100\n","\u001b[1m294/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8249 - auc: 0.8135 - loss: 0.5283\n","Epoch 17: val_loss improved from 0.21739 to 0.21102, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8253 - auc: 0.8136 - loss: 0.5276 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.2110\n","Epoch 18/100\n","\u001b[1m287/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8478 - auc: 0.8098 - loss: 0.4997\n","Epoch 18: val_loss improved from 0.21102 to 0.20646, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8476 - auc: 0.8093 - loss: 0.5003 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.2065\n","Epoch 19/100\n","\u001b[1m288/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8471 - auc: 0.8074 - loss: 0.4840\n","Epoch 19: val_loss improved from 0.20646 to 0.20435, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8468 - auc: 0.8074 - loss: 0.4849 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.2043\n","Epoch 20/100\n","\u001b[1m296/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8565 - auc: 0.8111 - loss: 0.4849\n","Epoch 20: val_loss improved from 0.20435 to 0.19950, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8563 - auc: 0.8109 - loss: 0.4852 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1995\n","Epoch 21/100\n","\u001b[1m294/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8219 - auc: 0.7586 - loss: 0.5202\n","Epoch 21: val_loss improved from 0.19950 to 0.19566, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8224 - auc: 0.7598 - loss: 0.5196 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1957\n","Epoch 22/100\n","\u001b[1m291/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8529 - auc: 0.8109 - loss: 0.4825\n","Epoch 22: val_loss improved from 0.19566 to 0.19378, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8524 - auc: 0.8104 - loss: 0.4830 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1938\n","Epoch 23/100\n","\u001b[1m281/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8404 - auc: 0.7850 - loss: 0.5008\n","Epoch 23: val_loss improved from 0.19378 to 0.18728, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8405 - auc: 0.7865 - loss: 0.4996 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1873\n","Epoch 24/100\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8382 - auc: 0.8000 - loss: 0.4954\n","Epoch 24: val_loss improved from 0.18728 to 0.18348, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8382 - auc: 0.8000 - loss: 0.4953 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1835\n","Epoch 25/100\n","\u001b[1m300/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8526 - auc: 0.8031 - loss: 0.4676\n","Epoch 25: val_loss improved from 0.18348 to 0.18067, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8526 - auc: 0.8032 - loss: 0.4677 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1807\n","Epoch 26/100\n","\u001b[1m296/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8428 - auc: 0.8034 - loss: 0.4887\n","Epoch 26: val_loss improved from 0.18067 to 0.17809, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8429 - auc: 0.8035 - loss: 0.4884 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1781\n","Epoch 27/100\n","\u001b[1m292/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8505 - auc: 0.8425 - loss: 0.4499\n","Epoch 27: val_loss improved from 0.17809 to 0.17471, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8502 - auc: 0.8416 - loss: 0.4504 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1747\n","Epoch 28/100\n","\u001b[1m291/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8343 - auc: 0.8050 - loss: 0.4844\n","Epoch 28: val_loss improved from 0.17471 to 0.17339, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8349 - auc: 0.8053 - loss: 0.4839 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1734\n","Epoch 29/100\n","\u001b[1m287/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8545 - auc: 0.8117 - loss: 0.4551\n","Epoch 29: val_loss improved from 0.17339 to 0.17014, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8542 - auc: 0.8123 - loss: 0.4553 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1701\n","Epoch 30/100\n","\u001b[1m290/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8591 - auc: 0.8118 - loss: 0.4500\n","Epoch 30: val_loss did not improve from 0.17014\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8589 - auc: 0.8117 - loss: 0.4508 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1711\n","Epoch 31/100\n","\u001b[1m285/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8531 - auc: 0.7960 - loss: 0.4739\n","Epoch 31: val_loss improved from 0.17014 to 0.16866, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8524 - auc: 0.7960 - loss: 0.4738 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1687\n","Epoch 32/100\n","\u001b[1m288/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8611 - auc: 0.8149 - loss: 0.4549\n","Epoch 32: val_loss improved from 0.16866 to 0.16763, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8606 - auc: 0.8155 - loss: 0.4549 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1676\n","Epoch 33/100\n","\u001b[1m292/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8567 - auc: 0.8251 - loss: 0.4447\n","Epoch 33: val_loss improved from 0.16763 to 0.16609, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8566 - auc: 0.8248 - loss: 0.4452 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1661\n","Epoch 34/100\n","\u001b[1m293/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8626 - auc: 0.8452 - loss: 0.4277\n","Epoch 34: val_loss improved from 0.16609 to 0.16601, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8622 - auc: 0.8446 - loss: 0.4285 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1660\n","Epoch 35/100\n","\u001b[1m285/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8374 - auc: 0.8096 - loss: 0.4696\n","Epoch 35: val_loss improved from 0.16601 to 0.16455, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8380 - auc: 0.8108 - loss: 0.4683 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1646\n","Epoch 36/100\n","\u001b[1m297/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8617 - auc: 0.8163 - loss: 0.4358\n","Epoch 36: val_loss improved from 0.16455 to 0.16155, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8615 - auc: 0.8165 - loss: 0.4359 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1615\n","Epoch 37/100\n","\u001b[1m299/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8159 - auc: 0.7949 - loss: 0.4962\n","Epoch 37: val_loss did not improve from 0.16155\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8163 - auc: 0.7952 - loss: 0.4956 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1627\n","Epoch 38/100\n","\u001b[1m294/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8674 - auc: 0.8018 - loss: 0.4452\n","Epoch 38: val_loss improved from 0.16155 to 0.16143, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8671 - auc: 0.8025 - loss: 0.4450 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1614\n","Epoch 39/100\n","\u001b[1m281/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8411 - auc: 0.7976 - loss: 0.4513\n","Epoch 39: val_loss improved from 0.16143 to 0.16126, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8418 - auc: 0.7992 - loss: 0.4506 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1613\n","Epoch 40/100\n","\u001b[1m293/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8693 - auc: 0.8217 - loss: 0.4352\n","Epoch 40: val_loss did not improve from 0.16126\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8689 - auc: 0.8215 - loss: 0.4355 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1629\n","Epoch 41/100\n","\u001b[1m295/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8705 - auc: 0.8312 - loss: 0.4216\n","Epoch 41: val_loss did not improve from 0.16126\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8701 - auc: 0.8310 - loss: 0.4221 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1639\n","Epoch 42/100\n","\u001b[1m297/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8577 - auc: 0.8384 - loss: 0.4265\n","Epoch 42: val_loss did not improve from 0.16126\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8576 - auc: 0.8382 - loss: 0.4267 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1635\n","Epoch 43/100\n","\u001b[1m291/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8505 - auc: 0.8202 - loss: 0.4441\n","Epoch 43: val_loss did not improve from 0.16126\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8508 - auc: 0.8201 - loss: 0.4440 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1627\n","Epoch 44/100\n","\u001b[1m295/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8506 - auc: 0.8404 - loss: 0.4271\n","Epoch 44: val_loss did not improve from 0.16126\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8507 - auc: 0.8400 - loss: 0.4273 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1623\n","Epoch 45/100\n","\u001b[1m291/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8550 - auc: 0.8313 - loss: 0.4323\n","Epoch 45: val_loss improved from 0.16126 to 0.16069, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8553 - auc: 0.8311 - loss: 0.4321 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1607\n","Epoch 46/100\n","\u001b[1m291/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8622 - auc: 0.8180 - loss: 0.4353\n","Epoch 46: val_loss improved from 0.16069 to 0.15962, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8622 - auc: 0.8184 - loss: 0.4349 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1596\n","Epoch 47/100\n","\u001b[1m294/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8520 - auc: 0.8331 - loss: 0.4305\n","Epoch 47: val_loss improved from 0.15962 to 0.15842, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8522 - auc: 0.8330 - loss: 0.4304 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1584\n","Epoch 48/100\n","\u001b[1m280/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8668 - auc: 0.8114 - loss: 0.4266\n","Epoch 48: val_loss did not improve from 0.15842\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8665 - auc: 0.8118 - loss: 0.4268 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1585\n","Epoch 49/100\n","\u001b[1m278/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8576 - auc: 0.8296 - loss: 0.4246\n","Epoch 49: val_loss improved from 0.15842 to 0.15689, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8577 - auc: 0.8295 - loss: 0.4246 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1569\n","Epoch 50/100\n","\u001b[1m293/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8523 - auc: 0.8355 - loss: 0.4178\n","Epoch 50: val_loss improved from 0.15689 to 0.15603, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8524 - auc: 0.8354 - loss: 0.4177 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1560\n","Epoch 51/100\n","\u001b[1m290/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8583 - auc: 0.8476 - loss: 0.4068\n","Epoch 51: val_loss improved from 0.15603 to 0.15602, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8584 - auc: 0.8473 - loss: 0.4069 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1560\n","Epoch 52/100\n","\u001b[1m289/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8588 - auc: 0.8365 - loss: 0.4188\n","Epoch 52: val_loss improved from 0.15602 to 0.15488, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8588 - auc: 0.8361 - loss: 0.4189 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1549\n","Epoch 53/100\n","\u001b[1m292/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8801 - auc: 0.8475 - loss: 0.3800\n","Epoch 53: val_loss improved from 0.15488 to 0.15402, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8794 - auc: 0.8474 - loss: 0.3808 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1540\n","Epoch 54/100\n","\u001b[1m297/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8588 - auc: 0.8082 - loss: 0.4270\n","Epoch 54: val_loss improved from 0.15402 to 0.15250, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8588 - auc: 0.8085 - loss: 0.4268 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1525\n","Epoch 55/100\n","\u001b[1m290/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8394 - auc: 0.8409 - loss: 0.4173\n","Epoch 55: val_loss improved from 0.15250 to 0.15244, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8401 - auc: 0.8406 - loss: 0.4168 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1524\n","Epoch 56/100\n","\u001b[1m296/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8624 - auc: 0.8514 - loss: 0.4022\n","Epoch 56: val_loss improved from 0.15244 to 0.15137, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8623 - auc: 0.8511 - loss: 0.4024 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1514\n","Epoch 57/100\n","\u001b[1m294/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8798 - auc: 0.8599 - loss: 0.3736\n","Epoch 57: val_loss did not improve from 0.15137\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8792 - auc: 0.8592 - loss: 0.3747 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1519\n","Epoch 58/100\n","\u001b[1m291/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8402 - auc: 0.8330 - loss: 0.4146\n","Epoch 58: val_loss improved from 0.15137 to 0.14930, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8410 - auc: 0.8335 - loss: 0.4138 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1493\n","Epoch 59/100\n","\u001b[1m294/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8472 - auc: 0.8270 - loss: 0.4162\n","Epoch 59: val_loss did not improve from 0.14930\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8475 - auc: 0.8270 - loss: 0.4159 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1506\n","Epoch 60/100\n","\u001b[1m285/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8611 - auc: 0.8399 - loss: 0.3984\n","Epoch 60: val_loss improved from 0.14930 to 0.14900, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8609 - auc: 0.8404 - loss: 0.3980 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1490\n","Epoch 61/100\n","\u001b[1m297/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8586 - auc: 0.8200 - loss: 0.4080\n","Epoch 61: val_loss improved from 0.14900 to 0.14661, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8587 - auc: 0.8205 - loss: 0.4076 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1466\n","Epoch 62/100\n","\u001b[1m297/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8665 - auc: 0.8600 - loss: 0.3767\n","Epoch 62: val_loss did not improve from 0.14661\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8663 - auc: 0.8596 - loss: 0.3770 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1468\n","Epoch 63/100\n","\u001b[1m283/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8744 - auc: 0.8444 - loss: 0.3835\n","Epoch 63: val_loss did not improve from 0.14661\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8734 - auc: 0.8435 - loss: 0.3848 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1473\n","Epoch 64/100\n","\u001b[1m285/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8600 - auc: 0.8010 - loss: 0.4109\n","Epoch 64: val_loss did not improve from 0.14661\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8601 - auc: 0.8032 - loss: 0.4096 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1467\n","Epoch 65/100\n","\u001b[1m291/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8539 - auc: 0.8124 - loss: 0.4129\n","Epoch 65: val_loss did not improve from 0.14661\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8541 - auc: 0.8132 - loss: 0.4124 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1475\n","Epoch 66/100\n","\u001b[1m279/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8671 - auc: 0.8478 - loss: 0.3828\n","Epoch 66: val_loss improved from 0.14661 to 0.14602, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8665 - auc: 0.8477 - loss: 0.3831 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1460\n","Epoch 67/100\n","\u001b[1m290/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8646 - auc: 0.8453 - loss: 0.3823\n","Epoch 67: val_loss improved from 0.14602 to 0.14559, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8644 - auc: 0.8450 - loss: 0.3827 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1456\n","Epoch 68/100\n","\u001b[1m295/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8588 - auc: 0.8424 - loss: 0.3988\n","Epoch 68: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8588 - auc: 0.8424 - loss: 0.3985 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1457\n","Epoch 69/100\n","\u001b[1m299/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8644 - auc: 0.8471 - loss: 0.3830\n","Epoch 69: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8643 - auc: 0.8470 - loss: 0.3830 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1457\n","Epoch 70/100\n","\u001b[1m293/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8609 - auc: 0.8221 - loss: 0.3992\n","Epoch 70: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8609 - auc: 0.8225 - loss: 0.3990 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1471\n","Epoch 71/100\n","\u001b[1m291/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8717 - auc: 0.8530 - loss: 0.3711\n","Epoch 71: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8713 - auc: 0.8526 - loss: 0.3718 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1480\n","Epoch 72/100\n","\u001b[1m294/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8496 - auc: 0.8399 - loss: 0.3883\n","Epoch 72: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8499 - auc: 0.8399 - loss: 0.3883 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1484\n","Epoch 73/100\n","\u001b[1m290/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8525 - auc: 0.8271 - loss: 0.3983\n","Epoch 73: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8527 - auc: 0.8279 - loss: 0.3976 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1484\n","Epoch 74/100\n","\u001b[1m290/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8580 - auc: 0.8312 - loss: 0.3887\n","Epoch 74: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8582 - auc: 0.8314 - loss: 0.3887 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1476\n","Epoch 75/100\n","\u001b[1m290/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8587 - auc: 0.8267 - loss: 0.3921\n","Epoch 75: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8587 - auc: 0.8273 - loss: 0.3919 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1475\n","Epoch 76/100\n","\u001b[1m297/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8559 - auc: 0.8138 - loss: 0.4053\n","Epoch 76: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8560 - auc: 0.8141 - loss: 0.4051 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1489\n","Epoch 77/100\n","\u001b[1m299/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8474 - auc: 0.8302 - loss: 0.4064\n","Epoch 77: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8476 - auc: 0.8304 - loss: 0.4061 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1469\n","Epoch 78/100\n","\u001b[1m290/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8506 - auc: 0.8346 - loss: 0.3950\n","Epoch 78: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8508 - auc: 0.8349 - loss: 0.3946 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1475\n","Epoch 79/100\n","\u001b[1m296/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8567 - auc: 0.8284 - loss: 0.3964\n","Epoch 79: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8568 - auc: 0.8284 - loss: 0.3962 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1462\n","Epoch 80/100\n","\u001b[1m297/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8594 - auc: 0.8343 - loss: 0.3870\n","Epoch 80: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8594 - auc: 0.8342 - loss: 0.3871 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1488\n","Epoch 81/100\n","\u001b[1m289/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8343 - auc: 0.8173 - loss: 0.4136\n","Epoch 81: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8353 - auc: 0.8181 - loss: 0.4123 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1478\n","Epoch 82/100\n","\u001b[1m287/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8761 - auc: 0.8309 - loss: 0.3753\n","Epoch 82: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8751 - auc: 0.8313 - loss: 0.3758 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1480\n","Epoch 83/100\n","\u001b[1m287/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8503 - auc: 0.8217 - loss: 0.3946\n","Epoch 83: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8506 - auc: 0.8228 - loss: 0.3939 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1461\n","Epoch 84/100\n","\u001b[1m285/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8661 - auc: 0.8569 - loss: 0.3557\n","Epoch 84: val_loss did not improve from 0.14559\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8656 - auc: 0.8555 - loss: 0.3574 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1468\n","Epoch 85/100\n","\u001b[1m295/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8545 - auc: 0.8272 - loss: 0.4002\n","Epoch 85: val_loss improved from 0.14559 to 0.14509, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8546 - auc: 0.8277 - loss: 0.3996 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1451\n","Epoch 86/100\n","\u001b[1m295/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8707 - auc: 0.8192 - loss: 0.3749\n","Epoch 86: val_loss did not improve from 0.14509\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8704 - auc: 0.8197 - loss: 0.3751 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1458\n","Epoch 87/100\n","\u001b[1m295/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8508 - auc: 0.8073 - loss: 0.4079\n","Epoch 87: val_loss did not improve from 0.14509\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8511 - auc: 0.8084 - loss: 0.4071 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1453\n","Epoch 88/100\n","\u001b[1m289/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8554 - auc: 0.8144 - loss: 0.4018\n","Epoch 88: val_loss did not improve from 0.14509\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8556 - auc: 0.8155 - loss: 0.4009 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1460\n","Epoch 89/100\n","\u001b[1m297/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8714 - auc: 0.8587 - loss: 0.3543\n","Epoch 89: val_loss did not improve from 0.14509\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8712 - auc: 0.8586 - loss: 0.3547 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1451\n","Epoch 90/100\n","\u001b[1m296/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8715 - auc: 0.8518 - loss: 0.3615\n","Epoch 90: val_loss did not improve from 0.14509\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8712 - auc: 0.8516 - loss: 0.3619 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1467\n","Epoch 91/100\n","\u001b[1m299/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8515 - auc: 0.8465 - loss: 0.3829\n","Epoch 91: val_loss did not improve from 0.14509\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8516 - auc: 0.8464 - loss: 0.3828 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1454\n","Epoch 92/100\n","\u001b[1m295/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8453 - auc: 0.8062 - loss: 0.4179\n","Epoch 92: val_loss did not improve from 0.14509\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8457 - auc: 0.8071 - loss: 0.4169 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1463\n","Epoch 93/100\n","\u001b[1m296/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8412 - auc: 0.8418 - loss: 0.3943\n","Epoch 93: val_loss improved from 0.14509 to 0.14437, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8417 - auc: 0.8419 - loss: 0.3938 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1444\n","Epoch 94/100\n","\u001b[1m298/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8452 - auc: 0.8406 - loss: 0.3882\n","Epoch 94: val_loss did not improve from 0.14437\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8455 - auc: 0.8407 - loss: 0.3880 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1445\n","Epoch 95/100\n","\u001b[1m296/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8280 - auc: 0.8096 - loss: 0.4287\n","Epoch 95: val_loss improved from 0.14437 to 0.14419, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8287 - auc: 0.8104 - loss: 0.4276 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1442\n","Epoch 96/100\n","\u001b[1m297/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8413 - auc: 0.8463 - loss: 0.3930\n","Epoch 96: val_loss improved from 0.14419 to 0.14402, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8416 - auc: 0.8463 - loss: 0.3927 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1440\n","Epoch 97/100\n","\u001b[1m297/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8490 - auc: 0.8230 - loss: 0.4036\n","Epoch 97: val_loss did not improve from 0.14402\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8492 - auc: 0.8233 - loss: 0.4031 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1443\n","Epoch 98/100\n","\u001b[1m291/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8395 - auc: 0.8078 - loss: 0.4087\n","Epoch 98: val_loss did not improve from 0.14402\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8403 - auc: 0.8099 - loss: 0.4068 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1440\n","Epoch 99/100\n","\u001b[1m288/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8529 - auc: 0.8435 - loss: 0.3741\n","Epoch 99: val_loss improved from 0.14402 to 0.14370, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8530 - auc: 0.8436 - loss: 0.3742 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1437\n","Epoch 100/100\n","\u001b[1m293/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8506 - auc: 0.8337 - loss: 0.3855\n","Epoch 100: val_loss improved from 0.14370 to 0.14194, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8508 - auc: 0.8343 - loss: 0.3851 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.1419\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 1 AUC: 0.0554\n","\n","--- Fold 2/10 ---\n"," train | ids:   35 | files: 1014 | pos:  327 | neg:  687\n","   val | ids:    4 | files:  106 | pos:   38 | neg:   68\n","  test | ids:    5 | files:   80 | pos:   40 | neg:   40\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m314/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3659 - auc: 0.4312 - loss: 0.7666\n","Epoch 1: val_loss improved from inf to 0.72839, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - acc: 0.3657 - auc: 0.4317 - loss: 0.7658 - val_acc: 0.3585 - val_auc: 0.0147 - val_loss: 0.7284\n","Epoch 2/100\n","\u001b[1m318/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3833 - auc: 0.4411 - loss: 0.7145\n","Epoch 2: val_loss improved from 0.72839 to 0.69952, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.3870 - auc: 0.4434 - loss: 0.7138 - val_acc: 0.2736 - val_auc: 0.0147 - val_loss: 0.6995\n","Epoch 3/100\n","\u001b[1m314/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6594 - auc: 0.6112 - loss: 0.6758\n","Epoch 3: val_loss improved from 0.69952 to 0.68411, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6599 - auc: 0.6114 - loss: 0.6753 - val_acc: 0.6415 - val_auc: 0.0000e+00 - val_loss: 0.6841\n","Epoch 4/100\n","\u001b[1m318/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6558 - auc: 0.6650 - loss: 0.6449\n","Epoch 4: val_loss improved from 0.68411 to 0.67464, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6556 - auc: 0.6627 - loss: 0.6451 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.6746\n","Epoch 5/100\n","\u001b[1m314/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6585 - auc: 0.6617 - loss: 0.6367\n","Epoch 5: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6589 - auc: 0.6605 - loss: 0.6365 - val_acc: 0.6415 - val_auc: 0.2059 - val_loss: 0.6749\n","Epoch 6/100\n","\u001b[1m320/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6618 - auc: 0.6930 - loss: 0.6205\n","Epoch 6: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6622 - auc: 0.6919 - loss: 0.6205 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.6787\n","Epoch 7/100\n","\u001b[1m315/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6670 - auc: 0.6364 - loss: 0.6242\n","Epoch 7: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6678 - auc: 0.6387 - loss: 0.6234 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.6848\n","Epoch 8/100\n","\u001b[1m334/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6928 - auc: 0.6746 - loss: 0.6017\n","Epoch 8: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6925 - auc: 0.6745 - loss: 0.6018 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.6903\n","Epoch 9/100\n","\u001b[1m333/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6768 - auc: 0.7362 - loss: 0.5955\n","Epoch 9: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6769 - auc: 0.7354 - loss: 0.5956 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.6968\n","Epoch 10/100\n","\u001b[1m329/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6819 - auc: 0.7086 - loss: 0.5954\n","Epoch 10: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6819 - auc: 0.7081 - loss: 0.5955 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7033\n","Epoch 11/100\n","\u001b[1m316/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6771 - auc: 0.6945 - loss: 0.5972\n","Epoch 11: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6771 - auc: 0.6947 - loss: 0.5972 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7098\n","Epoch 12/100\n","\u001b[1m318/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6889 - auc: 0.7384 - loss: 0.5793\n","Epoch 12: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6884 - auc: 0.7366 - loss: 0.5800 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7162\n","Epoch 13/100\n","\u001b[1m318/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6894 - auc: 0.7086 - loss: 0.5895\n","Epoch 13: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6893 - auc: 0.7085 - loss: 0.5896 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7230\n","Epoch 14/100\n","\u001b[1m318/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6805 - auc: 0.7045 - loss: 0.5923\n","Epoch 14: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6810 - auc: 0.7045 - loss: 0.5919 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7286\n","Epoch 15/100\n","\u001b[1m325/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7003 - auc: 0.6972 - loss: 0.5769\n","Epoch 15: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7000 - auc: 0.6970 - loss: 0.5773 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7333\n","Epoch 16/100\n","\u001b[1m324/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6869 - auc: 0.7265 - loss: 0.5866\n","Epoch 16: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6881 - auc: 0.7251 - loss: 0.5867 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7369\n","Epoch 17/100\n","\u001b[1m317/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7540 - auc: 0.7138 - loss: 0.5709\n","Epoch 17: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7531 - auc: 0.7128 - loss: 0.5718 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7420\n","Epoch 18/100\n","\u001b[1m319/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7371 - auc: 0.7042 - loss: 0.5990\n","Epoch 18: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7387 - auc: 0.7043 - loss: 0.5979 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7470\n","Epoch 19/100\n","\u001b[1m319/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7810 - auc: 0.7236 - loss: 0.5694\n","Epoch 19: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7806 - auc: 0.7223 - loss: 0.5699 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7510\n","Epoch 20/100\n","\u001b[1m324/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7954 - auc: 0.7178 - loss: 0.5586\n","Epoch 20: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7946 - auc: 0.7173 - loss: 0.5592 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7546\n","Epoch 21/100\n","\u001b[1m317/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7927 - auc: 0.7357 - loss: 0.5547\n","Epoch 21: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7922 - auc: 0.7335 - loss: 0.5555 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7585\n","Epoch 22/100\n","\u001b[1m322/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7914 - auc: 0.6988 - loss: 0.5563\n","Epoch 22: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7912 - auc: 0.6996 - loss: 0.5566 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7626\n","Epoch 23/100\n","\u001b[1m318/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7997 - auc: 0.7152 - loss: 0.5448\n","Epoch 23: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7989 - auc: 0.7147 - loss: 0.5458 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7649\n","Epoch 24/100\n","\u001b[1m316/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8046 - auc: 0.7007 - loss: 0.5628\n","Epoch 24: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8041 - auc: 0.7002 - loss: 0.5628 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7660\n","Epoch 25/100\n","\u001b[1m328/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7921 - auc: 0.7056 - loss: 0.5546\n","Epoch 25: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7922 - auc: 0.7055 - loss: 0.5547 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7660\n","Epoch 26/100\n","\u001b[1m315/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7886 - auc: 0.6665 - loss: 0.5647\n","Epoch 26: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7896 - auc: 0.6691 - loss: 0.5637 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7662\n","Epoch 27/100\n","\u001b[1m324/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8111 - auc: 0.6974 - loss: 0.5567\n","Epoch 27: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8112 - auc: 0.6970 - loss: 0.5566 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7621\n","Epoch 28/100\n","\u001b[1m320/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8055 - auc: 0.6914 - loss: 0.5517\n","Epoch 28: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8055 - auc: 0.6920 - loss: 0.5515 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7622\n","Epoch 29/100\n","\u001b[1m314/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7941 - auc: 0.7236 - loss: 0.5317\n","Epoch 29: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7944 - auc: 0.7228 - loss: 0.5318 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7650\n","Epoch 30/100\n","\u001b[1m313/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8220 - auc: 0.7597 - loss: 0.5161\n","Epoch 30: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8207 - auc: 0.7550 - loss: 0.5180 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7618\n","Epoch 31/100\n","\u001b[1m312/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7862 - auc: 0.7191 - loss: 0.5415\n","Epoch 31: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7875 - auc: 0.7185 - loss: 0.5411 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7603\n","Epoch 32/100\n","\u001b[1m321/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8343 - auc: 0.7229 - loss: 0.5148\n","Epoch 32: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8331 - auc: 0.7213 - loss: 0.5162 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7573\n","Epoch 33/100\n","\u001b[1m321/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8185 - auc: 0.7252 - loss: 0.5139\n","Epoch 33: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8179 - auc: 0.7244 - loss: 0.5147 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7551\n","Epoch 34/100\n","\u001b[1m323/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8249 - auc: 0.7322 - loss: 0.5041\n","Epoch 34: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8246 - auc: 0.7309 - loss: 0.5049 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7532\n","Epoch 35/100\n","\u001b[1m322/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8221 - auc: 0.7457 - loss: 0.4978\n","Epoch 35: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8220 - auc: 0.7443 - loss: 0.4987 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7529\n","Epoch 36/100\n","\u001b[1m320/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8238 - auc: 0.7069 - loss: 0.5158\n","Epoch 36: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8238 - auc: 0.7076 - loss: 0.5155 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7536\n","Epoch 37/100\n","\u001b[1m320/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8059 - auc: 0.7123 - loss: 0.5322\n","Epoch 37: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8066 - auc: 0.7119 - loss: 0.5316 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7538\n","Epoch 38/100\n","\u001b[1m318/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8109 - auc: 0.7232 - loss: 0.5184\n","Epoch 38: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8111 - auc: 0.7223 - loss: 0.5185 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7524\n","Epoch 39/100\n","\u001b[1m335/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8133 - auc: 0.6981 - loss: 0.5299\n","Epoch 39: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8134 - auc: 0.6982 - loss: 0.5297 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7556\n","Epoch 40/100\n","\u001b[1m315/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8364 - auc: 0.7477 - loss: 0.4895\n","Epoch 40: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8356 - auc: 0.7451 - loss: 0.4908 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7532\n","Epoch 41/100\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8399 - auc: 0.7086 - loss: 0.4969\n","Epoch 41: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8399 - auc: 0.7086 - loss: 0.4970 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7512\n","Epoch 42/100\n","\u001b[1m315/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8054 - auc: 0.7090 - loss: 0.5195\n","Epoch 42: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8066 - auc: 0.7100 - loss: 0.5183 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7532\n","Epoch 43/100\n","\u001b[1m323/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8237 - auc: 0.7045 - loss: 0.5003\n","Epoch 43: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8238 - auc: 0.7055 - loss: 0.4999 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7540\n","Epoch 44/100\n","\u001b[1m319/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8284 - auc: 0.7068 - loss: 0.5028\n","Epoch 44: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8281 - auc: 0.7062 - loss: 0.5031 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7529\n","Epoch 45/100\n","\u001b[1m321/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8486 - auc: 0.7275 - loss: 0.4756\n","Epoch 45: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8475 - auc: 0.7266 - loss: 0.4771 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7521\n","Epoch 46/100\n","\u001b[1m314/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8209 - auc: 0.6965 - loss: 0.5096\n","Epoch 46: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8208 - auc: 0.6973 - loss: 0.5091 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7542\n","Epoch 47/100\n","\u001b[1m318/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8251 - auc: 0.6654 - loss: 0.5003\n","Epoch 47: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8250 - auc: 0.6668 - loss: 0.5006 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7511\n","Epoch 48/100\n","\u001b[1m316/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8187 - auc: 0.7030 - loss: 0.4950\n","Epoch 48: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8190 - auc: 0.7035 - loss: 0.4947 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7540\n","Epoch 49/100\n","\u001b[1m320/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8136 - auc: 0.6732 - loss: 0.5172\n","Epoch 49: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8141 - auc: 0.6753 - loss: 0.5157 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7557\n","Epoch 50/100\n","\u001b[1m320/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8257 - auc: 0.6942 - loss: 0.4931\n","Epoch 50: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8259 - auc: 0.6951 - loss: 0.4927 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7551\n","Epoch 51/100\n","\u001b[1m322/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8288 - auc: 0.6906 - loss: 0.4966\n","Epoch 51: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8288 - auc: 0.6915 - loss: 0.4963 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7539\n","Epoch 52/100\n","\u001b[1m322/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8281 - auc: 0.7362 - loss: 0.4748\n","Epoch 52: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8280 - auc: 0.7352 - loss: 0.4752 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7533\n","Epoch 53/100\n","\u001b[1m317/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8253 - auc: 0.7175 - loss: 0.4813\n","Epoch 53: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8254 - auc: 0.7164 - loss: 0.4817 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7535\n","Epoch 54/100\n","\u001b[1m334/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8378 - auc: 0.7296 - loss: 0.4540\n","Epoch 54: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8376 - auc: 0.7293 - loss: 0.4543 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7518\n","Epoch 55/100\n","\u001b[1m316/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8406 - auc: 0.7268 - loss: 0.4646\n","Epoch 55: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8397 - auc: 0.7256 - loss: 0.4657 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7511\n","Epoch 56/100\n","\u001b[1m327/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8495 - auc: 0.7345 - loss: 0.4411\n","Epoch 56: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8487 - auc: 0.7342 - loss: 0.4421 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7492\n","Epoch 57/100\n","\u001b[1m319/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8212 - auc: 0.7241 - loss: 0.4804\n","Epoch 57: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8217 - auc: 0.7239 - loss: 0.4800 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7491\n","Epoch 58/100\n","\u001b[1m323/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8198 - auc: 0.7144 - loss: 0.4811\n","Epoch 58: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8201 - auc: 0.7152 - loss: 0.4807 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7509\n","Epoch 59/100\n","\u001b[1m318/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8284 - auc: 0.7223 - loss: 0.4696\n","Epoch 59: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8282 - auc: 0.7224 - loss: 0.4696 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7525\n","Epoch 60/100\n","\u001b[1m319/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8161 - auc: 0.7229 - loss: 0.4820\n","Epoch 60: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8166 - auc: 0.7230 - loss: 0.4813 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7487\n","Epoch 61/100\n","\u001b[1m324/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8335 - auc: 0.7505 - loss: 0.4529\n","Epoch 61: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8332 - auc: 0.7497 - loss: 0.4535 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7520\n","Epoch 62/100\n","\u001b[1m319/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8159 - auc: 0.6840 - loss: 0.4880\n","Epoch 62: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8164 - auc: 0.6865 - loss: 0.4867 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7514\n","Epoch 63/100\n","\u001b[1m319/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8241 - auc: 0.7310 - loss: 0.4655\n","Epoch 63: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8243 - auc: 0.7314 - loss: 0.4652 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7527\n","Epoch 64/100\n","\u001b[1m320/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8286 - auc: 0.7206 - loss: 0.4654\n","Epoch 64: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8288 - auc: 0.7207 - loss: 0.4652 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7484\n","Epoch 65/100\n","\u001b[1m321/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8301 - auc: 0.7106 - loss: 0.4664\n","Epoch 65: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8301 - auc: 0.7132 - loss: 0.4654 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7549\n","Epoch 66/100\n","\u001b[1m321/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8155 - auc: 0.7458 - loss: 0.4625\n","Epoch 66: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8160 - auc: 0.7448 - loss: 0.4624 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7538\n","Epoch 67/100\n","\u001b[1m315/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8360 - auc: 0.7549 - loss: 0.4449\n","Epoch 67: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8355 - auc: 0.7525 - loss: 0.4461 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7496\n","Epoch 68/100\n","\u001b[1m322/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8189 - auc: 0.7031 - loss: 0.4761\n","Epoch 68: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8192 - auc: 0.7049 - loss: 0.4751 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7485\n","Epoch 69/100\n","\u001b[1m313/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8150 - auc: 0.7644 - loss: 0.4562\n","Epoch 69: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8157 - auc: 0.7631 - loss: 0.4560 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7522\n","Epoch 70/100\n","\u001b[1m335/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8134 - auc: 0.7344 - loss: 0.4681\n","Epoch 70: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8135 - auc: 0.7346 - loss: 0.4679 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7542\n","Epoch 71/100\n","\u001b[1m321/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8393 - auc: 0.7292 - loss: 0.4411\n","Epoch 71: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8388 - auc: 0.7292 - loss: 0.4417 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7481\n","Epoch 72/100\n","\u001b[1m313/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8291 - auc: 0.7665 - loss: 0.4391\n","Epoch 72: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8286 - auc: 0.7651 - loss: 0.4401 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7477\n","Epoch 73/100\n","\u001b[1m318/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8256 - auc: 0.7129 - loss: 0.4605\n","Epoch 73: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8257 - auc: 0.7136 - loss: 0.4603 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7485\n","Epoch 74/100\n","\u001b[1m320/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8341 - auc: 0.7191 - loss: 0.4497\n","Epoch 74: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8337 - auc: 0.7201 - loss: 0.4498 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7486\n","Epoch 75/100\n","\u001b[1m321/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8181 - auc: 0.7871 - loss: 0.4401\n","Epoch 75: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8186 - auc: 0.7863 - loss: 0.4400 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7512\n","Epoch 76/100\n","\u001b[1m323/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8214 - auc: 0.7218 - loss: 0.4698\n","Epoch 76: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8215 - auc: 0.7215 - loss: 0.4696 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7490\n","Epoch 77/100\n","\u001b[1m318/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8243 - auc: 0.7665 - loss: 0.4393\n","Epoch 77: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8249 - auc: 0.7667 - loss: 0.4387 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7482\n","Epoch 78/100\n","\u001b[1m317/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8214 - auc: 0.7795 - loss: 0.4407\n","Epoch 78: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8215 - auc: 0.7781 - loss: 0.4411 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7479\n","Epoch 79/100\n","\u001b[1m332/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8234 - auc: 0.7148 - loss: 0.4596\n","Epoch 79: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8234 - auc: 0.7152 - loss: 0.4594 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7455\n","Epoch 80/100\n","\u001b[1m335/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8090 - auc: 0.7226 - loss: 0.4742\n","Epoch 80: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8091 - auc: 0.7229 - loss: 0.4739 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7434\n","Epoch 81/100\n","\u001b[1m335/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8233 - auc: 0.7583 - loss: 0.4439\n","Epoch 81: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8234 - auc: 0.7581 - loss: 0.4440 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7457\n","Epoch 82/100\n","\u001b[1m336/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8265 - auc: 0.7911 - loss: 0.4240\n","Epoch 82: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8265 - auc: 0.7911 - loss: 0.4240 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7496\n","Epoch 83/100\n","\u001b[1m335/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8441 - auc: 0.7494 - loss: 0.4265\n","Epoch 83: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8439 - auc: 0.7491 - loss: 0.4268 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7468\n","Epoch 84/100\n","\u001b[1m327/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8044 - auc: 0.7447 - loss: 0.4654\n","Epoch 84: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8052 - auc: 0.7448 - loss: 0.4646 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7454\n","Epoch 85/100\n","\u001b[1m329/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8303 - auc: 0.6930 - loss: 0.4532\n","Epoch 85: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8301 - auc: 0.6942 - loss: 0.4530 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7428\n","Epoch 86/100\n","\u001b[1m317/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8218 - auc: 0.7162 - loss: 0.4570\n","Epoch 86: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8224 - auc: 0.7168 - loss: 0.4563 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7428\n","Epoch 87/100\n","\u001b[1m330/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8317 - auc: 0.7544 - loss: 0.4297\n","Epoch 87: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8315 - auc: 0.7543 - loss: 0.4300 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7401\n","Epoch 88/100\n","\u001b[1m331/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8377 - auc: 0.7656 - loss: 0.4267\n","Epoch 88: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8375 - auc: 0.7652 - loss: 0.4270 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7436\n","Epoch 89/100\n","\u001b[1m333/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8364 - auc: 0.7444 - loss: 0.4371\n","Epoch 89: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8362 - auc: 0.7443 - loss: 0.4373 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7414\n","Epoch 90/100\n","\u001b[1m333/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8041 - auc: 0.7458 - loss: 0.4648\n","Epoch 90: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8045 - auc: 0.7461 - loss: 0.4643 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7397\n","Epoch 91/100\n","\u001b[1m337/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8324 - auc: 0.7652 - loss: 0.4267\n","Epoch 91: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8323 - auc: 0.7652 - loss: 0.4268 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7419\n","Epoch 92/100\n","\u001b[1m316/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8186 - auc: 0.7425 - loss: 0.4514\n","Epoch 92: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8192 - auc: 0.7423 - loss: 0.4509 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7401\n","Epoch 93/100\n","\u001b[1m314/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8145 - auc: 0.7136 - loss: 0.4651\n","Epoch 93: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8157 - auc: 0.7170 - loss: 0.4629 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7388\n","Epoch 94/100\n","\u001b[1m318/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8263 - auc: 0.7947 - loss: 0.4259\n","Epoch 94: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8265 - auc: 0.7928 - loss: 0.4264 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7423\n","Epoch 95/100\n","\u001b[1m315/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8128 - auc: 0.7636 - loss: 0.4430\n","Epoch 95: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8138 - auc: 0.7628 - loss: 0.4424 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7393\n","Epoch 96/100\n","\u001b[1m315/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8277 - auc: 0.7555 - loss: 0.4362\n","Epoch 96: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8278 - auc: 0.7550 - loss: 0.4362 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7413\n","Epoch 97/100\n","\u001b[1m314/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8315 - auc: 0.7746 - loss: 0.4241\n","Epoch 97: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8313 - auc: 0.7729 - loss: 0.4251 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7370\n","Epoch 98/100\n","\u001b[1m318/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8295 - auc: 0.7562 - loss: 0.4332\n","Epoch 98: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8293 - auc: 0.7559 - loss: 0.4335 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7365\n","Epoch 99/100\n","\u001b[1m334/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8431 - auc: 0.7501 - loss: 0.4174\n","Epoch 99: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8429 - auc: 0.7504 - loss: 0.4176 - val_acc: 0.6415 - val_auc: 0.4118 - val_loss: 0.7366\n","Epoch 100/100\n","\u001b[1m315/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8419 - auc: 0.7720 - loss: 0.4153\n","Epoch 100: val_loss did not improve from 0.67464\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8409 - auc: 0.7701 - loss: 0.4173 - val_acc: 0.6415 - val_auc: 0.2059 - val_loss: 0.7330\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 2 AUC: 0.9100\n","\n","--- Fold 3/10 ---\n"," train | ids:   35 | files:  978 | pos:  323 | neg:  655\n","   val | ids:    4 | files:   53 | pos:    1 | neg:   52\n","  test | ids:    5 | files:  169 | pos:   81 | neg:   88\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3027 - auc: 0.3500 - loss: 0.7485\n","Epoch 1: val_loss improved from inf to 0.67974, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - acc: 0.3039 - auc: 0.3510 - loss: 0.7481 - val_acc: 0.5660 - val_auc: 0.7788 - val_loss: 0.6797\n","Epoch 2/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5718 - auc: 0.5570 - loss: 0.6831\n","Epoch 2: val_loss improved from 0.67974 to 0.59413, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.5720 - auc: 0.5578 - loss: 0.6828 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.5941\n","Epoch 3/100\n","\u001b[1m321/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5802 - auc: 0.5966 - loss: 0.6549\n","Epoch 3: val_loss improved from 0.59413 to 0.54495, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.5807 - auc: 0.5972 - loss: 0.6546 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.5449\n","Epoch 4/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6633 - auc: 0.6353 - loss: 0.6183\n","Epoch 4: val_loss improved from 0.54495 to 0.51201, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6633 - auc: 0.6357 - loss: 0.6183 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.5120\n","Epoch 5/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6768 - auc: 0.6100 - loss: 0.6178\n","Epoch 5: val_loss improved from 0.51201 to 0.48805, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6771 - auc: 0.6111 - loss: 0.6178 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.4880\n","Epoch 6/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7766 - auc: 0.6548 - loss: 0.6176\n","Epoch 6: val_loss improved from 0.48805 to 0.46840, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7770 - auc: 0.6550 - loss: 0.6175 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.4684\n","Epoch 7/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8016 - auc: 0.6387 - loss: 0.6062\n","Epoch 7: val_loss improved from 0.46840 to 0.45653, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8019 - auc: 0.6393 - loss: 0.6061 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.4565\n","Epoch 8/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7778 - auc: 0.6587 - loss: 0.6123\n","Epoch 8: val_loss improved from 0.45653 to 0.44485, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7785 - auc: 0.6592 - loss: 0.6120 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.4448\n","Epoch 9/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8176 - auc: 0.6914 - loss: 0.5863\n","Epoch 9: val_loss improved from 0.44485 to 0.43376, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8173 - auc: 0.6912 - loss: 0.5864 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.4338\n","Epoch 10/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7932 - auc: 0.6373 - loss: 0.6033\n","Epoch 10: val_loss improved from 0.43376 to 0.42599, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7937 - auc: 0.6383 - loss: 0.6029 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.4260\n","Epoch 11/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8381 - auc: 0.7301 - loss: 0.5691\n","Epoch 11: val_loss improved from 0.42599 to 0.41784, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8373 - auc: 0.7283 - loss: 0.5699 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.4178\n","Epoch 12/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8261 - auc: 0.6829 - loss: 0.5831\n","Epoch 12: val_loss improved from 0.41784 to 0.41494, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8258 - auc: 0.6814 - loss: 0.5833 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.4149\n","Epoch 13/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7903 - auc: 0.6401 - loss: 0.5988\n","Epoch 13: val_loss improved from 0.41494 to 0.40682, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7911 - auc: 0.6416 - loss: 0.5979 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.4068\n","Epoch 14/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8167 - auc: 0.6839 - loss: 0.5728\n","Epoch 14: val_loss improved from 0.40682 to 0.39963, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8167 - auc: 0.6841 - loss: 0.5727 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3996\n","Epoch 15/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8125 - auc: 0.6659 - loss: 0.5700\n","Epoch 15: val_loss improved from 0.39963 to 0.39532, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8126 - auc: 0.6663 - loss: 0.5700 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3953\n","Epoch 16/100\n","\u001b[1m323/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8079 - auc: 0.6968 - loss: 0.5576\n","Epoch 16: val_loss improved from 0.39532 to 0.38955, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8080 - auc: 0.6967 - loss: 0.5577 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3896\n","Epoch 17/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8173 - auc: 0.6744 - loss: 0.5656\n","Epoch 17: val_loss improved from 0.38955 to 0.38462, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8174 - auc: 0.6748 - loss: 0.5654 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.3846\n","Epoch 18/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8075 - auc: 0.7042 - loss: 0.5593\n","Epoch 18: val_loss improved from 0.38462 to 0.38004, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8078 - auc: 0.7039 - loss: 0.5593 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3800\n","Epoch 19/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8235 - auc: 0.7230 - loss: 0.5382\n","Epoch 19: val_loss did not improve from 0.38004\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8226 - auc: 0.7207 - loss: 0.5393 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3803\n","Epoch 20/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8306 - auc: 0.6889 - loss: 0.5512\n","Epoch 20: val_loss improved from 0.38004 to 0.37767, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8301 - auc: 0.6883 - loss: 0.5516 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3777\n","Epoch 21/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8021 - auc: 0.6779 - loss: 0.5659\n","Epoch 21: val_loss improved from 0.37767 to 0.37700, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8024 - auc: 0.6778 - loss: 0.5658 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3770\n","Epoch 22/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8343 - auc: 0.7223 - loss: 0.5480\n","Epoch 22: val_loss improved from 0.37700 to 0.37240, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8342 - auc: 0.7211 - loss: 0.5479 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.3724\n","Epoch 23/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7959 - auc: 0.6937 - loss: 0.5607\n","Epoch 23: val_loss improved from 0.37240 to 0.37004, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7964 - auc: 0.6931 - loss: 0.5604 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3700\n","Epoch 24/100\n","\u001b[1m321/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8170 - auc: 0.6940 - loss: 0.5428\n","Epoch 24: val_loss improved from 0.37004 to 0.36762, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8170 - auc: 0.6938 - loss: 0.5429 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3676\n","Epoch 25/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8186 - auc: 0.6668 - loss: 0.5648\n","Epoch 25: val_loss did not improve from 0.36762\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8186 - auc: 0.6672 - loss: 0.5644 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.3685\n","Epoch 26/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8223 - auc: 0.6990 - loss: 0.5340\n","Epoch 26: val_loss improved from 0.36762 to 0.36660, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8225 - auc: 0.6983 - loss: 0.5341 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3666\n","Epoch 27/100\n","\u001b[1m305/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8493 - auc: 0.7148 - loss: 0.5206\n","Epoch 27: val_loss improved from 0.36660 to 0.36491, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8481 - auc: 0.7134 - loss: 0.5218 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3649\n","Epoch 28/100\n","\u001b[1m310/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8218 - auc: 0.6899 - loss: 0.5474\n","Epoch 28: val_loss improved from 0.36491 to 0.36436, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8219 - auc: 0.6890 - loss: 0.5473 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.3644\n","Epoch 29/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8333 - auc: 0.7193 - loss: 0.5191\n","Epoch 29: val_loss improved from 0.36436 to 0.36332, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8331 - auc: 0.7178 - loss: 0.5199 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3633\n","Epoch 30/100\n","\u001b[1m314/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8386 - auc: 0.7039 - loss: 0.5239\n","Epoch 30: val_loss improved from 0.36332 to 0.36071, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8383 - auc: 0.7027 - loss: 0.5243 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3607\n","Epoch 31/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8392 - auc: 0.6796 - loss: 0.5234\n","Epoch 31: val_loss did not improve from 0.36071\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8385 - auc: 0.6795 - loss: 0.5239 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3616\n","Epoch 32/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8247 - auc: 0.6811 - loss: 0.5426\n","Epoch 32: val_loss improved from 0.36071 to 0.35978, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8251 - auc: 0.6815 - loss: 0.5422 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3598\n","Epoch 33/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8229 - auc: 0.7305 - loss: 0.5186\n","Epoch 33: val_loss improved from 0.35978 to 0.35848, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8229 - auc: 0.7293 - loss: 0.5189 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3585\n","Epoch 34/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8059 - auc: 0.7134 - loss: 0.5235\n","Epoch 34: val_loss improved from 0.35848 to 0.35704, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8063 - auc: 0.7131 - loss: 0.5233 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3570\n","Epoch 35/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8379 - auc: 0.7285 - loss: 0.5016\n","Epoch 35: val_loss improved from 0.35704 to 0.35252, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8379 - auc: 0.7283 - loss: 0.5017 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3525\n","Epoch 36/100\n","\u001b[1m322/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8287 - auc: 0.6528 - loss: 0.5264\n","Epoch 36: val_loss did not improve from 0.35252\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8287 - auc: 0.6534 - loss: 0.5264 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3537\n","Epoch 37/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8343 - auc: 0.6946 - loss: 0.5164\n","Epoch 37: val_loss did not improve from 0.35252\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8342 - auc: 0.6936 - loss: 0.5168 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3573\n","Epoch 38/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8263 - auc: 0.6718 - loss: 0.5112\n","Epoch 38: val_loss did not improve from 0.35252\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8261 - auc: 0.6730 - loss: 0.5111 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.3546\n","Epoch 39/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8335 - auc: 0.7196 - loss: 0.5045\n","Epoch 39: val_loss did not improve from 0.35252\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8333 - auc: 0.7190 - loss: 0.5047 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3529\n","Epoch 40/100\n","\u001b[1m322/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8439 - auc: 0.7514 - loss: 0.4862\n","Epoch 40: val_loss improved from 0.35252 to 0.34846, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8439 - auc: 0.7513 - loss: 0.4863 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.3485\n","Epoch 41/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8120 - auc: 0.6928 - loss: 0.5129\n","Epoch 41: val_loss improved from 0.34846 to 0.34748, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8125 - auc: 0.6936 - loss: 0.5124 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3475\n","Epoch 42/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8282 - auc: 0.7350 - loss: 0.4920\n","Epoch 42: val_loss improved from 0.34748 to 0.34585, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8285 - auc: 0.7348 - loss: 0.4918 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3458\n","Epoch 43/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8421 - auc: 0.7545 - loss: 0.4721\n","Epoch 43: val_loss improved from 0.34585 to 0.34416, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8420 - auc: 0.7528 - loss: 0.4731 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3442\n","Epoch 44/100\n","\u001b[1m310/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8321 - auc: 0.7127 - loss: 0.4992\n","Epoch 44: val_loss did not improve from 0.34416\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8321 - auc: 0.7131 - loss: 0.4991 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3447\n","Epoch 45/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8361 - auc: 0.7022 - loss: 0.4944\n","Epoch 45: val_loss improved from 0.34416 to 0.33974, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8363 - auc: 0.7028 - loss: 0.4941 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.3397\n","Epoch 46/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8557 - auc: 0.6777 - loss: 0.4934\n","Epoch 46: val_loss did not improve from 0.33974\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8553 - auc: 0.6791 - loss: 0.4933 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3420\n","Epoch 47/100\n","\u001b[1m323/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8517 - auc: 0.7051 - loss: 0.4871\n","Epoch 47: val_loss improved from 0.33974 to 0.33899, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8518 - auc: 0.7054 - loss: 0.4870 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3390\n","Epoch 48/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8458 - auc: 0.7336 - loss: 0.4797\n","Epoch 48: val_loss improved from 0.33899 to 0.33484, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8460 - auc: 0.7338 - loss: 0.4796 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.3348\n","Epoch 49/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8525 - auc: 0.7329 - loss: 0.4728\n","Epoch 49: val_loss did not improve from 0.33484\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8523 - auc: 0.7330 - loss: 0.4728 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3376\n","Epoch 50/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8283 - auc: 0.7137 - loss: 0.4903\n","Epoch 50: val_loss did not improve from 0.33484\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8285 - auc: 0.7143 - loss: 0.4901 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3351\n","Epoch 51/100\n","\u001b[1m322/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8566 - auc: 0.7610 - loss: 0.4642\n","Epoch 51: val_loss improved from 0.33484 to 0.33216, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8565 - auc: 0.7609 - loss: 0.4642 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.3322\n","Epoch 52/100\n","\u001b[1m322/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8261 - auc: 0.7237 - loss: 0.4841\n","Epoch 52: val_loss did not improve from 0.33216\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8263 - auc: 0.7239 - loss: 0.4839 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3331\n","Epoch 53/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8516 - auc: 0.7232 - loss: 0.4699\n","Epoch 53: val_loss did not improve from 0.33216\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8515 - auc: 0.7236 - loss: 0.4699 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3323\n","Epoch 54/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8449 - auc: 0.7720 - loss: 0.4560\n","Epoch 54: val_loss improved from 0.33216 to 0.32839, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8449 - auc: 0.7716 - loss: 0.4562 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.3284\n","Epoch 55/100\n","\u001b[1m321/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8463 - auc: 0.7828 - loss: 0.4494\n","Epoch 55: val_loss improved from 0.32839 to 0.32359, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8463 - auc: 0.7825 - loss: 0.4496 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3236\n","Epoch 56/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8439 - auc: 0.7668 - loss: 0.4494\n","Epoch 56: val_loss did not improve from 0.32359\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8434 - auc: 0.7658 - loss: 0.4500 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3269\n","Epoch 57/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8453 - auc: 0.7692 - loss: 0.4509\n","Epoch 57: val_loss did not improve from 0.32359\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8446 - auc: 0.7679 - loss: 0.4519 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.3267\n","Epoch 58/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8530 - auc: 0.7471 - loss: 0.4570\n","Epoch 58: val_loss improved from 0.32359 to 0.32293, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8525 - auc: 0.7479 - loss: 0.4570 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3229\n","Epoch 59/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8295 - auc: 0.7600 - loss: 0.4619\n","Epoch 59: val_loss did not improve from 0.32293\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8295 - auc: 0.7599 - loss: 0.4620 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3244\n","Epoch 60/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8529 - auc: 0.7602 - loss: 0.4512\n","Epoch 60: val_loss improved from 0.32293 to 0.32125, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8517 - auc: 0.7600 - loss: 0.4519 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.3212\n","Epoch 61/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8275 - auc: 0.7742 - loss: 0.4691\n","Epoch 61: val_loss improved from 0.32125 to 0.31565, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8278 - auc: 0.7742 - loss: 0.4688 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3156\n","Epoch 62/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8631 - auc: 0.7451 - loss: 0.4510\n","Epoch 62: val_loss did not improve from 0.31565\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8625 - auc: 0.7457 - loss: 0.4511 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3170\n","Epoch 63/100\n","\u001b[1m314/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8329 - auc: 0.7531 - loss: 0.4666\n","Epoch 63: val_loss did not improve from 0.31565\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8330 - auc: 0.7531 - loss: 0.4664 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.3162\n","Epoch 64/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8306 - auc: 0.7404 - loss: 0.4681\n","Epoch 64: val_loss improved from 0.31565 to 0.31524, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8307 - auc: 0.7411 - loss: 0.4679 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3152\n","Epoch 65/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8359 - auc: 0.7735 - loss: 0.4458\n","Epoch 65: val_loss did not improve from 0.31524\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8363 - auc: 0.7737 - loss: 0.4457 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3162\n","Epoch 66/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8375 - auc: 0.7718 - loss: 0.4526\n","Epoch 66: val_loss improved from 0.31524 to 0.31447, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8377 - auc: 0.7718 - loss: 0.4524 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.3145\n","Epoch 67/100\n","\u001b[1m321/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8595 - auc: 0.8160 - loss: 0.4196\n","Epoch 67: val_loss improved from 0.31447 to 0.30685, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8594 - auc: 0.8159 - loss: 0.4197 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3068\n","Epoch 68/100\n","\u001b[1m324/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8371 - auc: 0.7491 - loss: 0.4508\n","Epoch 68: val_loss improved from 0.30685 to 0.30549, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8371 - auc: 0.7494 - loss: 0.4507 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3055\n","Epoch 69/100\n","\u001b[1m321/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8456 - auc: 0.7748 - loss: 0.4407\n","Epoch 69: val_loss did not improve from 0.30549\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8454 - auc: 0.7745 - loss: 0.4410 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3072\n","Epoch 70/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8344 - auc: 0.7920 - loss: 0.4449\n","Epoch 70: val_loss did not improve from 0.30549\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8345 - auc: 0.7917 - loss: 0.4449 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.3068\n","Epoch 71/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8387 - auc: 0.7618 - loss: 0.4462\n","Epoch 71: val_loss did not improve from 0.30549\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8385 - auc: 0.7621 - loss: 0.4463 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3086\n","Epoch 72/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8325 - auc: 0.8078 - loss: 0.4450\n","Epoch 72: val_loss did not improve from 0.30549\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8328 - auc: 0.8076 - loss: 0.4448 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3061\n","Epoch 73/100\n","\u001b[1m314/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8239 - auc: 0.7635 - loss: 0.4636\n","Epoch 73: val_loss improved from 0.30549 to 0.30286, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8245 - auc: 0.7648 - loss: 0.4627 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3029\n","Epoch 74/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8178 - auc: 0.7813 - loss: 0.4578\n","Epoch 74: val_loss did not improve from 0.30286\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8185 - auc: 0.7822 - loss: 0.4568 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3048\n","Epoch 75/100\n","\u001b[1m324/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8452 - auc: 0.8135 - loss: 0.4222\n","Epoch 75: val_loss did not improve from 0.30286\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8451 - auc: 0.8134 - loss: 0.4223 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3111\n","Epoch 76/100\n","\u001b[1m310/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8310 - auc: 0.8409 - loss: 0.4298\n","Epoch 76: val_loss improved from 0.30286 to 0.30205, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8310 - auc: 0.8406 - loss: 0.4299 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3021\n","Epoch 77/100\n","\u001b[1m321/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8497 - auc: 0.8195 - loss: 0.4101\n","Epoch 77: val_loss improved from 0.30205 to 0.30025, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8493 - auc: 0.8193 - loss: 0.4105 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.3003\n","Epoch 78/100\n","\u001b[1m321/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8217 - auc: 0.7969 - loss: 0.4428\n","Epoch 78: val_loss improved from 0.30025 to 0.29704, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8217 - auc: 0.7969 - loss: 0.4428 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2970\n","Epoch 79/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8336 - auc: 0.7715 - loss: 0.4448\n","Epoch 79: val_loss improved from 0.29704 to 0.29566, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8343 - auc: 0.7741 - loss: 0.4437 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.2957\n","Epoch 80/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8536 - auc: 0.8076 - loss: 0.4247\n","Epoch 80: val_loss improved from 0.29566 to 0.29242, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8533 - auc: 0.8078 - loss: 0.4247 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2924\n","Epoch 81/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8351 - auc: 0.8128 - loss: 0.4319\n","Epoch 81: val_loss improved from 0.29242 to 0.29198, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8354 - auc: 0.8133 - loss: 0.4316 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2920\n","Epoch 82/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8155 - auc: 0.8006 - loss: 0.4469\n","Epoch 82: val_loss did not improve from 0.29198\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8158 - auc: 0.8006 - loss: 0.4467 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2952\n","Epoch 83/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8516 - auc: 0.8474 - loss: 0.4078\n","Epoch 83: val_loss did not improve from 0.29198\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8505 - auc: 0.8458 - loss: 0.4092 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2942\n","Epoch 84/100\n","\u001b[1m322/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8387 - auc: 0.7942 - loss: 0.4409\n","Epoch 84: val_loss did not improve from 0.29198\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8388 - auc: 0.7945 - loss: 0.4407 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2925\n","Epoch 85/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8281 - auc: 0.7884 - loss: 0.4458\n","Epoch 85: val_loss improved from 0.29198 to 0.29156, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8282 - auc: 0.7890 - loss: 0.4454 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.2916\n","Epoch 86/100\n","\u001b[1m314/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8305 - auc: 0.8030 - loss: 0.4407\n","Epoch 86: val_loss did not improve from 0.29156\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8303 - auc: 0.8032 - loss: 0.4407 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.2944\n","Epoch 87/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8270 - auc: 0.8289 - loss: 0.4337\n","Epoch 87: val_loss improved from 0.29156 to 0.28799, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8274 - auc: 0.8292 - loss: 0.4333 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2880\n","Epoch 88/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8405 - auc: 0.8313 - loss: 0.4124\n","Epoch 88: val_loss improved from 0.28799 to 0.28740, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8406 - auc: 0.8312 - loss: 0.4125 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2874\n","Epoch 89/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8440 - auc: 0.7978 - loss: 0.4264\n","Epoch 89: val_loss did not improve from 0.28740\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8436 - auc: 0.7986 - loss: 0.4264 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2889\n","Epoch 90/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8327 - auc: 0.8329 - loss: 0.4176\n","Epoch 90: val_loss did not improve from 0.28740\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8322 - auc: 0.8321 - loss: 0.4184 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2944\n","Epoch 91/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8293 - auc: 0.7971 - loss: 0.4352\n","Epoch 91: val_loss improved from 0.28740 to 0.28552, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8305 - auc: 0.7994 - loss: 0.4335 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2855\n","Epoch 92/100\n","\u001b[1m310/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8430 - auc: 0.8413 - loss: 0.4064\n","Epoch 92: val_loss did not improve from 0.28552\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8429 - auc: 0.8411 - loss: 0.4066 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2864\n","Epoch 93/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8132 - auc: 0.7950 - loss: 0.4424\n","Epoch 93: val_loss did not improve from 0.28552\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8137 - auc: 0.7958 - loss: 0.4417 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.2859\n","Epoch 94/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8277 - auc: 0.8340 - loss: 0.4190\n","Epoch 94: val_loss improved from 0.28552 to 0.28135, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8281 - auc: 0.8346 - loss: 0.4185 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2814\n","Epoch 95/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8521 - auc: 0.8550 - loss: 0.3939\n","Epoch 95: val_loss improved from 0.28135 to 0.28014, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8516 - auc: 0.8539 - loss: 0.3946 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2801\n","Epoch 96/100\n","\u001b[1m322/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8481 - auc: 0.8476 - loss: 0.3973\n","Epoch 96: val_loss did not improve from 0.28014\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8479 - auc: 0.8474 - loss: 0.3976 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2850\n","Epoch 97/100\n","\u001b[1m321/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8414 - auc: 0.8296 - loss: 0.4114\n","Epoch 97: val_loss did not improve from 0.28014\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8415 - auc: 0.8298 - loss: 0.4113 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2821\n","Epoch 98/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8328 - auc: 0.8390 - loss: 0.4133\n","Epoch 98: val_loss did not improve from 0.28014\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8330 - auc: 0.8389 - loss: 0.4130 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.2802\n","Epoch 99/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8288 - auc: 0.8424 - loss: 0.4205\n","Epoch 99: val_loss did not improve from 0.28014\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8290 - auc: 0.8426 - loss: 0.4202 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2801\n","Epoch 100/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8313 - auc: 0.8063 - loss: 0.4290\n","Epoch 100: val_loss improved from 0.28014 to 0.27702, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8313 - auc: 0.8068 - loss: 0.4288 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.2770\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b21584f3560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b21584f3560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 3 AUC: 1.0000\n","\n","--- Fold 4/10 ---\n"," train | ids:   35 | files:  968 | pos:  337 | neg:  631\n","   val | ids:    4 | files:  181 | pos:   38 | neg:  143\n","  test | ids:    5 | files:   51 | pos:   30 | neg:   21\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m321/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.2702 - auc: 0.2897 - loss: 0.7545\n","Epoch 1: val_loss improved from inf to 0.70557, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - acc: 0.2702 - auc: 0.2898 - loss: 0.7544 - val_acc: 0.4254 - val_auc: 0.3706 - val_loss: 0.7056\n","Epoch 2/100\n","\u001b[1m313/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4295 - auc: 0.3246 - loss: 0.7071\n","Epoch 2: val_loss improved from 0.70557 to 0.65780, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.4325 - auc: 0.3256 - loss: 0.7068 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.6578\n","Epoch 3/100\n","\u001b[1m315/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6003 - auc: 0.5419 - loss: 0.6737\n","Epoch 3: val_loss improved from 0.65780 to 0.62852, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6000 - auc: 0.5430 - loss: 0.6736 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.6285\n","Epoch 4/100\n","\u001b[1m312/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6113 - auc: 0.6121 - loss: 0.6591\n","Epoch 4: val_loss improved from 0.62852 to 0.60951, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6122 - auc: 0.6121 - loss: 0.6588 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.6095\n","Epoch 5/100\n","\u001b[1m315/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6611 - auc: 0.6309 - loss: 0.6383\n","Epoch 5: val_loss improved from 0.60951 to 0.60036, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6611 - auc: 0.6305 - loss: 0.6383 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.6004\n","Epoch 6/100\n","\u001b[1m314/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6724 - auc: 0.6477 - loss: 0.6353\n","Epoch 6: val_loss improved from 0.60036 to 0.59231, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6729 - auc: 0.6471 - loss: 0.6351 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5923\n","Epoch 7/100\n","\u001b[1m314/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6775 - auc: 0.6454 - loss: 0.6254\n","Epoch 7: val_loss improved from 0.59231 to 0.58666, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6777 - auc: 0.6448 - loss: 0.6254 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5867\n","Epoch 8/100\n","\u001b[1m313/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6801 - auc: 0.5785 - loss: 0.6388\n","Epoch 8: val_loss improved from 0.58666 to 0.58255, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6802 - auc: 0.5793 - loss: 0.6385 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5826\n","Epoch 9/100\n","\u001b[1m318/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6649 - auc: 0.6221 - loss: 0.6302\n","Epoch 9: val_loss improved from 0.58255 to 0.57949, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6650 - auc: 0.6217 - loss: 0.6301 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5795\n","Epoch 10/100\n","\u001b[1m315/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7007 - auc: 0.6271 - loss: 0.6058\n","Epoch 10: val_loss improved from 0.57949 to 0.57550, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7000 - auc: 0.6271 - loss: 0.6061 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5755\n","Epoch 11/100\n","\u001b[1m317/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6821 - auc: 0.6181 - loss: 0.6246\n","Epoch 11: val_loss improved from 0.57550 to 0.57364, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6822 - auc: 0.6182 - loss: 0.6246 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5736\n","Epoch 12/100\n","\u001b[1m319/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6684 - auc: 0.6128 - loss: 0.6330\n","Epoch 12: val_loss improved from 0.57364 to 0.57181, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6685 - auc: 0.6133 - loss: 0.6328 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5718\n","Epoch 13/100\n","\u001b[1m306/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6751 - auc: 0.6632 - loss: 0.6205\n","Epoch 13: val_loss improved from 0.57181 to 0.57018, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6752 - auc: 0.6638 - loss: 0.6201 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5702\n","Epoch 14/100\n","\u001b[1m313/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6750 - auc: 0.6695 - loss: 0.6230\n","Epoch 14: val_loss improved from 0.57018 to 0.56857, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6753 - auc: 0.6693 - loss: 0.6227 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5686\n","Epoch 15/100\n","\u001b[1m301/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6682 - auc: 0.6822 - loss: 0.6224\n","Epoch 15: val_loss improved from 0.56857 to 0.56660, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6718 - auc: 0.6826 - loss: 0.6214 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5666\n","Epoch 16/100\n","\u001b[1m314/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7722 - auc: 0.6944 - loss: 0.6047\n","Epoch 16: val_loss improved from 0.56660 to 0.56576, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7719 - auc: 0.6936 - loss: 0.6050 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5658\n","Epoch 17/100\n","\u001b[1m317/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7746 - auc: 0.6941 - loss: 0.5897\n","Epoch 17: val_loss improved from 0.56576 to 0.56449, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7743 - auc: 0.6940 - loss: 0.5899 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5645\n","Epoch 18/100\n","\u001b[1m315/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7931 - auc: 0.7165 - loss: 0.6040\n","Epoch 18: val_loss improved from 0.56449 to 0.56431, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7928 - auc: 0.7155 - loss: 0.6042 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5643\n","Epoch 19/100\n","\u001b[1m317/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7741 - auc: 0.6954 - loss: 0.5969\n","Epoch 19: val_loss improved from 0.56431 to 0.56392, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7738 - auc: 0.6950 - loss: 0.5970 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5639\n","Epoch 20/100\n","\u001b[1m317/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7833 - auc: 0.7416 - loss: 0.5780\n","Epoch 20: val_loss improved from 0.56392 to 0.56234, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7831 - auc: 0.7411 - loss: 0.5782 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5623\n","Epoch 21/100\n","\u001b[1m316/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7667 - auc: 0.7209 - loss: 0.5903\n","Epoch 21: val_loss improved from 0.56234 to 0.56153, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7672 - auc: 0.7206 - loss: 0.5903 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5615\n","Epoch 22/100\n","\u001b[1m317/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7831 - auc: 0.6774 - loss: 0.5938\n","Epoch 22: val_loss did not improve from 0.56153\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7833 - auc: 0.6774 - loss: 0.5939 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5617\n","Epoch 23/100\n","\u001b[1m317/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7873 - auc: 0.7171 - loss: 0.5967\n","Epoch 23: val_loss did not improve from 0.56153\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7874 - auc: 0.7165 - loss: 0.5967 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5616\n","Epoch 24/100\n","\u001b[1m315/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7967 - auc: 0.6941 - loss: 0.5797\n","Epoch 24: val_loss improved from 0.56153 to 0.56135, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7965 - auc: 0.6942 - loss: 0.5799 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5613\n","Epoch 25/100\n","\u001b[1m315/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7991 - auc: 0.7110 - loss: 0.5684\n","Epoch 25: val_loss improved from 0.56135 to 0.56078, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7987 - auc: 0.7107 - loss: 0.5688 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5608\n","Epoch 26/100\n","\u001b[1m321/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7783 - auc: 0.6605 - loss: 0.5989\n","Epoch 26: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7783 - auc: 0.6606 - loss: 0.5989 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5612\n","Epoch 27/100\n","\u001b[1m314/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7835 - auc: 0.6608 - loss: 0.5943\n","Epoch 27: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7837 - auc: 0.6610 - loss: 0.5942 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5616\n","Epoch 28/100\n","\u001b[1m317/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7776 - auc: 0.6771 - loss: 0.5977\n","Epoch 28: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7778 - auc: 0.6773 - loss: 0.5973 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5611\n","Epoch 29/100\n","\u001b[1m306/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7997 - auc: 0.7112 - loss: 0.5717\n","Epoch 29: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7986 - auc: 0.7095 - loss: 0.5725 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5613\n","Epoch 30/100\n","\u001b[1m314/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8118 - auc: 0.7143 - loss: 0.5634\n","Epoch 30: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8112 - auc: 0.7132 - loss: 0.5639 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5612\n","Epoch 31/100\n","\u001b[1m321/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7932 - auc: 0.6635 - loss: 0.5910\n","Epoch 31: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7931 - auc: 0.6635 - loss: 0.5910 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5619\n","Epoch 32/100\n","\u001b[1m318/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7659 - auc: 0.6737 - loss: 0.5902\n","Epoch 32: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7661 - auc: 0.6736 - loss: 0.5901 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5624\n","Epoch 33/100\n","\u001b[1m315/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8008 - auc: 0.7051 - loss: 0.5670\n","Epoch 33: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8004 - auc: 0.7050 - loss: 0.5671 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5620\n","Epoch 34/100\n","\u001b[1m319/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7738 - auc: 0.6629 - loss: 0.5791\n","Epoch 34: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7737 - auc: 0.6628 - loss: 0.5792 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5624\n","Epoch 35/100\n","\u001b[1m322/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7697 - auc: 0.6611 - loss: 0.5830\n","Epoch 35: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7698 - auc: 0.6614 - loss: 0.5830 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5626\n","Epoch 36/100\n","\u001b[1m299/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7756 - auc: 0.6898 - loss: 0.5740\n","Epoch 36: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7761 - auc: 0.6900 - loss: 0.5739 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5622\n","Epoch 37/100\n","\u001b[1m321/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7786 - auc: 0.7003 - loss: 0.5768\n","Epoch 37: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7786 - auc: 0.7003 - loss: 0.5767 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5622\n","Epoch 38/100\n","\u001b[1m298/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7535 - auc: 0.6820 - loss: 0.5877\n","Epoch 38: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7550 - auc: 0.6839 - loss: 0.5862 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5618\n","Epoch 39/100\n","\u001b[1m322/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7513 - auc: 0.6973 - loss: 0.5847\n","Epoch 39: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7515 - auc: 0.6974 - loss: 0.5846 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5619\n","Epoch 40/100\n","\u001b[1m321/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7761 - auc: 0.6969 - loss: 0.5726\n","Epoch 40: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7762 - auc: 0.6970 - loss: 0.5726 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5619\n","Epoch 41/100\n","\u001b[1m298/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7821 - auc: 0.7591 - loss: 0.5483\n","Epoch 41: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7826 - auc: 0.7566 - loss: 0.5489 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5615\n","Epoch 42/100\n","\u001b[1m317/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7587 - auc: 0.6992 - loss: 0.5842\n","Epoch 42: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7592 - auc: 0.6995 - loss: 0.5838 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5615\n","Epoch 43/100\n","\u001b[1m318/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8029 - auc: 0.7025 - loss: 0.5565\n","Epoch 43: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8027 - auc: 0.7028 - loss: 0.5565 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5616\n","Epoch 44/100\n","\u001b[1m316/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7537 - auc: 0.6853 - loss: 0.5745\n","Epoch 44: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7543 - auc: 0.6856 - loss: 0.5742 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5618\n","Epoch 45/100\n","\u001b[1m313/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8227 - auc: 0.7528 - loss: 0.5224\n","Epoch 45: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8216 - auc: 0.7519 - loss: 0.5233 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5616\n","Epoch 46/100\n","\u001b[1m322/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7886 - auc: 0.6944 - loss: 0.5543\n","Epoch 46: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7885 - auc: 0.6945 - loss: 0.5543 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5619\n","Epoch 47/100\n","\u001b[1m319/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8048 - auc: 0.7379 - loss: 0.5365\n","Epoch 47: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8044 - auc: 0.7374 - loss: 0.5368 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5620\n","Epoch 48/100\n","\u001b[1m321/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8149 - auc: 0.7540 - loss: 0.5319\n","Epoch 48: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8147 - auc: 0.7539 - loss: 0.5320 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5620\n","Epoch 49/100\n","\u001b[1m321/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7997 - auc: 0.7288 - loss: 0.5373\n","Epoch 49: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7994 - auc: 0.7285 - loss: 0.5375 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5626\n","Epoch 50/100\n","\u001b[1m321/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7662 - auc: 0.7218 - loss: 0.5667\n","Epoch 50: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7663 - auc: 0.7217 - loss: 0.5667 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5628\n","Epoch 51/100\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8160 - auc: 0.7621 - loss: 0.5065\n","Epoch 51: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8159 - auc: 0.7620 - loss: 0.5065 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5620\n","Epoch 52/100\n","\u001b[1m319/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7928 - auc: 0.7608 - loss: 0.5238\n","Epoch 52: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7927 - auc: 0.7604 - loss: 0.5240 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5619\n","Epoch 53/100\n","\u001b[1m319/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7810 - auc: 0.7521 - loss: 0.5305\n","Epoch 53: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7809 - auc: 0.7517 - loss: 0.5307 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5619\n","Epoch 54/100\n","\u001b[1m299/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7949 - auc: 0.7542 - loss: 0.5261\n","Epoch 54: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7946 - auc: 0.7534 - loss: 0.5265 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5617\n","Epoch 55/100\n","\u001b[1m314/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7908 - auc: 0.7449 - loss: 0.5275\n","Epoch 55: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7906 - auc: 0.7446 - loss: 0.5277 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5618\n","Epoch 56/100\n","\u001b[1m320/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7802 - auc: 0.7146 - loss: 0.5385\n","Epoch 56: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7802 - auc: 0.7148 - loss: 0.5385 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5616\n","Epoch 57/100\n","\u001b[1m314/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8144 - auc: 0.7507 - loss: 0.5076\n","Epoch 57: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8138 - auc: 0.7503 - loss: 0.5082 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5618\n","Epoch 58/100\n","\u001b[1m316/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7479 - auc: 0.7240 - loss: 0.5520\n","Epoch 58: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7482 - auc: 0.7240 - loss: 0.5518 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5620\n","Epoch 59/100\n","\u001b[1m306/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7669 - auc: 0.7471 - loss: 0.5377\n","Epoch 59: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7680 - auc: 0.7463 - loss: 0.5374 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5621\n","Epoch 60/100\n","\u001b[1m320/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7983 - auc: 0.7420 - loss: 0.5248\n","Epoch 60: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7983 - auc: 0.7418 - loss: 0.5248 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5622\n","Epoch 61/100\n","\u001b[1m317/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7847 - auc: 0.7475 - loss: 0.5220\n","Epoch 61: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7845 - auc: 0.7473 - loss: 0.5221 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5621\n","Epoch 62/100\n","\u001b[1m318/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7996 - auc: 0.7618 - loss: 0.5109\n","Epoch 62: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7994 - auc: 0.7614 - loss: 0.5111 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5622\n","Epoch 63/100\n","\u001b[1m319/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7847 - auc: 0.7234 - loss: 0.5308\n","Epoch 63: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7848 - auc: 0.7236 - loss: 0.5306 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5623\n","Epoch 64/100\n","\u001b[1m321/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7915 - auc: 0.7251 - loss: 0.5235\n","Epoch 64: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7915 - auc: 0.7252 - loss: 0.5235 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5627\n","Epoch 65/100\n","\u001b[1m316/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7926 - auc: 0.7444 - loss: 0.5153\n","Epoch 65: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7924 - auc: 0.7443 - loss: 0.5155 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5627\n","Epoch 66/100\n","\u001b[1m318/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7871 - auc: 0.7355 - loss: 0.5226\n","Epoch 66: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7872 - auc: 0.7356 - loss: 0.5225 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5630\n","Epoch 67/100\n","\u001b[1m319/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8070 - auc: 0.7593 - loss: 0.5031\n","Epoch 67: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8069 - auc: 0.7593 - loss: 0.5030 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5632\n","Epoch 68/100\n","\u001b[1m319/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7987 - auc: 0.7810 - loss: 0.5037\n","Epoch 68: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7986 - auc: 0.7806 - loss: 0.5038 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5633\n","Epoch 69/100\n","\u001b[1m316/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7985 - auc: 0.7690 - loss: 0.4993\n","Epoch 69: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7982 - auc: 0.7686 - loss: 0.4996 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5636\n","Epoch 70/100\n","\u001b[1m315/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7995 - auc: 0.7643 - loss: 0.4881\n","Epoch 70: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7993 - auc: 0.7636 - loss: 0.4886 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5642\n","Epoch 71/100\n","\u001b[1m318/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7549 - auc: 0.7317 - loss: 0.5327\n","Epoch 71: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7555 - auc: 0.7318 - loss: 0.5323 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5647\n","Epoch 72/100\n","\u001b[1m311/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8021 - auc: 0.7555 - loss: 0.4946\n","Epoch 72: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8018 - auc: 0.7551 - loss: 0.4951 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5651\n","Epoch 73/100\n","\u001b[1m305/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7726 - auc: 0.7501 - loss: 0.5131\n","Epoch 73: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7730 - auc: 0.7499 - loss: 0.5126 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5655\n","Epoch 74/100\n","\u001b[1m303/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8120 - auc: 0.7612 - loss: 0.4879\n","Epoch 74: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8104 - auc: 0.7601 - loss: 0.4891 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5659\n","Epoch 75/100\n","\u001b[1m313/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8333 - auc: 0.7507 - loss: 0.4816\n","Epoch 75: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8322 - auc: 0.7508 - loss: 0.4822 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5664\n","Epoch 76/100\n","\u001b[1m317/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7829 - auc: 0.7369 - loss: 0.5068\n","Epoch 76: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7830 - auc: 0.7369 - loss: 0.5068 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5670\n","Epoch 77/100\n","\u001b[1m314/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8036 - auc: 0.7172 - loss: 0.5040\n","Epoch 77: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8033 - auc: 0.7177 - loss: 0.5040 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5680\n","Epoch 78/100\n","\u001b[1m319/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8038 - auc: 0.7505 - loss: 0.4880\n","Epoch 78: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8036 - auc: 0.7504 - loss: 0.4882 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5684\n","Epoch 79/100\n","\u001b[1m314/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7898 - auc: 0.7182 - loss: 0.5098\n","Epoch 79: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7897 - auc: 0.7183 - loss: 0.5098 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5693\n","Epoch 80/100\n","\u001b[1m317/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7755 - auc: 0.7530 - loss: 0.5077\n","Epoch 80: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7759 - auc: 0.7531 - loss: 0.5074 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5697\n","Epoch 81/100\n","\u001b[1m316/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7841 - auc: 0.7150 - loss: 0.5003\n","Epoch 81: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7839 - auc: 0.7156 - loss: 0.5003 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5699\n","Epoch 82/100\n","\u001b[1m318/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7831 - auc: 0.7438 - loss: 0.4959\n","Epoch 82: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7832 - auc: 0.7438 - loss: 0.4959 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5706\n","Epoch 83/100\n","\u001b[1m316/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8033 - auc: 0.7655 - loss: 0.4715\n","Epoch 83: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8028 - auc: 0.7652 - loss: 0.4719 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5709\n","Epoch 84/100\n","\u001b[1m319/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7994 - auc: 0.7805 - loss: 0.4772\n","Epoch 84: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7994 - auc: 0.7802 - loss: 0.4773 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5716\n","Epoch 85/100\n","\u001b[1m315/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8188 - auc: 0.7919 - loss: 0.4547\n","Epoch 85: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8184 - auc: 0.7915 - loss: 0.4552 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5715\n","Epoch 86/100\n","\u001b[1m319/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8040 - auc: 0.7844 - loss: 0.4660\n","Epoch 86: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8038 - auc: 0.7840 - loss: 0.4663 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5720\n","Epoch 87/100\n","\u001b[1m311/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8182 - auc: 0.7732 - loss: 0.4604\n","Epoch 87: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8174 - auc: 0.7725 - loss: 0.4614 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5723\n","Epoch 88/100\n","\u001b[1m316/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7801 - auc: 0.7508 - loss: 0.4940\n","Epoch 88: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7801 - auc: 0.7509 - loss: 0.4941 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5730\n","Epoch 89/100\n","\u001b[1m300/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7810 - auc: 0.7851 - loss: 0.4927\n","Epoch 89: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7818 - auc: 0.7857 - loss: 0.4915 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5733\n","Epoch 90/100\n","\u001b[1m322/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7754 - auc: 0.7449 - loss: 0.5065\n","Epoch 90: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7755 - auc: 0.7450 - loss: 0.5064 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5737\n","Epoch 91/100\n","\u001b[1m321/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8000 - auc: 0.7863 - loss: 0.4745\n","Epoch 91: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8000 - auc: 0.7862 - loss: 0.4746 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5745\n","Epoch 92/100\n","\u001b[1m319/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8098 - auc: 0.8174 - loss: 0.4573\n","Epoch 92: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8097 - auc: 0.8171 - loss: 0.4575 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5747\n","Epoch 93/100\n","\u001b[1m317/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8057 - auc: 0.7577 - loss: 0.4857\n","Epoch 93: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8057 - auc: 0.7589 - loss: 0.4854 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5753\n","Epoch 94/100\n","\u001b[1m316/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8114 - auc: 0.8229 - loss: 0.4607\n","Epoch 94: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8108 - auc: 0.8230 - loss: 0.4611 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5760\n","Epoch 95/100\n","\u001b[1m318/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8062 - auc: 0.8380 - loss: 0.4547\n","Epoch 95: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8060 - auc: 0.8377 - loss: 0.4550 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5766\n","Epoch 96/100\n","\u001b[1m316/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7823 - auc: 0.8294 - loss: 0.4750\n","Epoch 96: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7825 - auc: 0.8296 - loss: 0.4749 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5772\n","Epoch 97/100\n","\u001b[1m318/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7996 - auc: 0.8252 - loss: 0.4667\n","Epoch 97: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7993 - auc: 0.8248 - loss: 0.4670 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5787\n","Epoch 98/100\n","\u001b[1m316/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7742 - auc: 0.8166 - loss: 0.4917\n","Epoch 98: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7742 - auc: 0.8165 - loss: 0.4916 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5794\n","Epoch 99/100\n","\u001b[1m318/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7999 - auc: 0.8123 - loss: 0.4681\n","Epoch 99: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7998 - auc: 0.8124 - loss: 0.4682 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5805\n","Epoch 100/100\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8036 - auc: 0.8306 - loss: 0.4574\n","Epoch 100: val_loss did not improve from 0.56078\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8036 - auc: 0.8306 - loss: 0.4575 - val_acc: 0.7901 - val_auc: 0.0000e+00 - val_loss: 0.5799\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 4 AUC: 1.0000\n","\n","--- Fold 5/10 ---\n"," train | ids:   36 | files:  996 | pos:  309 | neg:  687\n","   val | ids:    4 | files:  145 | pos:   77 | neg:   68\n","  test | ids:    4 | files:   59 | pos:   19 | neg:   40\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m313/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5999 - auc: 0.5796 - loss: 0.6757\n","Epoch 1: val_loss improved from inf to 0.80908, saving model to best_tab_only_fold5.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - acc: 0.5997 - auc: 0.5792 - loss: 0.6754 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8091\n","Epoch 2/100\n","\u001b[1m314/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6804 - auc: 0.6406 - loss: 0.6034\n","Epoch 2: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6796 - auc: 0.6392 - loss: 0.6054 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8099\n","Epoch 3/100\n","\u001b[1m316/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6865 - auc: 0.5599 - loss: 0.6701\n","Epoch 3: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6871 - auc: 0.5616 - loss: 0.6691 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8103\n","Epoch 4/100\n","\u001b[1m316/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6966 - auc: 0.6023 - loss: 0.6592\n","Epoch 4: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6972 - auc: 0.6030 - loss: 0.6580 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8130\n","Epoch 5/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7260 - auc: 0.6287 - loss: 0.6259\n","Epoch 5: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7252 - auc: 0.6287 - loss: 0.6261 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8173\n","Epoch 6/100\n","\u001b[1m314/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7065 - auc: 0.6363 - loss: 0.6122\n","Epoch 6: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7063 - auc: 0.6354 - loss: 0.6135 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8186\n","Epoch 7/100\n","\u001b[1m314/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7152 - auc: 0.6216 - loss: 0.6235\n","Epoch 7: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7158 - auc: 0.6215 - loss: 0.6242 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8218\n","Epoch 8/100\n","\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7142 - auc: 0.6065 - loss: 0.6071\n","Epoch 8: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7146 - auc: 0.6070 - loss: 0.6077 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8247\n","Epoch 9/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7338 - auc: 0.6277 - loss: 0.6305\n","Epoch 9: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7345 - auc: 0.6279 - loss: 0.6303 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8268\n","Epoch 10/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7439 - auc: 0.6297 - loss: 0.6163\n","Epoch 10: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7441 - auc: 0.6308 - loss: 0.6157 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8318\n","Epoch 11/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7977 - auc: 0.6804 - loss: 0.5844\n","Epoch 11: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7976 - auc: 0.6797 - loss: 0.5851 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8345\n","Epoch 12/100\n","\u001b[1m312/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7384 - auc: 0.6598 - loss: 0.6262\n","Epoch 12: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7395 - auc: 0.6600 - loss: 0.6246 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8392\n","Epoch 13/100\n","\u001b[1m315/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7915 - auc: 0.6705 - loss: 0.5782\n","Epoch 13: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7915 - auc: 0.6706 - loss: 0.5790 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8424\n","Epoch 14/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8094 - auc: 0.7057 - loss: 0.5663\n","Epoch 14: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8093 - auc: 0.7055 - loss: 0.5665 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8447\n","Epoch 15/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7959 - auc: 0.6609 - loss: 0.5922\n","Epoch 15: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7959 - auc: 0.6613 - loss: 0.5922 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8466\n","Epoch 16/100\n","\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7708 - auc: 0.6831 - loss: 0.5893\n","Epoch 16: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7716 - auc: 0.6826 - loss: 0.5895 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8503\n","Epoch 17/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7929 - auc: 0.6825 - loss: 0.5844\n","Epoch 17: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7924 - auc: 0.6823 - loss: 0.5847 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8538\n","Epoch 18/100\n","\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8186 - auc: 0.7172 - loss: 0.5605\n","Epoch 18: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8182 - auc: 0.7164 - loss: 0.5612 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8585\n","Epoch 19/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7928 - auc: 0.6354 - loss: 0.5948\n","Epoch 19: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7930 - auc: 0.6362 - loss: 0.5948 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8607\n","Epoch 20/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7967 - auc: 0.6547 - loss: 0.6055\n","Epoch 20: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7972 - auc: 0.6555 - loss: 0.6046 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8638\n","Epoch 21/100\n","\u001b[1m316/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8231 - auc: 0.7254 - loss: 0.5361\n","Epoch 21: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8221 - auc: 0.7233 - loss: 0.5380 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8667\n","Epoch 22/100\n","\u001b[1m316/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7955 - auc: 0.6688 - loss: 0.5998\n","Epoch 22: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7962 - auc: 0.6705 - loss: 0.5981 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8696\n","Epoch 23/100\n","\u001b[1m312/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8018 - auc: 0.6642 - loss: 0.6092\n","Epoch 23: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8017 - auc: 0.6641 - loss: 0.6079 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8721\n","Epoch 24/100\n","\u001b[1m315/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8061 - auc: 0.6853 - loss: 0.5592\n","Epoch 24: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8060 - auc: 0.6860 - loss: 0.5595 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8758\n","Epoch 25/100\n","\u001b[1m313/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8144 - auc: 0.6935 - loss: 0.5688\n","Epoch 25: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8139 - auc: 0.6927 - loss: 0.5691 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8777\n","Epoch 26/100\n","\u001b[1m314/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8022 - auc: 0.7032 - loss: 0.5605\n","Epoch 26: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8021 - auc: 0.7027 - loss: 0.5608 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8809\n","Epoch 27/100\n","\u001b[1m311/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8353 - auc: 0.7731 - loss: 0.5198\n","Epoch 27: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8337 - auc: 0.7684 - loss: 0.5223 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8857\n","Epoch 28/100\n","\u001b[1m311/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8074 - auc: 0.7117 - loss: 0.5609\n","Epoch 28: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8085 - auc: 0.7121 - loss: 0.5599 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8895\n","Epoch 29/100\n","\u001b[1m308/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8163 - auc: 0.6157 - loss: 0.5773\n","Epoch 29: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8170 - auc: 0.6210 - loss: 0.5758 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8908\n","Epoch 30/100\n","\u001b[1m313/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8197 - auc: 0.6999 - loss: 0.5652\n","Epoch 30: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8195 - auc: 0.6996 - loss: 0.5645 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8937\n","Epoch 31/100\n","\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8099 - auc: 0.6917 - loss: 0.5477\n","Epoch 31: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8105 - auc: 0.6922 - loss: 0.5474 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8997\n","Epoch 32/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8153 - auc: 0.7102 - loss: 0.5552\n","Epoch 32: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8154 - auc: 0.7097 - loss: 0.5550 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.9025\n","Epoch 33/100\n","\u001b[1m317/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8200 - auc: 0.7032 - loss: 0.5484\n","Epoch 33: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8200 - auc: 0.7021 - loss: 0.5486 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.9035\n","Epoch 34/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8297 - auc: 0.6416 - loss: 0.5618\n","Epoch 34: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8302 - auc: 0.6440 - loss: 0.5608 - val_acc: 0.4690 - val_auc: 0.2059 - val_loss: 0.9086\n","Epoch 35/100\n","\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8400 - auc: 0.7258 - loss: 0.5105\n","Epoch 35: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8396 - auc: 0.7254 - loss: 0.5111 - val_acc: 0.4690 - val_auc: 0.2059 - val_loss: 0.9118\n","Epoch 36/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8302 - auc: 0.6914 - loss: 0.5372\n","Epoch 36: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8305 - auc: 0.6915 - loss: 0.5370 - val_acc: 0.4690 - val_auc: 0.2059 - val_loss: 0.9142\n","Epoch 37/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8292 - auc: 0.6544 - loss: 0.5535\n","Epoch 37: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8294 - auc: 0.6559 - loss: 0.5527 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9173\n","Epoch 38/100\n","\u001b[1m317/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8243 - auc: 0.7233 - loss: 0.5279\n","Epoch 38: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8247 - auc: 0.7218 - loss: 0.5278 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9188\n","Epoch 39/100\n","\u001b[1m313/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8626 - auc: 0.7355 - loss: 0.4892\n","Epoch 39: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8619 - auc: 0.7348 - loss: 0.4899 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9228\n","Epoch 40/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8147 - auc: 0.7003 - loss: 0.5360\n","Epoch 40: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8154 - auc: 0.7005 - loss: 0.5354 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9255\n","Epoch 41/100\n","\u001b[1m315/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8185 - auc: 0.7025 - loss: 0.5260\n","Epoch 41: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8191 - auc: 0.7027 - loss: 0.5253 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9286\n","Epoch 42/100\n","\u001b[1m314/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8403 - auc: 0.7174 - loss: 0.5147\n","Epoch 42: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8399 - auc: 0.7166 - loss: 0.5147 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9323\n","Epoch 43/100\n","\u001b[1m314/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8005 - auc: 0.6835 - loss: 0.5350\n","Epoch 43: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8020 - auc: 0.6846 - loss: 0.5336 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9362\n","Epoch 44/100\n","\u001b[1m308/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8199 - auc: 0.7271 - loss: 0.5151\n","Epoch 44: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8215 - auc: 0.7269 - loss: 0.5136 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9392\n","Epoch 45/100\n","\u001b[1m314/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8373 - auc: 0.7316 - loss: 0.4949\n","Epoch 45: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8371 - auc: 0.7313 - loss: 0.4951 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9432\n","Epoch 46/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8373 - auc: 0.7199 - loss: 0.4906\n","Epoch 46: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8379 - auc: 0.7196 - loss: 0.4906 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9474\n","Epoch 47/100\n","\u001b[1m315/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8382 - auc: 0.7204 - loss: 0.4815\n","Epoch 47: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8382 - auc: 0.7196 - loss: 0.4820 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9513\n","Epoch 48/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8263 - auc: 0.7177 - loss: 0.4968\n","Epoch 48: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8271 - auc: 0.7183 - loss: 0.4961 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9566\n","Epoch 49/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8141 - auc: 0.7173 - loss: 0.4922\n","Epoch 49: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8149 - auc: 0.7177 - loss: 0.4918 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9606\n","Epoch 50/100\n","\u001b[1m314/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8558 - auc: 0.7285 - loss: 0.4757\n","Epoch 50: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8557 - auc: 0.7285 - loss: 0.4757 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9647\n","Epoch 51/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8646 - auc: 0.7240 - loss: 0.4675\n","Epoch 51: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8641 - auc: 0.7232 - loss: 0.4683 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9650\n","Epoch 52/100\n","\u001b[1m316/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8467 - auc: 0.7201 - loss: 0.4838\n","Epoch 52: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8468 - auc: 0.7201 - loss: 0.4836 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9671\n","Epoch 53/100\n","\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8578 - auc: 0.7398 - loss: 0.4687\n","Epoch 53: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8576 - auc: 0.7398 - loss: 0.4688 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9730\n","Epoch 54/100\n","\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8836 - auc: 0.7821 - loss: 0.4266\n","Epoch 54: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8825 - auc: 0.7809 - loss: 0.4278 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9795\n","Epoch 55/100\n","\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8540 - auc: 0.7295 - loss: 0.4615\n","Epoch 55: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8539 - auc: 0.7296 - loss: 0.4616 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9828\n","Epoch 56/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8598 - auc: 0.7296 - loss: 0.4730\n","Epoch 56: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8593 - auc: 0.7294 - loss: 0.4731 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9842\n","Epoch 57/100\n","\u001b[1m311/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8690 - auc: 0.7693 - loss: 0.4420\n","Epoch 57: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8679 - auc: 0.7670 - loss: 0.4435 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9899\n","Epoch 58/100\n","\u001b[1m313/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8523 - auc: 0.7548 - loss: 0.4609\n","Epoch 58: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8523 - auc: 0.7546 - loss: 0.4605 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9945\n","Epoch 59/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8338 - auc: 0.7360 - loss: 0.4716\n","Epoch 59: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8339 - auc: 0.7361 - loss: 0.4715 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9986\n","Epoch 60/100\n","\u001b[1m317/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8602 - auc: 0.7959 - loss: 0.4326\n","Epoch 60: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8598 - auc: 0.7940 - loss: 0.4335 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0016\n","Epoch 61/100\n","\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8774 - auc: 0.8006 - loss: 0.4131\n","Epoch 61: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8767 - auc: 0.7994 - loss: 0.4140 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0081\n","Epoch 62/100\n","\u001b[1m316/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8436 - auc: 0.7264 - loss: 0.4694\n","Epoch 62: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8440 - auc: 0.7278 - loss: 0.4685 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0100\n","Epoch 63/100\n","\u001b[1m314/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8828 - auc: 0.7988 - loss: 0.4144\n","Epoch 63: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8815 - auc: 0.7969 - loss: 0.4158 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0162\n","Epoch 64/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8652 - auc: 0.7704 - loss: 0.4317\n","Epoch 64: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8651 - auc: 0.7699 - loss: 0.4319 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0187\n","Epoch 65/100\n","\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8570 - auc: 0.7700 - loss: 0.4315\n","Epoch 65: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8568 - auc: 0.7696 - loss: 0.4318 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0224\n","Epoch 66/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8499 - auc: 0.7501 - loss: 0.4417\n","Epoch 66: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8501 - auc: 0.7508 - loss: 0.4415 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0274\n","Epoch 67/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8417 - auc: 0.7653 - loss: 0.4401\n","Epoch 67: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8421 - auc: 0.7656 - loss: 0.4397 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0307\n","Epoch 68/100\n","\u001b[1m312/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8701 - auc: 0.7803 - loss: 0.4240\n","Epoch 68: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8691 - auc: 0.7792 - loss: 0.4251 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0331\n","Epoch 69/100\n","\u001b[1m317/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8317 - auc: 0.7965 - loss: 0.4326\n","Epoch 69: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8325 - auc: 0.7962 - loss: 0.4321 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0410\n","Epoch 70/100\n","\u001b[1m313/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8699 - auc: 0.8004 - loss: 0.4028\n","Epoch 70: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8689 - auc: 0.8000 - loss: 0.4036 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0450\n","Epoch 71/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8671 - auc: 0.7810 - loss: 0.4200\n","Epoch 71: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8667 - auc: 0.7806 - loss: 0.4203 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0502\n","Epoch 72/100\n","\u001b[1m310/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8493 - auc: 0.8008 - loss: 0.4164\n","Epoch 72: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8498 - auc: 0.8001 - loss: 0.4162 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0568\n","Epoch 73/100\n","\u001b[1m310/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8389 - auc: 0.7480 - loss: 0.4380\n","Epoch 73: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8394 - auc: 0.7500 - loss: 0.4371 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0601\n","Epoch 74/100\n","\u001b[1m311/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8531 - auc: 0.7791 - loss: 0.4188\n","Epoch 74: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8528 - auc: 0.7791 - loss: 0.4191 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0668\n","Epoch 75/100\n","\u001b[1m315/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8589 - auc: 0.8214 - loss: 0.4046\n","Epoch 75: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8588 - auc: 0.8204 - loss: 0.4051 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0764\n","Epoch 76/100\n","\u001b[1m315/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8510 - auc: 0.8279 - loss: 0.3988\n","Epoch 76: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8514 - auc: 0.8278 - loss: 0.3985 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0846\n","Epoch 77/100\n","\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8571 - auc: 0.7986 - loss: 0.4009\n","Epoch 77: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8569 - auc: 0.7983 - loss: 0.4012 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0856\n","Epoch 78/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8548 - auc: 0.8296 - loss: 0.3897\n","Epoch 78: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8546 - auc: 0.8287 - loss: 0.3903 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0891\n","Epoch 79/100\n","\u001b[1m313/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8253 - auc: 0.7554 - loss: 0.4353\n","Epoch 79: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8269 - auc: 0.7569 - loss: 0.4339 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0903\n","Epoch 80/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8650 - auc: 0.7944 - loss: 0.4013\n","Epoch 80: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8648 - auc: 0.7942 - loss: 0.4015 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0967\n","Epoch 81/100\n","\u001b[1m317/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8546 - auc: 0.7827 - loss: 0.4117\n","Epoch 81: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8546 - auc: 0.7833 - loss: 0.4115 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1004\n","Epoch 82/100\n","\u001b[1m317/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8605 - auc: 0.7868 - loss: 0.4053\n","Epoch 82: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8606 - auc: 0.7879 - loss: 0.4049 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1090\n","Epoch 83/100\n","\u001b[1m317/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8576 - auc: 0.8374 - loss: 0.3900\n","Epoch 83: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8578 - auc: 0.8367 - loss: 0.3902 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1171\n","Epoch 84/100\n","\u001b[1m317/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8516 - auc: 0.7920 - loss: 0.4051\n","Epoch 84: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8517 - auc: 0.7925 - loss: 0.4050 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1234\n","Epoch 85/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8686 - auc: 0.8339 - loss: 0.3854\n","Epoch 85: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8684 - auc: 0.8336 - loss: 0.3855 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1296\n","Epoch 86/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8449 - auc: 0.8172 - loss: 0.4124\n","Epoch 86: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8455 - auc: 0.8173 - loss: 0.4119 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1379\n","Epoch 87/100\n","\u001b[1m312/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8545 - auc: 0.8192 - loss: 0.3960\n","Epoch 87: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8547 - auc: 0.8198 - loss: 0.3957 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1496\n","Epoch 88/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8572 - auc: 0.8485 - loss: 0.3739\n","Epoch 88: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8572 - auc: 0.8483 - loss: 0.3740 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1566\n","Epoch 89/100\n","\u001b[1m310/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8476 - auc: 0.7715 - loss: 0.4162\n","Epoch 89: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8479 - auc: 0.7747 - loss: 0.4149 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1578\n","Epoch 90/100\n","\u001b[1m313/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8629 - auc: 0.8182 - loss: 0.3882\n","Epoch 90: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8629 - auc: 0.8187 - loss: 0.3882 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1636\n","Epoch 91/100\n","\u001b[1m317/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8431 - auc: 0.8463 - loss: 0.3948\n","Epoch 91: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8434 - auc: 0.8461 - loss: 0.3946 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1732\n","Epoch 92/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8577 - auc: 0.8409 - loss: 0.3884\n","Epoch 92: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8577 - auc: 0.8409 - loss: 0.3885 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1812\n","Epoch 93/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8705 - auc: 0.8469 - loss: 0.3639\n","Epoch 93: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8700 - auc: 0.8465 - loss: 0.3647 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1917\n","Epoch 94/100\n","\u001b[1m315/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8421 - auc: 0.8228 - loss: 0.4026\n","Epoch 94: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8428 - auc: 0.8230 - loss: 0.4021 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1921\n","Epoch 95/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8562 - auc: 0.8709 - loss: 0.3626\n","Epoch 95: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8560 - auc: 0.8704 - loss: 0.3632 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2039\n","Epoch 96/100\n","\u001b[1m310/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8643 - auc: 0.8421 - loss: 0.3768\n","Epoch 96: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8638 - auc: 0.8427 - loss: 0.3768 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2153\n","Epoch 97/100\n","\u001b[1m315/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8550 - auc: 0.8283 - loss: 0.3838\n","Epoch 97: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8552 - auc: 0.8293 - loss: 0.3835 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2204\n","Epoch 98/100\n","\u001b[1m316/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8534 - auc: 0.8657 - loss: 0.3651\n","Epoch 98: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8538 - auc: 0.8653 - loss: 0.3656 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2278\n","Epoch 99/100\n","\u001b[1m309/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8398 - auc: 0.8613 - loss: 0.3868\n","Epoch 99: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8413 - auc: 0.8604 - loss: 0.3862 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2334\n","Epoch 100/100\n","\u001b[1m316/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8640 - auc: 0.8727 - loss: 0.3529\n","Epoch 100: val_loss did not improve from 0.80908\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8634 - auc: 0.8719 - loss: 0.3540 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2414\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 5 AUC: 1.0000\n","\n","--- Fold 6/10 ---\n"," train | ids:   36 | files:  927 | pos:  327 | neg:  600\n","   val | ids:    4 | files:  234 | pos:   77 | neg:  157\n","  test | ids:    4 | files:   39 | pos:    1 | neg:   38\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m291/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3294 - auc: 0.4238 - loss: 0.7364\n","Epoch 1: val_loss improved from inf to 0.67880, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - acc: 0.3310 - auc: 0.4240 - loss: 0.7353 - val_acc: 0.6154 - val_auc: 0.7134 - val_loss: 0.6788\n","Epoch 2/100\n","\u001b[1m290/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5429 - auc: 0.5500 - loss: 0.6760\n","Epoch 2: val_loss improved from 0.67880 to 0.62918, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.5464 - auc: 0.5539 - loss: 0.6754 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6292\n","Epoch 3/100\n","\u001b[1m290/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6699 - auc: 0.6519 - loss: 0.6448\n","Epoch 3: val_loss improved from 0.62918 to 0.60787, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6713 - auc: 0.6528 - loss: 0.6445 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6079\n","Epoch 4/100\n","\u001b[1m290/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7644 - auc: 0.6880 - loss: 0.6246\n","Epoch 4: val_loss improved from 0.60787 to 0.59244, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7663 - auc: 0.6889 - loss: 0.6244 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5924\n","Epoch 5/100\n","\u001b[1m290/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7741 - auc: 0.6975 - loss: 0.6156\n","Epoch 5: val_loss improved from 0.59244 to 0.58530, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7745 - auc: 0.6972 - loss: 0.6155 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5853\n","Epoch 6/100\n","\u001b[1m292/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7855 - auc: 0.6993 - loss: 0.6070\n","Epoch 6: val_loss improved from 0.58530 to 0.58186, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7861 - auc: 0.6994 - loss: 0.6066 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5819\n","Epoch 7/100\n","\u001b[1m288/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8144 - auc: 0.7185 - loss: 0.5919\n","Epoch 7: val_loss improved from 0.58186 to 0.58118, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8139 - auc: 0.7180 - loss: 0.5919 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5812\n","Epoch 8/100\n","\u001b[1m289/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7993 - auc: 0.7053 - loss: 0.5933\n","Epoch 8: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7986 - auc: 0.7049 - loss: 0.5934 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5814\n","Epoch 9/100\n","\u001b[1m294/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7790 - auc: 0.6945 - loss: 0.5990\n","Epoch 9: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7797 - auc: 0.6949 - loss: 0.5985 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5817\n","Epoch 10/100\n","\u001b[1m293/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7880 - auc: 0.6585 - loss: 0.5986\n","Epoch 10: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7882 - auc: 0.6585 - loss: 0.5984 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5840\n","Epoch 11/100\n","\u001b[1m289/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8160 - auc: 0.7256 - loss: 0.5757\n","Epoch 11: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8151 - auc: 0.7228 - loss: 0.5761 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5850\n","Epoch 12/100\n","\u001b[1m292/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7916 - auc: 0.6535 - loss: 0.5874\n","Epoch 12: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7924 - auc: 0.6565 - loss: 0.5864 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5857\n","Epoch 13/100\n","\u001b[1m307/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7859 - auc: 0.6967 - loss: 0.5820\n","Epoch 13: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7861 - auc: 0.6968 - loss: 0.5818 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5864\n","Epoch 14/100\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7883 - auc: 0.6745 - loss: 0.5815\n","Epoch 14: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7883 - auc: 0.6746 - loss: 0.5814 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5890\n","Epoch 15/100\n","\u001b[1m292/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7811 - auc: 0.7223 - loss: 0.5636\n","Epoch 15: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7820 - auc: 0.7222 - loss: 0.5632 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5916\n","Epoch 16/100\n","\u001b[1m289/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7747 - auc: 0.7435 - loss: 0.5559\n","Epoch 16: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7760 - auc: 0.7434 - loss: 0.5554 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5921\n","Epoch 17/100\n","\u001b[1m289/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7712 - auc: 0.6842 - loss: 0.5783\n","Epoch 17: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7716 - auc: 0.6861 - loss: 0.5772 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5953\n","Epoch 18/100\n","\u001b[1m293/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8123 - auc: 0.7614 - loss: 0.5332\n","Epoch 18: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8112 - auc: 0.7590 - loss: 0.5342 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5971\n","Epoch 19/100\n","\u001b[1m293/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8009 - auc: 0.7104 - loss: 0.5509\n","Epoch 19: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8008 - auc: 0.7109 - loss: 0.5506 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6001\n","Epoch 20/100\n","\u001b[1m290/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7930 - auc: 0.7107 - loss: 0.5477\n","Epoch 20: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7930 - auc: 0.7124 - loss: 0.5471 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6029\n","Epoch 21/100\n","\u001b[1m290/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7765 - auc: 0.7006 - loss: 0.5483\n","Epoch 21: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7781 - auc: 0.7033 - loss: 0.5470 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6046\n","Epoch 22/100\n","\u001b[1m294/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8268 - auc: 0.7308 - loss: 0.5169\n","Epoch 22: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8265 - auc: 0.7314 - loss: 0.5169 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6078\n","Epoch 23/100\n","\u001b[1m289/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8113 - auc: 0.7284 - loss: 0.5338\n","Epoch 23: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8109 - auc: 0.7295 - loss: 0.5331 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6101\n","Epoch 24/100\n","\u001b[1m293/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7953 - auc: 0.7216 - loss: 0.5316\n","Epoch 24: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7963 - auc: 0.7232 - loss: 0.5304 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6126\n","Epoch 25/100\n","\u001b[1m296/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8161 - auc: 0.7594 - loss: 0.4918\n","Epoch 25: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8156 - auc: 0.7597 - loss: 0.4922 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6148\n","Epoch 26/100\n","\u001b[1m306/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8207 - auc: 0.7676 - loss: 0.4912\n","Epoch 26: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8206 - auc: 0.7674 - loss: 0.4913 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6182\n","Epoch 27/100\n","\u001b[1m283/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8327 - auc: 0.8129 - loss: 0.4641\n","Epoch 27: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8315 - auc: 0.8078 - loss: 0.4665 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6223\n","Epoch 28/100\n","\u001b[1m285/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8020 - auc: 0.7520 - loss: 0.5069\n","Epoch 28: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8025 - auc: 0.7513 - loss: 0.5065 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6252\n","Epoch 29/100\n","\u001b[1m308/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7643 - auc: 0.7798 - loss: 0.5173\n","Epoch 29: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7645 - auc: 0.7797 - loss: 0.5172 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6279\n","Epoch 30/100\n","\u001b[1m286/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7901 - auc: 0.7541 - loss: 0.5151\n","Epoch 30: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7909 - auc: 0.7565 - loss: 0.5136 - val_acc: 0.6709 - val_auc: 0.6624 - val_loss: 0.6325\n","Epoch 31/100\n","\u001b[1m289/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8019 - auc: 0.7763 - loss: 0.4898\n","Epoch 31: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8019 - auc: 0.7758 - loss: 0.4901 - val_acc: 0.6709 - val_auc: 0.6624 - val_loss: 0.6358\n","Epoch 32/100\n","\u001b[1m287/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8227 - auc: 0.8058 - loss: 0.4687\n","Epoch 32: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8213 - auc: 0.8056 - loss: 0.4695 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6398\n","Epoch 33/100\n","\u001b[1m289/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8069 - auc: 0.7895 - loss: 0.4881\n","Epoch 33: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8061 - auc: 0.7895 - loss: 0.4883 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6420\n","Epoch 34/100\n","\u001b[1m285/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7920 - auc: 0.8183 - loss: 0.4749\n","Epoch 34: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7927 - auc: 0.8175 - loss: 0.4749 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6462\n","Epoch 35/100\n","\u001b[1m290/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8219 - auc: 0.8119 - loss: 0.4668\n","Epoch 35: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8214 - auc: 0.8116 - loss: 0.4670 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6493\n","Epoch 36/100\n","\u001b[1m290/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8092 - auc: 0.7933 - loss: 0.4760\n","Epoch 36: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8090 - auc: 0.7941 - loss: 0.4757 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6528\n","Epoch 37/100\n","\u001b[1m291/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8139 - auc: 0.7921 - loss: 0.4592\n","Epoch 37: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8133 - auc: 0.7936 - loss: 0.4592 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6590\n","Epoch 38/100\n","\u001b[1m285/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8202 - auc: 0.8439 - loss: 0.4398\n","Epoch 38: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8198 - auc: 0.8423 - loss: 0.4407 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6635\n","Epoch 39/100\n","\u001b[1m284/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8161 - auc: 0.8251 - loss: 0.4476\n","Epoch 39: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8145 - auc: 0.8254 - loss: 0.4482 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6679\n","Epoch 40/100\n","\u001b[1m285/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8246 - auc: 0.8075 - loss: 0.4480\n","Epoch 40: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8234 - auc: 0.8080 - loss: 0.4487 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6726\n","Epoch 41/100\n","\u001b[1m308/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7896 - auc: 0.8050 - loss: 0.4695\n","Epoch 41: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7897 - auc: 0.8050 - loss: 0.4695 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6765\n","Epoch 42/100\n","\u001b[1m305/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8117 - auc: 0.7919 - loss: 0.4559\n","Epoch 42: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8118 - auc: 0.7920 - loss: 0.4558 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6791\n","Epoch 43/100\n","\u001b[1m295/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7743 - auc: 0.7924 - loss: 0.4807\n","Epoch 43: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7758 - auc: 0.7939 - loss: 0.4791 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6832\n","Epoch 44/100\n","\u001b[1m285/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8237 - auc: 0.8362 - loss: 0.4232\n","Epoch 44: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8232 - auc: 0.8345 - loss: 0.4243 - val_acc: 0.6709 - val_auc: 0.2866 - val_loss: 0.6881\n","Epoch 45/100\n","\u001b[1m307/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8038 - auc: 0.7788 - loss: 0.4660\n","Epoch 45: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8038 - auc: 0.7791 - loss: 0.4659 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.6939\n","Epoch 46/100\n","\u001b[1m288/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8334 - auc: 0.8253 - loss: 0.4170\n","Epoch 46: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8318 - auc: 0.8257 - loss: 0.4179 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.6984\n","Epoch 47/100\n","\u001b[1m290/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7892 - auc: 0.7826 - loss: 0.4707\n","Epoch 47: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7904 - auc: 0.7855 - loss: 0.4688 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7032\n","Epoch 48/100\n","\u001b[1m284/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7955 - auc: 0.7999 - loss: 0.4617\n","Epoch 48: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7963 - auc: 0.8017 - loss: 0.4603 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7068\n","Epoch 49/100\n","\u001b[1m287/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8235 - auc: 0.8510 - loss: 0.4190\n","Epoch 49: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8229 - auc: 0.8504 - loss: 0.4196 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7126\n","Epoch 50/100\n","\u001b[1m288/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8011 - auc: 0.8517 - loss: 0.4302\n","Epoch 50: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8015 - auc: 0.8514 - loss: 0.4300 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7181\n","Epoch 51/100\n","\u001b[1m289/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8314 - auc: 0.8228 - loss: 0.4282\n","Epoch 51: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8318 - auc: 0.8232 - loss: 0.4278 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7188\n","Epoch 52/100\n","\u001b[1m288/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8477 - auc: 0.8617 - loss: 0.3980\n","Epoch 52: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8463 - auc: 0.8601 - loss: 0.3995 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7253\n","Epoch 53/100\n","\u001b[1m286/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8101 - auc: 0.8682 - loss: 0.4148\n","Epoch 53: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8095 - auc: 0.8667 - loss: 0.4161 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7296\n","Epoch 54/100\n","\u001b[1m292/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7944 - auc: 0.8126 - loss: 0.4557\n","Epoch 54: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7954 - auc: 0.8139 - loss: 0.4545 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7332\n","Epoch 55/100\n","\u001b[1m289/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7998 - auc: 0.8180 - loss: 0.4400\n","Epoch 55: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8007 - auc: 0.8197 - loss: 0.4390 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7360\n","Epoch 56/100\n","\u001b[1m305/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8030 - auc: 0.8234 - loss: 0.4460\n","Epoch 56: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8032 - auc: 0.8239 - loss: 0.4456 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7384\n","Epoch 57/100\n","\u001b[1m307/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8174 - auc: 0.8313 - loss: 0.4323\n","Epoch 57: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8174 - auc: 0.8313 - loss: 0.4322 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7388\n","Epoch 58/100\n","\u001b[1m299/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8281 - auc: 0.8417 - loss: 0.4120\n","Epoch 58: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8279 - auc: 0.8422 - loss: 0.4120 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7440\n","Epoch 59/100\n","\u001b[1m287/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8400 - auc: 0.8657 - loss: 0.3909\n","Epoch 59: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8386 - auc: 0.8636 - loss: 0.3928 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7469\n","Epoch 60/100\n","\u001b[1m290/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8393 - auc: 0.8592 - loss: 0.4002\n","Epoch 60: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8388 - auc: 0.8595 - loss: 0.4006 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7518\n","Epoch 61/100\n","\u001b[1m289/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8339 - auc: 0.8567 - loss: 0.4038\n","Epoch 61: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8334 - auc: 0.8570 - loss: 0.4042 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7555\n","Epoch 62/100\n","\u001b[1m286/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8333 - auc: 0.8433 - loss: 0.4080\n","Epoch 62: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8325 - auc: 0.8438 - loss: 0.4082 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7583\n","Epoch 63/100\n","\u001b[1m293/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8090 - auc: 0.8663 - loss: 0.4085\n","Epoch 63: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8095 - auc: 0.8658 - loss: 0.4086 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7610\n","Epoch 64/100\n","\u001b[1m293/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8236 - auc: 0.8713 - loss: 0.3972\n","Epoch 64: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8238 - auc: 0.8710 - loss: 0.3974 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7647\n","Epoch 65/100\n","\u001b[1m290/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8164 - auc: 0.8742 - loss: 0.4000\n","Epoch 65: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8169 - auc: 0.8740 - loss: 0.3999 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7679\n","Epoch 66/100\n","\u001b[1m294/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8047 - auc: 0.8565 - loss: 0.4127\n","Epoch 66: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8044 - auc: 0.8566 - loss: 0.4131 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7726\n","Epoch 67/100\n","\u001b[1m291/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8347 - auc: 0.8953 - loss: 0.3785\n","Epoch 67: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8338 - auc: 0.8940 - loss: 0.3797 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7762\n","Epoch 68/100\n","\u001b[1m293/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8355 - auc: 0.8913 - loss: 0.3776\n","Epoch 68: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8347 - auc: 0.8899 - loss: 0.3791 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7770\n","Epoch 69/100\n","\u001b[1m292/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8266 - auc: 0.8745 - loss: 0.3919\n","Epoch 69: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8266 - auc: 0.8745 - loss: 0.3918 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7813\n","Epoch 70/100\n","\u001b[1m287/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8410 - auc: 0.8916 - loss: 0.3723\n","Epoch 70: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8394 - auc: 0.8907 - loss: 0.3742 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7865\n","Epoch 71/100\n","\u001b[1m286/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8353 - auc: 0.8865 - loss: 0.3853\n","Epoch 71: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8341 - auc: 0.8863 - loss: 0.3862 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7908\n","Epoch 72/100\n","\u001b[1m286/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8042 - auc: 0.8526 - loss: 0.4082\n","Epoch 72: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8056 - auc: 0.8532 - loss: 0.4076 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7915\n","Epoch 73/100\n","\u001b[1m303/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8334 - auc: 0.8860 - loss: 0.3817\n","Epoch 73: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8333 - auc: 0.8861 - loss: 0.3816 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7944\n","Epoch 74/100\n","\u001b[1m289/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8315 - auc: 0.8831 - loss: 0.3787\n","Epoch 74: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8315 - auc: 0.8837 - loss: 0.3788 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7968\n","Epoch 75/100\n","\u001b[1m286/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8099 - auc: 0.8545 - loss: 0.4135\n","Epoch 75: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8109 - auc: 0.8563 - loss: 0.4117 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7937\n","Epoch 76/100\n","\u001b[1m291/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8000 - auc: 0.8840 - loss: 0.4059\n","Epoch 76: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8004 - auc: 0.8838 - loss: 0.4055 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7947\n","Epoch 77/100\n","\u001b[1m290/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8175 - auc: 0.8986 - loss: 0.3779\n","Epoch 77: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8179 - auc: 0.8976 - loss: 0.3783 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7976\n","Epoch 78/100\n","\u001b[1m294/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8325 - auc: 0.9000 - loss: 0.3626\n","Epoch 78: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8325 - auc: 0.8999 - loss: 0.3628 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8014\n","Epoch 79/100\n","\u001b[1m292/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8047 - auc: 0.8708 - loss: 0.4019\n","Epoch 79: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8059 - auc: 0.8724 - loss: 0.4002 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8035\n","Epoch 80/100\n","\u001b[1m288/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8309 - auc: 0.8776 - loss: 0.3757\n","Epoch 80: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8302 - auc: 0.8788 - loss: 0.3754 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8063\n","Epoch 81/100\n","\u001b[1m292/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8122 - auc: 0.8771 - loss: 0.3925\n","Epoch 81: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8126 - auc: 0.8783 - loss: 0.3913 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8095\n","Epoch 82/100\n","\u001b[1m296/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8345 - auc: 0.9067 - loss: 0.3638\n","Epoch 82: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8339 - auc: 0.9065 - loss: 0.3640 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8132\n","Epoch 83/100\n","\u001b[1m290/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8414 - auc: 0.9077 - loss: 0.3461\n","Epoch 83: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8406 - auc: 0.9077 - loss: 0.3467 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8216\n","Epoch 84/100\n","\u001b[1m293/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7980 - auc: 0.9004 - loss: 0.3876\n","Epoch 84: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7990 - auc: 0.9005 - loss: 0.3867 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8271\n","Epoch 85/100\n","\u001b[1m295/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8214 - auc: 0.8955 - loss: 0.3724\n","Epoch 85: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8218 - auc: 0.8963 - loss: 0.3716 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8338\n","Epoch 86/100\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8340 - auc: 0.9126 - loss: 0.3496\n","Epoch 86: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8340 - auc: 0.9126 - loss: 0.3496 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8390\n","Epoch 87/100\n","\u001b[1m307/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8333 - auc: 0.9036 - loss: 0.3612\n","Epoch 87: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8333 - auc: 0.9038 - loss: 0.3611 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8466\n","Epoch 88/100\n","\u001b[1m306/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8008 - auc: 0.8839 - loss: 0.3859\n","Epoch 88: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8012 - auc: 0.8842 - loss: 0.3855 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8514\n","Epoch 89/100\n","\u001b[1m289/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8273 - auc: 0.9075 - loss: 0.3488\n","Epoch 89: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8278 - auc: 0.9076 - loss: 0.3484 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8578\n","Epoch 90/100\n","\u001b[1m289/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8080 - auc: 0.8997 - loss: 0.3699\n","Epoch 90: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8082 - auc: 0.9001 - loss: 0.3696 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8636\n","Epoch 91/100\n","\u001b[1m297/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8359 - auc: 0.9264 - loss: 0.3367\n","Epoch 91: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8362 - auc: 0.9261 - loss: 0.3369 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8707\n","Epoch 92/100\n","\u001b[1m295/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8209 - auc: 0.9117 - loss: 0.3475\n","Epoch 92: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8213 - auc: 0.9117 - loss: 0.3475 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8757\n","Epoch 93/100\n","\u001b[1m286/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8410 - auc: 0.9201 - loss: 0.3297\n","Epoch 93: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8401 - auc: 0.9201 - loss: 0.3305 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8819\n","Epoch 94/100\n","\u001b[1m289/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8110 - auc: 0.8961 - loss: 0.3653\n","Epoch 94: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8123 - auc: 0.8974 - loss: 0.3636 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8870\n","Epoch 95/100\n","\u001b[1m292/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8548 - auc: 0.9328 - loss: 0.3169\n","Epoch 95: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8534 - auc: 0.9320 - loss: 0.3183 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8920\n","Epoch 96/100\n","\u001b[1m291/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8260 - auc: 0.9063 - loss: 0.3501\n","Epoch 96: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8262 - auc: 0.9075 - loss: 0.3492 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8986\n","Epoch 97/100\n","\u001b[1m291/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8164 - auc: 0.9036 - loss: 0.3634\n","Epoch 97: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8170 - auc: 0.9043 - loss: 0.3622 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.9043\n","Epoch 98/100\n","\u001b[1m292/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8213 - auc: 0.9184 - loss: 0.3405\n","Epoch 98: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8212 - auc: 0.9186 - loss: 0.3407 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.9093\n","Epoch 99/100\n","\u001b[1m295/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8322 - auc: 0.9120 - loss: 0.3464\n","Epoch 99: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8320 - auc: 0.9123 - loss: 0.3461 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.9138\n","Epoch 100/100\n","\u001b[1m287/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8352 - auc: 0.9257 - loss: 0.3298\n","Epoch 100: val_loss did not improve from 0.58118\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8353 - auc: 0.9259 - loss: 0.3299 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.9211\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 6 AUC: 0.6316\n","\n","--- Fold 7/10 ---\n"," train | ids:   36 | files:  842 | pos:  290 | neg:  552\n","   val | ids:    4 | files:  220 | pos:   77 | neg:  143\n","  test | ids:    4 | files:  138 | pos:   38 | neg:  100\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m268/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.4454 - auc: 0.5378 - loss: 1.0138\n","Epoch 1: val_loss improved from inf to 0.96187, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - acc: 0.4458 - auc: 0.5372 - loss: 1.0115 - val_acc: 0.3500 - val_auc: 0.0490 - val_loss: 0.9619\n","Epoch 2/100\n","\u001b[1m265/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4607 - auc: 0.5782 - loss: 0.8846\n","Epoch 2: val_loss improved from 0.96187 to 0.87706, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.4601 - auc: 0.5802 - loss: 0.8833 - val_acc: 0.3500 - val_auc: 0.0490 - val_loss: 0.8771\n","Epoch 3/100\n","\u001b[1m269/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4479 - auc: 0.7375 - loss: 0.8016\n","Epoch 3: val_loss improved from 0.87706 to 0.81518, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.4481 - auc: 0.7371 - loss: 0.8002 - val_acc: 0.3500 - val_auc: 0.1853 - val_loss: 0.8152\n","Epoch 4/100\n","\u001b[1m264/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4737 - auc: 0.8313 - loss: 0.7003\n","Epoch 4: val_loss improved from 0.81518 to 0.77108, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.4733 - auc: 0.8296 - loss: 0.7002 - val_acc: 0.3500 - val_auc: 0.0490 - val_loss: 0.7711\n","Epoch 5/100\n","\u001b[1m260/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4650 - auc: 0.8847 - loss: 0.6500\n","Epoch 5: val_loss improved from 0.77108 to 0.73700, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.4640 - auc: 0.8850 - loss: 0.6496 - val_acc: 0.3500 - val_auc: 0.1853 - val_loss: 0.7370\n","Epoch 6/100\n","\u001b[1m267/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6029 - auc: 0.9001 - loss: 0.6078\n","Epoch 6: val_loss improved from 0.73700 to 0.71306, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6049 - auc: 0.9000 - loss: 0.6073 - val_acc: 0.2409 - val_auc: 0.0490 - val_loss: 0.7131\n","Epoch 7/100\n","\u001b[1m261/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7378 - auc: 0.9237 - loss: 0.5740\n","Epoch 7: val_loss improved from 0.71306 to 0.69832, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7419 - auc: 0.9229 - loss: 0.5737 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6983\n","Epoch 8/100\n","\u001b[1m260/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9207 - auc: 0.9330 - loss: 0.5525\n","Epoch 8: val_loss improved from 0.69832 to 0.69337, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9182 - auc: 0.9323 - loss: 0.5526 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6934\n","Epoch 9/100\n","\u001b[1m256/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8930 - auc: 0.9296 - loss: 0.5501\n","Epoch 9: val_loss improved from 0.69337 to 0.69326, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8918 - auc: 0.9292 - loss: 0.5498 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6933\n","Epoch 10/100\n","\u001b[1m258/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8835 - auc: 0.9328 - loss: 0.5356\n","Epoch 10: val_loss improved from 0.69326 to 0.69025, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8836 - auc: 0.9336 - loss: 0.5353 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6903\n","Epoch 11/100\n","\u001b[1m276/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8673 - auc: 0.9334 - loss: 0.5374\n","Epoch 11: val_loss improved from 0.69025 to 0.68866, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8677 - auc: 0.9335 - loss: 0.5371 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6887\n","Epoch 12/100\n","\u001b[1m262/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8860 - auc: 0.9350 - loss: 0.5155\n","Epoch 12: val_loss improved from 0.68866 to 0.68620, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8858 - auc: 0.9359 - loss: 0.5160 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6862\n","Epoch 13/100\n","\u001b[1m261/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8677 - auc: 0.9593 - loss: 0.5131\n","Epoch 13: val_loss improved from 0.68620 to 0.68477, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8685 - auc: 0.9591 - loss: 0.5132 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6848\n","Epoch 14/100\n","\u001b[1m268/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8853 - auc: 0.9521 - loss: 0.4962\n","Epoch 14: val_loss improved from 0.68477 to 0.68340, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8852 - auc: 0.9523 - loss: 0.4967 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6834\n","Epoch 15/100\n","\u001b[1m267/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8569 - auc: 0.9401 - loss: 0.5064\n","Epoch 15: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8582 - auc: 0.9402 - loss: 0.5059 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6858\n","Epoch 16/100\n","\u001b[1m265/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8940 - auc: 0.9442 - loss: 0.4917\n","Epoch 16: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8935 - auc: 0.9446 - loss: 0.4916 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6876\n","Epoch 17/100\n","\u001b[1m259/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8710 - auc: 0.9459 - loss: 0.4900\n","Epoch 17: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8722 - auc: 0.9462 - loss: 0.4895 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6890\n","Epoch 18/100\n","\u001b[1m265/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8822 - auc: 0.9599 - loss: 0.4838\n","Epoch 18: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8823 - auc: 0.9585 - loss: 0.4835 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6888\n","Epoch 19/100\n","\u001b[1m269/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8768 - auc: 0.9445 - loss: 0.4840\n","Epoch 19: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8772 - auc: 0.9445 - loss: 0.4834 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6898\n","Epoch 20/100\n","\u001b[1m268/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8928 - auc: 0.9480 - loss: 0.4678\n","Epoch 20: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8923 - auc: 0.9475 - loss: 0.4679 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6916\n","Epoch 21/100\n","\u001b[1m269/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8738 - auc: 0.9410 - loss: 0.4821\n","Epoch 21: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8743 - auc: 0.9410 - loss: 0.4813 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6916\n","Epoch 22/100\n","\u001b[1m264/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8819 - auc: 0.9292 - loss: 0.4635\n","Epoch 22: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8818 - auc: 0.9289 - loss: 0.4635 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6941\n","Epoch 23/100\n","\u001b[1m266/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8858 - auc: 0.9330 - loss: 0.4444\n","Epoch 23: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8857 - auc: 0.9331 - loss: 0.4450 - val_acc: 0.4727 - val_auc: 0.0490 - val_loss: 0.6952\n","Epoch 24/100\n","\u001b[1m264/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8853 - auc: 0.9445 - loss: 0.4397\n","Epoch 24: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8853 - auc: 0.9438 - loss: 0.4402 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6919\n","Epoch 25/100\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9104 - auc: 0.9626 - loss: 0.4218\n","Epoch 25: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9103 - auc: 0.9625 - loss: 0.4219 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6948\n","Epoch 26/100\n","\u001b[1m258/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8549 - auc: 0.9336 - loss: 0.4541\n","Epoch 26: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8569 - auc: 0.9339 - loss: 0.4531 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6946\n","Epoch 27/100\n","\u001b[1m278/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8651 - auc: 0.9273 - loss: 0.4435\n","Epoch 27: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8654 - auc: 0.9276 - loss: 0.4434 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6946\n","Epoch 28/100\n","\u001b[1m264/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8990 - auc: 0.9528 - loss: 0.4205\n","Epoch 28: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8978 - auc: 0.9523 - loss: 0.4214 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6965\n","Epoch 29/100\n","\u001b[1m265/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8984 - auc: 0.9614 - loss: 0.4230\n","Epoch 29: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8974 - auc: 0.9607 - loss: 0.4233 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6994\n","Epoch 30/100\n","\u001b[1m264/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8867 - auc: 0.9343 - loss: 0.4203\n","Epoch 30: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8863 - auc: 0.9341 - loss: 0.4207 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6956\n","Epoch 31/100\n","\u001b[1m263/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8906 - auc: 0.9540 - loss: 0.3985\n","Epoch 31: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8902 - auc: 0.9534 - loss: 0.3999 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6984\n","Epoch 32/100\n","\u001b[1m266/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8962 - auc: 0.9396 - loss: 0.4131\n","Epoch 32: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8953 - auc: 0.9393 - loss: 0.4134 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6991\n","Epoch 33/100\n","\u001b[1m265/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8875 - auc: 0.9417 - loss: 0.4167\n","Epoch 33: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8873 - auc: 0.9429 - loss: 0.4165 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6998\n","Epoch 34/100\n","\u001b[1m261/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8701 - auc: 0.9263 - loss: 0.4248\n","Epoch 34: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8711 - auc: 0.9269 - loss: 0.4237 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6973\n","Epoch 35/100\n","\u001b[1m260/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8770 - auc: 0.9463 - loss: 0.4115\n","Epoch 35: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8779 - auc: 0.9460 - loss: 0.4109 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6986\n","Epoch 36/100\n","\u001b[1m262/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8859 - auc: 0.9380 - loss: 0.4044\n","Epoch 36: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8856 - auc: 0.9384 - loss: 0.4046 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7008\n","Epoch 37/100\n","\u001b[1m264/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8761 - auc: 0.9213 - loss: 0.4134\n","Epoch 37: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8765 - auc: 0.9215 - loss: 0.4127 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6996\n","Epoch 38/100\n","\u001b[1m269/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8902 - auc: 0.9542 - loss: 0.3836\n","Epoch 38: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8898 - auc: 0.9530 - loss: 0.3843 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6998\n","Epoch 39/100\n","\u001b[1m264/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8829 - auc: 0.9576 - loss: 0.3936\n","Epoch 39: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8830 - auc: 0.9570 - loss: 0.3937 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6986\n","Epoch 40/100\n","\u001b[1m266/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8846 - auc: 0.9353 - loss: 0.3866\n","Epoch 40: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8844 - auc: 0.9359 - loss: 0.3868 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7027\n","Epoch 41/100\n","\u001b[1m257/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8796 - auc: 0.9398 - loss: 0.3984\n","Epoch 41: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8797 - auc: 0.9408 - loss: 0.3977 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7010\n","Epoch 42/100\n","\u001b[1m261/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8891 - auc: 0.9430 - loss: 0.3904\n","Epoch 42: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8886 - auc: 0.9420 - loss: 0.3902 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7003\n","Epoch 43/100\n","\u001b[1m276/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8898 - auc: 0.9455 - loss: 0.3760\n","Epoch 43: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8896 - auc: 0.9457 - loss: 0.3761 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7005\n","Epoch 44/100\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8848 - auc: 0.9061 - loss: 0.3915\n","Epoch 44: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8848 - auc: 0.9062 - loss: 0.3914 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7030\n","Epoch 45/100\n","\u001b[1m263/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8813 - auc: 0.9260 - loss: 0.3750\n","Epoch 45: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8812 - auc: 0.9267 - loss: 0.3754 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7017\n","Epoch 46/100\n","\u001b[1m265/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8657 - auc: 0.9428 - loss: 0.3917\n","Epoch 46: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8668 - auc: 0.9427 - loss: 0.3907 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7024\n","Epoch 47/100\n","\u001b[1m270/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8826 - auc: 0.9366 - loss: 0.3795\n","Epoch 47: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8828 - auc: 0.9370 - loss: 0.3792 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7034\n","Epoch 48/100\n","\u001b[1m264/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8954 - auc: 0.9355 - loss: 0.3581\n","Epoch 48: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8946 - auc: 0.9361 - loss: 0.3590 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7055\n","Epoch 49/100\n","\u001b[1m270/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8557 - auc: 0.9372 - loss: 0.3833\n","Epoch 49: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8569 - auc: 0.9374 - loss: 0.3828 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7029\n","Epoch 50/100\n","\u001b[1m268/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9002 - auc: 0.9453 - loss: 0.3467\n","Epoch 50: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8994 - auc: 0.9458 - loss: 0.3476 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7065\n","Epoch 51/100\n","\u001b[1m262/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8632 - auc: 0.9390 - loss: 0.3769\n","Epoch 51: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8647 - auc: 0.9395 - loss: 0.3758 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7064\n","Epoch 52/100\n","\u001b[1m265/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8611 - auc: 0.9472 - loss: 0.3842\n","Epoch 52: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8624 - auc: 0.9468 - loss: 0.3829 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7051\n","Epoch 53/100\n","\u001b[1m265/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8944 - auc: 0.9253 - loss: 0.3470\n","Epoch 53: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8937 - auc: 0.9263 - loss: 0.3478 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7070\n","Epoch 54/100\n","\u001b[1m267/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8947 - auc: 0.9569 - loss: 0.3406\n","Epoch 54: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8941 - auc: 0.9562 - loss: 0.3415 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7133\n","Epoch 55/100\n","\u001b[1m269/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8943 - auc: 0.9557 - loss: 0.3471\n","Epoch 55: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8938 - auc: 0.9554 - loss: 0.3475 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7091\n","Epoch 56/100\n","\u001b[1m261/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8886 - auc: 0.9547 - loss: 0.3469\n","Epoch 56: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8880 - auc: 0.9545 - loss: 0.3475 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7122\n","Epoch 57/100\n","\u001b[1m277/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8885 - auc: 0.9465 - loss: 0.3403\n","Epoch 57: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8884 - auc: 0.9465 - loss: 0.3405 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7124\n","Epoch 58/100\n","\u001b[1m262/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8571 - auc: 0.9010 - loss: 0.3780\n","Epoch 58: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8589 - auc: 0.9028 - loss: 0.3762 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7183\n","Epoch 59/100\n","\u001b[1m274/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8644 - auc: 0.9088 - loss: 0.3753\n","Epoch 59: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8649 - auc: 0.9096 - loss: 0.3746 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7183\n","Epoch 60/100\n","\u001b[1m264/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8942 - auc: 0.9583 - loss: 0.3342\n","Epoch 60: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8934 - auc: 0.9573 - loss: 0.3352 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7205\n","Epoch 61/100\n","\u001b[1m263/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9061 - auc: 0.9373 - loss: 0.3305\n","Epoch 61: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9046 - auc: 0.9379 - loss: 0.3313 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7230\n","Epoch 62/100\n","\u001b[1m264/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8889 - auc: 0.9394 - loss: 0.3359\n","Epoch 62: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8884 - auc: 0.9391 - loss: 0.3364 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7267\n","Epoch 63/100\n","\u001b[1m267/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8974 - auc: 0.9473 - loss: 0.3263\n","Epoch 63: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8967 - auc: 0.9468 - loss: 0.3271 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7293\n","Epoch 64/100\n","\u001b[1m267/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8643 - auc: 0.9407 - loss: 0.3651\n","Epoch 64: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8652 - auc: 0.9411 - loss: 0.3637 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7301\n","Epoch 65/100\n","\u001b[1m269/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8864 - auc: 0.9544 - loss: 0.3340\n","Epoch 65: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8862 - auc: 0.9541 - loss: 0.3341 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7316\n","Epoch 66/100\n","\u001b[1m266/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8801 - auc: 0.9010 - loss: 0.3478\n","Epoch 66: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8802 - auc: 0.9031 - loss: 0.3474 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7345\n","Epoch 67/100\n","\u001b[1m269/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8862 - auc: 0.9057 - loss: 0.3466\n","Epoch 67: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8861 - auc: 0.9068 - loss: 0.3463 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7374\n","Epoch 68/100\n","\u001b[1m264/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8897 - auc: 0.9458 - loss: 0.3358\n","Epoch 68: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8890 - auc: 0.9455 - loss: 0.3360 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7371\n","Epoch 69/100\n","\u001b[1m260/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8639 - auc: 0.9377 - loss: 0.3557\n","Epoch 69: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8652 - auc: 0.9376 - loss: 0.3541 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7444\n","Epoch 70/100\n","\u001b[1m263/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8679 - auc: 0.9307 - loss: 0.3432\n","Epoch 70: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8686 - auc: 0.9306 - loss: 0.3429 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7415\n","Epoch 71/100\n","\u001b[1m264/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8865 - auc: 0.9408 - loss: 0.3329\n","Epoch 71: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8862 - auc: 0.9409 - loss: 0.3329 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7476\n","Epoch 72/100\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8920 - auc: 0.9402 - loss: 0.3248\n","Epoch 72: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8919 - auc: 0.9402 - loss: 0.3248 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7472\n","Epoch 73/100\n","\u001b[1m279/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8802 - auc: 0.9352 - loss: 0.3335\n","Epoch 73: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8803 - auc: 0.9354 - loss: 0.3334 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7503\n","Epoch 74/100\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8762 - auc: 0.9353 - loss: 0.3296\n","Epoch 74: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8762 - auc: 0.9353 - loss: 0.3295 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7588\n","Epoch 75/100\n","\u001b[1m277/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8717 - auc: 0.9159 - loss: 0.3424\n","Epoch 75: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8720 - auc: 0.9161 - loss: 0.3421 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7537\n","Epoch 76/100\n","\u001b[1m264/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8907 - auc: 0.9397 - loss: 0.3132\n","Epoch 76: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8902 - auc: 0.9396 - loss: 0.3139 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7589\n","Epoch 77/100\n","\u001b[1m268/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8735 - auc: 0.9212 - loss: 0.3397\n","Epoch 77: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8740 - auc: 0.9220 - loss: 0.3389 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7605\n","Epoch 78/100\n","\u001b[1m263/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8968 - auc: 0.9103 - loss: 0.3143\n","Epoch 78: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8959 - auc: 0.9118 - loss: 0.3149 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7612\n","Epoch 79/100\n","\u001b[1m262/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8826 - auc: 0.9432 - loss: 0.3246\n","Epoch 79: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8827 - auc: 0.9430 - loss: 0.3243 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7649\n","Epoch 80/100\n","\u001b[1m271/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8743 - auc: 0.9354 - loss: 0.3325\n","Epoch 80: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8746 - auc: 0.9361 - loss: 0.3319 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7716\n","Epoch 81/100\n","\u001b[1m264/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8774 - auc: 0.9249 - loss: 0.3326\n","Epoch 81: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8778 - auc: 0.9263 - loss: 0.3316 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7758\n","Epoch 82/100\n","\u001b[1m266/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8904 - auc: 0.9514 - loss: 0.3047\n","Epoch 82: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8900 - auc: 0.9509 - loss: 0.3053 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7765\n","Epoch 83/100\n","\u001b[1m263/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8954 - auc: 0.9351 - loss: 0.3011\n","Epoch 83: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8944 - auc: 0.9353 - loss: 0.3022 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7788\n","Epoch 84/100\n","\u001b[1m268/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8792 - auc: 0.9365 - loss: 0.3185\n","Epoch 84: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8794 - auc: 0.9368 - loss: 0.3182 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7824\n","Epoch 85/100\n","\u001b[1m262/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8821 - auc: 0.9489 - loss: 0.3178\n","Epoch 85: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8822 - auc: 0.9492 - loss: 0.3172 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7846\n","Epoch 86/100\n","\u001b[1m266/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8871 - auc: 0.9385 - loss: 0.3073\n","Epoch 86: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8869 - auc: 0.9389 - loss: 0.3075 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7861\n","Epoch 87/100\n","\u001b[1m269/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8771 - auc: 0.9375 - loss: 0.3202\n","Epoch 87: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8773 - auc: 0.9374 - loss: 0.3198 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7942\n","Epoch 88/100\n","\u001b[1m268/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8855 - auc: 0.9378 - loss: 0.3083\n","Epoch 88: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8854 - auc: 0.9376 - loss: 0.3084 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7907\n","Epoch 89/100\n","\u001b[1m261/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8882 - auc: 0.9343 - loss: 0.3061\n","Epoch 89: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8878 - auc: 0.9338 - loss: 0.3067 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7911\n","Epoch 90/100\n","\u001b[1m261/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8890 - auc: 0.9406 - loss: 0.2988\n","Epoch 90: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8886 - auc: 0.9397 - loss: 0.2996 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7927\n","Epoch 91/100\n","\u001b[1m279/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8813 - auc: 0.9428 - loss: 0.3087\n","Epoch 91: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8813 - auc: 0.9428 - loss: 0.3087 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7939\n","Epoch 92/100\n","\u001b[1m266/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8933 - auc: 0.9500 - loss: 0.2890\n","Epoch 92: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8928 - auc: 0.9494 - loss: 0.2898 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.8044\n","Epoch 93/100\n","\u001b[1m272/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8836 - auc: 0.9262 - loss: 0.3126\n","Epoch 93: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8836 - auc: 0.9264 - loss: 0.3124 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7986\n","Epoch 94/100\n","\u001b[1m268/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8812 - auc: 0.9378 - loss: 0.3052\n","Epoch 94: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8814 - auc: 0.9379 - loss: 0.3049 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.8006\n","Epoch 95/100\n","\u001b[1m267/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8870 - auc: 0.9430 - loss: 0.2905\n","Epoch 95: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8869 - auc: 0.9430 - loss: 0.2910 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.8083\n","Epoch 96/100\n","\u001b[1m264/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8929 - auc: 0.9453 - loss: 0.2919\n","Epoch 96: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8923 - auc: 0.9453 - loss: 0.2923 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.8129\n","Epoch 97/100\n","\u001b[1m256/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9024 - auc: 0.9483 - loss: 0.2749\n","Epoch 97: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9006 - auc: 0.9475 - loss: 0.2771 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.8125\n","Epoch 98/100\n","\u001b[1m262/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8883 - auc: 0.9422 - loss: 0.2960\n","Epoch 98: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8878 - auc: 0.9416 - loss: 0.2965 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.8178\n","Epoch 99/100\n","\u001b[1m265/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8570 - auc: 0.8928 - loss: 0.3429\n","Epoch 99: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8585 - auc: 0.8956 - loss: 0.3404 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.8231\n","Epoch 100/100\n","\u001b[1m266/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8576 - auc: 0.9324 - loss: 0.3275\n","Epoch 100: val_loss did not improve from 0.68340\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8591 - auc: 0.9329 - loss: 0.3257 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.8175\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 7 AUC: 0.1550\n","\n","--- Fold 8/10 ---\n"," train | ids:   36 | files:  928 | pos:  269 | neg:  659\n","   val | ids:    4 | files:  192 | pos:   77 | neg:  115\n","  test | ids:    4 | files:   80 | pos:   59 | neg:   21\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.3615 - auc: 0.5248 - loss: 0.7703\n","Epoch 1: val_loss improved from inf to 0.71612, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - acc: 0.3612 - auc: 0.5252 - loss: 0.7702 - val_acc: 0.4010 - val_auc: 0.0000e+00 - val_loss: 0.7161\n","Epoch 2/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3840 - auc: 0.6230 - loss: 0.7149\n","Epoch 2: val_loss improved from 0.71612 to 0.70013, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.3847 - auc: 0.6250 - loss: 0.7141 - val_acc: 0.4010 - val_auc: 0.1000 - val_loss: 0.7001\n","Epoch 3/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5111 - auc: 0.7359 - loss: 0.6722\n","Epoch 3: val_loss improved from 0.70013 to 0.68975, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.5173 - auc: 0.7357 - loss: 0.6719 - val_acc: 0.5990 - val_auc: 0.0000e+00 - val_loss: 0.6898\n","Epoch 4/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6990 - auc: 0.6532 - loss: 0.6540\n","Epoch 4: val_loss improved from 0.68975 to 0.68422, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7016 - auc: 0.6545 - loss: 0.6534 - val_acc: 0.5990 - val_auc: 0.1522 - val_loss: 0.6842\n","Epoch 5/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8172 - auc: 0.6942 - loss: 0.6224\n","Epoch 5: val_loss improved from 0.68422 to 0.68026, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8157 - auc: 0.6917 - loss: 0.6226 - val_acc: 0.5990 - val_auc: 0.5000 - val_loss: 0.6803\n","Epoch 6/100\n","\u001b[1m293/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8375 - auc: 0.6083 - loss: 0.6121\n","Epoch 6: val_loss improved from 0.68026 to 0.67762, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8382 - auc: 0.6094 - loss: 0.6116 - val_acc: 0.5990 - val_auc: 0.1000 - val_loss: 0.6776\n","Epoch 7/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8446 - auc: 0.5546 - loss: 0.5988\n","Epoch 7: val_loss improved from 0.67762 to 0.67491, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8446 - auc: 0.5581 - loss: 0.5982 - val_acc: 0.5990 - val_auc: 0.4478 - val_loss: 0.6749\n","Epoch 8/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8630 - auc: 0.6613 - loss: 0.5710\n","Epoch 8: val_loss improved from 0.67491 to 0.67388, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8617 - auc: 0.6598 - loss: 0.5710 - val_acc: 0.5990 - val_auc: 0.4478 - val_loss: 0.6739\n","Epoch 9/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8382 - auc: 0.6252 - loss: 0.5762\n","Epoch 9: val_loss improved from 0.67388 to 0.67376, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8394 - auc: 0.6253 - loss: 0.5755 - val_acc: 0.5990 - val_auc: 0.4478 - val_loss: 0.6738\n","Epoch 10/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8333 - auc: 0.6211 - loss: 0.5656\n","Epoch 10: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8337 - auc: 0.6214 - loss: 0.5651 - val_acc: 0.5990 - val_auc: 0.4478 - val_loss: 0.6740\n","Epoch 11/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8402 - auc: 0.5843 - loss: 0.5549\n","Epoch 11: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8402 - auc: 0.5844 - loss: 0.5549 - val_acc: 0.5990 - val_auc: 0.4478 - val_loss: 0.6745\n","Epoch 12/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8451 - auc: 0.6047 - loss: 0.5460\n","Epoch 12: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8453 - auc: 0.6077 - loss: 0.5456 - val_acc: 0.5990 - val_auc: 0.4478 - val_loss: 0.6752\n","Epoch 13/100\n","\u001b[1m296/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8601 - auc: 0.6133 - loss: 0.5382\n","Epoch 13: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8595 - auc: 0.6147 - loss: 0.5382 - val_acc: 0.5990 - val_auc: 0.4478 - val_loss: 0.6761\n","Epoch 14/100\n","\u001b[1m304/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8508 - auc: 0.6613 - loss: 0.5254\n","Epoch 14: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8508 - auc: 0.6613 - loss: 0.5253 - val_acc: 0.5990 - val_auc: 0.5000 - val_loss: 0.6774\n","Epoch 15/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8474 - auc: 0.6776 - loss: 0.5154\n","Epoch 15: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8474 - auc: 0.6773 - loss: 0.5154 - val_acc: 0.5990 - val_auc: 0.4478 - val_loss: 0.6786\n","Epoch 16/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8486 - auc: 0.6792 - loss: 0.5165\n","Epoch 16: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8486 - auc: 0.6787 - loss: 0.5164 - val_acc: 0.5990 - val_auc: 0.4478 - val_loss: 0.6799\n","Epoch 17/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8479 - auc: 0.6157 - loss: 0.5215\n","Epoch 17: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8481 - auc: 0.6168 - loss: 0.5213 - val_acc: 0.5990 - val_auc: 0.8478 - val_loss: 0.6808\n","Epoch 18/100\n","\u001b[1m289/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8476 - auc: 0.6734 - loss: 0.5007\n","Epoch 18: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8480 - auc: 0.6743 - loss: 0.5001 - val_acc: 0.5990 - val_auc: 0.4478 - val_loss: 0.6823\n","Epoch 19/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8445 - auc: 0.6309 - loss: 0.5087\n","Epoch 19: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8447 - auc: 0.6318 - loss: 0.5084 - val_acc: 0.5990 - val_auc: 0.5000 - val_loss: 0.6833\n","Epoch 20/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8531 - auc: 0.6135 - loss: 0.5004\n","Epoch 20: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8531 - auc: 0.6154 - loss: 0.5003 - val_acc: 0.5990 - val_auc: 0.5000 - val_loss: 0.6844\n","Epoch 21/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8706 - auc: 0.6680 - loss: 0.4811\n","Epoch 21: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8691 - auc: 0.6649 - loss: 0.4826 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.6852\n","Epoch 22/100\n","\u001b[1m291/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8431 - auc: 0.6638 - loss: 0.4942\n","Epoch 22: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8436 - auc: 0.6631 - loss: 0.4938 - val_acc: 0.5990 - val_auc: 0.5000 - val_loss: 0.6863\n","Epoch 23/100\n","\u001b[1m289/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8480 - auc: 0.6591 - loss: 0.4926\n","Epoch 23: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8483 - auc: 0.6591 - loss: 0.4923 - val_acc: 0.5990 - val_auc: 0.5000 - val_loss: 0.6871\n","Epoch 24/100\n","\u001b[1m294/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8639 - auc: 0.6093 - loss: 0.4847\n","Epoch 24: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8633 - auc: 0.6104 - loss: 0.4848 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.6880\n","Epoch 25/100\n","\u001b[1m289/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8540 - auc: 0.6697 - loss: 0.4722\n","Epoch 25: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8541 - auc: 0.6688 - loss: 0.4722 - val_acc: 0.5990 - val_auc: 0.5000 - val_loss: 0.6887\n","Epoch 26/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8546 - auc: 0.6256 - loss: 0.4764\n","Epoch 26: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8547 - auc: 0.6264 - loss: 0.4760 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.6896\n","Epoch 27/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8580 - auc: 0.6845 - loss: 0.4560\n","Epoch 27: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8577 - auc: 0.6836 - loss: 0.4565 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.6908\n","Epoch 28/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8619 - auc: 0.6418 - loss: 0.4628\n","Epoch 28: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8616 - auc: 0.6410 - loss: 0.4635 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.6912\n","Epoch 29/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8466 - auc: 0.6009 - loss: 0.4900\n","Epoch 29: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8467 - auc: 0.6009 - loss: 0.4900 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.6912\n","Epoch 30/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8347 - auc: 0.6130 - loss: 0.4913\n","Epoch 30: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8350 - auc: 0.6134 - loss: 0.4910 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.6920\n","Epoch 31/100\n","\u001b[1m303/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8516 - auc: 0.6401 - loss: 0.4737\n","Epoch 31: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8516 - auc: 0.6407 - loss: 0.4735 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.6930\n","Epoch 32/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8571 - auc: 0.6609 - loss: 0.4668\n","Epoch 32: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8569 - auc: 0.6611 - loss: 0.4662 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.6938\n","Epoch 33/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8562 - auc: 0.5825 - loss: 0.4686\n","Epoch 33: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8558 - auc: 0.5839 - loss: 0.4686 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.6938\n","Epoch 34/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8621 - auc: 0.6349 - loss: 0.4495\n","Epoch 34: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8621 - auc: 0.6349 - loss: 0.4495 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.6943\n","Epoch 35/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8512 - auc: 0.6872 - loss: 0.4468\n","Epoch 35: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8512 - auc: 0.6849 - loss: 0.4473 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.6952\n","Epoch 36/100\n","\u001b[1m291/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8636 - auc: 0.7337 - loss: 0.4209\n","Epoch 36: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8630 - auc: 0.7310 - loss: 0.4221 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.6967\n","Epoch 37/100\n","\u001b[1m295/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8481 - auc: 0.6305 - loss: 0.4649\n","Epoch 37: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8483 - auc: 0.6314 - loss: 0.4643 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.6970\n","Epoch 38/100\n","\u001b[1m294/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8536 - auc: 0.6391 - loss: 0.4523\n","Epoch 38: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8534 - auc: 0.6388 - loss: 0.4525 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.6975\n","Epoch 39/100\n","\u001b[1m289/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8630 - auc: 0.6671 - loss: 0.4358\n","Epoch 39: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8619 - auc: 0.6651 - loss: 0.4374 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.6978\n","Epoch 40/100\n","\u001b[1m291/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8649 - auc: 0.6246 - loss: 0.4432\n","Epoch 40: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8641 - auc: 0.6248 - loss: 0.4440 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.6983\n","Epoch 41/100\n","\u001b[1m293/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8572 - auc: 0.6498 - loss: 0.4373\n","Epoch 41: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8569 - auc: 0.6483 - loss: 0.4383 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.6987\n","Epoch 42/100\n","\u001b[1m291/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8527 - auc: 0.6538 - loss: 0.4429\n","Epoch 42: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8525 - auc: 0.6548 - loss: 0.4426 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.6998\n","Epoch 43/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8662 - auc: 0.6878 - loss: 0.4336\n","Epoch 43: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8662 - auc: 0.6876 - loss: 0.4337 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7006\n","Epoch 44/100\n","\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8517 - auc: 0.6940 - loss: 0.4367\n","Epoch 44: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8517 - auc: 0.6934 - loss: 0.4369 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7011\n","Epoch 45/100\n","\u001b[1m304/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8459 - auc: 0.6380 - loss: 0.4546\n","Epoch 45: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8461 - auc: 0.6377 - loss: 0.4545 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7015\n","Epoch 46/100\n","\u001b[1m300/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8510 - auc: 0.6197 - loss: 0.4533\n","Epoch 46: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8511 - auc: 0.6201 - loss: 0.4530 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7020\n","Epoch 47/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8582 - auc: 0.6528 - loss: 0.4286\n","Epoch 47: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8577 - auc: 0.6535 - loss: 0.4293 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7032\n","Epoch 48/100\n","\u001b[1m294/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8566 - auc: 0.6433 - loss: 0.4343\n","Epoch 48: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8564 - auc: 0.6434 - loss: 0.4347 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7037\n","Epoch 49/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8595 - auc: 0.6378 - loss: 0.4404\n","Epoch 49: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8595 - auc: 0.6379 - loss: 0.4404 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7042\n","Epoch 50/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8264 - auc: 0.5769 - loss: 0.4753\n","Epoch 50: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8282 - auc: 0.5805 - loss: 0.4729 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7049\n","Epoch 51/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8484 - auc: 0.6032 - loss: 0.4489\n","Epoch 51: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8486 - auc: 0.6071 - loss: 0.4481 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7050\n","Epoch 52/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8684 - auc: 0.6248 - loss: 0.4267\n","Epoch 52: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8673 - auc: 0.6253 - loss: 0.4279 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7056\n","Epoch 53/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8408 - auc: 0.6351 - loss: 0.4456\n","Epoch 53: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8416 - auc: 0.6376 - loss: 0.4444 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7067\n","Epoch 54/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8661 - auc: 0.6584 - loss: 0.4145\n","Epoch 54: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8654 - auc: 0.6590 - loss: 0.4151 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7078\n","Epoch 55/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8448 - auc: 0.6564 - loss: 0.4366\n","Epoch 55: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8453 - auc: 0.6582 - loss: 0.4357 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7084\n","Epoch 56/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8603 - auc: 0.6405 - loss: 0.4201\n","Epoch 56: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8599 - auc: 0.6412 - loss: 0.4209 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7091\n","Epoch 57/100\n","\u001b[1m289/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8478 - auc: 0.6787 - loss: 0.4266\n","Epoch 57: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8483 - auc: 0.6799 - loss: 0.4259 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7102\n","Epoch 58/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8316 - auc: 0.5827 - loss: 0.4659\n","Epoch 58: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8331 - auc: 0.5891 - loss: 0.4629 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7112\n","Epoch 59/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8617 - auc: 0.6854 - loss: 0.4024\n","Epoch 59: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8609 - auc: 0.6852 - loss: 0.4035 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7125\n","Epoch 60/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8427 - auc: 0.6248 - loss: 0.4437\n","Epoch 60: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8427 - auc: 0.6248 - loss: 0.4436 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7121\n","Epoch 61/100\n","\u001b[1m303/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8673 - auc: 0.7176 - loss: 0.3945\n","Epoch 61: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8670 - auc: 0.7163 - loss: 0.3953 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7129\n","Epoch 62/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8763 - auc: 0.6940 - loss: 0.3922\n","Epoch 62: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8748 - auc: 0.6906 - loss: 0.3945 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7130\n","Epoch 63/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8367 - auc: 0.6294 - loss: 0.4437\n","Epoch 63: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8378 - auc: 0.6314 - loss: 0.4422 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7130\n","Epoch 64/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8462 - auc: 0.6320 - loss: 0.4345\n","Epoch 64: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8467 - auc: 0.6346 - loss: 0.4334 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7135\n","Epoch 65/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8536 - auc: 0.6848 - loss: 0.4118\n","Epoch 65: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8533 - auc: 0.6844 - loss: 0.4121 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7144\n","Epoch 66/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8681 - auc: 0.6946 - loss: 0.3940\n","Epoch 66: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8670 - auc: 0.6932 - loss: 0.3957 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7153\n","Epoch 67/100\n","\u001b[1m306/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8594 - auc: 0.6744 - loss: 0.4096\n","Epoch 67: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8593 - auc: 0.6742 - loss: 0.4097 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7152\n","Epoch 68/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8656 - auc: 0.6653 - loss: 0.4094\n","Epoch 68: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8646 - auc: 0.6658 - loss: 0.4102 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7156\n","Epoch 69/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8400 - auc: 0.6401 - loss: 0.4430\n","Epoch 69: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8408 - auc: 0.6430 - loss: 0.4415 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7155\n","Epoch 70/100\n","\u001b[1m294/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8464 - auc: 0.7290 - loss: 0.4088\n","Epoch 70: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8466 - auc: 0.7284 - loss: 0.4090 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7165\n","Epoch 71/100\n","\u001b[1m293/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8643 - auc: 0.7136 - loss: 0.3990\n","Epoch 71: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8638 - auc: 0.7131 - loss: 0.3998 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7175\n","Epoch 72/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8627 - auc: 0.7069 - loss: 0.4030\n","Epoch 72: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8620 - auc: 0.7072 - loss: 0.4035 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7177\n","Epoch 73/100\n","\u001b[1m293/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8525 - auc: 0.6384 - loss: 0.4302\n","Epoch 73: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8524 - auc: 0.6422 - loss: 0.4295 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7181\n","Epoch 74/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8699 - auc: 0.7317 - loss: 0.3959\n","Epoch 74: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8698 - auc: 0.7316 - loss: 0.3959 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7190\n","Epoch 75/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8549 - auc: 0.7043 - loss: 0.4164\n","Epoch 75: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8549 - auc: 0.7043 - loss: 0.4163 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7185\n","Epoch 76/100\n","\u001b[1m306/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8492 - auc: 0.7280 - loss: 0.4228\n","Epoch 76: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8493 - auc: 0.7284 - loss: 0.4226 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7183\n","Epoch 77/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8495 - auc: 0.7693 - loss: 0.4110\n","Epoch 77: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8497 - auc: 0.7694 - loss: 0.4106 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7191\n","Epoch 78/100\n","\u001b[1m293/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8675 - auc: 0.7739 - loss: 0.3894\n","Epoch 78: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8665 - auc: 0.7725 - loss: 0.3908 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7194\n","Epoch 79/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8676 - auc: 0.7926 - loss: 0.3800\n","Epoch 79: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8667 - auc: 0.7908 - loss: 0.3816 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7207\n","Epoch 80/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8616 - auc: 0.7713 - loss: 0.3947\n","Epoch 80: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8608 - auc: 0.7704 - loss: 0.3957 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7201\n","Epoch 81/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8635 - auc: 0.7515 - loss: 0.3943\n","Epoch 81: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8627 - auc: 0.7517 - loss: 0.3953 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7208\n","Epoch 82/100\n","\u001b[1m297/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8555 - auc: 0.7866 - loss: 0.3949\n","Epoch 82: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8554 - auc: 0.7852 - loss: 0.3955 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7209\n","Epoch 83/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8677 - auc: 0.7733 - loss: 0.3863\n","Epoch 83: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8668 - auc: 0.7718 - loss: 0.3879 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7213\n","Epoch 84/100\n","\u001b[1m294/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8516 - auc: 0.7584 - loss: 0.4095\n","Epoch 84: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8516 - auc: 0.7578 - loss: 0.4096 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7213\n","Epoch 85/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8331 - auc: 0.7301 - loss: 0.4328\n","Epoch 85: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8345 - auc: 0.7326 - loss: 0.4308 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7219\n","Epoch 86/100\n","\u001b[1m296/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8485 - auc: 0.7663 - loss: 0.4077\n","Epoch 86: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8487 - auc: 0.7661 - loss: 0.4075 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7221\n","Epoch 87/100\n","\u001b[1m291/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8533 - auc: 0.7648 - loss: 0.3985\n","Epoch 87: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8530 - auc: 0.7641 - loss: 0.3992 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.7225\n","Epoch 88/100\n","\u001b[1m289/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8639 - auc: 0.7411 - loss: 0.3975\n","Epoch 88: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8631 - auc: 0.7416 - loss: 0.3982 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7223\n","Epoch 89/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8395 - auc: 0.7266 - loss: 0.4229\n","Epoch 89: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8404 - auc: 0.7293 - loss: 0.4214 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7224\n","Epoch 90/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8640 - auc: 0.7451 - loss: 0.3934\n","Epoch 90: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8640 - auc: 0.7451 - loss: 0.3935 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7229\n","Epoch 91/100\n","\u001b[1m304/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8565 - auc: 0.7738 - loss: 0.3923\n","Epoch 91: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8564 - auc: 0.7741 - loss: 0.3923 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7246\n","Epoch 92/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8600 - auc: 0.7857 - loss: 0.3860\n","Epoch 92: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8599 - auc: 0.7856 - loss: 0.3861 - val_acc: 0.5990 - val_auc: 1.0000 - val_loss: 0.7252\n","Epoch 93/100\n","\u001b[1m293/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8648 - auc: 0.7942 - loss: 0.3721\n","Epoch 93: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8640 - auc: 0.7932 - loss: 0.3734 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7258\n","Epoch 94/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8462 - auc: 0.7610 - loss: 0.4075\n","Epoch 94: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8466 - auc: 0.7616 - loss: 0.4068 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7260\n","Epoch 95/100\n","\u001b[1m293/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8532 - auc: 0.7522 - loss: 0.3983\n","Epoch 95: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8533 - auc: 0.7538 - loss: 0.3979 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7270\n","Epoch 96/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8525 - auc: 0.7806 - loss: 0.3943\n","Epoch 96: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8524 - auc: 0.7800 - loss: 0.3944 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7274\n","Epoch 97/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8358 - auc: 0.7556 - loss: 0.4158\n","Epoch 97: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8369 - auc: 0.7560 - loss: 0.4145 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7274\n","Epoch 98/100\n","\u001b[1m291/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8546 - auc: 0.7652 - loss: 0.3935\n","Epoch 98: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8546 - auc: 0.7651 - loss: 0.3934 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7276\n","Epoch 99/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8616 - auc: 0.7588 - loss: 0.3849\n","Epoch 99: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8609 - auc: 0.7599 - loss: 0.3855 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7285\n","Epoch 100/100\n","\u001b[1m291/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8570 - auc: 0.7561 - loss: 0.3909\n","Epoch 100: val_loss did not improve from 0.67376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8567 - auc: 0.7564 - loss: 0.3912 - val_acc: 0.5990 - val_auc: 0.9000 - val_loss: 0.7279\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 8 AUC: 1.0000\n","\n","--- Fold 9/10 ---\n"," train | ids:   36 | files:  844 | pos:  286 | neg:  558\n","   val | ids:    4 | files:  207 | pos:   77 | neg:  130\n","  test | ids:    4 | files:  149 | pos:   42 | neg:  107\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m269/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.2946 - auc: 0.4230 - loss: 1.1103\n","Epoch 1: val_loss improved from inf to 1.07935, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - acc: 0.2968 - auc: 0.4236 - loss: 1.1061 - val_acc: 0.3720 - val_auc: 0.0923 - val_loss: 1.0793\n","Epoch 2/100\n","\u001b[1m262/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3541 - auc: 0.4596 - loss: 0.9143\n","Epoch 2: val_loss improved from 1.07935 to 0.94300, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.3538 - auc: 0.4607 - loss: 0.9134 - val_acc: 0.3720 - val_auc: 0.0923 - val_loss: 0.9430\n","Epoch 3/100\n","\u001b[1m263/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3847 - auc: 0.5240 - loss: 0.8197\n","Epoch 3: val_loss improved from 0.94300 to 0.85449, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.3830 - auc: 0.5233 - loss: 0.8192 - val_acc: 0.3720 - val_auc: 0.0923 - val_loss: 0.8545\n","Epoch 4/100\n","\u001b[1m262/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4051 - auc: 0.5366 - loss: 0.7650\n","Epoch 4: val_loss improved from 0.85449 to 0.79536, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.4052 - auc: 0.5381 - loss: 0.7641 - val_acc: 0.3720 - val_auc: 0.0923 - val_loss: 0.7954\n","Epoch 5/100\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4342 - auc: 0.6095 - loss: 0.7240\n","Epoch 5: val_loss improved from 0.79536 to 0.75144, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.4343 - auc: 0.6095 - loss: 0.7240 - val_acc: 0.0580 - val_auc: 0.0923 - val_loss: 0.7514\n","Epoch 6/100\n","\u001b[1m261/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5714 - auc: 0.6753 - loss: 0.6925\n","Epoch 6: val_loss improved from 0.75144 to 0.71827, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.5709 - auc: 0.6749 - loss: 0.6922 - val_acc: 0.0580 - val_auc: 0.0462 - val_loss: 0.7183\n","Epoch 7/100\n","\u001b[1m258/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6173 - auc: 0.7045 - loss: 0.6683\n","Epoch 7: val_loss improved from 0.71827 to 0.69886, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6233 - auc: 0.7069 - loss: 0.6672 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.6989\n","Epoch 8/100\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7985 - auc: 0.7977 - loss: 0.6333\n","Epoch 8: val_loss improved from 0.69886 to 0.68509, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7983 - auc: 0.7976 - loss: 0.6333 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.6851\n","Epoch 9/100\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7821 - auc: 0.8035 - loss: 0.6175\n","Epoch 9: val_loss improved from 0.68509 to 0.67477, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7821 - auc: 0.8035 - loss: 0.6175 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.6748\n","Epoch 10/100\n","\u001b[1m262/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7512 - auc: 0.7674 - loss: 0.6101\n","Epoch 10: val_loss improved from 0.67477 to 0.66645, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7507 - auc: 0.7657 - loss: 0.6105 - val_acc: 0.6280 - val_auc: 0.3462 - val_loss: 0.6664\n","Epoch 11/100\n","\u001b[1m264/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7271 - auc: 0.6967 - loss: 0.6262\n","Epoch 11: val_loss improved from 0.66645 to 0.66073, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7286 - auc: 0.6976 - loss: 0.6251 - val_acc: 0.6280 - val_auc: 0.6923 - val_loss: 0.6607\n","Epoch 12/100\n","\u001b[1m265/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7495 - auc: 0.7168 - loss: 0.6022\n","Epoch 12: val_loss improved from 0.66073 to 0.65587, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7500 - auc: 0.7166 - loss: 0.6019 - val_acc: 0.6280 - val_auc: 0.6923 - val_loss: 0.6559\n","Epoch 13/100\n","\u001b[1m261/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7484 - auc: 0.6718 - loss: 0.6007\n","Epoch 13: val_loss improved from 0.65587 to 0.65154, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7494 - auc: 0.6749 - loss: 0.5997 - val_acc: 0.6280 - val_auc: 0.6923 - val_loss: 0.6515\n","Epoch 14/100\n","\u001b[1m257/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7587 - auc: 0.6996 - loss: 0.5919\n","Epoch 14: val_loss improved from 0.65154 to 0.64823, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7610 - auc: 0.7002 - loss: 0.5909 - val_acc: 0.6280 - val_auc: 0.8000 - val_loss: 0.6482\n","Epoch 15/100\n","\u001b[1m257/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8007 - auc: 0.6939 - loss: 0.5769\n","Epoch 15: val_loss improved from 0.64823 to 0.64613, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7998 - auc: 0.6928 - loss: 0.5769 - val_acc: 0.6280 - val_auc: 0.8000 - val_loss: 0.6461\n","Epoch 16/100\n","\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8169 - auc: 0.6802 - loss: 0.5596\n","Epoch 16: val_loss improved from 0.64613 to 0.64497, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8166 - auc: 0.6802 - loss: 0.5596 - val_acc: 0.6280 - val_auc: 0.8000 - val_loss: 0.6450\n","Epoch 17/100\n","\u001b[1m258/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8170 - auc: 0.6589 - loss: 0.5548\n","Epoch 17: val_loss improved from 0.64497 to 0.64352, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8162 - auc: 0.6597 - loss: 0.5551 - val_acc: 0.6280 - val_auc: 0.9077 - val_loss: 0.6435\n","Epoch 18/100\n","\u001b[1m265/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8192 - auc: 0.7616 - loss: 0.5247\n","Epoch 18: val_loss improved from 0.64352 to 0.64265, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8191 - auc: 0.7596 - loss: 0.5253 - val_acc: 0.6280 - val_auc: 0.9077 - val_loss: 0.6426\n","Epoch 19/100\n","\u001b[1m265/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8188 - auc: 0.7035 - loss: 0.5385\n","Epoch 19: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8191 - auc: 0.7049 - loss: 0.5378 - val_acc: 0.6280 - val_auc: 0.9077 - val_loss: 0.6427\n","Epoch 20/100\n","\u001b[1m267/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7989 - auc: 0.7374 - loss: 0.5339\n","Epoch 20: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8000 - auc: 0.7378 - loss: 0.5334 - val_acc: 0.6280 - val_auc: 0.9077 - val_loss: 0.6431\n","Epoch 21/100\n","\u001b[1m258/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8041 - auc: 0.7065 - loss: 0.5348\n","Epoch 21: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8052 - auc: 0.7070 - loss: 0.5337 - val_acc: 0.6280 - val_auc: 0.9077 - val_loss: 0.6438\n","Epoch 22/100\n","\u001b[1m260/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8336 - auc: 0.7323 - loss: 0.5004\n","Epoch 22: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8324 - auc: 0.7329 - loss: 0.5012 - val_acc: 0.6280 - val_auc: 0.9077 - val_loss: 0.6442\n","Epoch 23/100\n","\u001b[1m264/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8668 - auc: 0.7724 - loss: 0.4806\n","Epoch 23: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8647 - auc: 0.7684 - loss: 0.4826 - val_acc: 0.6280 - val_auc: 0.9077 - val_loss: 0.6457\n","Epoch 24/100\n","\u001b[1m267/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8304 - auc: 0.7210 - loss: 0.5162\n","Epoch 24: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8309 - auc: 0.7226 - loss: 0.5154 - val_acc: 0.6280 - val_auc: 0.9077 - val_loss: 0.6471\n","Epoch 25/100\n","\u001b[1m263/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8265 - auc: 0.7672 - loss: 0.4921\n","Epoch 25: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8273 - auc: 0.7673 - loss: 0.4918 - val_acc: 0.6280 - val_auc: 0.9077 - val_loss: 0.6491\n","Epoch 26/100\n","\u001b[1m263/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8372 - auc: 0.7517 - loss: 0.4897\n","Epoch 26: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8379 - auc: 0.7518 - loss: 0.4893 - val_acc: 0.6280 - val_auc: 0.9077 - val_loss: 0.6508\n","Epoch 27/100\n","\u001b[1m263/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8508 - auc: 0.7773 - loss: 0.4734\n","Epoch 27: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8498 - auc: 0.7769 - loss: 0.4737 - val_acc: 0.6280 - val_auc: 0.9077 - val_loss: 0.6528\n","Epoch 28/100\n","\u001b[1m261/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8341 - auc: 0.7698 - loss: 0.4819\n","Epoch 28: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8340 - auc: 0.7689 - loss: 0.4819 - val_acc: 0.6280 - val_auc: 0.8000 - val_loss: 0.6558\n","Epoch 29/100\n","\u001b[1m262/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8525 - auc: 0.7735 - loss: 0.4584\n","Epoch 29: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8520 - auc: 0.7725 - loss: 0.4590 - val_acc: 0.6280 - val_auc: 0.8462 - val_loss: 0.6576\n","Epoch 30/100\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8381 - auc: 0.7762 - loss: 0.4791\n","Epoch 30: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8381 - auc: 0.7763 - loss: 0.4790 - val_acc: 0.6280 - val_auc: 0.8462 - val_loss: 0.6606\n","Epoch 31/100\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8351 - auc: 0.7890 - loss: 0.4657\n","Epoch 31: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8352 - auc: 0.7891 - loss: 0.4656 - val_acc: 0.6280 - val_auc: 0.6923 - val_loss: 0.6653\n","Epoch 32/100\n","\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8387 - auc: 0.7588 - loss: 0.4698\n","Epoch 32: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8387 - auc: 0.7593 - loss: 0.4695 - val_acc: 0.6280 - val_auc: 0.7385 - val_loss: 0.6655\n","Epoch 33/100\n","\u001b[1m262/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8400 - auc: 0.8261 - loss: 0.4476\n","Epoch 33: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8400 - auc: 0.8245 - loss: 0.4479 - val_acc: 0.6280 - val_auc: 0.7385 - val_loss: 0.6688\n","Epoch 34/100\n","\u001b[1m264/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8306 - auc: 0.7630 - loss: 0.4640\n","Epoch 34: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8311 - auc: 0.7644 - loss: 0.4629 - val_acc: 0.6280 - val_auc: 0.7846 - val_loss: 0.6710\n","Epoch 35/100\n","\u001b[1m265/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8495 - auc: 0.8352 - loss: 0.4306\n","Epoch 35: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8492 - auc: 0.8350 - loss: 0.4307 - val_acc: 0.6280 - val_auc: 0.7846 - val_loss: 0.6738\n","Epoch 36/100\n","\u001b[1m263/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8464 - auc: 0.8169 - loss: 0.4405\n","Epoch 36: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8461 - auc: 0.8158 - loss: 0.4406 - val_acc: 0.6280 - val_auc: 0.4385 - val_loss: 0.6761\n","Epoch 37/100\n","\u001b[1m262/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8317 - auc: 0.8090 - loss: 0.4360\n","Epoch 37: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8316 - auc: 0.8090 - loss: 0.4365 - val_acc: 0.6280 - val_auc: 0.4385 - val_loss: 0.6782\n","Epoch 38/100\n","\u001b[1m266/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8295 - auc: 0.8290 - loss: 0.4290\n","Epoch 38: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8298 - auc: 0.8299 - loss: 0.4291 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.6823\n","Epoch 39/100\n","\u001b[1m264/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8321 - auc: 0.7803 - loss: 0.4488\n","Epoch 39: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8330 - auc: 0.7841 - loss: 0.4471 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.6856\n","Epoch 40/100\n","\u001b[1m261/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8449 - auc: 0.8517 - loss: 0.4250\n","Epoch 40: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8453 - auc: 0.8520 - loss: 0.4244 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.6886\n","Epoch 41/100\n","\u001b[1m264/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8659 - auc: 0.8765 - loss: 0.3955\n","Epoch 41: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8642 - auc: 0.8747 - loss: 0.3970 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.6916\n","Epoch 42/100\n","\u001b[1m267/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8613 - auc: 0.8648 - loss: 0.3960\n","Epoch 42: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8599 - auc: 0.8637 - loss: 0.3972 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.6931\n","Epoch 43/100\n","\u001b[1m266/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8252 - auc: 0.8649 - loss: 0.4184\n","Epoch 43: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8258 - auc: 0.8644 - loss: 0.4181 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.6977\n","Epoch 44/100\n","\u001b[1m262/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8357 - auc: 0.8525 - loss: 0.4110\n","Epoch 44: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8358 - auc: 0.8527 - loss: 0.4111 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.6999\n","Epoch 45/100\n","\u001b[1m265/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8380 - auc: 0.8418 - loss: 0.4139\n","Epoch 45: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8378 - auc: 0.8421 - loss: 0.4140 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7016\n","Epoch 46/100\n","\u001b[1m261/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8318 - auc: 0.8374 - loss: 0.4137\n","Epoch 46: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8322 - auc: 0.8387 - loss: 0.4133 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7042\n","Epoch 47/100\n","\u001b[1m258/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8503 - auc: 0.8708 - loss: 0.3927\n","Epoch 47: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8499 - auc: 0.8703 - loss: 0.3935 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7062\n","Epoch 48/100\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8419 - auc: 0.8704 - loss: 0.3860\n","Epoch 48: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8419 - auc: 0.8703 - loss: 0.3860 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7074\n","Epoch 49/100\n","\u001b[1m264/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8594 - auc: 0.8757 - loss: 0.3824\n","Epoch 49: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8578 - auc: 0.8749 - loss: 0.3837 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7132\n","Epoch 50/100\n","\u001b[1m263/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8390 - auc: 0.8621 - loss: 0.4002\n","Epoch 50: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8386 - auc: 0.8619 - loss: 0.4002 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7151\n","Epoch 51/100\n","\u001b[1m267/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8662 - auc: 0.8774 - loss: 0.3708\n","Epoch 51: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8644 - auc: 0.8772 - loss: 0.3720 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7172\n","Epoch 52/100\n","\u001b[1m265/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8422 - auc: 0.8470 - loss: 0.3931\n","Epoch 52: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8418 - auc: 0.8468 - loss: 0.3937 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7190\n","Epoch 53/100\n","\u001b[1m268/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8544 - auc: 0.8478 - loss: 0.3969\n","Epoch 53: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8538 - auc: 0.8493 - loss: 0.3964 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7211\n","Epoch 54/100\n","\u001b[1m261/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8331 - auc: 0.8751 - loss: 0.3947\n","Epoch 54: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8337 - auc: 0.8756 - loss: 0.3939 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7235\n","Epoch 55/100\n","\u001b[1m260/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8341 - auc: 0.8818 - loss: 0.3784\n","Epoch 55: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8346 - auc: 0.8818 - loss: 0.3788 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7252\n","Epoch 56/100\n","\u001b[1m264/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8485 - auc: 0.8702 - loss: 0.3873\n","Epoch 56: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8480 - auc: 0.8696 - loss: 0.3878 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7274\n","Epoch 57/100\n","\u001b[1m266/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8538 - auc: 0.9040 - loss: 0.3708\n","Epoch 57: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8533 - auc: 0.9033 - loss: 0.3711 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7293\n","Epoch 58/100\n","\u001b[1m264/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8362 - auc: 0.8843 - loss: 0.3840\n","Epoch 58: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8366 - auc: 0.8847 - loss: 0.3836 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7321\n","Epoch 59/100\n","\u001b[1m269/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8433 - auc: 0.8777 - loss: 0.3767\n","Epoch 59: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8433 - auc: 0.8779 - loss: 0.3769 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7339\n","Epoch 60/100\n","\u001b[1m266/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8555 - auc: 0.8931 - loss: 0.3673\n","Epoch 60: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8551 - auc: 0.8927 - loss: 0.3676 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7364\n","Epoch 61/100\n","\u001b[1m265/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8264 - auc: 0.8890 - loss: 0.3887\n","Epoch 61: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8278 - auc: 0.8897 - loss: 0.3875 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7384\n","Epoch 62/100\n","\u001b[1m261/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8330 - auc: 0.8394 - loss: 0.4029\n","Epoch 62: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8335 - auc: 0.8418 - loss: 0.4013 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7402\n","Epoch 63/100\n","\u001b[1m259/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8461 - auc: 0.8995 - loss: 0.3635\n","Epoch 63: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8455 - auc: 0.8993 - loss: 0.3640 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7430\n","Epoch 64/100\n","\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8668 - auc: 0.9095 - loss: 0.3454\n","Epoch 64: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8664 - auc: 0.9094 - loss: 0.3457 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7450\n","Epoch 65/100\n","\u001b[1m258/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8469 - auc: 0.9122 - loss: 0.3506\n","Epoch 65: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8469 - auc: 0.9111 - loss: 0.3517 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7471\n","Epoch 66/100\n","\u001b[1m267/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8428 - auc: 0.8890 - loss: 0.3631\n","Epoch 66: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8426 - auc: 0.8886 - loss: 0.3636 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7489\n","Epoch 67/100\n","\u001b[1m265/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8433 - auc: 0.8904 - loss: 0.3575\n","Epoch 67: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8430 - auc: 0.8904 - loss: 0.3582 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7507\n","Epoch 68/100\n","\u001b[1m260/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8670 - auc: 0.9279 - loss: 0.3291\n","Epoch 68: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8650 - auc: 0.9265 - loss: 0.3312 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7529\n","Epoch 69/100\n","\u001b[1m267/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8592 - auc: 0.9028 - loss: 0.3517\n","Epoch 69: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8585 - auc: 0.9024 - loss: 0.3521 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7550\n","Epoch 70/100\n","\u001b[1m258/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8496 - auc: 0.8718 - loss: 0.3631\n","Epoch 70: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8493 - auc: 0.8737 - loss: 0.3631 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7569\n","Epoch 71/100\n","\u001b[1m259/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8147 - auc: 0.9010 - loss: 0.3687\n","Epoch 71: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8168 - auc: 0.9013 - loss: 0.3674 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7585\n","Epoch 72/100\n","\u001b[1m261/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8530 - auc: 0.9176 - loss: 0.3423\n","Epoch 72: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8526 - auc: 0.9166 - loss: 0.3428 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7605\n","Epoch 73/100\n","\u001b[1m258/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8464 - auc: 0.8901 - loss: 0.3655\n","Epoch 73: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8473 - auc: 0.8909 - loss: 0.3644 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7624\n","Epoch 74/100\n","\u001b[1m258/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8508 - auc: 0.8741 - loss: 0.3544\n","Epoch 74: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8505 - auc: 0.8760 - loss: 0.3544 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7651\n","Epoch 75/100\n","\u001b[1m261/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8440 - auc: 0.8879 - loss: 0.3616\n","Epoch 75: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8436 - auc: 0.8889 - loss: 0.3611 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7667\n","Epoch 76/100\n","\u001b[1m260/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8478 - auc: 0.8821 - loss: 0.3593\n","Epoch 76: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8481 - auc: 0.8835 - loss: 0.3585 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7682\n","Epoch 77/100\n","\u001b[1m262/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8302 - auc: 0.9043 - loss: 0.3628\n","Epoch 77: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8310 - auc: 0.9045 - loss: 0.3620 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7705\n","Epoch 78/100\n","\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8514 - auc: 0.9077 - loss: 0.3374\n","Epoch 78: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8513 - auc: 0.9077 - loss: 0.3375 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7726\n","Epoch 79/100\n","\u001b[1m259/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8554 - auc: 0.9379 - loss: 0.3173\n","Epoch 79: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8545 - auc: 0.9358 - loss: 0.3192 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7748\n","Epoch 80/100\n","\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8342 - auc: 0.8920 - loss: 0.3644\n","Epoch 80: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8348 - auc: 0.8922 - loss: 0.3639 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7745\n","Epoch 81/100\n","\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8467 - auc: 0.9140 - loss: 0.3405\n","Epoch 81: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8466 - auc: 0.9141 - loss: 0.3406 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7780\n","Epoch 82/100\n","\u001b[1m266/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8409 - auc: 0.9139 - loss: 0.3426\n","Epoch 82: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8409 - auc: 0.9139 - loss: 0.3426 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7801\n","Epoch 83/100\n","\u001b[1m262/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8392 - auc: 0.9178 - loss: 0.3378\n","Epoch 83: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8393 - auc: 0.9176 - loss: 0.3380 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7828\n","Epoch 84/100\n","\u001b[1m257/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8710 - auc: 0.9359 - loss: 0.3104\n","Epoch 84: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8684 - auc: 0.9337 - loss: 0.3131 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7846\n","Epoch 85/100\n","\u001b[1m263/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8456 - auc: 0.9048 - loss: 0.3343\n","Epoch 85: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8458 - auc: 0.9053 - loss: 0.3343 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7859\n","Epoch 86/100\n","\u001b[1m263/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8630 - auc: 0.9259 - loss: 0.3166\n","Epoch 86: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8615 - auc: 0.9248 - loss: 0.3182 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7875\n","Epoch 87/100\n","\u001b[1m259/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8558 - auc: 0.9081 - loss: 0.3274\n","Epoch 87: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8549 - auc: 0.9084 - loss: 0.3283 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7898\n","Epoch 88/100\n","\u001b[1m262/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8463 - auc: 0.9076 - loss: 0.3434\n","Epoch 88: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8465 - auc: 0.9083 - loss: 0.3424 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7924\n","Epoch 89/100\n","\u001b[1m261/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8446 - auc: 0.9227 - loss: 0.3269\n","Epoch 89: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8446 - auc: 0.9221 - loss: 0.3275 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7937\n","Epoch 90/100\n","\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8495 - auc: 0.9317 - loss: 0.3182\n","Epoch 90: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8495 - auc: 0.9316 - loss: 0.3183 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7964\n","Epoch 91/100\n","\u001b[1m263/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8386 - auc: 0.9183 - loss: 0.3364\n","Epoch 91: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8392 - auc: 0.9172 - loss: 0.3367 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7961\n","Epoch 92/100\n","\u001b[1m259/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8689 - auc: 0.9117 - loss: 0.3160\n","Epoch 92: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8674 - auc: 0.9115 - loss: 0.3173 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7980\n","Epoch 93/100\n","\u001b[1m260/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8506 - auc: 0.9236 - loss: 0.3323\n","Epoch 93: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8521 - auc: 0.9233 - loss: 0.3320 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.7992\n","Epoch 94/100\n","\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8630 - auc: 0.9102 - loss: 0.3398\n","Epoch 94: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8632 - auc: 0.9100 - loss: 0.3397 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.8012\n","Epoch 95/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8717 - auc: 0.9195 - loss: 0.3245\n","Epoch 95: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8717 - auc: 0.9195 - loss: 0.3246 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.8047\n","Epoch 96/100\n","\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8670 - auc: 0.9018 - loss: 0.3492\n","Epoch 96: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8675 - auc: 0.9021 - loss: 0.3486 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.8052\n","Epoch 97/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8789 - auc: 0.9135 - loss: 0.3362\n","Epoch 97: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8790 - auc: 0.9136 - loss: 0.3361 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.8063\n","Epoch 98/100\n","\u001b[1m262/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8847 - auc: 0.9027 - loss: 0.3362\n","Epoch 98: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8850 - auc: 0.9039 - loss: 0.3356 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.8086\n","Epoch 99/100\n","\u001b[1m263/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9030 - auc: 0.9173 - loss: 0.3029\n","Epoch 99: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9026 - auc: 0.9177 - loss: 0.3040 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.8129\n","Epoch 100/100\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8905 - auc: 0.9198 - loss: 0.3238\n","Epoch 100: val_loss did not improve from 0.64265\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8905 - auc: 0.9198 - loss: 0.3237 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.8133\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 9 AUC: 1.0000\n","\n","--- Fold 10/10 ---\n"," train | ids:   36 | files:  874 | pos:  319 | neg:  555\n","   val | ids:    4 | files:  145 | pos:   77 | neg:   68\n","  test | ids:    4 | files:  181 | pos:    9 | neg:  172\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m272/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.6734 - auc: 0.6014 - loss: 0.6686\n","Epoch 1: val_loss improved from inf to 0.79471, saving model to best_tab_only_fold10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - acc: 0.6721 - auc: 0.6004 - loss: 0.6689 - val_acc: 0.2000 - val_auc: 0.2059 - val_loss: 0.7947\n","Epoch 2/100\n","\u001b[1m268/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6912 - auc: 0.6208 - loss: 0.6495\n","Epoch 2: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6890 - auc: 0.6192 - loss: 0.6503 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.7955\n","Epoch 3/100\n","\u001b[1m280/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6785 - auc: 0.6611 - loss: 0.6355\n","Epoch 3: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6774 - auc: 0.6603 - loss: 0.6359 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.7990\n","Epoch 4/100\n","\u001b[1m283/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6403 - auc: 0.5740 - loss: 0.6625\n","Epoch 4: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6408 - auc: 0.5756 - loss: 0.6620 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8004\n","Epoch 5/100\n","\u001b[1m281/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6441 - auc: 0.5945 - loss: 0.6537\n","Epoch 5: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6453 - auc: 0.5962 - loss: 0.6533 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8014\n","Epoch 6/100\n","\u001b[1m279/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7000 - auc: 0.6048 - loss: 0.6614\n","Epoch 6: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6996 - auc: 0.6059 - loss: 0.6606 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8027\n","Epoch 7/100\n","\u001b[1m266/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6630 - auc: 0.6737 - loss: 0.6195\n","Epoch 7: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6613 - auc: 0.6694 - loss: 0.6221 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8035\n","Epoch 8/100\n","\u001b[1m288/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6863 - auc: 0.6439 - loss: 0.6532\n","Epoch 8: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6862 - auc: 0.6441 - loss: 0.6530 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8054\n","Epoch 9/100\n","\u001b[1m289/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7067 - auc: 0.6476 - loss: 0.6240\n","Epoch 9: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7064 - auc: 0.6478 - loss: 0.6241 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8095\n","Epoch 10/100\n","\u001b[1m286/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6777 - auc: 0.6712 - loss: 0.6369\n","Epoch 10: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6779 - auc: 0.6710 - loss: 0.6368 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8127\n","Epoch 11/100\n","\u001b[1m273/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6692 - auc: 0.6379 - loss: 0.6457\n","Epoch 11: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6697 - auc: 0.6398 - loss: 0.6446 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8155\n","Epoch 12/100\n","\u001b[1m288/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6536 - auc: 0.6494 - loss: 0.6518\n","Epoch 12: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6541 - auc: 0.6493 - loss: 0.6517 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8178\n","Epoch 13/100\n","\u001b[1m280/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6781 - auc: 0.6472 - loss: 0.6345\n","Epoch 13: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6778 - auc: 0.6468 - loss: 0.6348 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8197\n","Epoch 14/100\n","\u001b[1m279/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6723 - auc: 0.6790 - loss: 0.6382\n","Epoch 14: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6728 - auc: 0.6774 - loss: 0.6382 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8217\n","Epoch 15/100\n","\u001b[1m278/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6969 - auc: 0.6721 - loss: 0.6118\n","Epoch 15: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6956 - auc: 0.6723 - loss: 0.6122 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8246\n","Epoch 16/100\n","\u001b[1m280/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7337 - auc: 0.6389 - loss: 0.6343\n","Epoch 16: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7328 - auc: 0.6395 - loss: 0.6344 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8242\n","Epoch 17/100\n","\u001b[1m281/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6780 - auc: 0.6634 - loss: 0.6358\n","Epoch 17: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6782 - auc: 0.6637 - loss: 0.6353 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8258\n","Epoch 18/100\n","\u001b[1m284/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6873 - auc: 0.6751 - loss: 0.6316\n","Epoch 18: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6874 - auc: 0.6751 - loss: 0.6314 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8285\n","Epoch 19/100\n","\u001b[1m278/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6949 - auc: 0.6760 - loss: 0.6215\n","Epoch 19: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6950 - auc: 0.6749 - loss: 0.6220 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8295\n","Epoch 20/100\n","\u001b[1m281/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6837 - auc: 0.6616 - loss: 0.6375\n","Epoch 20: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6838 - auc: 0.6614 - loss: 0.6372 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8314\n","Epoch 21/100\n","\u001b[1m273/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6990 - auc: 0.6993 - loss: 0.6227\n","Epoch 21: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6986 - auc: 0.6977 - loss: 0.6225 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8341\n","Epoch 22/100\n","\u001b[1m272/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6805 - auc: 0.6580 - loss: 0.6378\n","Epoch 22: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6812 - auc: 0.6582 - loss: 0.6373 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8338\n","Epoch 23/100\n","\u001b[1m284/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6846 - auc: 0.6501 - loss: 0.6279\n","Epoch 23: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6848 - auc: 0.6506 - loss: 0.6278 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8357\n","Epoch 24/100\n","\u001b[1m281/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6666 - auc: 0.6488 - loss: 0.6416\n","Epoch 24: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6671 - auc: 0.6495 - loss: 0.6410 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8369\n","Epoch 25/100\n","\u001b[1m285/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7194 - auc: 0.6951 - loss: 0.6184\n","Epoch 25: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7193 - auc: 0.6949 - loss: 0.6183 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8399\n","Epoch 26/100\n","\u001b[1m288/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6996 - auc: 0.6355 - loss: 0.6204\n","Epoch 26: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6994 - auc: 0.6362 - loss: 0.6204 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8416\n","Epoch 27/100\n","\u001b[1m285/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7015 - auc: 0.6546 - loss: 0.6211\n","Epoch 27: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7016 - auc: 0.6556 - loss: 0.6208 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8442\n","Epoch 28/100\n","\u001b[1m286/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7028 - auc: 0.6888 - loss: 0.6062\n","Epoch 28: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7026 - auc: 0.6883 - loss: 0.6066 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8462\n","Epoch 29/100\n","\u001b[1m285/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6646 - auc: 0.6132 - loss: 0.6412\n","Epoch 29: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6656 - auc: 0.6144 - loss: 0.6407 - val_acc: 0.4690 - val_auc: 0.2059 - val_loss: 0.8470\n","Epoch 30/100\n","\u001b[1m287/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6937 - auc: 0.6664 - loss: 0.6186\n","Epoch 30: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6936 - auc: 0.6663 - loss: 0.6188 - val_acc: 0.4690 - val_auc: 0.2059 - val_loss: 0.8464\n","Epoch 31/100\n","\u001b[1m281/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6864 - auc: 0.6779 - loss: 0.6196\n","Epoch 31: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6865 - auc: 0.6772 - loss: 0.6196 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8492\n","Epoch 32/100\n","\u001b[1m286/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6801 - auc: 0.6560 - loss: 0.6167\n","Epoch 32: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6802 - auc: 0.6563 - loss: 0.6168 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8488\n","Epoch 33/100\n","\u001b[1m288/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7023 - auc: 0.6741 - loss: 0.6132\n","Epoch 33: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7022 - auc: 0.6741 - loss: 0.6133 - val_acc: 0.4690 - val_auc: 0.4118 - val_loss: 0.8502\n","Epoch 34/100\n","\u001b[1m266/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6945 - auc: 0.6673 - loss: 0.6348\n","Epoch 34: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6951 - auc: 0.6682 - loss: 0.6334 - val_acc: 0.4690 - val_auc: 0.2059 - val_loss: 0.8522\n","Epoch 35/100\n","\u001b[1m290/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6944 - auc: 0.6846 - loss: 0.6101\n","Epoch 35: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6943 - auc: 0.6844 - loss: 0.6102 - val_acc: 0.4690 - val_auc: 0.2059 - val_loss: 0.8531\n","Epoch 36/100\n","\u001b[1m285/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7507 - auc: 0.7281 - loss: 0.5820\n","Epoch 36: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7495 - auc: 0.7272 - loss: 0.5828 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8570\n","Epoch 37/100\n","\u001b[1m282/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6518 - auc: 0.6291 - loss: 0.6458\n","Epoch 37: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6525 - auc: 0.6298 - loss: 0.6453 - val_acc: 0.4690 - val_auc: 0.2059 - val_loss: 0.8543\n","Epoch 38/100\n","\u001b[1m278/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7241 - auc: 0.6964 - loss: 0.6085\n","Epoch 38: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7230 - auc: 0.6948 - loss: 0.6088 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8581\n","Epoch 39/100\n","\u001b[1m290/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7068 - auc: 0.6349 - loss: 0.6144\n","Epoch 39: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7068 - auc: 0.6352 - loss: 0.6145 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8599\n","Epoch 40/100\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7003 - auc: 0.7010 - loss: 0.6083\n","Epoch 40: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7003 - auc: 0.7010 - loss: 0.6083 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8611\n","Epoch 41/100\n","\u001b[1m285/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7118 - auc: 0.6575 - loss: 0.6190\n","Epoch 41: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7116 - auc: 0.6578 - loss: 0.6190 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8643\n","Epoch 42/100\n","\u001b[1m288/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7010 - auc: 0.6324 - loss: 0.6307\n","Epoch 42: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7012 - auc: 0.6330 - loss: 0.6305 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8659\n","Epoch 43/100\n","\u001b[1m287/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7206 - auc: 0.7115 - loss: 0.5871\n","Epoch 43: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7201 - auc: 0.7109 - loss: 0.5876 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8671\n","Epoch 44/100\n","\u001b[1m285/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7259 - auc: 0.7037 - loss: 0.5993\n","Epoch 44: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7251 - auc: 0.7033 - loss: 0.5997 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8701\n","Epoch 45/100\n","\u001b[1m284/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6906 - auc: 0.6860 - loss: 0.6279\n","Epoch 45: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6907 - auc: 0.6861 - loss: 0.6274 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8716\n","Epoch 46/100\n","\u001b[1m288/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7247 - auc: 0.7222 - loss: 0.5816\n","Epoch 46: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7243 - auc: 0.7214 - loss: 0.5821 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8767\n","Epoch 47/100\n","\u001b[1m290/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6999 - auc: 0.6789 - loss: 0.6211\n","Epoch 47: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6999 - auc: 0.6790 - loss: 0.6210 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8763\n","Epoch 48/100\n","\u001b[1m289/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6810 - auc: 0.7000 - loss: 0.6053\n","Epoch 48: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6812 - auc: 0.6998 - loss: 0.6053 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8799\n","Epoch 49/100\n","\u001b[1m289/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6858 - auc: 0.6518 - loss: 0.6253\n","Epoch 49: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6861 - auc: 0.6523 - loss: 0.6252 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8819\n","Epoch 50/100\n","\u001b[1m288/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7004 - auc: 0.6809 - loss: 0.6123\n","Epoch 50: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7005 - auc: 0.6810 - loss: 0.6124 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8830\n","Epoch 51/100\n","\u001b[1m269/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6999 - auc: 0.6938 - loss: 0.6137\n","Epoch 51: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7008 - auc: 0.6916 - loss: 0.6138 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8854\n","Epoch 52/100\n","\u001b[1m280/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7145 - auc: 0.6891 - loss: 0.5993\n","Epoch 52: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7138 - auc: 0.6882 - loss: 0.6003 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8861\n","Epoch 53/100\n","\u001b[1m278/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7155 - auc: 0.6717 - loss: 0.6166\n","Epoch 53: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7144 - auc: 0.6718 - loss: 0.6165 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8898\n","Epoch 54/100\n","\u001b[1m276/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7378 - auc: 0.7574 - loss: 0.5728\n","Epoch 54: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7370 - auc: 0.7549 - loss: 0.5743 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8941\n","Epoch 55/100\n","\u001b[1m288/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6865 - auc: 0.6602 - loss: 0.6355\n","Epoch 55: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6867 - auc: 0.6603 - loss: 0.6353 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8920\n","Epoch 56/100\n","\u001b[1m290/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7574 - auc: 0.6799 - loss: 0.5930\n","Epoch 56: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7569 - auc: 0.6798 - loss: 0.5933 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8956\n","Epoch 57/100\n","\u001b[1m286/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7375 - auc: 0.7098 - loss: 0.6026\n","Epoch 57: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7372 - auc: 0.7092 - loss: 0.6029 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8953\n","Epoch 58/100\n","\u001b[1m289/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7355 - auc: 0.6969 - loss: 0.5734\n","Epoch 58: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7351 - auc: 0.6967 - loss: 0.5739 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8981\n","Epoch 59/100\n","\u001b[1m291/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7540 - auc: 0.7252 - loss: 0.5823\n","Epoch 59: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7538 - auc: 0.7249 - loss: 0.5825 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8994\n","Epoch 60/100\n","\u001b[1m286/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7112 - auc: 0.6843 - loss: 0.6081\n","Epoch 60: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7114 - auc: 0.6843 - loss: 0.6081 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9036\n","Epoch 61/100\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7235 - auc: 0.7021 - loss: 0.5994\n","Epoch 61: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7234 - auc: 0.7021 - loss: 0.5994 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9071\n","Epoch 62/100\n","\u001b[1m287/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7159 - auc: 0.6898 - loss: 0.5923\n","Epoch 62: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7159 - auc: 0.6900 - loss: 0.5925 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9090\n","Epoch 63/100\n","\u001b[1m289/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7015 - auc: 0.6544 - loss: 0.6094\n","Epoch 63: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7014 - auc: 0.6544 - loss: 0.6095 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9107\n","Epoch 64/100\n","\u001b[1m291/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6917 - auc: 0.6438 - loss: 0.6194\n","Epoch 64: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6918 - auc: 0.6441 - loss: 0.6193 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9119\n","Epoch 65/100\n","\u001b[1m291/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7020 - auc: 0.6919 - loss: 0.6067\n","Epoch 65: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7019 - auc: 0.6917 - loss: 0.6067 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9127\n","Epoch 66/100\n","\u001b[1m290/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7163 - auc: 0.7264 - loss: 0.5923\n","Epoch 66: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7162 - auc: 0.7262 - loss: 0.5924 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9153\n","Epoch 67/100\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7605 - auc: 0.7172 - loss: 0.5824\n","Epoch 67: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7603 - auc: 0.7172 - loss: 0.5825 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9180\n","Epoch 68/100\n","\u001b[1m287/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7169 - auc: 0.7087 - loss: 0.5941\n","Epoch 68: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7167 - auc: 0.7084 - loss: 0.5943 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9196\n","Epoch 69/100\n","\u001b[1m281/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7070 - auc: 0.7067 - loss: 0.6097\n","Epoch 69: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7072 - auc: 0.7057 - loss: 0.6098 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9217\n","Epoch 70/100\n","\u001b[1m280/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6884 - auc: 0.6659 - loss: 0.6250\n","Epoch 70: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6895 - auc: 0.6673 - loss: 0.6242 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9248\n","Epoch 71/100\n","\u001b[1m285/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6952 - auc: 0.6793 - loss: 0.6112\n","Epoch 71: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6956 - auc: 0.6799 - loss: 0.6109 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9260\n","Epoch 72/100\n","\u001b[1m289/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6977 - auc: 0.6848 - loss: 0.6069\n","Epoch 72: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6980 - auc: 0.6852 - loss: 0.6068 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9306\n","Epoch 73/100\n","\u001b[1m285/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6950 - auc: 0.7004 - loss: 0.5969\n","Epoch 73: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6946 - auc: 0.6999 - loss: 0.5973 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9321\n","Epoch 74/100\n","\u001b[1m289/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7065 - auc: 0.6893 - loss: 0.6038\n","Epoch 74: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7065 - auc: 0.6895 - loss: 0.6038 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9344\n","Epoch 75/100\n","\u001b[1m289/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7159 - auc: 0.7331 - loss: 0.5937\n","Epoch 75: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7158 - auc: 0.7327 - loss: 0.5939 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9351\n","Epoch 76/100\n","\u001b[1m291/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7213 - auc: 0.7368 - loss: 0.5870\n","Epoch 76: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7212 - auc: 0.7367 - loss: 0.5871 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9370\n","Epoch 77/100\n","\u001b[1m289/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7016 - auc: 0.7039 - loss: 0.5878\n","Epoch 77: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7015 - auc: 0.7037 - loss: 0.5881 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9382\n","Epoch 78/100\n","\u001b[1m286/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7078 - auc: 0.6882 - loss: 0.6069\n","Epoch 78: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7077 - auc: 0.6882 - loss: 0.6070 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9388\n","Epoch 79/100\n","\u001b[1m282/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7038 - auc: 0.6894 - loss: 0.6101\n","Epoch 79: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7036 - auc: 0.6904 - loss: 0.6096 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9418\n","Epoch 80/100\n","\u001b[1m287/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6993 - auc: 0.6934 - loss: 0.5925\n","Epoch 80: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6991 - auc: 0.6933 - loss: 0.5929 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9431\n","Epoch 81/100\n","\u001b[1m289/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6996 - auc: 0.7389 - loss: 0.5890\n","Epoch 81: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6996 - auc: 0.7384 - loss: 0.5891 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9462\n","Epoch 82/100\n","\u001b[1m283/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7059 - auc: 0.7110 - loss: 0.5933\n","Epoch 82: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7050 - auc: 0.7104 - loss: 0.5939 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9452\n","Epoch 83/100\n","\u001b[1m291/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6763 - auc: 0.6753 - loss: 0.6311\n","Epoch 83: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6764 - auc: 0.6753 - loss: 0.6310 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9445\n","Epoch 84/100\n","\u001b[1m291/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6922 - auc: 0.6886 - loss: 0.6065\n","Epoch 84: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6922 - auc: 0.6887 - loss: 0.6065 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9468\n","Epoch 85/100\n","\u001b[1m280/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7036 - auc: 0.7255 - loss: 0.5878\n","Epoch 85: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7036 - auc: 0.7249 - loss: 0.5882 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9505\n","Epoch 86/100\n","\u001b[1m280/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7015 - auc: 0.6968 - loss: 0.6010\n","Epoch 86: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7011 - auc: 0.6965 - loss: 0.6013 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9486\n","Epoch 87/100\n","\u001b[1m278/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7165 - auc: 0.7208 - loss: 0.5923\n","Epoch 87: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7155 - auc: 0.7200 - loss: 0.5931 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9477\n","Epoch 88/100\n","\u001b[1m284/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7038 - auc: 0.7232 - loss: 0.6028\n","Epoch 88: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7037 - auc: 0.7230 - loss: 0.6026 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9488\n","Epoch 89/100\n","\u001b[1m291/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7031 - auc: 0.7159 - loss: 0.6003\n","Epoch 89: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7032 - auc: 0.7159 - loss: 0.6003 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9540\n","Epoch 90/100\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7043 - auc: 0.6844 - loss: 0.5973\n","Epoch 90: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7043 - auc: 0.6844 - loss: 0.5974 - val_acc: 0.4690 - val_auc: 0.0074 - val_loss: 0.9522\n","Epoch 91/100\n","\u001b[1m288/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7059 - auc: 0.7009 - loss: 0.5948\n","Epoch 91: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7054 - auc: 0.7008 - loss: 0.5950 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9529\n","Epoch 92/100\n","\u001b[1m291/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7193 - auc: 0.7246 - loss: 0.5889\n","Epoch 92: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7192 - auc: 0.7244 - loss: 0.5890 - val_acc: 0.4690 - val_auc: 0.0074 - val_loss: 0.9530\n","Epoch 93/100\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6851 - auc: 0.6832 - loss: 0.5999\n","Epoch 93: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6851 - auc: 0.6833 - loss: 0.5999 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9536\n","Epoch 94/100\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6974 - auc: 0.6628 - loss: 0.6165\n","Epoch 94: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6974 - auc: 0.6630 - loss: 0.6164 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9573\n","Epoch 95/100\n","\u001b[1m270/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6759 - auc: 0.7165 - loss: 0.5998\n","Epoch 95: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6783 - auc: 0.7162 - loss: 0.5995 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9585\n","Epoch 96/100\n","\u001b[1m285/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6955 - auc: 0.6920 - loss: 0.6244\n","Epoch 96: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6959 - auc: 0.6925 - loss: 0.6238 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9633\n","Epoch 97/100\n","\u001b[1m288/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7127 - auc: 0.6934 - loss: 0.6062\n","Epoch 97: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7121 - auc: 0.6931 - loss: 0.6064 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9578\n","Epoch 98/100\n","\u001b[1m268/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6891 - auc: 0.6599 - loss: 0.6223\n","Epoch 98: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6908 - auc: 0.6625 - loss: 0.6210 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9565\n","Epoch 99/100\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6737 - auc: 0.7028 - loss: 0.6156\n","Epoch 99: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6738 - auc: 0.7028 - loss: 0.6156 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9588\n","Epoch 100/100\n","\u001b[1m282/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7309 - auc: 0.7305 - loss: 0.5823\n","Epoch 100: val_loss did not improve from 0.79471\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7299 - auc: 0.7295 - loss: 0.5831 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9579\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 10 AUC: 1.0000\n","\n","AUCs per fold: [0.05537098560354374, 0.91, 1.0, 1.0, 1.0, 0.631578947368421, 0.15500000000000003, 1.0, 1.0, 1.0]\n","Mean AUC: 0.7752 ± 0.3528\n"]}]},{"cell_type":"code","source":["# =========================\n","# Results across folds\n","# =========================\n","print(\"\\nPer-fold AUCs:\")\n","for i, a in enumerate(fold_aucs, start=1):\n","    if np.isnan(a):\n","        print(f\"  Fold {i:2d}: NaN\")\n","    else:\n","        print(f\"  Fold {i:2d}: {a:.4f}\")\n","\n","print(\"\\nAUCs list:\", fold_aucs)\n","\n","valid_aucs = [a for a in fold_aucs if not np.isnan(a)]\n","if valid_aucs:\n","    print(f\"Mean AUC: {np.mean(valid_aucs):.4f} ± {np.std(valid_aucs):.4f}\")\n","    print(f\"Min/Max AUC: {np.min(valid_aucs):.4f} / {np.max(valid_aucs):.4f}\")\n","else:\n","    print(\"All AUCs are NaN; cannot compute summary statistics.\")"],"metadata":{"id":"KUgcBvQhpHVE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760500815802,"user_tz":300,"elapsed":12,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"outputId":"6a788066-2f25-4787-d7c7-7cdebcb3d0a8"},"id":"KUgcBvQhpHVE","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Per-fold AUCs:\n","  Fold  1: 0.0554\n","  Fold  2: 0.9100\n","  Fold  3: 1.0000\n","  Fold  4: 1.0000\n","  Fold  5: 1.0000\n","  Fold  6: 0.6316\n","  Fold  7: 0.1550\n","  Fold  8: 1.0000\n","  Fold  9: 1.0000\n","  Fold 10: 1.0000\n","\n","AUCs list: [0.05537098560354374, 0.91, 1.0, 1.0, 1.0, 0.631578947368421, 0.15500000000000003, 1.0, 1.0, 1.0]\n","Mean AUC: 0.7752 ± 0.3528\n","Min/Max AUC: 0.0554 / 1.0000\n"]}]},{"cell_type":"code","source":["# === Plot per-fold AUCs ===\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","fold_indices = np.arange(1, len(fold_aucs) + 1, dtype=int)\n","auc_array = np.array(fold_aucs, dtype=float)\n","\n","plt.figure(figsize=(14, 8))\n","# line+markers; NaNs will break the line, which is fine\n","plt.plot(fold_indices, auc_array, marker=\"o\", linewidth=1)\n","\n","# annotate non-NaN points with their values\n","for i, a in enumerate(auc_array, start=1):\n","    if not np.isnan(a):\n","        plt.text(i, a, f\"{a:.3f}\", ha=\"center\", va=\"bottom\", fontsize=8)\n","\n","# draw mean AUC if available\n","valid_mask = ~np.isnan(auc_array)\n","if valid_mask.any():\n","    mean_auc = auc_array[valid_mask].mean()\n","    plt.axhline(mean_auc, linestyle=\"--\", linewidth=1, label=f\"Mean AUC = {mean_auc:.3f}\")\n","\n","plt.title(\"Per-fold AUC\")\n","plt.xlabel(\"Fold #\")\n","plt.ylabel(\"AUC\")\n","plt.xticks(fold_indices)\n","plt.ylim(0.0, 1.0)\n","plt.grid(True, linewidth=0.3)\n","plt.legend(loc=\"lower right\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"IrWZ5cUFpHXs","colab":{"base_uri":"https://localhost:8080/","height":807},"executionInfo":{"status":"ok","timestamp":1760500818883,"user_tz":300,"elapsed":261,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"outputId":"9d69c5e3-8cee-456b-c3a8-7a721de60f5c"},"id":"IrWZ5cUFpHXs","execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1400x800 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"sPOzCNAug4NW","executionInfo":{"status":"aborted","timestamp":1760500813645,"user_tz":300,"elapsed":873087,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"sPOzCNAug4NW","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xxOkMiS4g4SL","executionInfo":{"status":"aborted","timestamp":1760500813646,"user_tz":300,"elapsed":873087,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"xxOkMiS4g4SL","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"ksQMstdc-o-3","metadata":{"id":"ksQMstdc-o-3","executionInfo":{"status":"aborted","timestamp":1760500813646,"user_tz":300,"elapsed":873087,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"JSdB6j-a-pDF","metadata":{"id":"JSdB6j-a-pDF","executionInfo":{"status":"aborted","timestamp":1760500813661,"user_tz":300,"elapsed":873101,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"U7ouQnxD-pF_","metadata":{"id":"U7ouQnxD-pF_","executionInfo":{"status":"aborted","timestamp":1760500813663,"user_tz":300,"elapsed":873103,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"WnjxgEPK-pIJ","metadata":{"id":"WnjxgEPK-pIJ","executionInfo":{"status":"aborted","timestamp":1760500813664,"user_tz":300,"elapsed":873103,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"j28g8Lqp-pKy","metadata":{"id":"j28g8Lqp-pKy","executionInfo":{"status":"aborted","timestamp":1760500813665,"user_tz":300,"elapsed":873104,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"DJbv-4-G-pMn","metadata":{"id":"DJbv-4-G-pMn","executionInfo":{"status":"aborted","timestamp":1760500813666,"user_tz":300,"elapsed":873105,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"Cxtz-1Fo-pPP","metadata":{"id":"Cxtz-1Fo-pPP","executionInfo":{"status":"aborted","timestamp":1760500813667,"user_tz":300,"elapsed":873106,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"JinSNJgh-pRf","metadata":{"id":"JinSNJgh-pRf","executionInfo":{"status":"aborted","timestamp":1760500813667,"user_tz":300,"elapsed":873106,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ywg21ljv-pcL","metadata":{"id":"ywg21ljv-pcL","executionInfo":{"status":"aborted","timestamp":1760500813668,"user_tz":300,"elapsed":873107,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"Jl01Xhpa-pfL","metadata":{"id":"Jl01Xhpa-pfL","executionInfo":{"status":"aborted","timestamp":1760500813669,"user_tz":300,"elapsed":873107,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ErNrKHRm-pg_","metadata":{"id":"ErNrKHRm-pg_","executionInfo":{"status":"aborted","timestamp":1760500813670,"user_tz":300,"elapsed":873108,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"IElgvqQj-pit","metadata":{"id":"IElgvqQj-pit","executionInfo":{"status":"aborted","timestamp":1760500813671,"user_tz":300,"elapsed":873109,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"-TADzyG9-pnO","metadata":{"id":"-TADzyG9-pnO","executionInfo":{"status":"aborted","timestamp":1760500813671,"user_tz":300,"elapsed":873109,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"miiDblbz-ppC","metadata":{"id":"miiDblbz-ppC","executionInfo":{"status":"aborted","timestamp":1760500813672,"user_tz":300,"elapsed":873109,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"Bnp7fHxm-pqu","metadata":{"id":"Bnp7fHxm-pqu","executionInfo":{"status":"aborted","timestamp":1760500813673,"user_tz":300,"elapsed":873110,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"UiQbsLv47Xu-","metadata":{"id":"UiQbsLv47Xu-","executionInfo":{"status":"aborted","timestamp":1760500813674,"user_tz":300,"elapsed":873111,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"hhAiYZZVGIsM","metadata":{"id":"hhAiYZZVGIsM","executionInfo":{"status":"aborted","timestamp":1760500813675,"user_tz":300,"elapsed":873112,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"EWQ7UG7zGIuj","metadata":{"id":"EWQ7UG7zGIuj","executionInfo":{"status":"aborted","timestamp":1760500813678,"user_tz":300,"elapsed":873115,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"hUObArfBGIw5","metadata":{"id":"hUObArfBGIw5","executionInfo":{"status":"aborted","timestamp":1760500813679,"user_tz":300,"elapsed":873116,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ln5ftwRAGI0C","metadata":{"id":"ln5ftwRAGI0C","executionInfo":{"status":"aborted","timestamp":1760500813680,"user_tz":300,"elapsed":873116,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"jgczkpH8GI2s","metadata":{"id":"jgczkpH8GI2s","executionInfo":{"status":"aborted","timestamp":1760500813681,"user_tz":300,"elapsed":873117,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"CFxtsYm4DJxo","metadata":{"id":"CFxtsYm4DJxo","executionInfo":{"status":"aborted","timestamp":1760500813681,"user_tz":300,"elapsed":873117,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"zIo_rXgnDJzw","metadata":{"id":"zIo_rXgnDJzw","executionInfo":{"status":"aborted","timestamp":1760500813682,"user_tz":300,"elapsed":873118,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"N4iBf4B0DJ14","metadata":{"id":"N4iBf4B0DJ14","executionInfo":{"status":"aborted","timestamp":1760500813683,"user_tz":300,"elapsed":873119,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"mGuWgjhCDJ5y","metadata":{"id":"mGuWgjhCDJ5y","executionInfo":{"status":"aborted","timestamp":1760500813684,"user_tz":300,"elapsed":873120,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"mtPQw2LIDJ8A","metadata":{"id":"mtPQw2LIDJ8A","executionInfo":{"status":"aborted","timestamp":1760500813685,"user_tz":300,"elapsed":873120,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"VRIqcx7HDJ9m","metadata":{"id":"VRIqcx7HDJ9m","executionInfo":{"status":"aborted","timestamp":1760500813686,"user_tz":300,"elapsed":873121,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"HfhdGuLEDJ_u","metadata":{"id":"HfhdGuLEDJ_u","executionInfo":{"status":"aborted","timestamp":1760500813687,"user_tz":300,"elapsed":873122,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"virtual ENV","language":"python","name":"environment_instance"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":5}