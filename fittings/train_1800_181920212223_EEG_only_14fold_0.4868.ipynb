{"cells":[{"cell_type":"code","execution_count":1,"id":"8f5a4f5b-bad9-49e3-8dd6-7304666df443","metadata":{"id":"8f5a4f5b-bad9-49e3-8dd6-7304666df443","executionInfo":{"status":"ok","timestamp":1760666411496,"user_tz":300,"elapsed":10593,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","import torchvision\n","import torchvision.transforms as transforms\n","import os\n","import argparse\n","from pathlib import Path\n","import re\n","import random\n","import math\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":2,"id":"dr2Fm7p5mAAN","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16014,"status":"ok","timestamp":1760666427538,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"},"user_tz":300},"id":"dr2Fm7p5mAAN","outputId":"73b87d4e-86a7-461f-e8da-50279a08d08d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":[],"metadata":{"id":"gUHWAH8qdC05","executionInfo":{"status":"ok","timestamp":1760666427546,"user_tz":300,"elapsed":5,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"gUHWAH8qdC05","execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L2wH-XagdC3h","executionInfo":{"status":"ok","timestamp":1760666427557,"user_tz":300,"elapsed":6,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"L2wH-XagdC3h","execution_count":2,"outputs":[]},{"cell_type":"markdown","id":"-6k2Q8eaHxYK","metadata":{"id":"-6k2Q8eaHxYK"},"source":["### Normalization across the whole dataset"]},{"cell_type":"code","source":[],"metadata":{"id":"uJrVqvBtpHJK","executionInfo":{"status":"ok","timestamp":1760666427566,"user_tz":300,"elapsed":4,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"uJrVqvBtpHJK","execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"REn1fKi1pHMT","executionInfo":{"status":"ok","timestamp":1760666427575,"user_tz":300,"elapsed":4,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"REn1fKi1pHMT","execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### No normalization!"],"metadata":{"id":"vCi0eO54p2NW"},"id":"vCi0eO54p2NW"},{"cell_type":"code","source":["from pathlib import Path\n","import re, random, math, os\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# =========================\n","# Config\n","# =========================\n","SPLIT_DIR = r\"/content/drive/MyDrive/CD/patient_data_clean_nozero_181920212223_1800\"\n","POS_PATIENTS = {1, 2, 16, 19, 21, 22, 25, 37, 39, 43, 44, 47, 50, 56, 58, 62, 65, 66, 73, 78}\n","\n","BATCH_SIZE       = 3\n","EPOCHS           = 100\n","LR               = 1e-4\n","SEED             = 1\n","K_FOLDS          = 14\n","BEST_MODEL_TPL   = \"best_fold_{:02d}.h5\"\n","\n","# not used for dedup height; kept for reference\n","TARGET_H = 300\n","\n","# =========================\n","# Noise config (train-time augmentation only)\n","# =========================\n","TRAIN_ADD_GAUSS_NOISE = True     # training generator only\n","TRAIN_NOISE_FRAC      = 0.10\n","TRAIN_NOISE_PROB      = 1.0\n","EPS_STD               = 1e-8\n","\n","# =========================\n","# Repro\n","# =========================\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n","for g in tf.config.list_physical_devices('GPU'):\n","    try:\n","        tf.config.experimental.set_memory_growth(g, True)\n","    except Exception:\n","        pass\n","\n","# =========================\n","# Helpers for ID/labels\n","# =========================\n","PATIENT_NUM_RX = re.compile(r'^ID(\\d+)')\n","\n","def patient_num_from_path(pathlike):\n","    stem = Path(pathlike).stem\n","    m = PATIENT_NUM_RX.match(stem)\n","    return int(m.group(1)) if m else None\n","\n","def label_for_file(p: Path) -> int:\n","    pnum = patient_num_from_path(p)\n","    return 1 if (pnum is not None and pnum in POS_PATIENTS) else 0\n","\n","# =========================\n","# List files (all) & labels by patient ID\n","# =========================\n","split_dir = Path(SPLIT_DIR)\n","all_csvs = sorted(split_dir.glob(\"*.csv\"))\n","if not all_csvs:\n","    raise FileNotFoundError(f\"No CSV found in {SPLIT_DIR}\")\n","\n","id_to_files = {}\n","for f in all_csvs:\n","    pid = patient_num_from_path(f)\n","    if pid is None:\n","        continue\n","    id_to_files.setdefault(pid, []).append(f)\n","\n","all_ids = sorted(id_to_files.keys())\n","id_labels = np.array([1 if pid in POS_PATIENTS else 0 for pid in all_ids], dtype=int)\n","print(\"Total IDs:\", len(all_ids), \"| Pos IDs:\", id_labels.sum(), \"| Neg IDs:\", (1 - id_labels).sum())\n","\n","# =========================\n","# Column handling\n","# =========================\n","def _drop_time_cols(df: pd.DataFrame) -> pd.DataFrame:\n","    time_like = [c for c in df.columns if isinstance(c, str) and c.strip().lower() == \"time\"]\n","    return df.drop(columns=time_like, errors=\"ignore\")\n","\n","def _to_numeric_df(df: pd.DataFrame) -> pd.DataFrame:\n","    df = _drop_time_cols(df)\n","    return df.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n","\n","def _pad_crop_2d(x: np.ndarray, H: int, W: int) -> np.ndarray:\n","    h, w = x.shape\n","    if h < H:\n","        pad = np.zeros((H, w), dtype=x.dtype); pad[:h, :] = x; x = pad; h = H\n","    elif h > H:\n","        x = x[:H, :]; h = H\n","    if w < W:\n","        pad = np.zeros((h, W), dtype=x.dtype); pad[:, :w] = x; x = pad\n","    elif w > W:\n","        x = x[:, :W]\n","    return x\n","\n","def _infer_target_width(example_csv: Path) -> int:\n","    df = pd.read_csv(example_csv)\n","    df2 = _to_numeric_df(df)\n","    return df2.shape[1]\n","\n","# Fix width/height ONCE using the whole dataset (so all folds match)\n","TARGET_W = _infer_target_width(all_csvs[0])\n","print(f\"TARGET_W={TARGET_W} (non-Time columns)\")\n","\n","def _dedupe_consecutive_rows(mat: np.ndarray) -> np.ndarray:\n","    if mat.size == 0:\n","        return mat\n","    if mat.ndim == 1:\n","        mat = mat[:, None]\n","    if mat.shape[0] == 1:\n","        return mat\n","    diffs = np.any(mat[1:] != mat[:-1], axis=1)\n","    keep = np.concatenate(([True], diffs))\n","    return mat[keep]\n","\n","def _dedup_len_from_csv(p: Path) -> int:\n","    df = pd.read_csv(p)\n","    mat = _to_numeric_df(df).to_numpy(dtype=np.float32)\n","    mat_d = _dedupe_consecutive_rows(mat)\n","    return int(mat_d.shape[0])\n","\n","TARGET_H_DEDUP = max(_dedup_len_from_csv(f) for f in all_csvs)\n","if TARGET_H_DEDUP <= 0:\n","    raise RuntimeError(\"After de-dup, zero-length found in data.\")\n","print(f\"Fixed input height after de-dup (all IDs): H={TARGET_H_DEDUP}\")\n","\n","def load_csv_as_image_dedup(csv_path: Path) -> np.ndarray:\n","    df  = pd.read_csv(csv_path)\n","    df2 = _to_numeric_df(df)\n","    mat = df2.to_numpy(dtype=np.float32)\n","    if mat.ndim != 2:\n","        mat = mat.reshape(mat.shape[0], -1) if mat.ndim > 2 else mat\n","    mat = _dedupe_consecutive_rows(mat)\n","    if mat.shape[0] == 0:\n","        mat = np.zeros((1, TARGET_W), dtype=np.float32)\n","    mat = _pad_crop_2d(mat, TARGET_H_DEDUP, TARGET_W)\n","    img = np.expand_dims(mat, axis=-1).astype(np.float32)\n","    if img.shape != (TARGET_H_DEDUP, TARGET_W, 1):\n","        raise ValueError(f\"loader produced {img.shape}, expected {(TARGET_H_DEDUP, TARGET_W, 1)} for {csv_path}\")\n","    return img\n","\n","# cache\n","CACHE_DEDUP = {}\n","def load_csv_as_image_cached(csv_path: Path) -> np.ndarray:\n","    key = (\"dedup\", str(csv_path))\n","    if key in CACHE_DEDUP:\n","        return CACHE_DEDUP[key]\n","    img = load_csv_as_image_dedup(csv_path)\n","    CACHE_DEDUP[key] = img\n","    return img\n","\n","print(\"Normalization: NONE. De-dup: remove consecutive duplicate rows (row-wise).\")\n","\n","# =========================\n","# Keras Sequence\n","# =========================\n","class ImageSequence(keras.utils.Sequence):\n","    def __init__(self, files, batch_size=BATCH_SIZE, shuffle=True,\n","                 add_noise=False, noise_frac=TRAIN_NOISE_FRAC, noise_prob=TRAIN_NOISE_PROB):\n","        super().__init__()\n","        self.files = list(files)\n","        self.batch_size = int(batch_size)\n","        self.shuffle = shuffle\n","        self.add_noise = add_noise\n","        self.noise_frac = float(noise_frac)\n","        self.noise_prob = float(noise_prob)\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        return math.ceil(len(self.files) / self.batch_size)\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.files))\n","        if self.shuffle:\n","            np.random.shuffle(self.indexes)\n","\n","    def __getitem__(self, idx):\n","        idxs = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n","        batch_files = [self.files[i] for i in idxs]\n","        B = len(batch_files)\n","        X = np.empty((B, TARGET_H_DEDUP, TARGET_W, 1), dtype=np.float32)\n","        y = np.empty((B,), dtype=np.int32)\n","\n","        for i, f in enumerate(batch_files):\n","            xi = load_csv_as_image_cached(f)\n","            if xi.ndim == 2:\n","                xi = xi[..., None]\n","            if xi.shape != (TARGET_H_DEDUP, TARGET_W, 1):\n","                raise ValueError(f\"Sample shape {xi.shape} for {f}; expected {(TARGET_H_DEDUP, TARGET_W, 1)}\")\n","            X[i] = xi\n","            y[i] = label_for_file(f)\n","\n","        if self.add_noise and self.noise_frac > 0.0 and self.noise_prob > 0.0:\n","            samp_std = X.reshape(B, -1).std(axis=1).astype(np.float32)\n","            samp_std = np.maximum(samp_std, EPS_STD).reshape(B, 1, 1, 1)\n","            noise = np.random.normal(0.0, 1.0, size=X.shape).astype(np.float32)\n","            noise *= (self.noise_frac * samp_std)\n","            if self.noise_prob < 1.0:\n","                mask = (np.random.rand(B, 1, 1, 1) < self.noise_prob).astype(np.float32)\n","                noise *= mask\n","            X = X + noise\n","\n","        if X.shape[1:] != (TARGET_H_DEDUP, TARGET_W, 1):\n","            raise ValueError(f\"Batch X has shape {X.shape}; expected (B, {TARGET_H_DEDUP}, {TARGET_W}, 1)\")\n","        return X, y\n","\n","# =========================\n","# DenseNet-style 2D CNN (binary head)\n","# =========================\n","def build_model(h=TARGET_H_DEDUP, w=TARGET_W, c=1, lr=LR,\n","                growth_rate=4, block_layers=(2, 2, 2, 2),\n","                compression=0.5, dropout=0.2):\n","\n","    inputs = keras.Input(shape=(h, w, c))\n","\n","    def bn_relu_conv(x, filters, ksize, stride=1):\n","        x = layers.ReLU()(x)\n","        x = layers.Conv2D(filters, ksize, strides=stride, padding=\"same\", use_bias=False)(x)\n","        return x\n","\n","    def dense_layer(x):\n","        y = bn_relu_conv(x, 4 * growth_rate, 1)\n","        y = bn_relu_conv(y, growth_rate, 3)\n","        return layers.Concatenate()([x, y])\n","\n","    def dense_block(x, L):\n","        for _ in range(L):\n","            x = dense_layer(x)\n","        return x\n","\n","    def transition_layer(x):\n","        filters = max(8, int(int(x.shape[-1]) * compression))\n","        x = bn_relu_conv(x, filters, 1)\n","        return layers.AveragePooling2D(pool_size=(2, 2), strides=2, padding=\"same\")(x)\n","\n","    x = layers.Conv2D(32, 3, padding=\"same\", use_bias=False)(inputs)\n","    x = layers.ReLU()(x)\n","\n","    for i, L in enumerate(block_layers):\n","        x = dense_block(x, L)\n","        if i != len(block_layers) - 1:\n","            x = transition_layer(x)\n","\n","    x = layers.GlobalAveragePooling2D()(x)\n","    x = layers.Dense(128, activation=\"relu\")(x)\n","    x = layers.Dropout(dropout)(x)\n","    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","\n","    model = keras.Model(inputs, outputs)\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(learning_rate=lr),\n","        loss=\"binary_crossentropy\",\n","        metrics=[keras.metrics.BinaryAccuracy(name=\"acc\"), keras.metrics.AUC(name=\"auc\")],\n","    )\n","    return model\n","\n","# =========================\n","# 7-fold CV by patient ID\n","# =========================\n","skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=SEED)\n","\n","fold_test_accs, fold_test_aucs = [], []\n","rows = []\n","\n","print(f\"\\n=== {K_FOLDS}-Fold CV (by patient ID) ===\")\n","for fold_idx, (train_idx, test_idx) in enumerate(skf.split(all_ids, id_labels), start=1):\n","    ids_train_full = [all_ids[i] for i in train_idx]\n","    ids_test       = [all_ids[i] for i in test_idx]\n","\n","    # small validation split from training IDs (for checkpointing)\n","    train_labels_full = np.array([1 if pid in POS_PATIENTS else 0 for pid in ids_train_full], dtype=int)\n","    try:\n","        ids_tr, ids_val = train_test_split(\n","            ids_train_full, test_size=0.10, random_state=SEED, stratify=train_labels_full\n","        )\n","    except ValueError:\n","        ids_tr, ids_val = train_test_split(ids_train_full, test_size=0.10, random_state=SEED, shuffle=True)\n","        print(f\"(Fold {fold_idx}) Warning: stratified VAL split failed; using unstratified split.\")\n","\n","    # Files for each split\n","    train_files = [f for pid in ids_tr  for f in id_to_files[pid]]\n","    val_files   = [f for pid in ids_val for f in id_to_files[pid]]\n","    test_files  = [f for pid in ids_test for f in id_to_files[pid]]\n","\n","    def split_summary(name, ids, files):\n","        ys = np.array([label_for_file(f) for f in files], dtype=int)\n","        print(f\"{name:>6} | ids: {len(ids):4d} | files: {len(files):5d} | pos files: {(ys==1).sum():4d} | neg files: {(ys==0).sum():4d}\")\n","\n","    print(f\"\\n--- Fold {fold_idx}/{K_FOLDS} ---\")\n","    split_summary(\"train\", ids_tr,  train_files)\n","    split_summary(\"val\",   ids_val, val_files)\n","    split_summary(\"test\",  ids_test, test_files)\n","\n","    # Generators\n","    train_gen = ImageSequence(train_files, batch_size=BATCH_SIZE, shuffle=True,\n","                              add_noise=TRAIN_ADD_GAUSS_NOISE,\n","                              noise_frac=TRAIN_NOISE_FRAC,\n","                              noise_prob=TRAIN_NOISE_PROB)\n","    val_gen   = ImageSequence(val_files,   batch_size=BATCH_SIZE, shuffle=False, add_noise=False)\n","    test_gen  = ImageSequence(test_files,  batch_size=BATCH_SIZE, shuffle=False, add_noise=False)\n","\n","    # Train & pick best by val_loss\n","    model = build_model()\n","    best_path = BEST_MODEL_TPL.format(fold_idx)\n","    ckpt = keras.callbacks.ModelCheckpoint(best_path, monitor=\"val_loss\", mode=\"min\",\n","                                           save_best_only=True, verbose=1)\n","    _ = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS, callbacks=[ckpt], verbose=1)\n","\n","    # Evaluate on TEST\n","    best_model = keras.models.load_model(best_path)\n","    test_probs = best_model.predict(test_gen, verbose=0).ravel().astype(float)\n","    test_y     = np.array([label_for_file(f) for f in test_gen.files], dtype=int)\n","    test_pred  = (test_probs >= 0.5).astype(int)\n","\n","    try:\n","        test_auc = roc_auc_score(test_y, test_probs)\n","    except ValueError:\n","        test_auc = float('nan')\n","    test_acc = accuracy_score(test_y, test_pred)\n","\n","    fold_test_accs.append(float(test_acc))\n","    fold_test_aucs.append(float(test_auc))\n","\n","    print(f\"Fold {fold_idx} | TEST ACC={test_acc:.4f} | TEST AUC={test_auc:.4f} | n={len(test_y)}\")\n","    print(\"Confusion matrix:\\n\", confusion_matrix(test_y, test_pred))\n","    print(\"Classification report:\\n\", classification_report(test_y, test_pred, digits=3))\n","\n","    rows.append({\n","        \"fold\": fold_idx,\n","        \"train_files\": len(train_files),\n","        \"val_files\": len(val_files),\n","        \"test_files\": len(test_files),\n","        \"test_acc\": test_acc,\n","        \"test_auc\": test_auc,\n","    })\n","\n","# =========================\n","# Summary across folds\n","# =========================\n","print(\"\\nPer-fold TEST ACC:\", [round(x,4) for x in fold_test_accs])\n","print(\"Per-fold TEST AUC:\", [None if np.isnan(x) else round(x,4) for x in fold_test_aucs])\n","\n","def mean_std(x):\n","    x = np.asarray(x, dtype=float)\n","    return np.nanmean(x), np.nanstd(x)\n","\n","mACC, sACC = mean_std(fold_test_accs)\n","mAUC, sAUC = mean_std(fold_test_aucs)\n","print(f\"\\nMean TEST ACC: {mACC:.4f} ± {sACC:.4f}\")\n","print(f\"Mean TEST AUC: {mAUC:.4f} ± {sAUC:.4f}\")\n","\n","metrics_df = pd.DataFrame(rows)\n","metrics_df.to_csv(\"cv7_img_fold_metrics.csv\", index=False)\n","print(\"\\nSaved TEST-only per-fold metrics to cv7_img_fold_metrics.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lD7pVdaPpHPi","outputId":"ff2f62e3-567d-4d69-ac88-5b79c156d8f2","executionInfo":{"status":"ok","timestamp":1760668615303,"user_tz":300,"elapsed":2187724,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"lD7pVdaPpHPi","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Total IDs: 44 | Pos IDs: 14 | Neg IDs: 30\n","TARGET_W=6 (non-Time columns)\n","Fixed input height after de-dup (all IDs): H=360\n","Normalization: NONE. De-dup: remove consecutive duplicate rows (row-wise).\n","\n","=== 14-Fold CV (by patient ID) ===\n","\n","--- Fold 1/14 ---\n"," train | ids:   36 | files:   909 | pos files:  323 | neg files:  586\n","   val | ids:    4 | files:   118 | pos files:   77 | neg files:   41\n","  test | ids:    4 | files:   173 | pos files:    5 | neg files:  168\n","Epoch 1/100\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - acc: 0.6181 - auc: 0.4619 - loss: 0.6881\n","Epoch 1: val_loss improved from inf to 0.73380, saving model to best_fold_01.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 37ms/step - acc: 0.6182 - auc: 0.4620 - loss: 0.6880 - val_acc: 0.3475 - val_auc: 0.8163 - val_loss: 0.7338\n","Epoch 2/100\n","\u001b[1m300/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6781 - auc: 0.3787 - loss: 0.6514\n","Epoch 2: val_loss did not improve from 0.73380\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6777 - auc: 0.3789 - loss: 0.6516 - val_acc: 0.3475 - val_auc: 0.8670 - val_loss: 0.7673\n","Epoch 3/100\n","\u001b[1m300/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6185 - auc: 0.4287 - loss: 0.6691\n","Epoch 3: val_loss did not improve from 0.73380\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6189 - auc: 0.4285 - loss: 0.6689 - val_acc: 0.3475 - val_auc: 0.8910 - val_loss: 0.7958\n","Epoch 4/100\n","\u001b[1m296/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6623 - auc: 0.4190 - loss: 0.6472\n","Epoch 4: val_loss did not improve from 0.73380\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6618 - auc: 0.4202 - loss: 0.6474 - val_acc: 0.3475 - val_auc: 0.9579 - val_loss: 0.7815\n","Epoch 5/100\n","\u001b[1m297/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6362 - auc: 0.4387 - loss: 0.6595\n","Epoch 5: val_loss did not improve from 0.73380\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6364 - auc: 0.4393 - loss: 0.6594 - val_acc: 0.3475 - val_auc: 0.9745 - val_loss: 0.7790\n","Epoch 6/100\n","\u001b[1m297/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6188 - auc: 0.4644 - loss: 0.6671\n","Epoch 6: val_loss did not improve from 0.73380\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6195 - auc: 0.4649 - loss: 0.6668 - val_acc: 0.3475 - val_auc: 0.9840 - val_loss: 0.7999\n","Epoch 7/100\n","\u001b[1m294/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6506 - auc: 0.4656 - loss: 0.6503\n","Epoch 7: val_loss did not improve from 0.73380\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6504 - auc: 0.4670 - loss: 0.6503 - val_acc: 0.3475 - val_auc: 0.9910 - val_loss: 0.7822\n","Epoch 8/100\n","\u001b[1m290/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6161 - auc: 0.5410 - loss: 0.6633\n","Epoch 8: val_loss did not improve from 0.73380\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6174 - auc: 0.5405 - loss: 0.6627 - val_acc: 0.3475 - val_auc: 0.9933 - val_loss: 0.8032\n","Epoch 9/100\n","\u001b[1m301/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6576 - auc: 0.5545 - loss: 0.6367\n","Epoch 9: val_loss did not improve from 0.73380\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6574 - auc: 0.5545 - loss: 0.6367 - val_acc: 0.3475 - val_auc: 0.9853 - val_loss: 0.7683\n","Epoch 10/100\n","\u001b[1m291/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6674 - auc: 0.5368 - loss: 0.6322\n","Epoch 10: val_loss did not improve from 0.73380\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6666 - auc: 0.5374 - loss: 0.6326 - val_acc: 0.3475 - val_auc: 0.9755 - val_loss: 0.7411\n","Epoch 11/100\n","\u001b[1m292/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6923 - auc: 0.6003 - loss: 0.6295\n","Epoch 11: val_loss did not improve from 0.73380\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6918 - auc: 0.5994 - loss: 0.6297 - val_acc: 0.3475 - val_auc: 0.9800 - val_loss: 0.7765\n","Epoch 12/100\n","\u001b[1m294/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7067 - auc: 0.5919 - loss: 0.6120\n","Epoch 12: val_loss did not improve from 0.73380\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7062 - auc: 0.5913 - loss: 0.6124 - val_acc: 0.3475 - val_auc: 0.9850 - val_loss: 0.7697\n","Epoch 13/100\n","\u001b[1m293/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7160 - auc: 0.6069 - loss: 0.5983\n","Epoch 13: val_loss improved from 0.73380 to 0.61334, saving model to best_fold_01.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7153 - auc: 0.6074 - loss: 0.5987 - val_acc: 0.7288 - val_auc: 0.9621 - val_loss: 0.6133\n","Epoch 14/100\n","\u001b[1m295/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6545 - auc: 0.5975 - loss: 0.6201\n","Epoch 14: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6554 - auc: 0.5980 - loss: 0.6197 - val_acc: 0.3475 - val_auc: 0.9766 - val_loss: 0.7707\n","Epoch 15/100\n","\u001b[1m294/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7221 - auc: 0.6457 - loss: 0.5737\n","Epoch 15: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7212 - auc: 0.6454 - loss: 0.5745 - val_acc: 0.3475 - val_auc: 0.9579 - val_loss: 0.7260\n","Epoch 16/100\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7303 - auc: 0.6449 - loss: 0.5676\n","Epoch 16: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7302 - auc: 0.6449 - loss: 0.5676 - val_acc: 0.3475 - val_auc: 0.9214 - val_loss: 0.7896\n","Epoch 17/100\n","\u001b[1m291/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6836 - auc: 0.6489 - loss: 0.5867\n","Epoch 17: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6837 - auc: 0.6499 - loss: 0.5863 - val_acc: 0.3475 - val_auc: 0.5445 - val_loss: 0.7886\n","Epoch 18/100\n","\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6987 - auc: 0.7142 - loss: 0.5639\n","Epoch 18: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6986 - auc: 0.7142 - loss: 0.5639 - val_acc: 0.3475 - val_auc: 0.6072 - val_loss: 0.8716\n","Epoch 19/100\n","\u001b[1m293/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7120 - auc: 0.7185 - loss: 0.5453\n","Epoch 19: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7112 - auc: 0.7184 - loss: 0.5458 - val_acc: 0.3475 - val_auc: 0.5846 - val_loss: 0.9387\n","Epoch 20/100\n","\u001b[1m295/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6642 - auc: 0.7262 - loss: 0.5727\n","Epoch 20: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6650 - auc: 0.7260 - loss: 0.5722 - val_acc: 0.3475 - val_auc: 0.5687 - val_loss: 0.9365\n","Epoch 21/100\n","\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7030 - auc: 0.7263 - loss: 0.5439\n","Epoch 21: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7029 - auc: 0.7263 - loss: 0.5439 - val_acc: 0.3475 - val_auc: 0.5122 - val_loss: 0.8483\n","Epoch 22/100\n","\u001b[1m296/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6467 - auc: 0.7121 - loss: 0.5769\n","Epoch 22: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6481 - auc: 0.7128 - loss: 0.5760 - val_acc: 0.3475 - val_auc: 0.5250 - val_loss: 1.0506\n","Epoch 23/100\n","\u001b[1m297/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6965 - auc: 0.7146 - loss: 0.5499\n","Epoch 23: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6964 - auc: 0.7150 - loss: 0.5497 - val_acc: 0.3644 - val_auc: 0.5288 - val_loss: 0.8708\n","Epoch 24/100\n","\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6907 - auc: 0.7389 - loss: 0.5383\n","Epoch 24: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6907 - auc: 0.7389 - loss: 0.5383 - val_acc: 0.3559 - val_auc: 0.5122 - val_loss: 0.9092\n","Epoch 25/100\n","\u001b[1m297/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7006 - auc: 0.7295 - loss: 0.5381\n","Epoch 25: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7006 - auc: 0.7299 - loss: 0.5380 - val_acc: 0.3390 - val_auc: 0.5016 - val_loss: 0.9541\n","Epoch 26/100\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6834 - auc: 0.7052 - loss: 0.5583\n","Epoch 26: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6834 - auc: 0.7053 - loss: 0.5583 - val_acc: 0.3475 - val_auc: 0.5200 - val_loss: 0.9990\n","Epoch 27/100\n","\u001b[1m301/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7226 - auc: 0.7562 - loss: 0.5126\n","Epoch 27: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7225 - auc: 0.7562 - loss: 0.5127 - val_acc: 0.3475 - val_auc: 0.6923 - val_loss: 1.0207\n","Epoch 28/100\n","\u001b[1m294/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7195 - auc: 0.7633 - loss: 0.5172\n","Epoch 28: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7193 - auc: 0.7629 - loss: 0.5176 - val_acc: 0.4407 - val_auc: 0.5847 - val_loss: 0.8145\n","Epoch 29/100\n","\u001b[1m292/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7210 - auc: 0.7571 - loss: 0.5196\n","Epoch 29: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7206 - auc: 0.7567 - loss: 0.5200 - val_acc: 0.3475 - val_auc: 0.5081 - val_loss: 1.0152\n","Epoch 30/100\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7169 - auc: 0.7472 - loss: 0.5196\n","Epoch 30: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7168 - auc: 0.7473 - loss: 0.5196 - val_acc: 0.3475 - val_auc: 0.5141 - val_loss: 0.9648\n","Epoch 31/100\n","\u001b[1m296/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7056 - auc: 0.7503 - loss: 0.5184\n","Epoch 31: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7055 - auc: 0.7502 - loss: 0.5187 - val_acc: 0.3475 - val_auc: 0.5201 - val_loss: 0.9588\n","Epoch 32/100\n","\u001b[1m299/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7022 - auc: 0.7311 - loss: 0.5634\n","Epoch 32: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7023 - auc: 0.7316 - loss: 0.5628 - val_acc: 0.3475 - val_auc: 0.5322 - val_loss: 1.0451\n","Epoch 33/100\n","\u001b[1m297/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7221 - auc: 0.7631 - loss: 0.5199\n","Epoch 33: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7218 - auc: 0.7628 - loss: 0.5202 - val_acc: 0.3559 - val_auc: 0.5303 - val_loss: 0.9658\n","Epoch 34/100\n","\u001b[1m290/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7214 - auc: 0.7624 - loss: 0.5213\n","Epoch 34: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7209 - auc: 0.7623 - loss: 0.5214 - val_acc: 0.3475 - val_auc: 0.5165 - val_loss: 0.9418\n","Epoch 35/100\n","\u001b[1m294/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7291 - auc: 0.7624 - loss: 0.5296\n","Epoch 35: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7286 - auc: 0.7619 - loss: 0.5297 - val_acc: 0.3475 - val_auc: 0.5211 - val_loss: 0.9447\n","Epoch 36/100\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7162 - auc: 0.7584 - loss: 0.5069\n","Epoch 36: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7162 - auc: 0.7584 - loss: 0.5069 - val_acc: 0.3390 - val_auc: 0.5673 - val_loss: 0.9834\n","Epoch 37/100\n","\u001b[1m295/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7036 - auc: 0.7522 - loss: 0.5265\n","Epoch 37: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7038 - auc: 0.7522 - loss: 0.5266 - val_acc: 0.3475 - val_auc: 0.5529 - val_loss: 1.0090\n","Epoch 38/100\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7251 - auc: 0.7700 - loss: 0.5163\n","Epoch 38: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7250 - auc: 0.7700 - loss: 0.5163 - val_acc: 0.3475 - val_auc: 0.5616 - val_loss: 1.0223\n","Epoch 39/100\n","\u001b[1m298/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7009 - auc: 0.7439 - loss: 0.5247\n","Epoch 39: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7008 - auc: 0.7440 - loss: 0.5248 - val_acc: 0.3305 - val_auc: 0.5160 - val_loss: 0.9985\n","Epoch 40/100\n","\u001b[1m290/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7277 - auc: 0.7725 - loss: 0.5141\n","Epoch 40: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7271 - auc: 0.7723 - loss: 0.5143 - val_acc: 0.3475 - val_auc: 0.5323 - val_loss: 0.9457\n","Epoch 41/100\n","\u001b[1m292/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7408 - auc: 0.7707 - loss: 0.5073\n","Epoch 41: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7396 - auc: 0.7701 - loss: 0.5081 - val_acc: 0.3220 - val_auc: 0.5116 - val_loss: 1.0178\n","Epoch 42/100\n","\u001b[1m296/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7132 - auc: 0.7394 - loss: 0.5252\n","Epoch 42: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7131 - auc: 0.7397 - loss: 0.5253 - val_acc: 0.3220 - val_auc: 0.5190 - val_loss: 0.9935\n","Epoch 43/100\n","\u001b[1m291/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7151 - auc: 0.7585 - loss: 0.5007\n","Epoch 43: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7146 - auc: 0.7584 - loss: 0.5017 - val_acc: 0.3390 - val_auc: 0.5177 - val_loss: 0.9460\n","Epoch 44/100\n","\u001b[1m294/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7031 - auc: 0.7271 - loss: 0.5450\n","Epoch 44: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7038 - auc: 0.7282 - loss: 0.5442 - val_acc: 0.3898 - val_auc: 0.5548 - val_loss: 0.7395\n","Epoch 45/100\n","\u001b[1m294/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6889 - auc: 0.7463 - loss: 0.5489\n","Epoch 45: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6895 - auc: 0.7466 - loss: 0.5483 - val_acc: 0.3220 - val_auc: 0.5162 - val_loss: 0.9848\n","Epoch 46/100\n","\u001b[1m299/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7316 - auc: 0.7598 - loss: 0.5090\n","Epoch 46: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7312 - auc: 0.7598 - loss: 0.5092 - val_acc: 0.3475 - val_auc: 0.5193 - val_loss: 1.0764\n","Epoch 47/100\n","\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6936 - auc: 0.7633 - loss: 0.5318\n","Epoch 47: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6936 - auc: 0.7633 - loss: 0.5318 - val_acc: 0.3305 - val_auc: 0.5182 - val_loss: 1.0182\n","Epoch 48/100\n","\u001b[1m292/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7159 - auc: 0.7627 - loss: 0.5178\n","Epoch 48: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7159 - auc: 0.7628 - loss: 0.5179 - val_acc: 0.3390 - val_auc: 0.5516 - val_loss: 0.9664\n","Epoch 49/100\n","\u001b[1m298/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7071 - auc: 0.7494 - loss: 0.5200\n","Epoch 49: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7070 - auc: 0.7497 - loss: 0.5200 - val_acc: 0.3305 - val_auc: 0.5214 - val_loss: 1.0044\n","Epoch 50/100\n","\u001b[1m298/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7375 - auc: 0.7651 - loss: 0.5157\n","Epoch 50: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7374 - auc: 0.7651 - loss: 0.5158 - val_acc: 0.3305 - val_auc: 0.5550 - val_loss: 0.9175\n","Epoch 51/100\n","\u001b[1m299/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7341 - auc: 0.7831 - loss: 0.5260\n","Epoch 51: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7341 - auc: 0.7830 - loss: 0.5257 - val_acc: 0.3475 - val_auc: 0.5814 - val_loss: 0.9756\n","Epoch 52/100\n","\u001b[1m296/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7533 - auc: 0.7715 - loss: 0.4979\n","Epoch 52: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7527 - auc: 0.7715 - loss: 0.4984 - val_acc: 0.3390 - val_auc: 0.5502 - val_loss: 0.9664\n","Epoch 53/100\n","\u001b[1m295/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7261 - auc: 0.7742 - loss: 0.5154\n","Epoch 53: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7258 - auc: 0.7740 - loss: 0.5154 - val_acc: 0.3729 - val_auc: 0.5453 - val_loss: 0.8537\n","Epoch 54/100\n","\u001b[1m294/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6869 - auc: 0.7376 - loss: 0.5478\n","Epoch 54: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6881 - auc: 0.7387 - loss: 0.5466 - val_acc: 0.3475 - val_auc: 0.7607 - val_loss: 1.1325\n","Epoch 55/100\n","\u001b[1m295/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7182 - auc: 0.7655 - loss: 0.5189\n","Epoch 55: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7181 - auc: 0.7653 - loss: 0.5190 - val_acc: 0.3390 - val_auc: 0.5771 - val_loss: 0.8767\n","Epoch 56/100\n","\u001b[1m293/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7377 - auc: 0.7584 - loss: 0.5105\n","Epoch 56: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7372 - auc: 0.7588 - loss: 0.5107 - val_acc: 0.3390 - val_auc: 0.5146 - val_loss: 0.8421\n","Epoch 57/100\n","\u001b[1m293/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7024 - auc: 0.7501 - loss: 0.5309\n","Epoch 57: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7034 - auc: 0.7507 - loss: 0.5304 - val_acc: 0.3305 - val_auc: 0.5402 - val_loss: 1.0202\n","Epoch 58/100\n","\u001b[1m290/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7417 - auc: 0.7821 - loss: 0.4970\n","Epoch 58: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7410 - auc: 0.7818 - loss: 0.4978 - val_acc: 0.3305 - val_auc: 0.5927 - val_loss: 0.9684\n","Epoch 59/100\n","\u001b[1m294/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7276 - auc: 0.7909 - loss: 0.5053\n","Epoch 59: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7272 - auc: 0.7902 - loss: 0.5057 - val_acc: 0.3475 - val_auc: 0.5665 - val_loss: 0.9746\n","Epoch 60/100\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6911 - auc: 0.7295 - loss: 0.5390\n","Epoch 60: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6912 - auc: 0.7296 - loss: 0.5389 - val_acc: 0.3220 - val_auc: 0.5388 - val_loss: 0.9448\n","Epoch 61/100\n","\u001b[1m296/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7155 - auc: 0.7758 - loss: 0.5129\n","Epoch 61: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7157 - auc: 0.7758 - loss: 0.5129 - val_acc: 0.3475 - val_auc: 0.5447 - val_loss: 1.0143\n","Epoch 62/100\n","\u001b[1m298/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7370 - auc: 0.7832 - loss: 0.5053\n","Epoch 62: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7368 - auc: 0.7830 - loss: 0.5056 - val_acc: 0.3559 - val_auc: 0.6053 - val_loss: 0.9580\n","Epoch 63/100\n","\u001b[1m295/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7084 - auc: 0.7761 - loss: 0.5240\n","Epoch 63: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7090 - auc: 0.7762 - loss: 0.5235 - val_acc: 0.3475 - val_auc: 0.6408 - val_loss: 1.0261\n","Epoch 64/100\n","\u001b[1m291/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7594 - auc: 0.7865 - loss: 0.4822\n","Epoch 64: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7580 - auc: 0.7859 - loss: 0.4835 - val_acc: 0.3305 - val_auc: 0.5665 - val_loss: 0.9621\n","Epoch 65/100\n","\u001b[1m295/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7330 - auc: 0.7813 - loss: 0.5010\n","Epoch 65: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7327 - auc: 0.7810 - loss: 0.5015 - val_acc: 0.3220 - val_auc: 0.5478 - val_loss: 0.9294\n","Epoch 66/100\n","\u001b[1m297/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7234 - auc: 0.7549 - loss: 0.5184\n","Epoch 66: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7233 - auc: 0.7551 - loss: 0.5184 - val_acc: 0.3220 - val_auc: 0.5383 - val_loss: 0.9372\n","Epoch 67/100\n","\u001b[1m292/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7320 - auc: 0.7913 - loss: 0.4971\n","Epoch 67: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7312 - auc: 0.7906 - loss: 0.4978 - val_acc: 0.3136 - val_auc: 0.5283 - val_loss: 0.9251\n","Epoch 68/100\n","\u001b[1m299/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7458 - auc: 0.8003 - loss: 0.5011\n","Epoch 68: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7456 - auc: 0.7998 - loss: 0.5013 - val_acc: 0.3220 - val_auc: 0.5326 - val_loss: 0.9526\n","Epoch 69/100\n","\u001b[1m291/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7041 - auc: 0.7714 - loss: 0.5122\n","Epoch 69: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7049 - auc: 0.7717 - loss: 0.5122 - val_acc: 0.3475 - val_auc: 0.6088 - val_loss: 0.9866\n","Epoch 70/100\n","\u001b[1m298/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7179 - auc: 0.7680 - loss: 0.5076\n","Epoch 70: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7178 - auc: 0.7680 - loss: 0.5078 - val_acc: 0.3390 - val_auc: 0.5949 - val_loss: 0.9969\n","Epoch 71/100\n","\u001b[1m300/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7262 - auc: 0.7612 - loss: 0.5187\n","Epoch 71: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7263 - auc: 0.7614 - loss: 0.5186 - val_acc: 0.3305 - val_auc: 0.5249 - val_loss: 0.8975\n","Epoch 72/100\n","\u001b[1m298/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7073 - auc: 0.7691 - loss: 0.5088\n","Epoch 72: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7074 - auc: 0.7691 - loss: 0.5089 - val_acc: 0.2966 - val_auc: 0.5222 - val_loss: 0.9256\n","Epoch 73/100\n","\u001b[1m299/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7370 - auc: 0.7847 - loss: 0.4961\n","Epoch 73: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7370 - auc: 0.7846 - loss: 0.4963 - val_acc: 0.3136 - val_auc: 0.5143 - val_loss: 0.9103\n","Epoch 74/100\n","\u001b[1m292/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7422 - auc: 0.7872 - loss: 0.4916\n","Epoch 74: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7419 - auc: 0.7866 - loss: 0.4924 - val_acc: 0.3475 - val_auc: 0.5849 - val_loss: 1.0441\n","Epoch 75/100\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7377 - auc: 0.7559 - loss: 0.5050\n","Epoch 75: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7377 - auc: 0.7559 - loss: 0.5050 - val_acc: 0.3644 - val_auc: 0.6296 - val_loss: 0.9309\n","Epoch 76/100\n","\u001b[1m295/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7365 - auc: 0.7742 - loss: 0.5059\n","Epoch 76: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7360 - auc: 0.7742 - loss: 0.5060 - val_acc: 0.3390 - val_auc: 0.5499 - val_loss: 1.0225\n","Epoch 77/100\n","\u001b[1m295/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7594 - auc: 0.8087 - loss: 0.4727\n","Epoch 77: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7583 - auc: 0.8076 - loss: 0.4739 - val_acc: 0.3220 - val_auc: 0.5451 - val_loss: 0.9480\n","Epoch 78/100\n","\u001b[1m293/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7221 - auc: 0.7732 - loss: 0.5127\n","Epoch 78: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7221 - auc: 0.7732 - loss: 0.5127 - val_acc: 0.3220 - val_auc: 0.5341 - val_loss: 0.9307\n","Epoch 79/100\n","\u001b[1m296/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7213 - auc: 0.7892 - loss: 0.5016\n","Epoch 79: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7213 - auc: 0.7889 - loss: 0.5018 - val_acc: 0.3559 - val_auc: 0.6047 - val_loss: 0.9198\n","Epoch 80/100\n","\u001b[1m296/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7065 - auc: 0.7622 - loss: 0.5323\n","Epoch 80: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7070 - auc: 0.7627 - loss: 0.5317 - val_acc: 0.3390 - val_auc: 0.5415 - val_loss: 1.0309\n","Epoch 81/100\n","\u001b[1m298/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7203 - auc: 0.7865 - loss: 0.4865\n","Epoch 81: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7204 - auc: 0.7863 - loss: 0.4869 - val_acc: 0.3305 - val_auc: 0.5977 - val_loss: 0.9866\n","Epoch 82/100\n","\u001b[1m298/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7626 - auc: 0.7780 - loss: 0.4723\n","Epoch 82: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7620 - auc: 0.7780 - loss: 0.4730 - val_acc: 0.3305 - val_auc: 0.5634 - val_loss: 0.9127\n","Epoch 83/100\n","\u001b[1m296/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7614 - auc: 0.8088 - loss: 0.4733\n","Epoch 83: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7608 - auc: 0.8082 - loss: 0.4740 - val_acc: 0.3475 - val_auc: 0.6204 - val_loss: 0.9415\n","Epoch 84/100\n","\u001b[1m300/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7264 - auc: 0.7602 - loss: 0.5273\n","Epoch 84: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7264 - auc: 0.7604 - loss: 0.5271 - val_acc: 0.3390 - val_auc: 0.6256 - val_loss: 0.9797\n","Epoch 85/100\n","\u001b[1m297/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7134 - auc: 0.7820 - loss: 0.5119\n","Epoch 85: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7141 - auc: 0.7822 - loss: 0.5117 - val_acc: 0.3898 - val_auc: 0.5792 - val_loss: 0.8553\n","Epoch 86/100\n","\u001b[1m293/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7237 - auc: 0.7917 - loss: 0.4964\n","Epoch 86: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7237 - auc: 0.7918 - loss: 0.4964 - val_acc: 0.3220 - val_auc: 0.6010 - val_loss: 0.9034\n","Epoch 87/100\n","\u001b[1m296/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6978 - auc: 0.7791 - loss: 0.5225\n","Epoch 87: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6981 - auc: 0.7790 - loss: 0.5221 - val_acc: 0.3390 - val_auc: 0.6137 - val_loss: 1.0044\n","Epoch 88/100\n","\u001b[1m291/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7218 - auc: 0.7808 - loss: 0.5014\n","Epoch 88: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7222 - auc: 0.7811 - loss: 0.5015 - val_acc: 0.3559 - val_auc: 0.5721 - val_loss: 1.0998\n","Epoch 89/100\n","\u001b[1m295/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7272 - auc: 0.7730 - loss: 0.5148\n","Epoch 89: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7275 - auc: 0.7732 - loss: 0.5145 - val_acc: 0.3559 - val_auc: 0.6262 - val_loss: 0.9167\n","Epoch 90/100\n","\u001b[1m297/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6996 - auc: 0.7611 - loss: 0.5053\n","Epoch 90: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7002 - auc: 0.7615 - loss: 0.5053 - val_acc: 0.3220 - val_auc: 0.5729 - val_loss: 0.8941\n","Epoch 91/100\n","\u001b[1m296/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7323 - auc: 0.7766 - loss: 0.5155\n","Epoch 91: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7323 - auc: 0.7766 - loss: 0.5153 - val_acc: 0.3220 - val_auc: 0.5434 - val_loss: 0.9094\n","Epoch 92/100\n","\u001b[1m289/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7114 - auc: 0.7587 - loss: 0.5344\n","Epoch 92: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7126 - auc: 0.7597 - loss: 0.5330 - val_acc: 0.3559 - val_auc: 0.6294 - val_loss: 0.9447\n","Epoch 93/100\n","\u001b[1m292/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7432 - auc: 0.7838 - loss: 0.4898\n","Epoch 93: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7430 - auc: 0.7838 - loss: 0.4904 - val_acc: 0.3559 - val_auc: 0.6307 - val_loss: 0.8772\n","Epoch 94/100\n","\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7223 - auc: 0.7755 - loss: 0.5043\n","Epoch 94: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7223 - auc: 0.7756 - loss: 0.5043 - val_acc: 0.3475 - val_auc: 0.6148 - val_loss: 0.9113\n","Epoch 95/100\n","\u001b[1m291/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7168 - auc: 0.7846 - loss: 0.5080\n","Epoch 95: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7173 - auc: 0.7846 - loss: 0.5078 - val_acc: 0.3559 - val_auc: 0.5464 - val_loss: 1.0620\n","Epoch 96/100\n","\u001b[1m294/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7437 - auc: 0.7964 - loss: 0.5014\n","Epoch 96: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7433 - auc: 0.7959 - loss: 0.5015 - val_acc: 0.3220 - val_auc: 0.5293 - val_loss: 0.9277\n","Epoch 97/100\n","\u001b[1m298/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7509 - auc: 0.7837 - loss: 0.4820\n","Epoch 97: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7507 - auc: 0.7837 - loss: 0.4825 - val_acc: 0.3390 - val_auc: 0.5957 - val_loss: 1.0043\n","Epoch 98/100\n","\u001b[1m296/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7371 - auc: 0.7768 - loss: 0.4938\n","Epoch 98: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7371 - auc: 0.7769 - loss: 0.4941 - val_acc: 0.3559 - val_auc: 0.6188 - val_loss: 1.0750\n","Epoch 99/100\n","\u001b[1m296/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7415 - auc: 0.7929 - loss: 0.4974\n","Epoch 99: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7414 - auc: 0.7926 - loss: 0.4976 - val_acc: 0.3390 - val_auc: 0.5980 - val_loss: 0.9771\n","Epoch 100/100\n","\u001b[1m294/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7468 - auc: 0.7962 - loss: 0.4986\n","Epoch 100: val_loss did not improve from 0.61334\n","\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7464 - auc: 0.7957 - loss: 0.4988 - val_acc: 0.3475 - val_auc: 0.6177 - val_loss: 0.9598\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 1 | TEST ACC=0.9249 | TEST AUC=0.5143 | n=173\n","Confusion matrix:\n"," [[160   8]\n"," [  5   0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.970     0.952     0.961       168\n","           1      0.000     0.000     0.000         5\n","\n","    accuracy                          0.925       173\n","   macro avg      0.485     0.476     0.480       173\n","weighted avg      0.942     0.925     0.933       173\n","\n","\n","--- Fold 2/14 ---\n"," train | ids:   36 | files:   934 | pos files:  247 | neg files:  687\n","   val | ids:    4 | files:   145 | pos files:   77 | neg files:   68\n","  test | ids:    4 | files:   121 | pos files:   81 | neg files:   40\n","Epoch 1/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.7649 - auc: 0.4652 - loss: 0.6636\n","Epoch 1: val_loss improved from inf to 0.76101, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - acc: 0.7643 - auc: 0.4650 - loss: 0.6632 - val_acc: 0.4690 - val_auc: 0.7612 - val_loss: 0.7610\n","Epoch 2/100\n","\u001b[1m304/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7366 - auc: 0.5142 - loss: 0.5793\n","Epoch 2: val_loss did not improve from 0.76101\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7366 - auc: 0.5144 - loss: 0.5792 - val_acc: 0.4690 - val_auc: 0.7837 - val_loss: 0.7665\n","Epoch 3/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7288 - auc: 0.5368 - loss: 0.5828\n","Epoch 3: val_loss did not improve from 0.76101\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7289 - auc: 0.5373 - loss: 0.5826 - val_acc: 0.4690 - val_auc: 0.7946 - val_loss: 0.7793\n","Epoch 4/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7571 - auc: 0.5868 - loss: 0.5438\n","Epoch 4: val_loss did not improve from 0.76101\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7569 - auc: 0.5867 - loss: 0.5441 - val_acc: 0.4690 - val_auc: 0.7999 - val_loss: 0.7653\n","Epoch 5/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7345 - auc: 0.6037 - loss: 0.5665\n","Epoch 5: val_loss improved from 0.76101 to 0.73843, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7345 - auc: 0.6038 - loss: 0.5664 - val_acc: 0.4690 - val_auc: 0.8030 - val_loss: 0.7384\n","Epoch 6/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7550 - auc: 0.6412 - loss: 0.5363\n","Epoch 6: val_loss improved from 0.73843 to 0.72051, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7547 - auc: 0.6414 - loss: 0.5367 - val_acc: 0.4690 - val_auc: 0.7967 - val_loss: 0.7205\n","Epoch 7/100\n","\u001b[1m303/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7396 - auc: 0.6392 - loss: 0.5490\n","Epoch 7: val_loss did not improve from 0.72051\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7394 - auc: 0.6394 - loss: 0.5491 - val_acc: 0.4690 - val_auc: 0.7937 - val_loss: 0.7305\n","Epoch 8/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7255 - auc: 0.6359 - loss: 0.5650\n","Epoch 8: val_loss improved from 0.72051 to 0.71058, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7258 - auc: 0.6364 - loss: 0.5645 - val_acc: 0.4690 - val_auc: 0.7914 - val_loss: 0.7106\n","Epoch 9/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7460 - auc: 0.6675 - loss: 0.5308\n","Epoch 9: val_loss did not improve from 0.71058\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7458 - auc: 0.6676 - loss: 0.5310 - val_acc: 0.4690 - val_auc: 0.7857 - val_loss: 0.7288\n","Epoch 10/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7275 - auc: 0.6264 - loss: 0.5649\n","Epoch 10: val_loss improved from 0.71058 to 0.67407, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7277 - auc: 0.6277 - loss: 0.5642 - val_acc: 0.4690 - val_auc: 0.7846 - val_loss: 0.6741\n","Epoch 11/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7403 - auc: 0.6510 - loss: 0.5365\n","Epoch 11: val_loss did not improve from 0.67407\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7402 - auc: 0.6515 - loss: 0.5365 - val_acc: 0.4690 - val_auc: 0.7781 - val_loss: 0.6826\n","Epoch 12/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7567 - auc: 0.6714 - loss: 0.5222\n","Epoch 12: val_loss improved from 0.67407 to 0.67024, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7565 - auc: 0.6715 - loss: 0.5223 - val_acc: 0.4690 - val_auc: 0.7763 - val_loss: 0.6702\n","Epoch 13/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7580 - auc: 0.6991 - loss: 0.5091\n","Epoch 13: val_loss improved from 0.67024 to 0.65592, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7579 - auc: 0.6990 - loss: 0.5093 - val_acc: 0.4690 - val_auc: 0.7808 - val_loss: 0.6559\n","Epoch 14/100\n","\u001b[1m304/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7648 - auc: 0.6929 - loss: 0.5101\n","Epoch 14: val_loss did not improve from 0.65592\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7646 - auc: 0.6930 - loss: 0.5104 - val_acc: 0.4690 - val_auc: 0.7677 - val_loss: 0.6562\n","Epoch 15/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7723 - auc: 0.6867 - loss: 0.5260\n","Epoch 15: val_loss did not improve from 0.65592\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7723 - auc: 0.6872 - loss: 0.5258 - val_acc: 0.4690 - val_auc: 0.7654 - val_loss: 0.6602\n","Epoch 16/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7649 - auc: 0.6886 - loss: 0.5330\n","Epoch 16: val_loss did not improve from 0.65592\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7649 - auc: 0.6887 - loss: 0.5328 - val_acc: 0.4690 - val_auc: 0.7609 - val_loss: 0.6821\n","Epoch 17/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7712 - auc: 0.6763 - loss: 0.5113\n","Epoch 17: val_loss improved from 0.65592 to 0.64675, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7712 - auc: 0.6766 - loss: 0.5113 - val_acc: 0.4690 - val_auc: 0.7731 - val_loss: 0.6468\n","Epoch 18/100\n","\u001b[1m301/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7914 - auc: 0.6698 - loss: 0.5074\n","Epoch 18: val_loss improved from 0.64675 to 0.62876, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7908 - auc: 0.6709 - loss: 0.5076 - val_acc: 0.4414 - val_auc: 0.7750 - val_loss: 0.6288\n","Epoch 19/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7715 - auc: 0.6665 - loss: 0.5174\n","Epoch 19: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7716 - auc: 0.6668 - loss: 0.5174 - val_acc: 0.4690 - val_auc: 0.7651 - val_loss: 0.6564\n","Epoch 20/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7757 - auc: 0.6681 - loss: 0.5183\n","Epoch 20: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7756 - auc: 0.6690 - loss: 0.5182 - val_acc: 0.4690 - val_auc: 0.7644 - val_loss: 0.6602\n","Epoch 21/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7708 - auc: 0.7147 - loss: 0.4995\n","Epoch 21: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7710 - auc: 0.7144 - loss: 0.4996 - val_acc: 0.4414 - val_auc: 0.7628 - val_loss: 0.6497\n","Epoch 22/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7498 - auc: 0.7243 - loss: 0.5083\n","Epoch 22: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7500 - auc: 0.7242 - loss: 0.5083 - val_acc: 0.4414 - val_auc: 0.7576 - val_loss: 0.6529\n","Epoch 23/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7786 - auc: 0.7263 - loss: 0.4819\n","Epoch 23: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7786 - auc: 0.7263 - loss: 0.4820 - val_acc: 0.4414 - val_auc: 0.7566 - val_loss: 0.6531\n","Epoch 24/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7589 - auc: 0.6902 - loss: 0.5104\n","Epoch 24: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7594 - auc: 0.6907 - loss: 0.5100 - val_acc: 0.4690 - val_auc: 0.7301 - val_loss: 0.6806\n","Epoch 25/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7584 - auc: 0.6935 - loss: 0.5226\n","Epoch 25: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7587 - auc: 0.6938 - loss: 0.5221 - val_acc: 0.4690 - val_auc: 0.7597 - val_loss: 0.6671\n","Epoch 26/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7999 - auc: 0.7448 - loss: 0.4650\n","Epoch 26: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7994 - auc: 0.7442 - loss: 0.4656 - val_acc: 0.4690 - val_auc: 0.7419 - val_loss: 0.6746\n","Epoch 27/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7554 - auc: 0.6992 - loss: 0.5085\n","Epoch 27: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7561 - auc: 0.6995 - loss: 0.5080 - val_acc: 0.4690 - val_auc: 0.7371 - val_loss: 0.6992\n","Epoch 28/100\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7689 - auc: 0.7461 - loss: 0.4774\n","Epoch 28: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7689 - auc: 0.7460 - loss: 0.4774 - val_acc: 0.4690 - val_auc: 0.7352 - val_loss: 0.6845\n","Epoch 29/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7863 - auc: 0.7030 - loss: 0.4730\n","Epoch 29: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7862 - auc: 0.7031 - loss: 0.4731 - val_acc: 0.4414 - val_auc: 0.7268 - val_loss: 0.6673\n","Epoch 30/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7599 - auc: 0.7160 - loss: 0.4982\n","Epoch 30: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7605 - auc: 0.7164 - loss: 0.4977 - val_acc: 0.4690 - val_auc: 0.7264 - val_loss: 0.7114\n","Epoch 31/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7959 - auc: 0.7406 - loss: 0.4502\n","Epoch 31: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7955 - auc: 0.7404 - loss: 0.4508 - val_acc: 0.4690 - val_auc: 0.7044 - val_loss: 0.6788\n","Epoch 32/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7662 - auc: 0.7408 - loss: 0.4863\n","Epoch 32: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7662 - auc: 0.7407 - loss: 0.4863 - val_acc: 0.4690 - val_auc: 0.6823 - val_loss: 0.7022\n","Epoch 33/100\n","\u001b[1m299/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7747 - auc: 0.7583 - loss: 0.4670\n","Epoch 33: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7749 - auc: 0.7573 - loss: 0.4671 - val_acc: 0.4690 - val_auc: 0.6870 - val_loss: 0.7119\n","Epoch 34/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7939 - auc: 0.7710 - loss: 0.4522\n","Epoch 34: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7936 - auc: 0.7705 - loss: 0.4527 - val_acc: 0.4690 - val_auc: 0.6131 - val_loss: 0.7068\n","Epoch 35/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7991 - auc: 0.7074 - loss: 0.4698\n","Epoch 35: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7990 - auc: 0.7077 - loss: 0.4698 - val_acc: 0.4690 - val_auc: 0.5501 - val_loss: 0.7170\n","Epoch 36/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8050 - auc: 0.7713 - loss: 0.4407\n","Epoch 36: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.8046 - auc: 0.7709 - loss: 0.4412 - val_acc: 0.4414 - val_auc: 0.5333 - val_loss: 0.6840\n","Epoch 37/100\n","\u001b[1m304/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7979 - auc: 0.7353 - loss: 0.4538\n","Epoch 37: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7976 - auc: 0.7356 - loss: 0.4542 - val_acc: 0.4414 - val_auc: 0.5295 - val_loss: 0.6925\n","Epoch 38/100\n","\u001b[1m298/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7907 - auc: 0.7764 - loss: 0.4397\n","Epoch 38: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7898 - auc: 0.7757 - loss: 0.4409 - val_acc: 0.4690 - val_auc: 0.5320 - val_loss: 0.7479\n","Epoch 39/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7862 - auc: 0.7848 - loss: 0.4500\n","Epoch 39: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7861 - auc: 0.7848 - loss: 0.4500 - val_acc: 0.4690 - val_auc: 0.5371 - val_loss: 0.7908\n","Epoch 40/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7819 - auc: 0.7742 - loss: 0.4499\n","Epoch 40: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7819 - auc: 0.7742 - loss: 0.4500 - val_acc: 0.4690 - val_auc: 0.5194 - val_loss: 0.7506\n","Epoch 41/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8144 - auc: 0.8047 - loss: 0.4072\n","Epoch 41: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.8137 - auc: 0.8040 - loss: 0.4083 - val_acc: 0.4690 - val_auc: 0.5138 - val_loss: 0.7802\n","Epoch 42/100\n","\u001b[1m301/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7724 - auc: 0.7632 - loss: 0.4708\n","Epoch 42: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7730 - auc: 0.7637 - loss: 0.4702 - val_acc: 0.4621 - val_auc: 0.4965 - val_loss: 0.7464\n","Epoch 43/100\n","\u001b[1m303/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7979 - auc: 0.7421 - loss: 0.4513\n","Epoch 43: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7977 - auc: 0.7428 - loss: 0.4514 - val_acc: 0.4690 - val_auc: 0.5138 - val_loss: 0.7903\n","Epoch 44/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7779 - auc: 0.7692 - loss: 0.4653\n","Epoch 44: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7781 - auc: 0.7692 - loss: 0.4651 - val_acc: 0.4621 - val_auc: 0.4752 - val_loss: 0.7529\n","Epoch 45/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7893 - auc: 0.7963 - loss: 0.4432\n","Epoch 45: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7893 - auc: 0.7962 - loss: 0.4434 - val_acc: 0.4690 - val_auc: 0.5369 - val_loss: 0.8556\n","Epoch 46/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7756 - auc: 0.7809 - loss: 0.4552\n","Epoch 46: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7756 - auc: 0.7809 - loss: 0.4551 - val_acc: 0.4690 - val_auc: 0.5271 - val_loss: 0.8229\n","Epoch 47/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8135 - auc: 0.8123 - loss: 0.4269\n","Epoch 47: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.8133 - auc: 0.8122 - loss: 0.4271 - val_acc: 0.4966 - val_auc: 0.4899 - val_loss: 0.7777\n","Epoch 48/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7833 - auc: 0.7919 - loss: 0.4547\n","Epoch 48: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7834 - auc: 0.7919 - loss: 0.4546 - val_acc: 0.4414 - val_auc: 0.5123 - val_loss: 0.7366\n","Epoch 49/100\n","\u001b[1m299/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7874 - auc: 0.7950 - loss: 0.4438\n","Epoch 49: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7874 - auc: 0.7950 - loss: 0.4440 - val_acc: 0.4759 - val_auc: 0.4892 - val_loss: 0.8264\n","Epoch 50/100\n","\u001b[1m299/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7906 - auc: 0.7737 - loss: 0.4475\n","Epoch 50: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7904 - auc: 0.7740 - loss: 0.4476 - val_acc: 0.4690 - val_auc: 0.5006 - val_loss: 0.8359\n","Epoch 51/100\n","\u001b[1m299/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7925 - auc: 0.8177 - loss: 0.4323\n","Epoch 51: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7928 - auc: 0.8167 - loss: 0.4328 - val_acc: 0.4759 - val_auc: 0.4925 - val_loss: 0.8421\n","Epoch 52/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7896 - auc: 0.8082 - loss: 0.4431\n","Epoch 52: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7895 - auc: 0.8079 - loss: 0.4432 - val_acc: 0.4690 - val_auc: 0.5199 - val_loss: 0.8271\n","Epoch 53/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7932 - auc: 0.8272 - loss: 0.4297\n","Epoch 53: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7931 - auc: 0.8267 - loss: 0.4299 - val_acc: 0.4690 - val_auc: 0.5241 - val_loss: 0.8425\n","Epoch 54/100\n","\u001b[1m298/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7854 - auc: 0.8084 - loss: 0.4400\n","Epoch 54: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7853 - auc: 0.8079 - loss: 0.4402 - val_acc: 0.4828 - val_auc: 0.4861 - val_loss: 0.8322\n","Epoch 55/100\n","\u001b[1m304/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8011 - auc: 0.8062 - loss: 0.4277\n","Epoch 55: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.8008 - auc: 0.8059 - loss: 0.4281 - val_acc: 0.4966 - val_auc: 0.4898 - val_loss: 0.8115\n","Epoch 56/100\n","\u001b[1m299/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7912 - auc: 0.8140 - loss: 0.4228\n","Epoch 56: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7909 - auc: 0.8132 - loss: 0.4236 - val_acc: 0.5103 - val_auc: 0.4971 - val_loss: 0.8126\n","Epoch 57/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7885 - auc: 0.7967 - loss: 0.4450\n","Epoch 57: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7887 - auc: 0.7967 - loss: 0.4449 - val_acc: 0.4690 - val_auc: 0.5180 - val_loss: 0.9053\n","Epoch 58/100\n","\u001b[1m299/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8145 - auc: 0.8203 - loss: 0.4213\n","Epoch 58: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.8138 - auc: 0.8195 - loss: 0.4223 - val_acc: 0.4690 - val_auc: 0.5070 - val_loss: 0.8400\n","Epoch 59/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7819 - auc: 0.7893 - loss: 0.4458\n","Epoch 59: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7820 - auc: 0.7894 - loss: 0.4457 - val_acc: 0.4759 - val_auc: 0.4938 - val_loss: 0.8848\n","Epoch 60/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7955 - auc: 0.7843 - loss: 0.4465\n","Epoch 60: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7955 - auc: 0.7845 - loss: 0.4463 - val_acc: 0.4759 - val_auc: 0.4841 - val_loss: 0.8970\n","Epoch 61/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7921 - auc: 0.7885 - loss: 0.4318\n","Epoch 61: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7921 - auc: 0.7886 - loss: 0.4318 - val_acc: 0.4828 - val_auc: 0.5028 - val_loss: 0.7900\n","Epoch 62/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8289 - auc: 0.8253 - loss: 0.4049\n","Epoch 62: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.8286 - auc: 0.8252 - loss: 0.4052 - val_acc: 0.4690 - val_auc: 0.5095 - val_loss: 0.9623\n","Epoch 63/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7860 - auc: 0.7930 - loss: 0.4357\n","Epoch 63: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7858 - auc: 0.7933 - loss: 0.4358 - val_acc: 0.4966 - val_auc: 0.4950 - val_loss: 0.8308\n","Epoch 64/100\n","\u001b[1m297/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.8025 - auc: 0.8182 - loss: 0.4141\n","Epoch 64: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.8014 - auc: 0.8173 - loss: 0.4155 - val_acc: 0.4897 - val_auc: 0.5049 - val_loss: 0.8122\n","Epoch 65/100\n","\u001b[1m301/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8101 - auc: 0.8107 - loss: 0.4200\n","Epoch 65: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.8095 - auc: 0.8105 - loss: 0.4206 - val_acc: 0.4690 - val_auc: 0.5008 - val_loss: 0.8876\n","Epoch 66/100\n","\u001b[1m300/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8116 - auc: 0.8102 - loss: 0.4200\n","Epoch 66: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.8108 - auc: 0.8102 - loss: 0.4206 - val_acc: 0.4828 - val_auc: 0.5077 - val_loss: 0.8249\n","Epoch 67/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7633 - auc: 0.7902 - loss: 0.4587\n","Epoch 67: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7639 - auc: 0.7904 - loss: 0.4583 - val_acc: 0.4966 - val_auc: 0.4958 - val_loss: 0.8431\n","Epoch 68/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7848 - auc: 0.8205 - loss: 0.4227\n","Epoch 68: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7849 - auc: 0.8202 - loss: 0.4229 - val_acc: 0.4828 - val_auc: 0.5013 - val_loss: 0.8527\n","Epoch 69/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7986 - auc: 0.8138 - loss: 0.4218\n","Epoch 69: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7984 - auc: 0.8136 - loss: 0.4221 - val_acc: 0.4690 - val_auc: 0.5176 - val_loss: 0.9126\n","Epoch 70/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7782 - auc: 0.8044 - loss: 0.4490\n","Epoch 70: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7785 - auc: 0.8044 - loss: 0.4488 - val_acc: 0.4759 - val_auc: 0.5165 - val_loss: 0.8296\n","Epoch 71/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7965 - auc: 0.7532 - loss: 0.4416\n","Epoch 71: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7964 - auc: 0.7543 - loss: 0.4414 - val_acc: 0.4897 - val_auc: 0.4968 - val_loss: 0.8480\n","Epoch 72/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7784 - auc: 0.8006 - loss: 0.4429\n","Epoch 72: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7786 - auc: 0.8007 - loss: 0.4428 - val_acc: 0.4690 - val_auc: 0.5310 - val_loss: 0.9201\n","Epoch 73/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7789 - auc: 0.8024 - loss: 0.4586\n","Epoch 73: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7791 - auc: 0.8025 - loss: 0.4582 - val_acc: 0.4690 - val_auc: 0.5011 - val_loss: 0.9110\n","Epoch 74/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7709 - auc: 0.7822 - loss: 0.4495\n","Epoch 74: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7712 - auc: 0.7828 - loss: 0.4491 - val_acc: 0.5034 - val_auc: 0.5239 - val_loss: 0.8142\n","Epoch 75/100\n","\u001b[1m302/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7961 - auc: 0.8185 - loss: 0.4163\n","Epoch 75: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7959 - auc: 0.8179 - loss: 0.4172 - val_acc: 0.4690 - val_auc: 0.5531 - val_loss: 1.0256\n","Epoch 76/100\n","\u001b[1m301/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7959 - auc: 0.8222 - loss: 0.4205\n","Epoch 76: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7956 - auc: 0.8217 - loss: 0.4210 - val_acc: 0.4690 - val_auc: 0.5003 - val_loss: 0.9392\n","Epoch 77/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7908 - auc: 0.8146 - loss: 0.4371\n","Epoch 77: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7908 - auc: 0.8146 - loss: 0.4371 - val_acc: 0.4759 - val_auc: 0.5319 - val_loss: 0.8473\n","Epoch 78/100\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7558 - auc: 0.8062 - loss: 0.4552\n","Epoch 78: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7559 - auc: 0.8062 - loss: 0.4551 - val_acc: 0.4690 - val_auc: 0.5171 - val_loss: 0.8960\n","Epoch 79/100\n","\u001b[1m299/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7951 - auc: 0.8293 - loss: 0.4198\n","Epoch 79: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7950 - auc: 0.8285 - loss: 0.4204 - val_acc: 0.5172 - val_auc: 0.5228 - val_loss: 0.8361\n","Epoch 80/100\n","\u001b[1m303/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8136 - auc: 0.8201 - loss: 0.4086\n","Epoch 80: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.8128 - auc: 0.8196 - loss: 0.4093 - val_acc: 0.4828 - val_auc: 0.5570 - val_loss: 0.8201\n","Epoch 81/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7841 - auc: 0.8189 - loss: 0.4287\n","Epoch 81: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7843 - auc: 0.8187 - loss: 0.4286 - val_acc: 0.5241 - val_auc: 0.5362 - val_loss: 0.7956\n","Epoch 82/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7803 - auc: 0.7950 - loss: 0.4366\n","Epoch 82: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7804 - auc: 0.7952 - loss: 0.4366 - val_acc: 0.4897 - val_auc: 0.5179 - val_loss: 0.8907\n","Epoch 83/100\n","\u001b[1m303/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7971 - auc: 0.7893 - loss: 0.4320\n","Epoch 83: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7967 - auc: 0.7898 - loss: 0.4320 - val_acc: 0.4690 - val_auc: 0.5403 - val_loss: 0.9837\n","Epoch 84/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7947 - auc: 0.8125 - loss: 0.4236\n","Epoch 84: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7946 - auc: 0.8126 - loss: 0.4237 - val_acc: 0.4759 - val_auc: 0.5364 - val_loss: 0.8904\n","Epoch 85/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7980 - auc: 0.8390 - loss: 0.4073\n","Epoch 85: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7980 - auc: 0.8389 - loss: 0.4075 - val_acc: 0.5448 - val_auc: 0.5487 - val_loss: 0.7990\n","Epoch 86/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7979 - auc: 0.8289 - loss: 0.4096\n","Epoch 86: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7979 - auc: 0.8288 - loss: 0.4098 - val_acc: 0.4690 - val_auc: 0.5388 - val_loss: 0.9398\n","Epoch 87/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7811 - auc: 0.7980 - loss: 0.4451\n","Epoch 87: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7813 - auc: 0.7982 - loss: 0.4448 - val_acc: 0.4828 - val_auc: 0.5295 - val_loss: 0.8962\n","Epoch 88/100\n","\u001b[1m298/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7945 - auc: 0.8189 - loss: 0.4169\n","Epoch 88: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7945 - auc: 0.8186 - loss: 0.4174 - val_acc: 0.4828 - val_auc: 0.5328 - val_loss: 0.9053\n","Epoch 89/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8012 - auc: 0.8396 - loss: 0.4121\n","Epoch 89: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.8010 - auc: 0.8392 - loss: 0.4124 - val_acc: 0.5310 - val_auc: 0.5505 - val_loss: 0.7941\n","Epoch 90/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7867 - auc: 0.8205 - loss: 0.4220\n","Epoch 90: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7868 - auc: 0.8204 - loss: 0.4221 - val_acc: 0.6000 - val_auc: 0.5563 - val_loss: 0.7660\n","Epoch 91/100\n","\u001b[1m304/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7809 - auc: 0.8218 - loss: 0.4404\n","Epoch 91: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7814 - auc: 0.8218 - loss: 0.4399 - val_acc: 0.4897 - val_auc: 0.5116 - val_loss: 0.9597\n","Epoch 92/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7580 - auc: 0.7846 - loss: 0.4687\n","Epoch 92: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7586 - auc: 0.7852 - loss: 0.4679 - val_acc: 0.5793 - val_auc: 0.5582 - val_loss: 0.8171\n","Epoch 93/100\n","\u001b[1m301/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7957 - auc: 0.8351 - loss: 0.4043\n","Epoch 93: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7957 - auc: 0.8348 - loss: 0.4049 - val_acc: 0.5034 - val_auc: 0.5286 - val_loss: 0.8792\n","Epoch 94/100\n","\u001b[1m304/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7762 - auc: 0.8214 - loss: 0.4236\n","Epoch 94: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7763 - auc: 0.8215 - loss: 0.4235 - val_acc: 0.4897 - val_auc: 0.5824 - val_loss: 0.8592\n","Epoch 95/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7810 - auc: 0.8071 - loss: 0.4521\n","Epoch 95: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7813 - auc: 0.8075 - loss: 0.4514 - val_acc: 0.4828 - val_auc: 0.5519 - val_loss: 0.9145\n","Epoch 96/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7917 - auc: 0.8302 - loss: 0.4056\n","Epoch 96: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7917 - auc: 0.8301 - loss: 0.4057 - val_acc: 0.5103 - val_auc: 0.5706 - val_loss: 0.8503\n","Epoch 97/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7727 - auc: 0.8003 - loss: 0.4432\n","Epoch 97: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7728 - auc: 0.8004 - loss: 0.4430 - val_acc: 0.4897 - val_auc: 0.5810 - val_loss: 0.8840\n","Epoch 98/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7983 - auc: 0.8245 - loss: 0.4193\n","Epoch 98: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7981 - auc: 0.8245 - loss: 0.4193 - val_acc: 0.5379 - val_auc: 0.5583 - val_loss: 0.8768\n","Epoch 99/100\n","\u001b[1m303/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8154 - auc: 0.8303 - loss: 0.3828\n","Epoch 99: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.8146 - auc: 0.8300 - loss: 0.3840 - val_acc: 0.6000 - val_auc: 0.5913 - val_loss: 0.7488\n","Epoch 100/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7703 - auc: 0.8215 - loss: 0.4332\n","Epoch 100: val_loss did not improve from 0.62876\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7708 - auc: 0.8217 - loss: 0.4328 - val_acc: 0.5724 - val_auc: 0.6022 - val_loss: 0.7187\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 2 | TEST ACC=0.3306 | TEST AUC=0.2704 | n=121\n","Confusion matrix:\n"," [[40  0]\n"," [81  0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.331     1.000     0.497        40\n","           1      0.000     0.000     0.000        81\n","\n","    accuracy                          0.331       121\n","   macro avg      0.165     0.500     0.248       121\n","weighted avg      0.109     0.331     0.164       121\n","\n","\n","--- Fold 3/14 ---\n"," train | ids:   36 | files:  1006 | pos files:  394 | neg files:  612\n","   val | ids:    5 | files:   137 | pos files:    5 | neg files:  132\n","  test | ids:    3 | files:    57 | pos files:    6 | neg files:   51\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m332/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.5992 - auc: 0.5022 - loss: 0.6883\n","Epoch 1: val_loss improved from inf to 0.56224, saving model to best_fold_03.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - acc: 0.5993 - auc: 0.5024 - loss: 0.6882 - val_acc: 0.9635 - val_auc: 0.1258 - val_loss: 0.5622\n","Epoch 2/100\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5980 - auc: 0.5461 - loss: 0.6707\n","Epoch 2: val_loss improved from 0.56224 to 0.52517, saving model to best_fold_03.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5981 - auc: 0.5461 - loss: 0.6707 - val_acc: 0.9635 - val_auc: 0.1621 - val_loss: 0.5252\n","Epoch 3/100\n","\u001b[1m334/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6161 - auc: 0.5404 - loss: 0.6633\n","Epoch 3: val_loss improved from 0.52517 to 0.52040, saving model to best_fold_03.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6160 - auc: 0.5405 - loss: 0.6634 - val_acc: 0.9635 - val_auc: 0.1727 - val_loss: 0.5204\n","Epoch 4/100\n","\u001b[1m334/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6343 - auc: 0.5812 - loss: 0.6516\n","Epoch 4: val_loss improved from 0.52040 to 0.49495, saving model to best_fold_03.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6341 - auc: 0.5815 - loss: 0.6517 - val_acc: 0.9635 - val_auc: 0.1795 - val_loss: 0.4949\n","Epoch 5/100\n","\u001b[1m333/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6071 - auc: 0.6408 - loss: 0.6536\n","Epoch 5: val_loss did not improve from 0.49495\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6072 - auc: 0.6405 - loss: 0.6536 - val_acc: 0.9635 - val_auc: 0.1917 - val_loss: 0.5069\n","Epoch 6/100\n","\u001b[1m323/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6110 - auc: 0.6737 - loss: 0.6359\n","Epoch 6: val_loss improved from 0.49495 to 0.46620, saving model to best_fold_03.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6109 - auc: 0.6726 - loss: 0.6360 - val_acc: 0.9635 - val_auc: 0.2023 - val_loss: 0.4662\n","Epoch 7/100\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6195 - auc: 0.6619 - loss: 0.6160\n","Epoch 7: val_loss improved from 0.46620 to 0.44787, saving model to best_fold_03.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6194 - auc: 0.6619 - loss: 0.6160 - val_acc: 0.9635 - val_auc: 0.2121 - val_loss: 0.4479\n","Epoch 8/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6123 - auc: 0.6813 - loss: 0.6074\n","Epoch 8: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6122 - auc: 0.6811 - loss: 0.6072 - val_acc: 0.9635 - val_auc: 0.2023 - val_loss: 0.4628\n","Epoch 9/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6460 - auc: 0.6778 - loss: 0.5832\n","Epoch 9: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6455 - auc: 0.6779 - loss: 0.5834 - val_acc: 0.8175 - val_auc: 0.2159 - val_loss: 0.4961\n","Epoch 10/100\n","\u001b[1m324/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5998 - auc: 0.6625 - loss: 0.5923\n","Epoch 10: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6006 - auc: 0.6634 - loss: 0.5919 - val_acc: 0.7518 - val_auc: 0.2152 - val_loss: 0.4948\n","Epoch 11/100\n","\u001b[1m334/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6209 - auc: 0.6872 - loss: 0.5676\n","Epoch 11: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6207 - auc: 0.6870 - loss: 0.5677 - val_acc: 0.7518 - val_auc: 0.2227 - val_loss: 0.4987\n","Epoch 12/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5826 - auc: 0.6636 - loss: 0.5894\n","Epoch 12: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5829 - auc: 0.6639 - loss: 0.5892 - val_acc: 0.7664 - val_auc: 0.2386 - val_loss: 0.4881\n","Epoch 13/100\n","\u001b[1m325/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6319 - auc: 0.6896 - loss: 0.5678\n","Epoch 13: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6310 - auc: 0.6892 - loss: 0.5680 - val_acc: 0.7518 - val_auc: 0.2659 - val_loss: 0.4937\n","Epoch 14/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6098 - auc: 0.6721 - loss: 0.5736\n","Epoch 14: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6100 - auc: 0.6723 - loss: 0.5736 - val_acc: 0.6861 - val_auc: 0.2265 - val_loss: 0.5019\n","Epoch 15/100\n","\u001b[1m332/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5943 - auc: 0.6676 - loss: 0.5783\n","Epoch 15: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5946 - auc: 0.6678 - loss: 0.5783 - val_acc: 0.7226 - val_auc: 0.2909 - val_loss: 0.5215\n","Epoch 16/100\n","\u001b[1m325/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6400 - auc: 0.7093 - loss: 0.5485\n","Epoch 16: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6388 - auc: 0.7082 - loss: 0.5492 - val_acc: 0.6934 - val_auc: 0.2705 - val_loss: 0.5119\n","Epoch 17/100\n","\u001b[1m334/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5941 - auc: 0.6771 - loss: 0.5762\n","Epoch 17: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5941 - auc: 0.6772 - loss: 0.5762 - val_acc: 0.7153 - val_auc: 0.3341 - val_loss: 0.5296\n","Epoch 18/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6164 - auc: 0.6951 - loss: 0.5623\n","Epoch 18: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6164 - auc: 0.6952 - loss: 0.5623 - val_acc: 0.6934 - val_auc: 0.3250 - val_loss: 0.5071\n","Epoch 19/100\n","\u001b[1m332/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6057 - auc: 0.6852 - loss: 0.5664\n","Epoch 19: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6059 - auc: 0.6854 - loss: 0.5663 - val_acc: 0.6934 - val_auc: 0.3311 - val_loss: 0.5280\n","Epoch 20/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6244 - auc: 0.6897 - loss: 0.5664\n","Epoch 20: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6242 - auc: 0.6898 - loss: 0.5665 - val_acc: 0.6496 - val_auc: 0.2955 - val_loss: 0.4967\n","Epoch 21/100\n","\u001b[1m329/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6379 - auc: 0.6965 - loss: 0.5603\n","Epoch 21: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6379 - auc: 0.6965 - loss: 0.5603 - val_acc: 0.6496 - val_auc: 0.3045 - val_loss: 0.4784\n","Epoch 22/100\n","\u001b[1m335/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5974 - auc: 0.6739 - loss: 0.5746\n","Epoch 22: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5975 - auc: 0.6740 - loss: 0.5745 - val_acc: 0.6569 - val_auc: 0.3227 - val_loss: 0.4971\n","Epoch 23/100\n","\u001b[1m323/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6146 - auc: 0.6811 - loss: 0.5577\n","Epoch 23: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6148 - auc: 0.6818 - loss: 0.5580 - val_acc: 0.6861 - val_auc: 0.3758 - val_loss: 0.5087\n","Epoch 24/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6406 - auc: 0.7160 - loss: 0.5562\n","Epoch 24: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6399 - auc: 0.7154 - loss: 0.5565 - val_acc: 0.6861 - val_auc: 0.3545 - val_loss: 0.5366\n","Epoch 25/100\n","\u001b[1m329/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6328 - auc: 0.7049 - loss: 0.5692\n","Epoch 25: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6325 - auc: 0.7047 - loss: 0.5691 - val_acc: 0.6423 - val_auc: 0.3038 - val_loss: 0.5246\n","Epoch 26/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6428 - auc: 0.7331 - loss: 0.5353\n","Epoch 26: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6426 - auc: 0.7325 - loss: 0.5358 - val_acc: 0.6861 - val_auc: 0.3735 - val_loss: 0.5674\n","Epoch 27/100\n","\u001b[1m332/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6219 - auc: 0.6938 - loss: 0.5621\n","Epoch 27: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6221 - auc: 0.6941 - loss: 0.5620 - val_acc: 0.6496 - val_auc: 0.3212 - val_loss: 0.5489\n","Epoch 28/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6349 - auc: 0.7091 - loss: 0.5649\n","Epoch 28: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6348 - auc: 0.7091 - loss: 0.5648 - val_acc: 0.6496 - val_auc: 0.3182 - val_loss: 0.5079\n","Epoch 29/100\n","\u001b[1m329/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6031 - auc: 0.6870 - loss: 0.5801\n","Epoch 29: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6037 - auc: 0.6877 - loss: 0.5797 - val_acc: 0.6861 - val_auc: 0.3568 - val_loss: 0.5138\n","Epoch 30/100\n","\u001b[1m325/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6085 - auc: 0.6789 - loss: 0.5869\n","Epoch 30: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6091 - auc: 0.6800 - loss: 0.5861 - val_acc: 0.6861 - val_auc: 0.3742 - val_loss: 0.5591\n","Epoch 31/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6059 - auc: 0.6870 - loss: 0.5588\n","Epoch 31: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6065 - auc: 0.6875 - loss: 0.5589 - val_acc: 0.6861 - val_auc: 0.3917 - val_loss: 0.5617\n","Epoch 32/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6213 - auc: 0.7059 - loss: 0.5484\n","Epoch 32: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6214 - auc: 0.7060 - loss: 0.5488 - val_acc: 0.6861 - val_auc: 0.3561 - val_loss: 0.5358\n","Epoch 33/100\n","\u001b[1m323/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6072 - auc: 0.7043 - loss: 0.5672\n","Epoch 33: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6080 - auc: 0.7049 - loss: 0.5670 - val_acc: 0.6861 - val_auc: 0.3750 - val_loss: 0.5666\n","Epoch 34/100\n","\u001b[1m334/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6435 - auc: 0.7193 - loss: 0.5507\n","Epoch 34: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6434 - auc: 0.7191 - loss: 0.5508 - val_acc: 0.6861 - val_auc: 0.3758 - val_loss: 0.5751\n","Epoch 35/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6226 - auc: 0.7123 - loss: 0.5626\n","Epoch 35: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6228 - auc: 0.7124 - loss: 0.5626 - val_acc: 0.6569 - val_auc: 0.3371 - val_loss: 0.5253\n","Epoch 36/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6616 - auc: 0.7323 - loss: 0.5437\n","Epoch 36: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6611 - auc: 0.7321 - loss: 0.5441 - val_acc: 0.6058 - val_auc: 0.2720 - val_loss: 0.5174\n","Epoch 37/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6032 - auc: 0.6938 - loss: 0.5642\n","Epoch 37: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6043 - auc: 0.6945 - loss: 0.5642 - val_acc: 0.6788 - val_auc: 0.3485 - val_loss: 0.5552\n","Epoch 38/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6453 - auc: 0.7093 - loss: 0.5755\n","Epoch 38: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6451 - auc: 0.7096 - loss: 0.5751 - val_acc: 0.6861 - val_auc: 0.3788 - val_loss: 0.5445\n","Epoch 39/100\n","\u001b[1m322/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6215 - auc: 0.7182 - loss: 0.5648\n","Epoch 39: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6213 - auc: 0.7180 - loss: 0.5646 - val_acc: 0.6861 - val_auc: 0.3917 - val_loss: 0.6471\n","Epoch 40/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6388 - auc: 0.7064 - loss: 0.5609\n","Epoch 40: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6385 - auc: 0.7067 - loss: 0.5610 - val_acc: 0.6642 - val_auc: 0.3144 - val_loss: 0.5690\n","Epoch 41/100\n","\u001b[1m324/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5955 - auc: 0.7097 - loss: 0.5781\n","Epoch 41: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5964 - auc: 0.7105 - loss: 0.5774 - val_acc: 0.6715 - val_auc: 0.3409 - val_loss: 0.5676\n","Epoch 42/100\n","\u001b[1m323/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6542 - auc: 0.7260 - loss: 0.5450\n","Epoch 42: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6532 - auc: 0.7257 - loss: 0.5456 - val_acc: 0.6861 - val_auc: 0.3871 - val_loss: 0.6161\n","Epoch 43/100\n","\u001b[1m323/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6413 - auc: 0.7096 - loss: 0.5650\n","Epoch 43: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6411 - auc: 0.7104 - loss: 0.5647 - val_acc: 0.6861 - val_auc: 0.3674 - val_loss: 0.5769\n","Epoch 44/100\n","\u001b[1m324/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6288 - auc: 0.7224 - loss: 0.5499\n","Epoch 44: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6287 - auc: 0.7223 - loss: 0.5504 - val_acc: 0.6861 - val_auc: 0.3750 - val_loss: 0.5637\n","Epoch 45/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6328 - auc: 0.7245 - loss: 0.5576\n","Epoch 45: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6330 - auc: 0.7247 - loss: 0.5577 - val_acc: 0.6569 - val_auc: 0.3788 - val_loss: 0.5256\n","Epoch 46/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6459 - auc: 0.7522 - loss: 0.5640\n","Epoch 46: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6456 - auc: 0.7518 - loss: 0.5638 - val_acc: 0.6569 - val_auc: 0.3689 - val_loss: 0.5400\n","Epoch 47/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6583 - auc: 0.7410 - loss: 0.5608\n","Epoch 47: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6580 - auc: 0.7405 - loss: 0.5608 - val_acc: 0.6861 - val_auc: 0.3780 - val_loss: 0.6071\n","Epoch 48/100\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6360 - auc: 0.7457 - loss: 0.5581\n","Epoch 48: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6360 - auc: 0.7457 - loss: 0.5581 - val_acc: 0.6715 - val_auc: 0.3500 - val_loss: 0.5628\n","Epoch 49/100\n","\u001b[1m324/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6473 - auc: 0.7344 - loss: 0.5643\n","Epoch 49: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6473 - auc: 0.7343 - loss: 0.5641 - val_acc: 0.7153 - val_auc: 0.3689 - val_loss: 0.6350\n","Epoch 50/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6664 - auc: 0.7468 - loss: 0.5392\n","Epoch 50: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6661 - auc: 0.7467 - loss: 0.5397 - val_acc: 0.6569 - val_auc: 0.3432 - val_loss: 0.5753\n","Epoch 51/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6375 - auc: 0.7276 - loss: 0.5643\n","Epoch 51: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6379 - auc: 0.7276 - loss: 0.5642 - val_acc: 0.6569 - val_auc: 0.3727 - val_loss: 0.5792\n","Epoch 52/100\n","\u001b[1m334/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6371 - auc: 0.7285 - loss: 0.5661\n","Epoch 52: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6372 - auc: 0.7286 - loss: 0.5660 - val_acc: 0.8686 - val_auc: 0.3250 - val_loss: 0.5376\n","Epoch 53/100\n","\u001b[1m334/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6544 - auc: 0.7168 - loss: 0.5569\n","Epoch 53: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6545 - auc: 0.7170 - loss: 0.5569 - val_acc: 0.6861 - val_auc: 0.3955 - val_loss: 0.6027\n","Epoch 54/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6574 - auc: 0.7469 - loss: 0.5527\n","Epoch 54: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6573 - auc: 0.7465 - loss: 0.5529 - val_acc: 0.8175 - val_auc: 0.3576 - val_loss: 0.5731\n","Epoch 55/100\n","\u001b[1m323/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6448 - auc: 0.7549 - loss: 0.5566\n","Epoch 55: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6452 - auc: 0.7547 - loss: 0.5565 - val_acc: 0.8978 - val_auc: 0.3697 - val_loss: 0.5843\n","Epoch 56/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6605 - auc: 0.7249 - loss: 0.5678\n","Epoch 56: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6606 - auc: 0.7255 - loss: 0.5674 - val_acc: 0.7518 - val_auc: 0.3780 - val_loss: 0.6138\n","Epoch 57/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6619 - auc: 0.7586 - loss: 0.5452\n","Epoch 57: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6619 - auc: 0.7583 - loss: 0.5455 - val_acc: 0.8905 - val_auc: 0.3606 - val_loss: 0.5610\n","Epoch 58/100\n","\u001b[1m324/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7036 - auc: 0.7600 - loss: 0.5364\n","Epoch 58: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7026 - auc: 0.7597 - loss: 0.5370 - val_acc: 0.6788 - val_auc: 0.3773 - val_loss: 0.5208\n","Epoch 59/100\n","\u001b[1m323/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6463 - auc: 0.7120 - loss: 0.5744\n","Epoch 59: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6476 - auc: 0.7136 - loss: 0.5735 - val_acc: 0.8686 - val_auc: 0.3833 - val_loss: 0.5677\n","Epoch 60/100\n","\u001b[1m323/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6596 - auc: 0.7390 - loss: 0.5400\n","Epoch 60: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6601 - auc: 0.7393 - loss: 0.5405 - val_acc: 0.8978 - val_auc: 0.3614 - val_loss: 0.5711\n","Epoch 61/100\n","\u001b[1m335/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6647 - auc: 0.7281 - loss: 0.5529\n","Epoch 61: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6648 - auc: 0.7282 - loss: 0.5529 - val_acc: 0.7445 - val_auc: 0.3333 - val_loss: 0.5776\n","Epoch 62/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6699 - auc: 0.7394 - loss: 0.5493\n","Epoch 62: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6700 - auc: 0.7397 - loss: 0.5493 - val_acc: 0.7737 - val_auc: 0.3629 - val_loss: 0.5996\n","Epoch 63/100\n","\u001b[1m325/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6808 - auc: 0.7491 - loss: 0.5286\n","Epoch 63: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6803 - auc: 0.7491 - loss: 0.5292 - val_acc: 0.8540 - val_auc: 0.3447 - val_loss: 0.5762\n","Epoch 64/100\n","\u001b[1m323/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6947 - auc: 0.7554 - loss: 0.5444\n","Epoch 64: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6946 - auc: 0.7559 - loss: 0.5443 - val_acc: 0.6861 - val_auc: 0.4303 - val_loss: 0.8065\n","Epoch 65/100\n","\u001b[1m325/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6538 - auc: 0.7480 - loss: 0.5541\n","Epoch 65: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6543 - auc: 0.7484 - loss: 0.5537 - val_acc: 0.8978 - val_auc: 0.3530 - val_loss: 0.5296\n","Epoch 66/100\n","\u001b[1m324/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6976 - auc: 0.7790 - loss: 0.5288\n","Epoch 66: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6975 - auc: 0.7785 - loss: 0.5292 - val_acc: 0.8978 - val_auc: 0.3614 - val_loss: 0.6356\n","Epoch 67/100\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6529 - auc: 0.7534 - loss: 0.5261\n","Epoch 67: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6529 - auc: 0.7534 - loss: 0.5261 - val_acc: 0.8978 - val_auc: 0.3795 - val_loss: 0.5596\n","Epoch 68/100\n","\u001b[1m335/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6977 - auc: 0.7764 - loss: 0.5290\n","Epoch 68: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6976 - auc: 0.7764 - loss: 0.5290 - val_acc: 0.8905 - val_auc: 0.3902 - val_loss: 0.7125\n","Epoch 69/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7141 - auc: 0.7928 - loss: 0.5399\n","Epoch 69: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7136 - auc: 0.7925 - loss: 0.5398 - val_acc: 0.8467 - val_auc: 0.3909 - val_loss: 0.5850\n","Epoch 70/100\n","\u001b[1m332/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6766 - auc: 0.7752 - loss: 0.5291\n","Epoch 70: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6768 - auc: 0.7751 - loss: 0.5292 - val_acc: 0.8759 - val_auc: 0.2598 - val_loss: 0.4825\n","Epoch 71/100\n","\u001b[1m325/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7009 - auc: 0.7826 - loss: 0.5222\n","Epoch 71: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7003 - auc: 0.7819 - loss: 0.5228 - val_acc: 0.7007 - val_auc: 0.4424 - val_loss: 0.8731\n","Epoch 72/100\n","\u001b[1m325/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6678 - auc: 0.7546 - loss: 0.5540\n","Epoch 72: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6686 - auc: 0.7550 - loss: 0.5535 - val_acc: 0.9343 - val_auc: 0.3591 - val_loss: 0.4869\n","Epoch 73/100\n","\u001b[1m324/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7026 - auc: 0.7685 - loss: 0.5332\n","Epoch 73: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7025 - auc: 0.7688 - loss: 0.5329 - val_acc: 0.8394 - val_auc: 0.3750 - val_loss: 0.6419\n","Epoch 74/100\n","\u001b[1m323/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6937 - auc: 0.7893 - loss: 0.5033\n","Epoch 74: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6933 - auc: 0.7888 - loss: 0.5041 - val_acc: 0.9562 - val_auc: 0.3955 - val_loss: 0.5238\n","Epoch 75/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7223 - auc: 0.7869 - loss: 0.5240\n","Epoch 75: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7219 - auc: 0.7870 - loss: 0.5239 - val_acc: 0.8686 - val_auc: 0.3795 - val_loss: 0.6257\n","Epoch 76/100\n","\u001b[1m329/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7030 - auc: 0.7967 - loss: 0.5081\n","Epoch 76: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7030 - auc: 0.7963 - loss: 0.5084 - val_acc: 0.8978 - val_auc: 0.3576 - val_loss: 0.5225\n","Epoch 77/100\n","\u001b[1m334/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7174 - auc: 0.7926 - loss: 0.5080\n","Epoch 77: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7174 - auc: 0.7926 - loss: 0.5081 - val_acc: 0.8248 - val_auc: 0.3932 - val_loss: 0.6175\n","Epoch 78/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6969 - auc: 0.7791 - loss: 0.5244\n","Epoch 78: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6970 - auc: 0.7792 - loss: 0.5242 - val_acc: 0.7956 - val_auc: 0.4303 - val_loss: 0.7161\n","Epoch 79/100\n","\u001b[1m331/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6814 - auc: 0.7541 - loss: 0.5354\n","Epoch 79: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6817 - auc: 0.7545 - loss: 0.5352 - val_acc: 0.7372 - val_auc: 0.3894 - val_loss: 0.5915\n","Epoch 80/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7040 - auc: 0.7883 - loss: 0.5106\n","Epoch 80: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7038 - auc: 0.7880 - loss: 0.5108 - val_acc: 0.8686 - val_auc: 0.3856 - val_loss: 0.6343\n","Epoch 81/100\n","\u001b[1m324/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7061 - auc: 0.7812 - loss: 0.5204\n","Epoch 81: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7060 - auc: 0.7812 - loss: 0.5202 - val_acc: 0.8467 - val_auc: 0.3992 - val_loss: 0.6240\n","Epoch 82/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6807 - auc: 0.7668 - loss: 0.5384\n","Epoch 82: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6813 - auc: 0.7674 - loss: 0.5378 - val_acc: 0.9124 - val_auc: 0.3795 - val_loss: 0.5717\n","Epoch 83/100\n","\u001b[1m329/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6933 - auc: 0.7754 - loss: 0.5220\n","Epoch 83: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6938 - auc: 0.7756 - loss: 0.5219 - val_acc: 0.9343 - val_auc: 0.3447 - val_loss: 0.4536\n","Epoch 84/100\n","\u001b[1m324/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7286 - auc: 0.7862 - loss: 0.5047\n","Epoch 84: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7281 - auc: 0.7864 - loss: 0.5047 - val_acc: 0.8832 - val_auc: 0.3902 - val_loss: 0.5352\n","Epoch 85/100\n","\u001b[1m335/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7264 - auc: 0.7829 - loss: 0.5020\n","Epoch 85: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7263 - auc: 0.7829 - loss: 0.5020 - val_acc: 0.9343 - val_auc: 0.3538 - val_loss: 0.5463\n","Epoch 86/100\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7116 - auc: 0.7964 - loss: 0.4965\n","Epoch 86: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7116 - auc: 0.7964 - loss: 0.4965 - val_acc: 0.8978 - val_auc: 0.3818 - val_loss: 0.6060\n","Epoch 87/100\n","\u001b[1m325/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7012 - auc: 0.7594 - loss: 0.5195\n","Epoch 87: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7018 - auc: 0.7606 - loss: 0.5188 - val_acc: 0.8759 - val_auc: 0.3470 - val_loss: 0.5976\n","Epoch 88/100\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7010 - auc: 0.7790 - loss: 0.5220\n","Epoch 88: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7011 - auc: 0.7790 - loss: 0.5220 - val_acc: 0.9489 - val_auc: 0.3667 - val_loss: 0.6054\n","Epoch 89/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7315 - auc: 0.7910 - loss: 0.4897\n","Epoch 89: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7314 - auc: 0.7910 - loss: 0.4902 - val_acc: 0.9051 - val_auc: 0.3470 - val_loss: 0.5633\n","Epoch 90/100\n","\u001b[1m322/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6915 - auc: 0.7845 - loss: 0.5058\n","Epoch 90: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6928 - auc: 0.7850 - loss: 0.5054 - val_acc: 0.9124 - val_auc: 0.3712 - val_loss: 0.5952\n","Epoch 91/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7263 - auc: 0.7899 - loss: 0.4961\n","Epoch 91: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7258 - auc: 0.7897 - loss: 0.4965 - val_acc: 0.9270 - val_auc: 0.3583 - val_loss: 0.5093\n","Epoch 92/100\n","\u001b[1m322/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7085 - auc: 0.7825 - loss: 0.5228\n","Epoch 92: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7092 - auc: 0.7834 - loss: 0.5218 - val_acc: 0.9562 - val_auc: 0.3629 - val_loss: 0.4990\n","Epoch 93/100\n","\u001b[1m331/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7414 - auc: 0.8140 - loss: 0.5044\n","Epoch 93: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7412 - auc: 0.8138 - loss: 0.5044 - val_acc: 0.8686 - val_auc: 0.3803 - val_loss: 0.6260\n","Epoch 94/100\n","\u001b[1m323/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7445 - auc: 0.7923 - loss: 0.4935\n","Epoch 94: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7441 - auc: 0.7928 - loss: 0.4936 - val_acc: 0.8978 - val_auc: 0.3917 - val_loss: 0.7003\n","Epoch 95/100\n","\u001b[1m332/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7044 - auc: 0.7532 - loss: 0.5191\n","Epoch 95: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7048 - auc: 0.7538 - loss: 0.5187 - val_acc: 0.8832 - val_auc: 0.3591 - val_loss: 0.6576\n","Epoch 96/100\n","\u001b[1m323/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7404 - auc: 0.8099 - loss: 0.4841\n","Epoch 96: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7399 - auc: 0.8090 - loss: 0.4848 - val_acc: 0.9489 - val_auc: 0.3583 - val_loss: 0.4778\n","Epoch 97/100\n","\u001b[1m323/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7450 - auc: 0.8020 - loss: 0.5023\n","Epoch 97: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7443 - auc: 0.8016 - loss: 0.5022 - val_acc: 0.8905 - val_auc: 0.3750 - val_loss: 0.6261\n","Epoch 98/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7371 - auc: 0.8245 - loss: 0.4781\n","Epoch 98: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7368 - auc: 0.8239 - loss: 0.4784 - val_acc: 0.9416 - val_auc: 0.3689 - val_loss: 0.5833\n","Epoch 99/100\n","\u001b[1m325/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7249 - auc: 0.7847 - loss: 0.4962\n","Epoch 99: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7249 - auc: 0.7850 - loss: 0.4963 - val_acc: 0.9197 - val_auc: 0.4129 - val_loss: 0.6793\n","Epoch 100/100\n","\u001b[1m331/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7306 - auc: 0.7883 - loss: 0.5035\n","Epoch 100: val_loss did not improve from 0.44787\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7306 - auc: 0.7886 - loss: 0.5034 - val_acc: 0.7810 - val_auc: 0.3924 - val_loss: 0.6738\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 3 | TEST ACC=0.8947 | TEST AUC=0.1471 | n=57\n","Confusion matrix:\n"," [[51  0]\n"," [ 6  0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.895     1.000     0.944        51\n","           1      0.000     0.000     0.000         6\n","\n","    accuracy                          0.895        57\n","   macro avg      0.447     0.500     0.472        57\n","weighted avg      0.801     0.895     0.845        57\n","\n","\n","--- Fold 4/14 ---\n"," train | ids:   36 | files:  1050 | pos files:  361 | neg files:  689\n","   val | ids:    5 | files:    78 | pos files:   10 | neg files:   68\n","  test | ids:    3 | files:    72 | pos files:   34 | neg files:   38\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m336/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5807 - auc: 0.4962 - loss: 0.6872\n","Epoch 1: val_loss improved from inf to 0.55622, saving model to best_fold_04.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - acc: 0.5830 - auc: 0.4964 - loss: 0.6867 - val_acc: 0.8718 - val_auc: 0.0154 - val_loss: 0.5562\n","Epoch 2/100\n","\u001b[1m339/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6835 - auc: 0.4826 - loss: 0.6304\n","Epoch 2: val_loss improved from 0.55622 to 0.54277, saving model to best_fold_04.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6826 - auc: 0.4823 - loss: 0.6309 - val_acc: 0.8718 - val_auc: 0.0279 - val_loss: 0.5428\n","Epoch 3/100\n","\u001b[1m345/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6217 - auc: 0.5288 - loss: 0.6612\n","Epoch 3: val_loss improved from 0.54277 to 0.51633, saving model to best_fold_04.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6223 - auc: 0.5290 - loss: 0.6609 - val_acc: 0.8718 - val_auc: 0.0338 - val_loss: 0.5163\n","Epoch 4/100\n","\u001b[1m348/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6499 - auc: 0.5452 - loss: 0.6444\n","Epoch 4: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6500 - auc: 0.5453 - loss: 0.6444 - val_acc: 0.8718 - val_auc: 0.0596 - val_loss: 0.5231\n","Epoch 5/100\n","\u001b[1m348/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6615 - auc: 0.6105 - loss: 0.6288\n","Epoch 5: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6615 - auc: 0.6101 - loss: 0.6289 - val_acc: 0.8718 - val_auc: 0.1096 - val_loss: 0.5267\n","Epoch 6/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6484 - auc: 0.5911 - loss: 0.6394\n","Epoch 6: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6484 - auc: 0.5912 - loss: 0.6394 - val_acc: 0.8718 - val_auc: 0.1647 - val_loss: 0.5284\n","Epoch 7/100\n","\u001b[1m342/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6501 - auc: 0.6615 - loss: 0.6242\n","Epoch 7: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6502 - auc: 0.6606 - loss: 0.6242 - val_acc: 0.8718 - val_auc: 0.2132 - val_loss: 0.5429\n","Epoch 8/100\n","\u001b[1m337/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6522 - auc: 0.6183 - loss: 0.6281\n","Epoch 8: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6524 - auc: 0.6190 - loss: 0.6277 - val_acc: 0.8718 - val_auc: 0.2338 - val_loss: 0.5495\n","Epoch 9/100\n","\u001b[1m343/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6614 - auc: 0.6635 - loss: 0.6089\n","Epoch 9: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6613 - auc: 0.6634 - loss: 0.6089 - val_acc: 0.8718 - val_auc: 0.2441 - val_loss: 0.5474\n","Epoch 10/100\n","\u001b[1m348/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6604 - auc: 0.6741 - loss: 0.6013\n","Epoch 10: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6603 - auc: 0.6741 - loss: 0.6013 - val_acc: 0.8718 - val_auc: 0.2500 - val_loss: 0.5555\n","Epoch 11/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6658 - auc: 0.6704 - loss: 0.6102\n","Epoch 11: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6658 - auc: 0.6704 - loss: 0.6101 - val_acc: 0.8205 - val_auc: 0.2551 - val_loss: 0.5621\n","Epoch 12/100\n","\u001b[1m349/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6789 - auc: 0.6812 - loss: 0.5997\n","Epoch 12: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6789 - auc: 0.6813 - loss: 0.5997 - val_acc: 0.7436 - val_auc: 0.2765 - val_loss: 0.5845\n","Epoch 13/100\n","\u001b[1m346/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6906 - auc: 0.6991 - loss: 0.5610\n","Epoch 13: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6902 - auc: 0.6991 - loss: 0.5612 - val_acc: 0.7692 - val_auc: 0.2765 - val_loss: 0.5954\n","Epoch 14/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6769 - auc: 0.6783 - loss: 0.5825\n","Epoch 14: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6769 - auc: 0.6784 - loss: 0.5825 - val_acc: 0.7564 - val_auc: 0.2919 - val_loss: 0.6088\n","Epoch 15/100\n","\u001b[1m338/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6830 - auc: 0.7089 - loss: 0.5555\n","Epoch 15: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6826 - auc: 0.7087 - loss: 0.5556 - val_acc: 0.7564 - val_auc: 0.3088 - val_loss: 0.6215\n","Epoch 16/100\n","\u001b[1m338/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6594 - auc: 0.7011 - loss: 0.5543\n","Epoch 16: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6596 - auc: 0.7013 - loss: 0.5542 - val_acc: 0.7179 - val_auc: 0.3206 - val_loss: 0.6409\n","Epoch 17/100\n","\u001b[1m346/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6722 - auc: 0.6890 - loss: 0.5416\n","Epoch 17: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6721 - auc: 0.6893 - loss: 0.5417 - val_acc: 0.6923 - val_auc: 0.3353 - val_loss: 0.6512\n","Epoch 18/100\n","\u001b[1m341/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6699 - auc: 0.7187 - loss: 0.5414\n","Epoch 18: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6701 - auc: 0.7184 - loss: 0.5416 - val_acc: 0.7308 - val_auc: 0.3309 - val_loss: 0.6768\n","Epoch 19/100\n","\u001b[1m338/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6705 - auc: 0.7101 - loss: 0.5396\n","Epoch 19: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6707 - auc: 0.7103 - loss: 0.5395 - val_acc: 0.6538 - val_auc: 0.3397 - val_loss: 0.6976\n","Epoch 20/100\n","\u001b[1m347/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7083 - auc: 0.7318 - loss: 0.5224\n","Epoch 20: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7080 - auc: 0.7316 - loss: 0.5225 - val_acc: 0.7308 - val_auc: 0.3110 - val_loss: 0.7204\n","Epoch 21/100\n","\u001b[1m343/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6825 - auc: 0.7056 - loss: 0.5443\n","Epoch 21: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6825 - auc: 0.7060 - loss: 0.5441 - val_acc: 0.6795 - val_auc: 0.2971 - val_loss: 0.7417\n","Epoch 22/100\n","\u001b[1m343/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6762 - auc: 0.6800 - loss: 0.5437\n","Epoch 22: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6759 - auc: 0.6805 - loss: 0.5435 - val_acc: 0.7179 - val_auc: 0.3022 - val_loss: 0.7464\n","Epoch 23/100\n","\u001b[1m347/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6742 - auc: 0.6919 - loss: 0.5341\n","Epoch 23: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6741 - auc: 0.6921 - loss: 0.5341 - val_acc: 0.6538 - val_auc: 0.3331 - val_loss: 0.7490\n","Epoch 24/100\n","\u001b[1m345/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6526 - auc: 0.7291 - loss: 0.5342\n","Epoch 24: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6529 - auc: 0.7290 - loss: 0.5341 - val_acc: 0.7692 - val_auc: 0.2993 - val_loss: 0.7878\n","Epoch 25/100\n","\u001b[1m345/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6819 - auc: 0.7068 - loss: 0.5233\n","Epoch 25: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6818 - auc: 0.7070 - loss: 0.5234 - val_acc: 0.7436 - val_auc: 0.2993 - val_loss: 0.7675\n","Epoch 26/100\n","\u001b[1m348/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6900 - auc: 0.7250 - loss: 0.5148\n","Epoch 26: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6899 - auc: 0.7249 - loss: 0.5149 - val_acc: 0.7308 - val_auc: 0.3081 - val_loss: 0.7970\n","Epoch 27/100\n","\u001b[1m343/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6619 - auc: 0.6561 - loss: 0.5460\n","Epoch 27: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6623 - auc: 0.6574 - loss: 0.5456 - val_acc: 0.6410 - val_auc: 0.3162 - val_loss: 0.8314\n","Epoch 28/100\n","\u001b[1m337/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6540 - auc: 0.6862 - loss: 0.5318\n","Epoch 28: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6545 - auc: 0.6875 - loss: 0.5315 - val_acc: 0.7436 - val_auc: 0.3051 - val_loss: 0.8460\n","Epoch 29/100\n","\u001b[1m345/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6847 - auc: 0.7192 - loss: 0.5180\n","Epoch 29: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6845 - auc: 0.7192 - loss: 0.5180 - val_acc: 0.8205 - val_auc: 0.3022 - val_loss: 0.9127\n","Epoch 30/100\n","\u001b[1m348/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7037 - auc: 0.7405 - loss: 0.5006\n","Epoch 30: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7035 - auc: 0.7403 - loss: 0.5008 - val_acc: 0.6667 - val_auc: 0.3132 - val_loss: 0.7992\n","Epoch 31/100\n","\u001b[1m341/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6823 - auc: 0.7093 - loss: 0.5250\n","Epoch 31: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6823 - auc: 0.7099 - loss: 0.5249 - val_acc: 0.7692 - val_auc: 0.3037 - val_loss: 0.8909\n","Epoch 32/100\n","\u001b[1m346/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7016 - auc: 0.7335 - loss: 0.5114\n","Epoch 32: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7016 - auc: 0.7334 - loss: 0.5115 - val_acc: 0.8205 - val_auc: 0.2993 - val_loss: 0.8665\n","Epoch 33/100\n","\u001b[1m349/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6984 - auc: 0.7371 - loss: 0.5110\n","Epoch 33: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6983 - auc: 0.7371 - loss: 0.5111 - val_acc: 0.8077 - val_auc: 0.3029 - val_loss: 0.8185\n","Epoch 34/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7181 - auc: 0.7305 - loss: 0.5044\n","Epoch 34: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7181 - auc: 0.7305 - loss: 0.5044 - val_acc: 0.8205 - val_auc: 0.3000 - val_loss: 0.8901\n","Epoch 35/100\n","\u001b[1m340/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7007 - auc: 0.7412 - loss: 0.4951\n","Epoch 35: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7002 - auc: 0.7408 - loss: 0.4958 - val_acc: 0.8462 - val_auc: 0.3000 - val_loss: 0.8928\n","Epoch 36/100\n","\u001b[1m349/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7003 - auc: 0.7207 - loss: 0.5062\n","Epoch 36: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7003 - auc: 0.7208 - loss: 0.5063 - val_acc: 0.8205 - val_auc: 0.3029 - val_loss: 0.9504\n","Epoch 37/100\n","\u001b[1m347/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6954 - auc: 0.7454 - loss: 0.5015\n","Epoch 37: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6953 - auc: 0.7451 - loss: 0.5016 - val_acc: 0.8718 - val_auc: 0.2985 - val_loss: 0.8935\n","Epoch 38/100\n","\u001b[1m347/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6915 - auc: 0.7234 - loss: 0.5097\n","Epoch 38: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6915 - auc: 0.7234 - loss: 0.5097 - val_acc: 0.8205 - val_auc: 0.2985 - val_loss: 0.9525\n","Epoch 39/100\n","\u001b[1m347/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6752 - auc: 0.7314 - loss: 0.5113\n","Epoch 39: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6753 - auc: 0.7314 - loss: 0.5113 - val_acc: 0.8205 - val_auc: 0.3051 - val_loss: 1.0121\n","Epoch 40/100\n","\u001b[1m343/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6685 - auc: 0.7280 - loss: 0.5117\n","Epoch 40: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6690 - auc: 0.7283 - loss: 0.5117 - val_acc: 0.8205 - val_auc: 0.2993 - val_loss: 0.8898\n","Epoch 41/100\n","\u001b[1m337/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6633 - auc: 0.7176 - loss: 0.5174\n","Epoch 41: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6643 - auc: 0.7176 - loss: 0.5173 - val_acc: 0.8205 - val_auc: 0.2941 - val_loss: 0.9291\n","Epoch 42/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6716 - auc: 0.7317 - loss: 0.5195\n","Epoch 42: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6717 - auc: 0.7317 - loss: 0.5195 - val_acc: 0.8718 - val_auc: 0.2963 - val_loss: 0.9567\n","Epoch 43/100\n","\u001b[1m336/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6978 - auc: 0.7357 - loss: 0.5062\n","Epoch 43: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6977 - auc: 0.7350 - loss: 0.5064 - val_acc: 0.7821 - val_auc: 0.3125 - val_loss: 0.8700\n","Epoch 44/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6935 - auc: 0.7561 - loss: 0.5119\n","Epoch 44: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6935 - auc: 0.7561 - loss: 0.5119 - val_acc: 0.8205 - val_auc: 0.3051 - val_loss: 0.8961\n","Epoch 45/100\n","\u001b[1m346/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7018 - auc: 0.7144 - loss: 0.5062\n","Epoch 45: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7017 - auc: 0.7146 - loss: 0.5062 - val_acc: 0.8718 - val_auc: 0.3007 - val_loss: 1.0291\n","Epoch 46/100\n","\u001b[1m336/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6850 - auc: 0.7205 - loss: 0.5200\n","Epoch 46: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6855 - auc: 0.7212 - loss: 0.5195 - val_acc: 0.7564 - val_auc: 0.3235 - val_loss: 0.8305\n","Epoch 47/100\n","\u001b[1m336/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7065 - auc: 0.7293 - loss: 0.5204\n","Epoch 47: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7063 - auc: 0.7297 - loss: 0.5197 - val_acc: 0.8205 - val_auc: 0.3441 - val_loss: 0.9133\n","Epoch 48/100\n","\u001b[1m346/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7137 - auc: 0.7499 - loss: 0.4977\n","Epoch 48: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7135 - auc: 0.7499 - loss: 0.4978 - val_acc: 0.7821 - val_auc: 0.3706 - val_loss: 0.9358\n","Epoch 49/100\n","\u001b[1m338/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7055 - auc: 0.7346 - loss: 0.5182\n","Epoch 49: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7052 - auc: 0.7350 - loss: 0.5177 - val_acc: 0.8718 - val_auc: 0.2971 - val_loss: 0.9864\n","Epoch 50/100\n","\u001b[1m341/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6642 - auc: 0.7269 - loss: 0.5277\n","Epoch 50: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6652 - auc: 0.7275 - loss: 0.5271 - val_acc: 0.8718 - val_auc: 0.3066 - val_loss: 0.9994\n","Epoch 51/100\n","\u001b[1m339/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7064 - auc: 0.7405 - loss: 0.4990\n","Epoch 51: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7061 - auc: 0.7403 - loss: 0.4992 - val_acc: 0.8077 - val_auc: 0.3324 - val_loss: 0.8844\n","Epoch 52/100\n","\u001b[1m348/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6979 - auc: 0.7743 - loss: 0.5002\n","Epoch 52: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6980 - auc: 0.7742 - loss: 0.5002 - val_acc: 0.8205 - val_auc: 0.3904 - val_loss: 0.8921\n","Epoch 53/100\n","\u001b[1m338/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7225 - auc: 0.7746 - loss: 0.4842\n","Epoch 53: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7220 - auc: 0.7738 - loss: 0.4849 - val_acc: 0.7949 - val_auc: 0.4537 - val_loss: 0.9908\n","Epoch 54/100\n","\u001b[1m340/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6931 - auc: 0.7699 - loss: 0.4822\n","Epoch 54: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6932 - auc: 0.7691 - loss: 0.4828 - val_acc: 0.8205 - val_auc: 0.4588 - val_loss: 0.8857\n","Epoch 55/100\n","\u001b[1m344/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6969 - auc: 0.7622 - loss: 0.4964\n","Epoch 55: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6969 - auc: 0.7621 - loss: 0.4965 - val_acc: 0.8205 - val_auc: 0.4191 - val_loss: 0.9747\n","Epoch 56/100\n","\u001b[1m338/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6948 - auc: 0.7494 - loss: 0.5099\n","Epoch 56: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6950 - auc: 0.7495 - loss: 0.5096 - val_acc: 0.8205 - val_auc: 0.4478 - val_loss: 0.8228\n","Epoch 57/100\n","\u001b[1m345/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6829 - auc: 0.7385 - loss: 0.5080\n","Epoch 57: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6830 - auc: 0.7385 - loss: 0.5079 - val_acc: 0.8718 - val_auc: 0.3390 - val_loss: 1.0766\n","Epoch 58/100\n","\u001b[1m341/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6971 - auc: 0.7358 - loss: 0.5095\n","Epoch 58: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6973 - auc: 0.7362 - loss: 0.5093 - val_acc: 0.8718 - val_auc: 0.4368 - val_loss: 1.0232\n","Epoch 59/100\n","\u001b[1m344/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6969 - auc: 0.7257 - loss: 0.5066\n","Epoch 59: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6969 - auc: 0.7260 - loss: 0.5065 - val_acc: 0.8718 - val_auc: 0.4757 - val_loss: 0.9124\n","Epoch 60/100\n","\u001b[1m338/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6924 - auc: 0.7402 - loss: 0.4975\n","Epoch 60: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6923 - auc: 0.7401 - loss: 0.4978 - val_acc: 0.8333 - val_auc: 0.4706 - val_loss: 0.8663\n","Epoch 61/100\n","\u001b[1m349/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7316 - auc: 0.7698 - loss: 0.4897\n","Epoch 61: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7314 - auc: 0.7698 - loss: 0.4898 - val_acc: 0.8718 - val_auc: 0.5066 - val_loss: 0.8940\n","Epoch 62/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6881 - auc: 0.7524 - loss: 0.5122\n","Epoch 62: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6882 - auc: 0.7524 - loss: 0.5121 - val_acc: 0.8718 - val_auc: 0.4493 - val_loss: 1.1252\n","Epoch 63/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7316 - auc: 0.7712 - loss: 0.4853\n","Epoch 63: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7316 - auc: 0.7712 - loss: 0.4853 - val_acc: 0.8718 - val_auc: 0.4412 - val_loss: 0.7459\n","Epoch 64/100\n","\u001b[1m346/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7338 - auc: 0.7590 - loss: 0.4812\n","Epoch 64: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7335 - auc: 0.7592 - loss: 0.4814 - val_acc: 0.5000 - val_auc: 0.4956 - val_loss: 1.0191\n","Epoch 65/100\n","\u001b[1m347/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6954 - auc: 0.7734 - loss: 0.5011\n","Epoch 65: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6955 - auc: 0.7733 - loss: 0.5010 - val_acc: 0.8718 - val_auc: 0.4478 - val_loss: 0.9161\n","Epoch 66/100\n","\u001b[1m346/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7069 - auc: 0.7674 - loss: 0.4885\n","Epoch 66: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7068 - auc: 0.7672 - loss: 0.4887 - val_acc: 0.8718 - val_auc: 0.4765 - val_loss: 0.8476\n","Epoch 67/100\n","\u001b[1m337/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6862 - auc: 0.7508 - loss: 0.5158\n","Epoch 67: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6871 - auc: 0.7511 - loss: 0.5152 - val_acc: 0.8718 - val_auc: 0.4816 - val_loss: 0.9427\n","Epoch 68/100\n","\u001b[1m343/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7061 - auc: 0.7389 - loss: 0.5047\n","Epoch 68: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7061 - auc: 0.7393 - loss: 0.5045 - val_acc: 0.8718 - val_auc: 0.4485 - val_loss: 1.0298\n","Epoch 69/100\n","\u001b[1m343/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7071 - auc: 0.7437 - loss: 0.5040\n","Epoch 69: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7069 - auc: 0.7439 - loss: 0.5040 - val_acc: 0.8718 - val_auc: 0.4279 - val_loss: 0.9875\n","Epoch 70/100\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7268 - auc: 0.7825 - loss: 0.4891\n","Epoch 70: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7267 - auc: 0.7824 - loss: 0.4891 - val_acc: 0.8718 - val_auc: 0.4426 - val_loss: 0.9395\n","Epoch 71/100\n","\u001b[1m348/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7176 - auc: 0.7546 - loss: 0.4982\n","Epoch 71: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7176 - auc: 0.7547 - loss: 0.4982 - val_acc: 0.8718 - val_auc: 0.4051 - val_loss: 1.0382\n","Epoch 72/100\n","\u001b[1m337/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7196 - auc: 0.7666 - loss: 0.4850\n","Epoch 72: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7193 - auc: 0.7666 - loss: 0.4854 - val_acc: 0.8333 - val_auc: 0.4412 - val_loss: 0.8710\n","Epoch 73/100\n","\u001b[1m346/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7024 - auc: 0.7476 - loss: 0.4885\n","Epoch 73: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7025 - auc: 0.7478 - loss: 0.4886 - val_acc: 0.8718 - val_auc: 0.4757 - val_loss: 0.9832\n","Epoch 74/100\n","\u001b[1m337/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7297 - auc: 0.7507 - loss: 0.4949\n","Epoch 74: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7291 - auc: 0.7509 - loss: 0.4949 - val_acc: 0.7949 - val_auc: 0.5221 - val_loss: 0.8965\n","Epoch 75/100\n","\u001b[1m346/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7230 - auc: 0.7681 - loss: 0.4820\n","Epoch 75: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7229 - auc: 0.7680 - loss: 0.4822 - val_acc: 0.7564 - val_auc: 0.5162 - val_loss: 0.9769\n","Epoch 76/100\n","\u001b[1m343/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7103 - auc: 0.7706 - loss: 0.4837\n","Epoch 76: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7101 - auc: 0.7703 - loss: 0.4841 - val_acc: 0.8718 - val_auc: 0.4368 - val_loss: 1.0009\n","Epoch 77/100\n","\u001b[1m340/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7124 - auc: 0.7597 - loss: 0.4942\n","Epoch 77: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7122 - auc: 0.7597 - loss: 0.4943 - val_acc: 0.8718 - val_auc: 0.4662 - val_loss: 0.8800\n","Epoch 78/100\n","\u001b[1m349/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7143 - auc: 0.7708 - loss: 0.4917\n","Epoch 78: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7143 - auc: 0.7707 - loss: 0.4917 - val_acc: 0.8718 - val_auc: 0.4301 - val_loss: 0.8270\n","Epoch 79/100\n","\u001b[1m343/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7148 - auc: 0.7793 - loss: 0.4758\n","Epoch 79: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7148 - auc: 0.7793 - loss: 0.4762 - val_acc: 0.8590 - val_auc: 0.4463 - val_loss: 0.9317\n","Epoch 80/100\n","\u001b[1m345/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6903 - auc: 0.7398 - loss: 0.4992\n","Epoch 80: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6905 - auc: 0.7400 - loss: 0.4992 - val_acc: 0.8590 - val_auc: 0.4493 - val_loss: 0.8637\n","Epoch 81/100\n","\u001b[1m343/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7026 - auc: 0.7828 - loss: 0.4824\n","Epoch 81: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7024 - auc: 0.7823 - loss: 0.4827 - val_acc: 0.8718 - val_auc: 0.4449 - val_loss: 0.8117\n","Epoch 82/100\n","\u001b[1m343/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7206 - auc: 0.7804 - loss: 0.4912\n","Epoch 82: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7204 - auc: 0.7802 - loss: 0.4913 - val_acc: 0.8590 - val_auc: 0.4184 - val_loss: 1.0971\n","Epoch 83/100\n","\u001b[1m340/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7218 - auc: 0.7607 - loss: 0.4897\n","Epoch 83: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7217 - auc: 0.7610 - loss: 0.4897 - val_acc: 0.8462 - val_auc: 0.4228 - val_loss: 1.0896\n","Epoch 84/100\n","\u001b[1m343/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7119 - auc: 0.7534 - loss: 0.5048\n","Epoch 84: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7120 - auc: 0.7538 - loss: 0.5045 - val_acc: 0.8590 - val_auc: 0.4904 - val_loss: 0.9058\n","Epoch 85/100\n","\u001b[1m345/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7273 - auc: 0.7651 - loss: 0.4895\n","Epoch 85: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7271 - auc: 0.7651 - loss: 0.4896 - val_acc: 0.7564 - val_auc: 0.4559 - val_loss: 1.0746\n","Epoch 86/100\n","\u001b[1m337/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7088 - auc: 0.7806 - loss: 0.4841\n","Epoch 86: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7089 - auc: 0.7804 - loss: 0.4844 - val_acc: 0.8718 - val_auc: 0.3993 - val_loss: 1.0035\n","Epoch 87/100\n","\u001b[1m344/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6855 - auc: 0.7603 - loss: 0.5029\n","Epoch 87: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6860 - auc: 0.7605 - loss: 0.5026 - val_acc: 0.8718 - val_auc: 0.4118 - val_loss: 0.9826\n","Epoch 88/100\n","\u001b[1m343/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7006 - auc: 0.7870 - loss: 0.4796\n","Epoch 88: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7006 - auc: 0.7868 - loss: 0.4800 - val_acc: 0.8718 - val_auc: 0.3985 - val_loss: 0.9179\n","Epoch 89/100\n","\u001b[1m348/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7002 - auc: 0.7713 - loss: 0.5014\n","Epoch 89: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7003 - auc: 0.7713 - loss: 0.5013 - val_acc: 0.8590 - val_auc: 0.4176 - val_loss: 0.9289\n","Epoch 90/100\n","\u001b[1m345/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7204 - auc: 0.7794 - loss: 0.4918\n","Epoch 90: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7203 - auc: 0.7792 - loss: 0.4918 - val_acc: 0.8718 - val_auc: 0.4044 - val_loss: 0.8485\n","Epoch 91/100\n","\u001b[1m338/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7192 - auc: 0.7875 - loss: 0.4698\n","Epoch 91: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7190 - auc: 0.7869 - loss: 0.4707 - val_acc: 0.8462 - val_auc: 0.4191 - val_loss: 0.8931\n","Epoch 92/100\n","\u001b[1m346/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6934 - auc: 0.7612 - loss: 0.5102\n","Epoch 92: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6938 - auc: 0.7615 - loss: 0.5098 - val_acc: 0.8590 - val_auc: 0.4015 - val_loss: 1.1013\n","Epoch 93/100\n","\u001b[1m337/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7286 - auc: 0.7932 - loss: 0.4728\n","Epoch 93: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7282 - auc: 0.7922 - loss: 0.4736 - val_acc: 0.8205 - val_auc: 0.4162 - val_loss: 0.9063\n","Epoch 94/100\n","\u001b[1m346/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6999 - auc: 0.7551 - loss: 0.4840\n","Epoch 94: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7001 - auc: 0.7555 - loss: 0.4841 - val_acc: 0.8590 - val_auc: 0.4199 - val_loss: 0.9191\n","Epoch 95/100\n","\u001b[1m341/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7212 - auc: 0.7760 - loss: 0.4838\n","Epoch 95: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7209 - auc: 0.7759 - loss: 0.4840 - val_acc: 0.8590 - val_auc: 0.4265 - val_loss: 0.9379\n","Epoch 96/100\n","\u001b[1m349/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7130 - auc: 0.7848 - loss: 0.4910\n","Epoch 96: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7130 - auc: 0.7848 - loss: 0.4909 - val_acc: 0.8718 - val_auc: 0.4000 - val_loss: 0.9031\n","Epoch 97/100\n","\u001b[1m339/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7325 - auc: 0.7652 - loss: 0.4820\n","Epoch 97: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7320 - auc: 0.7656 - loss: 0.4821 - val_acc: 0.8462 - val_auc: 0.4353 - val_loss: 1.0283\n","Epoch 98/100\n","\u001b[1m349/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7065 - auc: 0.7740 - loss: 0.4777\n","Epoch 98: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7066 - auc: 0.7740 - loss: 0.4777 - val_acc: 0.8462 - val_auc: 0.4015 - val_loss: 0.9430\n","Epoch 99/100\n","\u001b[1m345/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6827 - auc: 0.7767 - loss: 0.4985\n","Epoch 99: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6832 - auc: 0.7768 - loss: 0.4982 - val_acc: 0.8718 - val_auc: 0.4029 - val_loss: 1.2174\n","Epoch 100/100\n","\u001b[1m343/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7299 - auc: 0.7890 - loss: 0.4664\n","Epoch 100: val_loss did not improve from 0.51633\n","\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7294 - auc: 0.7888 - loss: 0.4669 - val_acc: 0.8590 - val_auc: 0.4015 - val_loss: 1.0031\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 4 | TEST ACC=0.5278 | TEST AUC=0.6664 | n=72\n","Confusion matrix:\n"," [[38  0]\n"," [34  0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.528     1.000     0.691        38\n","           1      0.000     0.000     0.000        34\n","\n","    accuracy                          0.528        72\n","   macro avg      0.264     0.500     0.345        72\n","weighted avg      0.279     0.528     0.365        72\n","\n","\n","--- Fold 5/14 ---\n"," train | ids:   36 | files:   994 | pos files:  362 | neg files:  632\n","   val | ids:    5 | files:   182 | pos files:   39 | neg files:  143\n","  test | ids:    3 | files:    24 | pos files:    4 | neg files:   20\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.5878 - auc: 0.4897 - loss: 0.6872\n","Epoch 1: val_loss improved from inf to 0.61874, saving model to best_fold_05.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - acc: 0.5883 - auc: 0.4894 - loss: 0.6871 - val_acc: 0.7857 - val_auc: 0.3423 - val_loss: 0.6187\n","Epoch 2/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6146 - auc: 0.5219 - loss: 0.6668\n","Epoch 2: val_loss improved from 0.61874 to 0.58982, saving model to best_fold_05.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6151 - auc: 0.5218 - loss: 0.6666 - val_acc: 0.7857 - val_auc: 0.3601 - val_loss: 0.5898\n","Epoch 3/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6370 - auc: 0.5518 - loss: 0.6519\n","Epoch 3: val_loss improved from 0.58982 to 0.57445, saving model to best_fold_05.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6370 - auc: 0.5520 - loss: 0.6519 - val_acc: 0.7857 - val_auc: 0.3653 - val_loss: 0.5744\n","Epoch 4/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6449 - auc: 0.5752 - loss: 0.6442\n","Epoch 4: val_loss did not improve from 0.57445\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6446 - auc: 0.5759 - loss: 0.6443 - val_acc: 0.7857 - val_auc: 0.3874 - val_loss: 0.5985\n","Epoch 5/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6298 - auc: 0.6268 - loss: 0.6423\n","Epoch 5: val_loss improved from 0.57445 to 0.57437, saving model to best_fold_05.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6301 - auc: 0.6265 - loss: 0.6422 - val_acc: 0.7857 - val_auc: 0.4416 - val_loss: 0.5744\n","Epoch 6/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6459 - auc: 0.6203 - loss: 0.6315\n","Epoch 6: val_loss improved from 0.57437 to 0.55714, saving model to best_fold_05.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6459 - auc: 0.6214 - loss: 0.6313 - val_acc: 0.7857 - val_auc: 0.4571 - val_loss: 0.5571\n","Epoch 7/100\n","\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6738 - auc: 0.7066 - loss: 0.5950\n","Epoch 7: val_loss did not improve from 0.55714\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6736 - auc: 0.7063 - loss: 0.5952 - val_acc: 0.7637 - val_auc: 0.5030 - val_loss: 0.5968\n","Epoch 8/100\n","\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6490 - auc: 0.6580 - loss: 0.6253\n","Epoch 8: val_loss did not improve from 0.55714\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6493 - auc: 0.6585 - loss: 0.6248 - val_acc: 0.7747 - val_auc: 0.5299 - val_loss: 0.5935\n","Epoch 9/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6318 - auc: 0.6781 - loss: 0.6121\n","Epoch 9: val_loss did not improve from 0.55714\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6319 - auc: 0.6781 - loss: 0.6120 - val_acc: 0.7527 - val_auc: 0.5488 - val_loss: 0.5797\n","Epoch 10/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6742 - auc: 0.6995 - loss: 0.5722\n","Epoch 10: val_loss did not improve from 0.55714\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6740 - auc: 0.6994 - loss: 0.5723 - val_acc: 0.6593 - val_auc: 0.5441 - val_loss: 0.6293\n","Epoch 11/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6195 - auc: 0.6753 - loss: 0.5926\n","Epoch 11: val_loss did not improve from 0.55714\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6196 - auc: 0.6754 - loss: 0.5925 - val_acc: 0.7198 - val_auc: 0.5614 - val_loss: 0.5758\n","Epoch 12/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6206 - auc: 0.6650 - loss: 0.5917\n","Epoch 12: val_loss did not improve from 0.55714\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6208 - auc: 0.6653 - loss: 0.5916 - val_acc: 0.6648 - val_auc: 0.5582 - val_loss: 0.5853\n","Epoch 13/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6444 - auc: 0.6769 - loss: 0.5818\n","Epoch 13: val_loss did not improve from 0.55714\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6443 - auc: 0.6772 - loss: 0.5819 - val_acc: 0.6758 - val_auc: 0.5626 - val_loss: 0.5740\n","Epoch 14/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6427 - auc: 0.6809 - loss: 0.5743\n","Epoch 14: val_loss did not improve from 0.55714\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6428 - auc: 0.6812 - loss: 0.5743 - val_acc: 0.6264 - val_auc: 0.5595 - val_loss: 0.6290\n","Epoch 15/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6066 - auc: 0.6572 - loss: 0.5962\n","Epoch 15: val_loss did not improve from 0.55714\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6076 - auc: 0.6585 - loss: 0.5952 - val_acc: 0.6593 - val_auc: 0.5653 - val_loss: 0.5713\n","Epoch 16/100\n","\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6468 - auc: 0.7187 - loss: 0.5535\n","Epoch 16: val_loss did not improve from 0.55714\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6468 - auc: 0.7186 - loss: 0.5536 - val_acc: 0.6374 - val_auc: 0.5644 - val_loss: 0.6166\n","Epoch 17/100\n","\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6277 - auc: 0.7155 - loss: 0.5641\n","Epoch 17: val_loss improved from 0.55714 to 0.53780, saving model to best_fold_05.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6277 - auc: 0.7153 - loss: 0.5641 - val_acc: 0.6538 - val_auc: 0.5725 - val_loss: 0.5378\n","Epoch 18/100\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6418 - auc: 0.6867 - loss: 0.5665\n","Epoch 18: val_loss did not improve from 0.53780\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6418 - auc: 0.6867 - loss: 0.5665 - val_acc: 0.6538 - val_auc: 0.5709 - val_loss: 0.5781\n","Epoch 19/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6202 - auc: 0.6878 - loss: 0.5668\n","Epoch 19: val_loss improved from 0.53780 to 0.52885, saving model to best_fold_05.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6206 - auc: 0.6881 - loss: 0.5667 - val_acc: 0.6538 - val_auc: 0.5751 - val_loss: 0.5289\n","Epoch 20/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6428 - auc: 0.6944 - loss: 0.5722\n","Epoch 20: val_loss did not improve from 0.52885\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6431 - auc: 0.6943 - loss: 0.5718 - val_acc: 0.6209 - val_auc: 0.5738 - val_loss: 0.5685\n","Epoch 21/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6445 - auc: 0.7054 - loss: 0.5606\n","Epoch 21: val_loss improved from 0.52885 to 0.51616, saving model to best_fold_05.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6444 - auc: 0.7053 - loss: 0.5606 - val_acc: 0.6758 - val_auc: 0.5731 - val_loss: 0.5162\n","Epoch 22/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6554 - auc: 0.7038 - loss: 0.5507\n","Epoch 22: val_loss did not improve from 0.51616\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6551 - auc: 0.7039 - loss: 0.5511 - val_acc: 0.6429 - val_auc: 0.5734 - val_loss: 0.5422\n","Epoch 23/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6461 - auc: 0.6717 - loss: 0.5556\n","Epoch 23: val_loss did not improve from 0.51616\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6469 - auc: 0.6734 - loss: 0.5556 - val_acc: 0.6209 - val_auc: 0.5734 - val_loss: 0.5485\n","Epoch 24/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6320 - auc: 0.6965 - loss: 0.5560\n","Epoch 24: val_loss did not improve from 0.51616\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6322 - auc: 0.6965 - loss: 0.5560 - val_acc: 0.6758 - val_auc: 0.5715 - val_loss: 0.5224\n","Epoch 25/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6563 - auc: 0.7127 - loss: 0.5561\n","Epoch 25: val_loss did not improve from 0.51616\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6560 - auc: 0.7125 - loss: 0.5559 - val_acc: 0.6429 - val_auc: 0.5681 - val_loss: 0.5287\n","Epoch 26/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6562 - auc: 0.6961 - loss: 0.5472\n","Epoch 26: val_loss improved from 0.51616 to 0.51120, saving model to best_fold_05.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6561 - auc: 0.6960 - loss: 0.5474 - val_acc: 0.6758 - val_auc: 0.5647 - val_loss: 0.5112\n","Epoch 27/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6593 - auc: 0.7191 - loss: 0.5456\n","Epoch 27: val_loss improved from 0.51120 to 0.49217, saving model to best_fold_05.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - acc: 0.6588 - auc: 0.7186 - loss: 0.5458 - val_acc: 0.7418 - val_auc: 0.5613 - val_loss: 0.4922\n","Epoch 28/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6575 - auc: 0.7283 - loss: 0.5354\n","Epoch 28: val_loss did not improve from 0.49217\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6576 - auc: 0.7279 - loss: 0.5357 - val_acc: 0.6374 - val_auc: 0.5576 - val_loss: 0.5203\n","Epoch 29/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6531 - auc: 0.6825 - loss: 0.5676\n","Epoch 29: val_loss did not improve from 0.49217\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6531 - auc: 0.6831 - loss: 0.5672 - val_acc: 0.6538 - val_auc: 0.5450 - val_loss: 0.5020\n","Epoch 30/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6630 - auc: 0.7154 - loss: 0.5418\n","Epoch 30: val_loss did not improve from 0.49217\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6629 - auc: 0.7153 - loss: 0.5419 - val_acc: 0.6264 - val_auc: 0.5460 - val_loss: 0.5100\n","Epoch 31/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6742 - auc: 0.7199 - loss: 0.5273\n","Epoch 31: val_loss did not improve from 0.49217\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6735 - auc: 0.7194 - loss: 0.5279 - val_acc: 0.6813 - val_auc: 0.5431 - val_loss: 0.4953\n","Epoch 32/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6617 - auc: 0.7200 - loss: 0.5353\n","Epoch 32: val_loss improved from 0.49217 to 0.48856, saving model to best_fold_05.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - acc: 0.6614 - auc: 0.7196 - loss: 0.5356 - val_acc: 0.6868 - val_auc: 0.5407 - val_loss: 0.4886\n","Epoch 33/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6545 - auc: 0.7146 - loss: 0.5366\n","Epoch 33: val_loss did not improve from 0.48856\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6545 - auc: 0.7145 - loss: 0.5367 - val_acc: 0.6648 - val_auc: 0.5364 - val_loss: 0.4966\n","Epoch 34/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6471 - auc: 0.7000 - loss: 0.5481\n","Epoch 34: val_loss improved from 0.48856 to 0.47992, saving model to best_fold_05.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6475 - auc: 0.7005 - loss: 0.5479 - val_acc: 0.7418 - val_auc: 0.5329 - val_loss: 0.4799\n","Epoch 35/100\n","\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6371 - auc: 0.6995 - loss: 0.5586\n","Epoch 35: val_loss did not improve from 0.47992\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6374 - auc: 0.6998 - loss: 0.5582 - val_acc: 0.7198 - val_auc: 0.5332 - val_loss: 0.4801\n","Epoch 36/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6363 - auc: 0.6829 - loss: 0.5624\n","Epoch 36: val_loss did not improve from 0.47992\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6366 - auc: 0.6835 - loss: 0.5620 - val_acc: 0.6703 - val_auc: 0.5330 - val_loss: 0.4850\n","Epoch 37/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6624 - auc: 0.7270 - loss: 0.5382\n","Epoch 37: val_loss did not improve from 0.47992\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6622 - auc: 0.7269 - loss: 0.5383 - val_acc: 0.6593 - val_auc: 0.5334 - val_loss: 0.4868\n","Epoch 38/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6571 - auc: 0.7143 - loss: 0.5421\n","Epoch 38: val_loss improved from 0.47992 to 0.47949, saving model to best_fold_05.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6570 - auc: 0.7144 - loss: 0.5420 - val_acc: 0.7363 - val_auc: 0.5388 - val_loss: 0.4795\n","Epoch 39/100\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6624 - auc: 0.7081 - loss: 0.5324\n","Epoch 39: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6624 - auc: 0.7081 - loss: 0.5324 - val_acc: 0.6209 - val_auc: 0.5368 - val_loss: 0.4917\n","Epoch 40/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6343 - auc: 0.6976 - loss: 0.5370\n","Epoch 40: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6343 - auc: 0.6977 - loss: 0.5370 - val_acc: 0.7143 - val_auc: 0.5378 - val_loss: 0.4847\n","Epoch 41/100\n","\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6133 - auc: 0.6986 - loss: 0.5507\n","Epoch 41: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6141 - auc: 0.6990 - loss: 0.5503 - val_acc: 0.7033 - val_auc: 0.5347 - val_loss: 0.4877\n","Epoch 42/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6763 - auc: 0.7408 - loss: 0.5184\n","Epoch 42: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6752 - auc: 0.7399 - loss: 0.5192 - val_acc: 0.7088 - val_auc: 0.5331 - val_loss: 0.4841\n","Epoch 43/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6605 - auc: 0.7039 - loss: 0.5366\n","Epoch 43: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6604 - auc: 0.7042 - loss: 0.5365 - val_acc: 0.7198 - val_auc: 0.5367 - val_loss: 0.5013\n","Epoch 44/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6504 - auc: 0.7108 - loss: 0.5317\n","Epoch 44: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6502 - auc: 0.7108 - loss: 0.5318 - val_acc: 0.6538 - val_auc: 0.5324 - val_loss: 0.4924\n","Epoch 45/100\n","\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6527 - auc: 0.6973 - loss: 0.5421\n","Epoch 45: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6526 - auc: 0.6980 - loss: 0.5418 - val_acc: 0.7253 - val_auc: 0.5354 - val_loss: 0.5602\n","Epoch 46/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6096 - auc: 0.6949 - loss: 0.5611\n","Epoch 46: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6107 - auc: 0.6959 - loss: 0.5601 - val_acc: 0.6374 - val_auc: 0.5403 - val_loss: 0.5095\n","Epoch 47/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6608 - auc: 0.7542 - loss: 0.5226\n","Epoch 47: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6606 - auc: 0.7533 - loss: 0.5230 - val_acc: 0.7418 - val_auc: 0.5319 - val_loss: 0.4993\n","Epoch 48/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6985 - auc: 0.7173 - loss: 0.5179\n","Epoch 48: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6979 - auc: 0.7174 - loss: 0.5181 - val_acc: 0.6703 - val_auc: 0.5414 - val_loss: 0.5964\n","Epoch 49/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6614 - auc: 0.7230 - loss: 0.5254\n","Epoch 49: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6610 - auc: 0.7233 - loss: 0.5255 - val_acc: 0.7418 - val_auc: 0.5403 - val_loss: 0.5525\n","Epoch 50/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6657 - auc: 0.6873 - loss: 0.5348\n","Epoch 50: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6656 - auc: 0.6880 - loss: 0.5346 - val_acc: 0.7253 - val_auc: 0.5362 - val_loss: 0.6088\n","Epoch 51/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6157 - auc: 0.7045 - loss: 0.5383\n","Epoch 51: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6169 - auc: 0.7054 - loss: 0.5379 - val_acc: 0.7088 - val_auc: 0.5410 - val_loss: 0.6102\n","Epoch 52/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6641 - auc: 0.7291 - loss: 0.5210\n","Epoch 52: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6640 - auc: 0.7291 - loss: 0.5210 - val_acc: 0.7363 - val_auc: 0.5427 - val_loss: 0.6071\n","Epoch 53/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6644 - auc: 0.7280 - loss: 0.5308\n","Epoch 53: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6643 - auc: 0.7280 - loss: 0.5307 - val_acc: 0.7637 - val_auc: 0.5214 - val_loss: 0.7161\n","Epoch 54/100\n","\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6938 - auc: 0.7338 - loss: 0.5052\n","Epoch 54: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6925 - auc: 0.7333 - loss: 0.5058 - val_acc: 0.7363 - val_auc: 0.5413 - val_loss: 0.6406\n","Epoch 55/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6416 - auc: 0.7222 - loss: 0.5300\n","Epoch 55: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6423 - auc: 0.7223 - loss: 0.5297 - val_acc: 0.7473 - val_auc: 0.5355 - val_loss: 0.5653\n","Epoch 56/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6415 - auc: 0.7133 - loss: 0.5188\n","Epoch 56: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6416 - auc: 0.7134 - loss: 0.5189 - val_acc: 0.7418 - val_auc: 0.5381 - val_loss: 0.6538\n","Epoch 57/100\n","\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6556 - auc: 0.7191 - loss: 0.5099\n","Epoch 57: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6553 - auc: 0.7191 - loss: 0.5102 - val_acc: 0.7088 - val_auc: 0.5498 - val_loss: 0.6501\n","Epoch 58/100\n","\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6621 - auc: 0.7311 - loss: 0.5053\n","Epoch 58: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6620 - auc: 0.7310 - loss: 0.5054 - val_acc: 0.7637 - val_auc: 0.5385 - val_loss: 0.6547\n","Epoch 59/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6543 - auc: 0.7462 - loss: 0.5098\n","Epoch 59: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6545 - auc: 0.7450 - loss: 0.5104 - val_acc: 0.7473 - val_auc: 0.5395 - val_loss: 0.6878\n","Epoch 60/100\n","\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6727 - auc: 0.7297 - loss: 0.5180\n","Epoch 60: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6724 - auc: 0.7296 - loss: 0.5180 - val_acc: 0.7418 - val_auc: 0.5465 - val_loss: 0.5634\n","Epoch 61/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6763 - auc: 0.7618 - loss: 0.5097\n","Epoch 61: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6758 - auc: 0.7610 - loss: 0.5098 - val_acc: 0.7637 - val_auc: 0.5033 - val_loss: 0.8045\n","Epoch 62/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6483 - auc: 0.7216 - loss: 0.5243\n","Epoch 62: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6484 - auc: 0.7215 - loss: 0.5242 - val_acc: 0.7473 - val_auc: 0.5488 - val_loss: 0.6259\n","Epoch 63/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6688 - auc: 0.7032 - loss: 0.5090\n","Epoch 63: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6680 - auc: 0.7034 - loss: 0.5093 - val_acc: 0.7418 - val_auc: 0.5172 - val_loss: 0.7790\n","Epoch 64/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7020 - auc: 0.7004 - loss: 0.5084\n","Epoch 64: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7004 - auc: 0.7020 - loss: 0.5085 - val_acc: 0.6319 - val_auc: 0.5559 - val_loss: 0.7441\n","Epoch 65/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6628 - auc: 0.7397 - loss: 0.5116\n","Epoch 65: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6628 - auc: 0.7397 - loss: 0.5115 - val_acc: 0.7473 - val_auc: 0.5723 - val_loss: 0.6370\n","Epoch 66/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6612 - auc: 0.7301 - loss: 0.5185\n","Epoch 66: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6612 - auc: 0.7301 - loss: 0.5185 - val_acc: 0.7473 - val_auc: 0.5405 - val_loss: 0.7641\n","Epoch 67/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6522 - auc: 0.7343 - loss: 0.5258\n","Epoch 67: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6528 - auc: 0.7343 - loss: 0.5251 - val_acc: 0.7473 - val_auc: 0.5182 - val_loss: 0.8178\n","Epoch 68/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6809 - auc: 0.7441 - loss: 0.4984\n","Epoch 68: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6802 - auc: 0.7435 - loss: 0.4987 - val_acc: 0.7692 - val_auc: 0.5293 - val_loss: 1.0001\n","Epoch 69/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6763 - auc: 0.7415 - loss: 0.5104\n","Epoch 69: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6762 - auc: 0.7414 - loss: 0.5104 - val_acc: 0.7637 - val_auc: 0.5373 - val_loss: 0.7643\n","Epoch 70/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6881 - auc: 0.7040 - loss: 0.5069\n","Epoch 70: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6879 - auc: 0.7048 - loss: 0.5069 - val_acc: 0.7637 - val_auc: 0.5307 - val_loss: 1.0637\n","Epoch 71/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6685 - auc: 0.7202 - loss: 0.5129\n","Epoch 71: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6686 - auc: 0.7207 - loss: 0.5127 - val_acc: 0.7198 - val_auc: 0.5490 - val_loss: 1.0144\n","Epoch 72/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6531 - auc: 0.7269 - loss: 0.5092\n","Epoch 72: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6533 - auc: 0.7271 - loss: 0.5092 - val_acc: 0.7857 - val_auc: 0.5092 - val_loss: 0.9407\n","Epoch 73/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6627 - auc: 0.7325 - loss: 0.5039\n","Epoch 73: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6631 - auc: 0.7324 - loss: 0.5040 - val_acc: 0.7857 - val_auc: 0.5251 - val_loss: 0.9614\n","Epoch 74/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6459 - auc: 0.7070 - loss: 0.5191\n","Epoch 74: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6462 - auc: 0.7074 - loss: 0.5189 - val_acc: 0.7857 - val_auc: 0.5338 - val_loss: 1.0602\n","Epoch 75/100\n","\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6815 - auc: 0.7372 - loss: 0.4984\n","Epoch 75: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6813 - auc: 0.7371 - loss: 0.4985 - val_acc: 0.7857 - val_auc: 0.5526 - val_loss: 0.9857\n","Epoch 76/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6843 - auc: 0.7609 - loss: 0.4951\n","Epoch 76: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6838 - auc: 0.7598 - loss: 0.4952 - val_acc: 0.7033 - val_auc: 0.5553 - val_loss: 1.0142\n","Epoch 77/100\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6476 - auc: 0.7306 - loss: 0.5240\n","Epoch 77: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6477 - auc: 0.7306 - loss: 0.5239 - val_acc: 0.7857 - val_auc: 0.5367 - val_loss: 0.8579\n","Epoch 78/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7248 - auc: 0.7351 - loss: 0.4892\n","Epoch 78: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7239 - auc: 0.7353 - loss: 0.4895 - val_acc: 0.7857 - val_auc: 0.5640 - val_loss: 1.0598\n","Epoch 79/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6448 - auc: 0.7326 - loss: 0.5023\n","Epoch 79: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6455 - auc: 0.7328 - loss: 0.5022 - val_acc: 0.6813 - val_auc: 0.6125 - val_loss: 0.9635\n","Epoch 80/100\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6648 - auc: 0.7332 - loss: 0.5002\n","Epoch 80: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6648 - auc: 0.7332 - loss: 0.5002 - val_acc: 0.7802 - val_auc: 0.5775 - val_loss: 0.9911\n","Epoch 81/100\n","\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6520 - auc: 0.7407 - loss: 0.5042\n","Epoch 81: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6521 - auc: 0.7408 - loss: 0.5041 - val_acc: 0.7857 - val_auc: 0.5451 - val_loss: 1.1353\n","Epoch 82/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6824 - auc: 0.7316 - loss: 0.4996\n","Epoch 82: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6823 - auc: 0.7316 - loss: 0.4996 - val_acc: 0.7857 - val_auc: 0.5643 - val_loss: 1.1167\n","Epoch 83/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7257 - auc: 0.7479 - loss: 0.4809\n","Epoch 83: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7252 - auc: 0.7478 - loss: 0.4811 - val_acc: 0.7308 - val_auc: 0.5897 - val_loss: 1.3017\n","Epoch 84/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6862 - auc: 0.7226 - loss: 0.4941\n","Epoch 84: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6860 - auc: 0.7231 - loss: 0.4943 - val_acc: 0.7857 - val_auc: 0.5547 - val_loss: 1.1482\n","Epoch 85/100\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6987 - auc: 0.7241 - loss: 0.5066\n","Epoch 85: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6986 - auc: 0.7241 - loss: 0.5066 - val_acc: 0.7857 - val_auc: 0.5311 - val_loss: 0.9957\n","Epoch 86/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6951 - auc: 0.7201 - loss: 0.5025\n","Epoch 86: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6948 - auc: 0.7207 - loss: 0.5025 - val_acc: 0.7637 - val_auc: 0.6345 - val_loss: 0.7061\n","Epoch 87/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6667 - auc: 0.7316 - loss: 0.5166\n","Epoch 87: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6668 - auc: 0.7317 - loss: 0.5165 - val_acc: 0.7637 - val_auc: 0.5759 - val_loss: 1.3487\n","Epoch 88/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7032 - auc: 0.7448 - loss: 0.4751\n","Epoch 88: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7024 - auc: 0.7449 - loss: 0.4757 - val_acc: 0.7857 - val_auc: 0.5652 - val_loss: 1.0872\n","Epoch 89/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6477 - auc: 0.7288 - loss: 0.5109\n","Epoch 89: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6487 - auc: 0.7294 - loss: 0.5102 - val_acc: 0.7088 - val_auc: 0.6233 - val_loss: 1.2977\n","Epoch 90/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6774 - auc: 0.7566 - loss: 0.5013\n","Epoch 90: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6774 - auc: 0.7562 - loss: 0.5012 - val_acc: 0.7857 - val_auc: 0.5964 - val_loss: 1.2642\n","Epoch 91/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6617 - auc: 0.7340 - loss: 0.5145\n","Epoch 91: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6618 - auc: 0.7340 - loss: 0.5144 - val_acc: 0.7857 - val_auc: 0.5407 - val_loss: 1.0403\n","Epoch 92/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6940 - auc: 0.7636 - loss: 0.4870\n","Epoch 92: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6936 - auc: 0.7634 - loss: 0.4871 - val_acc: 0.7637 - val_auc: 0.5882 - val_loss: 1.4156\n","Epoch 93/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6433 - auc: 0.7187 - loss: 0.5073\n","Epoch 93: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6441 - auc: 0.7194 - loss: 0.5070 - val_acc: 0.7857 - val_auc: 0.5456 - val_loss: 1.2903\n","Epoch 94/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6626 - auc: 0.7034 - loss: 0.5332\n","Epoch 94: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6635 - auc: 0.7051 - loss: 0.5317 - val_acc: 0.7857 - val_auc: 0.5711 - val_loss: 1.4681\n","Epoch 95/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6624 - auc: 0.7460 - loss: 0.5180\n","Epoch 95: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6631 - auc: 0.7462 - loss: 0.5172 - val_acc: 0.7857 - val_auc: 0.5952 - val_loss: 1.0895\n","Epoch 96/100\n","\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6859 - auc: 0.7513 - loss: 0.4897\n","Epoch 96: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6859 - auc: 0.7510 - loss: 0.4898 - val_acc: 0.7637 - val_auc: 0.5710 - val_loss: 1.3215\n","Epoch 97/100\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6996 - auc: 0.7613 - loss: 0.4793\n","Epoch 97: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6996 - auc: 0.7613 - loss: 0.4793 - val_acc: 0.7857 - val_auc: 0.5842 - val_loss: 0.7247\n","Epoch 98/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6888 - auc: 0.7535 - loss: 0.4929\n","Epoch 98: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6888 - auc: 0.7534 - loss: 0.4929 - val_acc: 0.7857 - val_auc: 0.5670 - val_loss: 1.4332\n","Epoch 99/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6869 - auc: 0.7643 - loss: 0.4799\n","Epoch 99: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6865 - auc: 0.7641 - loss: 0.4803 - val_acc: 0.7857 - val_auc: 0.5886 - val_loss: 1.2549\n","Epoch 100/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6925 - auc: 0.7510 - loss: 0.4875\n","Epoch 100: val_loss did not improve from 0.47949\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6923 - auc: 0.7510 - loss: 0.4875 - val_acc: 0.7802 - val_auc: 0.6022 - val_loss: 1.4537\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 5 | TEST ACC=0.7917 | TEST AUC=0.0000 | n=24\n","Confusion matrix:\n"," [[19  1]\n"," [ 4  0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.826     0.950     0.884        20\n","           1      0.000     0.000     0.000         4\n","\n","    accuracy                          0.792        24\n","   macro avg      0.413     0.475     0.442        24\n","weighted avg      0.688     0.792     0.736        24\n","\n","\n","--- Fold 6/14 ---\n"," train | ids:   36 | files:   978 | pos files:  289 | neg files:  689\n","   val | ids:    5 | files:   107 | pos files:   39 | neg files:   68\n","  test | ids:    3 | files:   115 | pos files:   77 | neg files:   38\n","Epoch 1/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5303 - auc: 0.4908 - loss: 0.6914\n","Epoch 1: val_loss improved from inf to 0.65859, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - acc: 0.5340 - auc: 0.4922 - loss: 0.6909 - val_acc: 0.6355 - val_auc: 0.3652 - val_loss: 0.6586\n","Epoch 2/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6943 - auc: 0.3845 - loss: 0.6315\n","Epoch 2: val_loss did not improve from 0.65859\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6946 - auc: 0.3855 - loss: 0.6312 - val_acc: 0.6355 - val_auc: 0.3893 - val_loss: 0.6663\n","Epoch 3/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7289 - auc: 0.4165 - loss: 0.5970\n","Epoch 3: val_loss improved from 0.65859 to 0.65840, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7281 - auc: 0.4175 - loss: 0.5976 - val_acc: 0.6355 - val_auc: 0.4021 - val_loss: 0.6584\n","Epoch 4/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7263 - auc: 0.4610 - loss: 0.5968\n","Epoch 4: val_loss improved from 0.65840 to 0.65730, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7256 - auc: 0.4602 - loss: 0.5974 - val_acc: 0.6355 - val_auc: 0.4001 - val_loss: 0.6573\n","Epoch 5/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6959 - auc: 0.4611 - loss: 0.6206\n","Epoch 5: val_loss did not improve from 0.65730\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6961 - auc: 0.4610 - loss: 0.6204 - val_acc: 0.6355 - val_auc: 0.4338 - val_loss: 0.6607\n","Epoch 6/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6946 - auc: 0.4720 - loss: 0.6218\n","Epoch 6: val_loss improved from 0.65730 to 0.65582, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6949 - auc: 0.4721 - loss: 0.6216 - val_acc: 0.6355 - val_auc: 0.4934 - val_loss: 0.6558\n","Epoch 7/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7088 - auc: 0.4806 - loss: 0.6090\n","Epoch 7: val_loss improved from 0.65582 to 0.65371, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7088 - auc: 0.4807 - loss: 0.6090 - val_acc: 0.6355 - val_auc: 0.5420 - val_loss: 0.6537\n","Epoch 8/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7030 - auc: 0.4873 - loss: 0.6130\n","Epoch 8: val_loss did not improve from 0.65371\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7030 - auc: 0.4883 - loss: 0.6129 - val_acc: 0.6355 - val_auc: 0.5732 - val_loss: 0.6566\n","Epoch 9/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7198 - auc: 0.5260 - loss: 0.5934\n","Epoch 9: val_loss improved from 0.65371 to 0.64933, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7194 - auc: 0.5262 - loss: 0.5937 - val_acc: 0.6355 - val_auc: 0.5988 - val_loss: 0.6493\n","Epoch 10/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7054 - auc: 0.5389 - loss: 0.6044\n","Epoch 10: val_loss did not improve from 0.64933\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7053 - auc: 0.5402 - loss: 0.6042 - val_acc: 0.6355 - val_auc: 0.5980 - val_loss: 0.6626\n","Epoch 11/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7141 - auc: 0.5531 - loss: 0.5945\n","Epoch 11: val_loss improved from 0.64933 to 0.64769, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7138 - auc: 0.5538 - loss: 0.5947 - val_acc: 0.6355 - val_auc: 0.5926 - val_loss: 0.6477\n","Epoch 12/100\n","\u001b[1m323/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6931 - auc: 0.6006 - loss: 0.6017\n","Epoch 12: val_loss improved from 0.64769 to 0.64406, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6932 - auc: 0.6005 - loss: 0.6016 - val_acc: 0.6355 - val_auc: 0.5760 - val_loss: 0.6441\n","Epoch 13/100\n","\u001b[1m322/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7070 - auc: 0.6195 - loss: 0.5837\n","Epoch 13: val_loss did not improve from 0.64406\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7069 - auc: 0.6195 - loss: 0.5837 - val_acc: 0.6355 - val_auc: 0.5649 - val_loss: 0.6456\n","Epoch 14/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6873 - auc: 0.6340 - loss: 0.5954\n","Epoch 14: val_loss did not improve from 0.64406\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6879 - auc: 0.6338 - loss: 0.5948 - val_acc: 0.6355 - val_auc: 0.5479 - val_loss: 0.6526\n","Epoch 15/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7017 - auc: 0.6305 - loss: 0.5856\n","Epoch 15: val_loss improved from 0.64406 to 0.62878, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7018 - auc: 0.6308 - loss: 0.5854 - val_acc: 0.6355 - val_auc: 0.5437 - val_loss: 0.6288\n","Epoch 16/100\n","\u001b[1m314/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7258 - auc: 0.6596 - loss: 0.5512\n","Epoch 16: val_loss improved from 0.62878 to 0.61959, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7251 - auc: 0.6590 - loss: 0.5520 - val_acc: 0.6355 - val_auc: 0.5370 - val_loss: 0.6196\n","Epoch 17/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7186 - auc: 0.6579 - loss: 0.5688\n","Epoch 17: val_loss did not improve from 0.61959\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7185 - auc: 0.6574 - loss: 0.5689 - val_acc: 0.6355 - val_auc: 0.5164 - val_loss: 0.6268\n","Epoch 18/100\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7216 - auc: 0.6683 - loss: 0.5551\n","Epoch 18: val_loss did not improve from 0.61959\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7216 - auc: 0.6683 - loss: 0.5551 - val_acc: 0.6355 - val_auc: 0.5077 - val_loss: 0.6249\n","Epoch 19/100\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7187 - auc: 0.6565 - loss: 0.5756\n","Epoch 19: val_loss did not improve from 0.61959\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7188 - auc: 0.6565 - loss: 0.5756 - val_acc: 0.6355 - val_auc: 0.4960 - val_loss: 0.6598\n","Epoch 20/100\n","\u001b[1m322/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7327 - auc: 0.6340 - loss: 0.5720\n","Epoch 20: val_loss did not improve from 0.61959\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7327 - auc: 0.6344 - loss: 0.5718 - val_acc: 0.6355 - val_auc: 0.4874 - val_loss: 0.6297\n","Epoch 21/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7261 - auc: 0.6636 - loss: 0.5678\n","Epoch 21: val_loss did not improve from 0.61959\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7265 - auc: 0.6641 - loss: 0.5672 - val_acc: 0.6355 - val_auc: 0.4855 - val_loss: 0.6274\n","Epoch 22/100\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7573 - auc: 0.6550 - loss: 0.5507\n","Epoch 22: val_loss improved from 0.61959 to 0.61953, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7572 - auc: 0.6551 - loss: 0.5507 - val_acc: 0.6075 - val_auc: 0.4844 - val_loss: 0.6195\n","Epoch 23/100\n","\u001b[1m324/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7345 - auc: 0.6633 - loss: 0.5585\n","Epoch 23: val_loss did not improve from 0.61953\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7346 - auc: 0.6634 - loss: 0.5583 - val_acc: 0.6355 - val_auc: 0.4762 - val_loss: 0.6337\n","Epoch 24/100\n","\u001b[1m322/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7407 - auc: 0.6874 - loss: 0.5419\n","Epoch 24: val_loss improved from 0.61953 to 0.61375, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7407 - auc: 0.6873 - loss: 0.5418 - val_acc: 0.6075 - val_auc: 0.4872 - val_loss: 0.6137\n","Epoch 25/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7360 - auc: 0.6740 - loss: 0.5402\n","Epoch 25: val_loss did not improve from 0.61375\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7360 - auc: 0.6741 - loss: 0.5401 - val_acc: 0.6262 - val_auc: 0.4740 - val_loss: 0.6291\n","Epoch 26/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7280 - auc: 0.6648 - loss: 0.5432\n","Epoch 26: val_loss improved from 0.61375 to 0.61018, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7286 - auc: 0.6657 - loss: 0.5427 - val_acc: 0.5981 - val_auc: 0.4953 - val_loss: 0.6102\n","Epoch 27/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7123 - auc: 0.6767 - loss: 0.5471\n","Epoch 27: val_loss did not improve from 0.61018\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7135 - auc: 0.6771 - loss: 0.5464 - val_acc: 0.5981 - val_auc: 0.4830 - val_loss: 0.6183\n","Epoch 28/100\n","\u001b[1m324/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7378 - auc: 0.6911 - loss: 0.5274\n","Epoch 28: val_loss did not improve from 0.61018\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7379 - auc: 0.6912 - loss: 0.5274 - val_acc: 0.5981 - val_auc: 0.4870 - val_loss: 0.6133\n","Epoch 29/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7691 - auc: 0.6840 - loss: 0.5062\n","Epoch 29: val_loss improved from 0.61018 to 0.60906, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7685 - auc: 0.6843 - loss: 0.5066 - val_acc: 0.5981 - val_auc: 0.4913 - val_loss: 0.6091\n","Epoch 30/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7483 - auc: 0.6937 - loss: 0.5212\n","Epoch 30: val_loss did not improve from 0.60906\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7483 - auc: 0.6932 - loss: 0.5213 - val_acc: 0.6355 - val_auc: 0.4768 - val_loss: 0.6250\n","Epoch 31/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7519 - auc: 0.7031 - loss: 0.5150\n","Epoch 31: val_loss did not improve from 0.60906\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7519 - auc: 0.7031 - loss: 0.5150 - val_acc: 0.5514 - val_auc: 0.5551 - val_loss: 0.6244\n","Epoch 32/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7041 - auc: 0.6946 - loss: 0.5404\n","Epoch 32: val_loss did not improve from 0.60906\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7048 - auc: 0.6949 - loss: 0.5399 - val_acc: 0.6355 - val_auc: 0.4730 - val_loss: 0.6316\n","Epoch 33/100\n","\u001b[1m324/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7538 - auc: 0.7017 - loss: 0.5142\n","Epoch 33: val_loss did not improve from 0.60906\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7538 - auc: 0.7019 - loss: 0.5141 - val_acc: 0.6355 - val_auc: 0.4766 - val_loss: 0.6627\n","Epoch 34/100\n","\u001b[1m322/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7443 - auc: 0.6798 - loss: 0.5282\n","Epoch 34: val_loss improved from 0.60906 to 0.60738, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7444 - auc: 0.6804 - loss: 0.5280 - val_acc: 0.6355 - val_auc: 0.5209 - val_loss: 0.6074\n","Epoch 35/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7786 - auc: 0.7289 - loss: 0.4778\n","Epoch 35: val_loss improved from 0.60738 to 0.57509, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7778 - auc: 0.7286 - loss: 0.4787 - val_acc: 0.6355 - val_auc: 0.7163 - val_loss: 0.5751\n","Epoch 36/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7510 - auc: 0.7190 - loss: 0.5085\n","Epoch 36: val_loss did not improve from 0.57509\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7511 - auc: 0.7191 - loss: 0.5085 - val_acc: 0.6355 - val_auc: 0.5841 - val_loss: 0.6061\n","Epoch 37/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7870 - auc: 0.7348 - loss: 0.4716\n","Epoch 37: val_loss did not improve from 0.57509\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7863 - auc: 0.7349 - loss: 0.4721 - val_acc: 0.6355 - val_auc: 0.7360 - val_loss: 0.5767\n","Epoch 38/100\n","\u001b[1m323/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7565 - auc: 0.7424 - loss: 0.4922\n","Epoch 38: val_loss did not improve from 0.57509\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7565 - auc: 0.7425 - loss: 0.4922 - val_acc: 0.6355 - val_auc: 0.4947 - val_loss: 0.6533\n","Epoch 39/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7580 - auc: 0.7480 - loss: 0.4971\n","Epoch 39: val_loss did not improve from 0.57509\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7581 - auc: 0.7482 - loss: 0.4969 - val_acc: 0.6355 - val_auc: 0.6322 - val_loss: 0.6200\n","Epoch 40/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7723 - auc: 0.7427 - loss: 0.4781\n","Epoch 40: val_loss improved from 0.57509 to 0.54756, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7720 - auc: 0.7427 - loss: 0.4785 - val_acc: 0.6542 - val_auc: 0.7841 - val_loss: 0.5476\n","Epoch 41/100\n","\u001b[1m321/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7609 - auc: 0.7336 - loss: 0.4930\n","Epoch 41: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7610 - auc: 0.7336 - loss: 0.4931 - val_acc: 0.6355 - val_auc: 0.7538 - val_loss: 0.5723\n","Epoch 42/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7679 - auc: 0.7570 - loss: 0.4872\n","Epoch 42: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7678 - auc: 0.7570 - loss: 0.4872 - val_acc: 0.6355 - val_auc: 0.6748 - val_loss: 0.6099\n","Epoch 43/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7861 - auc: 0.7363 - loss: 0.4683\n","Epoch 43: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7857 - auc: 0.7369 - loss: 0.4685 - val_acc: 0.6355 - val_auc: 0.7198 - val_loss: 0.6041\n","Epoch 44/100\n","\u001b[1m314/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7545 - auc: 0.7506 - loss: 0.4833\n","Epoch 44: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7546 - auc: 0.7504 - loss: 0.4837 - val_acc: 0.6355 - val_auc: 0.6127 - val_loss: 0.6362\n","Epoch 45/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7545 - auc: 0.7346 - loss: 0.5006\n","Epoch 45: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7546 - auc: 0.7350 - loss: 0.5002 - val_acc: 0.6449 - val_auc: 0.7802 - val_loss: 0.5658\n","Epoch 46/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7546 - auc: 0.7346 - loss: 0.4973\n","Epoch 46: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7546 - auc: 0.7350 - loss: 0.4971 - val_acc: 0.6355 - val_auc: 0.7787 - val_loss: 0.5754\n","Epoch 47/100\n","\u001b[1m321/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7510 - auc: 0.7464 - loss: 0.4842\n","Epoch 47: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7511 - auc: 0.7464 - loss: 0.4843 - val_acc: 0.6355 - val_auc: 0.7483 - val_loss: 0.5744\n","Epoch 48/100\n","\u001b[1m321/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7427 - auc: 0.7711 - loss: 0.4945\n","Epoch 48: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7430 - auc: 0.7711 - loss: 0.4944 - val_acc: 0.6355 - val_auc: 0.7217 - val_loss: 0.6038\n","Epoch 49/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7689 - auc: 0.7593 - loss: 0.4716\n","Epoch 49: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7688 - auc: 0.7595 - loss: 0.4718 - val_acc: 0.6355 - val_auc: 0.7360 - val_loss: 0.5749\n","Epoch 50/100\n","\u001b[1m322/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7868 - auc: 0.7707 - loss: 0.4604\n","Epoch 50: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7864 - auc: 0.7706 - loss: 0.4607 - val_acc: 0.6542 - val_auc: 0.7530 - val_loss: 0.5594\n","Epoch 51/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7902 - auc: 0.7549 - loss: 0.4613\n","Epoch 51: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7887 - auc: 0.7552 - loss: 0.4621 - val_acc: 0.6355 - val_auc: 0.7440 - val_loss: 0.5926\n","Epoch 52/100\n","\u001b[1m321/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7842 - auc: 0.7665 - loss: 0.4655\n","Epoch 52: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7838 - auc: 0.7664 - loss: 0.4659 - val_acc: 0.6355 - val_auc: 0.7526 - val_loss: 0.5898\n","Epoch 53/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7381 - auc: 0.7411 - loss: 0.5103\n","Epoch 53: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7388 - auc: 0.7417 - loss: 0.5095 - val_acc: 0.6729 - val_auc: 0.7464 - val_loss: 0.5908\n","Epoch 54/100\n","\u001b[1m321/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7724 - auc: 0.7624 - loss: 0.4759\n","Epoch 54: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7721 - auc: 0.7625 - loss: 0.4759 - val_acc: 0.6355 - val_auc: 0.7332 - val_loss: 0.5861\n","Epoch 55/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7773 - auc: 0.7830 - loss: 0.4688\n","Epoch 55: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7772 - auc: 0.7830 - loss: 0.4688 - val_acc: 0.6355 - val_auc: 0.5696 - val_loss: 0.6954\n","Epoch 56/100\n","\u001b[1m324/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7638 - auc: 0.7628 - loss: 0.4866\n","Epoch 56: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7638 - auc: 0.7628 - loss: 0.4865 - val_acc: 0.6355 - val_auc: 0.7672 - val_loss: 0.5813\n","Epoch 57/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7792 - auc: 0.7732 - loss: 0.4681\n","Epoch 57: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7788 - auc: 0.7733 - loss: 0.4683 - val_acc: 0.6355 - val_auc: 0.7494 - val_loss: 0.5739\n","Epoch 58/100\n","\u001b[1m314/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7582 - auc: 0.7846 - loss: 0.4611\n","Epoch 58: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7583 - auc: 0.7843 - loss: 0.4616 - val_acc: 0.6355 - val_auc: 0.7391 - val_loss: 0.6117\n","Epoch 59/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7533 - auc: 0.7867 - loss: 0.4796\n","Epoch 59: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7532 - auc: 0.7865 - loss: 0.4796 - val_acc: 0.6355 - val_auc: 0.6976 - val_loss: 0.6177\n","Epoch 60/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7492 - auc: 0.7413 - loss: 0.5037\n","Epoch 60: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7496 - auc: 0.7420 - loss: 0.5031 - val_acc: 0.6355 - val_auc: 0.5617 - val_loss: 0.7503\n","Epoch 61/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7608 - auc: 0.7497 - loss: 0.4786\n","Epoch 61: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7607 - auc: 0.7502 - loss: 0.4787 - val_acc: 0.6355 - val_auc: 0.7410 - val_loss: 0.5954\n","Epoch 62/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7498 - auc: 0.7443 - loss: 0.4907\n","Epoch 62: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7499 - auc: 0.7448 - loss: 0.4904 - val_acc: 0.6355 - val_auc: 0.7311 - val_loss: 0.6364\n","Epoch 63/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7723 - auc: 0.7681 - loss: 0.4670\n","Epoch 63: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7720 - auc: 0.7683 - loss: 0.4672 - val_acc: 0.6355 - val_auc: 0.6987 - val_loss: 0.6817\n","Epoch 64/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7704 - auc: 0.7466 - loss: 0.4898\n","Epoch 64: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7702 - auc: 0.7473 - loss: 0.4892 - val_acc: 0.6355 - val_auc: 0.7336 - val_loss: 0.6017\n","Epoch 65/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7495 - auc: 0.7748 - loss: 0.4943\n","Epoch 65: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7501 - auc: 0.7748 - loss: 0.4938 - val_acc: 0.6355 - val_auc: 0.7327 - val_loss: 0.6841\n","Epoch 66/100\n","\u001b[1m324/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7685 - auc: 0.7586 - loss: 0.4687\n","Epoch 66: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7684 - auc: 0.7586 - loss: 0.4687 - val_acc: 0.6449 - val_auc: 0.7364 - val_loss: 0.6088\n","Epoch 67/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7813 - auc: 0.8024 - loss: 0.4483\n","Epoch 67: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7807 - auc: 0.8018 - loss: 0.4491 - val_acc: 0.6636 - val_auc: 0.7426 - val_loss: 0.5663\n","Epoch 68/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7569 - auc: 0.7503 - loss: 0.5005\n","Epoch 68: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7573 - auc: 0.7509 - loss: 0.4997 - val_acc: 0.6355 - val_auc: 0.7440 - val_loss: 0.6088\n","Epoch 69/100\n","\u001b[1m314/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7400 - auc: 0.7664 - loss: 0.5130\n","Epoch 69: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7404 - auc: 0.7659 - loss: 0.5123 - val_acc: 0.6355 - val_auc: 0.7391 - val_loss: 0.6007\n","Epoch 70/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7493 - auc: 0.7719 - loss: 0.4893\n","Epoch 70: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7495 - auc: 0.7719 - loss: 0.4889 - val_acc: 0.6355 - val_auc: 0.7475 - val_loss: 0.6141\n","Epoch 71/100\n","\u001b[1m314/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7616 - auc: 0.7918 - loss: 0.4575\n","Epoch 71: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7620 - auc: 0.7917 - loss: 0.4575 - val_acc: 0.6729 - val_auc: 0.7170 - val_loss: 0.5905\n","Epoch 72/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7749 - auc: 0.7875 - loss: 0.4612\n","Epoch 72: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7748 - auc: 0.7874 - loss: 0.4613 - val_acc: 0.6355 - val_auc: 0.7396 - val_loss: 0.6486\n","Epoch 73/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7416 - auc: 0.7898 - loss: 0.4760\n","Epoch 73: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7423 - auc: 0.7897 - loss: 0.4755 - val_acc: 0.6355 - val_auc: 0.7302 - val_loss: 0.6114\n","Epoch 74/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7720 - auc: 0.8004 - loss: 0.4483\n","Epoch 74: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7719 - auc: 0.7999 - loss: 0.4488 - val_acc: 0.6449 - val_auc: 0.7509 - val_loss: 0.5980\n","Epoch 75/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7746 - auc: 0.7888 - loss: 0.4567\n","Epoch 75: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7745 - auc: 0.7887 - loss: 0.4569 - val_acc: 0.7103 - val_auc: 0.7583 - val_loss: 0.5616\n","Epoch 76/100\n","\u001b[1m322/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7634 - auc: 0.7605 - loss: 0.4749\n","Epoch 76: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7635 - auc: 0.7607 - loss: 0.4748 - val_acc: 0.6355 - val_auc: 0.7344 - val_loss: 0.6198\n","Epoch 77/100\n","\u001b[1m321/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7711 - auc: 0.7939 - loss: 0.4620\n","Epoch 77: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7710 - auc: 0.7937 - loss: 0.4621 - val_acc: 0.6449 - val_auc: 0.7496 - val_loss: 0.6163\n","Epoch 78/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7429 - auc: 0.7850 - loss: 0.4844\n","Epoch 78: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7437 - auc: 0.7851 - loss: 0.4838 - val_acc: 0.6355 - val_auc: 0.7023 - val_loss: 0.6710\n","Epoch 79/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7801 - auc: 0.8168 - loss: 0.4390\n","Epoch 79: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7796 - auc: 0.8158 - loss: 0.4397 - val_acc: 0.6449 - val_auc: 0.7381 - val_loss: 0.6160\n","Epoch 80/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7613 - auc: 0.7905 - loss: 0.4715\n","Epoch 80: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7617 - auc: 0.7903 - loss: 0.4713 - val_acc: 0.6355 - val_auc: 0.7508 - val_loss: 0.6107\n","Epoch 81/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7633 - auc: 0.8074 - loss: 0.4610\n","Epoch 81: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7634 - auc: 0.8066 - loss: 0.4612 - val_acc: 0.6355 - val_auc: 0.7306 - val_loss: 0.6671\n","Epoch 82/100\n","\u001b[1m323/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7354 - auc: 0.7687 - loss: 0.4936\n","Epoch 82: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7357 - auc: 0.7689 - loss: 0.4933 - val_acc: 0.6355 - val_auc: 0.7302 - val_loss: 0.6955\n","Epoch 83/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7646 - auc: 0.7857 - loss: 0.4570\n","Epoch 83: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7644 - auc: 0.7855 - loss: 0.4574 - val_acc: 0.6449 - val_auc: 0.7466 - val_loss: 0.6333\n","Epoch 84/100\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7607 - auc: 0.7869 - loss: 0.4614\n","Epoch 84: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7607 - auc: 0.7869 - loss: 0.4614 - val_acc: 0.6355 - val_auc: 0.7440 - val_loss: 0.6347\n","Epoch 85/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7842 - auc: 0.8004 - loss: 0.4316\n","Epoch 85: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7834 - auc: 0.8002 - loss: 0.4326 - val_acc: 0.6355 - val_auc: 0.7104 - val_loss: 0.6962\n","Epoch 86/100\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7665 - auc: 0.7849 - loss: 0.4684\n","Epoch 86: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7665 - auc: 0.7850 - loss: 0.4684 - val_acc: 0.6355 - val_auc: 0.7193 - val_loss: 0.7070\n","Epoch 87/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7624 - auc: 0.7868 - loss: 0.4585\n","Epoch 87: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7624 - auc: 0.7871 - loss: 0.4584 - val_acc: 0.6355 - val_auc: 0.7440 - val_loss: 0.6630\n","Epoch 88/100\n","\u001b[1m321/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7493 - auc: 0.7716 - loss: 0.4733\n","Epoch 88: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7495 - auc: 0.7718 - loss: 0.4732 - val_acc: 0.6355 - val_auc: 0.7457 - val_loss: 0.6157\n","Epoch 89/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7858 - auc: 0.7571 - loss: 0.4486\n","Epoch 89: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7853 - auc: 0.7580 - loss: 0.4490 - val_acc: 0.6542 - val_auc: 0.7455 - val_loss: 0.6143\n","Epoch 90/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7675 - auc: 0.7891 - loss: 0.4582\n","Epoch 90: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7675 - auc: 0.7890 - loss: 0.4582 - val_acc: 0.6355 - val_auc: 0.7364 - val_loss: 0.6602\n","Epoch 91/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7820 - auc: 0.7659 - loss: 0.4570\n","Epoch 91: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7818 - auc: 0.7663 - loss: 0.4573 - val_acc: 0.7103 - val_auc: 0.7498 - val_loss: 0.6184\n","Epoch 92/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7524 - auc: 0.7773 - loss: 0.4880\n","Epoch 92: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7529 - auc: 0.7781 - loss: 0.4870 - val_acc: 0.6355 - val_auc: 0.7046 - val_loss: 0.7910\n","Epoch 93/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7492 - auc: 0.7757 - loss: 0.4772\n","Epoch 93: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7494 - auc: 0.7758 - loss: 0.4769 - val_acc: 0.6542 - val_auc: 0.7477 - val_loss: 0.6278\n","Epoch 94/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7505 - auc: 0.8059 - loss: 0.4691\n","Epoch 94: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7506 - auc: 0.8059 - loss: 0.4690 - val_acc: 0.6355 - val_auc: 0.7221 - val_loss: 0.7279\n","Epoch 95/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7684 - auc: 0.7958 - loss: 0.4523\n","Epoch 95: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7682 - auc: 0.7952 - loss: 0.4526 - val_acc: 0.6355 - val_auc: 0.7385 - val_loss: 0.7042\n","Epoch 96/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7731 - auc: 0.7896 - loss: 0.4578\n","Epoch 96: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7732 - auc: 0.7901 - loss: 0.4575 - val_acc: 0.6729 - val_auc: 0.7462 - val_loss: 0.6189\n","Epoch 97/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7509 - auc: 0.7508 - loss: 0.4783\n","Epoch 97: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7513 - auc: 0.7518 - loss: 0.4778 - val_acc: 0.6355 - val_auc: 0.7368 - val_loss: 0.6480\n","Epoch 98/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7881 - auc: 0.8076 - loss: 0.4364\n","Epoch 98: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7876 - auc: 0.8074 - loss: 0.4369 - val_acc: 0.6355 - val_auc: 0.7345 - val_loss: 0.6919\n","Epoch 99/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7832 - auc: 0.7929 - loss: 0.4312\n","Epoch 99: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7827 - auc: 0.7929 - loss: 0.4320 - val_acc: 0.6822 - val_auc: 0.7359 - val_loss: 0.7324\n","Epoch 100/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7471 - auc: 0.7848 - loss: 0.4750\n","Epoch 100: val_loss did not improve from 0.54756\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7478 - auc: 0.7850 - loss: 0.4744 - val_acc: 0.6355 - val_auc: 0.7300 - val_loss: 0.7360\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 6 | TEST ACC=0.4609 | TEST AUC=0.8930 | n=115\n","Confusion matrix:\n"," [[37  1]\n"," [61 16]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.378     0.974     0.544        38\n","           1      0.941     0.208     0.340        77\n","\n","    accuracy                          0.461       115\n","   macro avg      0.659     0.591     0.442       115\n","weighted avg      0.755     0.461     0.408       115\n","\n","\n","--- Fold 7/14 ---\n"," train | ids:   36 | files:  1016 | pos files:  394 | neg files:  622\n","   val | ids:    5 | files:   167 | pos files:   10 | neg files:  157\n","  test | ids:    3 | files:    17 | pos files:    1 | neg files:   16\n","Epoch 1/100\n","\u001b[1m327/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - acc: 0.5942 - auc: 0.5198 - loss: 0.6828\n","Epoch 1: val_loss improved from inf to 0.54498, saving model to best_fold_07.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - acc: 0.5950 - auc: 0.5196 - loss: 0.6826 - val_acc: 0.9401 - val_auc: 0.0099 - val_loss: 0.5450\n","Epoch 2/100\n","\u001b[1m329/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6110 - auc: 0.5509 - loss: 0.6653\n","Epoch 2: val_loss improved from 0.54498 to 0.52524, saving model to best_fold_07.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6111 - auc: 0.5513 - loss: 0.6653 - val_acc: 0.9401 - val_auc: 0.0268 - val_loss: 0.5252\n","Epoch 3/100\n","\u001b[1m332/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5984 - auc: 0.6128 - loss: 0.6657\n","Epoch 3: val_loss improved from 0.52524 to 0.51626, saving model to best_fold_07.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.5987 - auc: 0.6120 - loss: 0.6656 - val_acc: 0.9401 - val_auc: 0.0465 - val_loss: 0.5163\n","Epoch 4/100\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6291 - auc: 0.5922 - loss: 0.6504\n","Epoch 4: val_loss did not improve from 0.51626\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6291 - auc: 0.5922 - loss: 0.6504 - val_acc: 0.9401 - val_auc: 0.1035 - val_loss: 0.5522\n","Epoch 5/100\n","\u001b[1m328/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6023 - auc: 0.6473 - loss: 0.6565\n","Epoch 5: val_loss did not improve from 0.51626\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6027 - auc: 0.6465 - loss: 0.6564 - val_acc: 0.9401 - val_auc: 0.1920 - val_loss: 0.5341\n","Epoch 6/100\n","\u001b[1m330/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6124 - auc: 0.6376 - loss: 0.6454\n","Epoch 6: val_loss did not improve from 0.51626\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6124 - auc: 0.6378 - loss: 0.6453 - val_acc: 0.9401 - val_auc: 0.2525 - val_loss: 0.5323\n","Epoch 7/100\n","\u001b[1m326/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6297 - auc: 0.6415 - loss: 0.6311\n","Epoch 7: val_loss improved from 0.51626 to 0.49407, saving model to best_fold_07.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6293 - auc: 0.6422 - loss: 0.6311 - val_acc: 0.9401 - val_auc: 0.2815 - val_loss: 0.4941\n","Epoch 8/100\n","\u001b[1m333/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6407 - auc: 0.6789 - loss: 0.6170\n","Epoch 8: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6405 - auc: 0.6787 - loss: 0.6169 - val_acc: 0.8563 - val_auc: 0.3013 - val_loss: 0.5181\n","Epoch 9/100\n","\u001b[1m331/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6430 - auc: 0.6650 - loss: 0.6088\n","Epoch 9: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6427 - auc: 0.6655 - loss: 0.6086 - val_acc: 0.7545 - val_auc: 0.3118 - val_loss: 0.5459\n","Epoch 10/100\n","\u001b[1m332/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6070 - auc: 0.6737 - loss: 0.5983\n","Epoch 10: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6071 - auc: 0.6739 - loss: 0.5982 - val_acc: 0.7006 - val_auc: 0.3226 - val_loss: 0.5583\n","Epoch 11/100\n","\u001b[1m335/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6423 - auc: 0.7043 - loss: 0.5808\n","Epoch 11: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6419 - auc: 0.7040 - loss: 0.5809 - val_acc: 0.7006 - val_auc: 0.3287 - val_loss: 0.5547\n","Epoch 12/100\n","\u001b[1m330/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6247 - auc: 0.6978 - loss: 0.5826\n","Epoch 12: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6244 - auc: 0.6976 - loss: 0.5825 - val_acc: 0.7605 - val_auc: 0.3242 - val_loss: 0.5192\n","Epoch 13/100\n","\u001b[1m332/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6029 - auc: 0.6749 - loss: 0.5822\n","Epoch 13: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6031 - auc: 0.6751 - loss: 0.5821 - val_acc: 0.7964 - val_auc: 0.3338 - val_loss: 0.5157\n","Epoch 14/100\n","\u001b[1m333/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6413 - auc: 0.7186 - loss: 0.5693\n","Epoch 14: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6405 - auc: 0.7180 - loss: 0.5695 - val_acc: 0.6527 - val_auc: 0.3424 - val_loss: 0.5530\n","Epoch 15/100\n","\u001b[1m328/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6280 - auc: 0.6949 - loss: 0.5614\n","Epoch 15: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6280 - auc: 0.6950 - loss: 0.5617 - val_acc: 0.6048 - val_auc: 0.3475 - val_loss: 0.5689\n","Epoch 16/100\n","\u001b[1m329/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6449 - auc: 0.7182 - loss: 0.5630\n","Epoch 16: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6443 - auc: 0.7174 - loss: 0.5632 - val_acc: 0.7545 - val_auc: 0.3455 - val_loss: 0.5252\n","Epoch 17/100\n","\u001b[1m332/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6331 - auc: 0.6786 - loss: 0.5767\n","Epoch 17: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6331 - auc: 0.6787 - loss: 0.5766 - val_acc: 0.7126 - val_auc: 0.3455 - val_loss: 0.5342\n","Epoch 18/100\n","\u001b[1m334/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5981 - auc: 0.6692 - loss: 0.5844\n","Epoch 18: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5984 - auc: 0.6695 - loss: 0.5842 - val_acc: 0.7784 - val_auc: 0.3529 - val_loss: 0.5304\n","Epoch 19/100\n","\u001b[1m333/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6244 - auc: 0.7087 - loss: 0.5740\n","Epoch 19: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6241 - auc: 0.7085 - loss: 0.5739 - val_acc: 0.8743 - val_auc: 0.3548 - val_loss: 0.5261\n","Epoch 20/100\n","\u001b[1m330/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6316 - auc: 0.6770 - loss: 0.5822\n","Epoch 20: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6315 - auc: 0.6775 - loss: 0.5819 - val_acc: 0.8084 - val_auc: 0.3618 - val_loss: 0.5370\n","Epoch 21/100\n","\u001b[1m329/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6195 - auc: 0.6958 - loss: 0.5616\n","Epoch 21: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6195 - auc: 0.6958 - loss: 0.5618 - val_acc: 0.8024 - val_auc: 0.3672 - val_loss: 0.5403\n","Epoch 22/100\n","\u001b[1m336/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6229 - auc: 0.6790 - loss: 0.5631\n","Epoch 22: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6230 - auc: 0.6791 - loss: 0.5631 - val_acc: 0.7964 - val_auc: 0.3748 - val_loss: 0.5414\n","Epoch 23/100\n","\u001b[1m335/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6312 - auc: 0.7055 - loss: 0.5399\n","Epoch 23: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6312 - auc: 0.7054 - loss: 0.5403 - val_acc: 0.7605 - val_auc: 0.3901 - val_loss: 0.5462\n","Epoch 24/100\n","\u001b[1m328/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6477 - auc: 0.7396 - loss: 0.5330\n","Epoch 24: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6466 - auc: 0.7381 - loss: 0.5340 - val_acc: 0.8263 - val_auc: 0.3952 - val_loss: 0.5361\n","Epoch 25/100\n","\u001b[1m334/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6327 - auc: 0.7238 - loss: 0.5593\n","Epoch 25: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6326 - auc: 0.7235 - loss: 0.5593 - val_acc: 0.8743 - val_auc: 0.4414 - val_loss: 0.5675\n","Epoch 26/100\n","\u001b[1m329/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6197 - auc: 0.6956 - loss: 0.5744\n","Epoch 26: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6198 - auc: 0.6958 - loss: 0.5741 - val_acc: 0.7605 - val_auc: 0.4032 - val_loss: 0.5361\n","Epoch 27/100\n","\u001b[1m335/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6449 - auc: 0.7186 - loss: 0.5585\n","Epoch 27: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6447 - auc: 0.7184 - loss: 0.5586 - val_acc: 0.8263 - val_auc: 0.4258 - val_loss: 0.5316\n","Epoch 28/100\n","\u001b[1m332/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6093 - auc: 0.6944 - loss: 0.5728\n","Epoch 28: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6095 - auc: 0.6945 - loss: 0.5726 - val_acc: 0.8024 - val_auc: 0.4006 - val_loss: 0.5336\n","Epoch 29/100\n","\u001b[1m333/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6285 - auc: 0.7005 - loss: 0.5625\n","Epoch 29: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6283 - auc: 0.7005 - loss: 0.5625 - val_acc: 0.8563 - val_auc: 0.4153 - val_loss: 0.5190\n","Epoch 30/100\n","\u001b[1m329/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6084 - auc: 0.6949 - loss: 0.5584\n","Epoch 30: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6084 - auc: 0.6949 - loss: 0.5586 - val_acc: 0.8263 - val_auc: 0.4201 - val_loss: 0.5201\n","Epoch 31/100\n","\u001b[1m335/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6311 - auc: 0.7009 - loss: 0.5503\n","Epoch 31: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6310 - auc: 0.7009 - loss: 0.5504 - val_acc: 0.8683 - val_auc: 0.4484 - val_loss: 0.5427\n","Epoch 32/100\n","\u001b[1m334/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6039 - auc: 0.6967 - loss: 0.5630\n","Epoch 32: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6041 - auc: 0.6968 - loss: 0.5629 - val_acc: 0.8144 - val_auc: 0.4309 - val_loss: 0.5268\n","Epoch 33/100\n","\u001b[1m331/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6764 - auc: 0.7528 - loss: 0.5371\n","Epoch 33: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6751 - auc: 0.7515 - loss: 0.5377 - val_acc: 0.8743 - val_auc: 0.4245 - val_loss: 0.5233\n","Epoch 34/100\n","\u001b[1m336/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6449 - auc: 0.7186 - loss: 0.5498\n","Epoch 34: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6448 - auc: 0.7185 - loss: 0.5499 - val_acc: 0.8204 - val_auc: 0.4194 - val_loss: 0.5216\n","Epoch 35/100\n","\u001b[1m334/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6308 - auc: 0.7043 - loss: 0.5572\n","Epoch 35: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6308 - auc: 0.7043 - loss: 0.5572 - val_acc: 0.8743 - val_auc: 0.4080 - val_loss: 0.5314\n","Epoch 36/100\n","\u001b[1m337/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6120 - auc: 0.6681 - loss: 0.5806\n","Epoch 36: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6121 - auc: 0.6684 - loss: 0.5804 - val_acc: 0.8204 - val_auc: 0.4334 - val_loss: 0.5425\n","Epoch 37/100\n","\u001b[1m331/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6212 - auc: 0.7026 - loss: 0.5664\n","Epoch 37: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6216 - auc: 0.7028 - loss: 0.5663 - val_acc: 0.8862 - val_auc: 0.4105 - val_loss: 0.5071\n","Epoch 38/100\n","\u001b[1m326/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6177 - auc: 0.6994 - loss: 0.5492\n","Epoch 38: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6182 - auc: 0.6994 - loss: 0.5496 - val_acc: 0.8743 - val_auc: 0.4357 - val_loss: 0.5145\n","Epoch 39/100\n","\u001b[1m336/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6575 - auc: 0.7279 - loss: 0.5507\n","Epoch 39: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6574 - auc: 0.7276 - loss: 0.5508 - val_acc: 0.8204 - val_auc: 0.4264 - val_loss: 0.5345\n","Epoch 40/100\n","\u001b[1m334/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6119 - auc: 0.6984 - loss: 0.5672\n","Epoch 40: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6121 - auc: 0.6985 - loss: 0.5670 - val_acc: 0.8862 - val_auc: 0.4347 - val_loss: 0.5318\n","Epoch 41/100\n","\u001b[1m333/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6699 - auc: 0.6961 - loss: 0.5509\n","Epoch 41: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6694 - auc: 0.6965 - loss: 0.5511 - val_acc: 0.7665 - val_auc: 0.4382 - val_loss: 0.5187\n","Epoch 42/100\n","\u001b[1m337/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6178 - auc: 0.6966 - loss: 0.5552\n","Epoch 42: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6178 - auc: 0.6967 - loss: 0.5552 - val_acc: 0.8263 - val_auc: 0.4201 - val_loss: 0.5169\n","Epoch 43/100\n","\u001b[1m329/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6188 - auc: 0.6959 - loss: 0.5517\n","Epoch 43: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6190 - auc: 0.6960 - loss: 0.5518 - val_acc: 0.8204 - val_auc: 0.4427 - val_loss: 0.5292\n","Epoch 44/100\n","\u001b[1m325/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6273 - auc: 0.6865 - loss: 0.5597\n","Epoch 44: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6279 - auc: 0.6873 - loss: 0.5595 - val_acc: 0.8802 - val_auc: 0.4363 - val_loss: 0.5174\n","Epoch 45/100\n","\u001b[1m335/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6559 - auc: 0.6925 - loss: 0.5655\n","Epoch 45: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6556 - auc: 0.6927 - loss: 0.5653 - val_acc: 0.8263 - val_auc: 0.4328 - val_loss: 0.5210\n","Epoch 46/100\n","\u001b[1m331/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6353 - auc: 0.7236 - loss: 0.5401\n","Epoch 46: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6349 - auc: 0.7231 - loss: 0.5403 - val_acc: 0.8443 - val_auc: 0.4452 - val_loss: 0.5124\n","Epoch 47/100\n","\u001b[1m332/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6371 - auc: 0.7184 - loss: 0.5392\n","Epoch 47: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6367 - auc: 0.7182 - loss: 0.5395 - val_acc: 0.8683 - val_auc: 0.4554 - val_loss: 0.5170\n","Epoch 48/100\n","\u001b[1m332/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6504 - auc: 0.7092 - loss: 0.5486\n","Epoch 48: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6503 - auc: 0.7094 - loss: 0.5487 - val_acc: 0.8263 - val_auc: 0.4490 - val_loss: 0.5159\n","Epoch 49/100\n","\u001b[1m332/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6079 - auc: 0.6937 - loss: 0.5553\n","Epoch 49: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6082 - auc: 0.6940 - loss: 0.5552 - val_acc: 0.8263 - val_auc: 0.4430 - val_loss: 0.5138\n","Epoch 50/100\n","\u001b[1m329/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6124 - auc: 0.7087 - loss: 0.5447\n","Epoch 50: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6129 - auc: 0.7086 - loss: 0.5450 - val_acc: 0.8922 - val_auc: 0.4481 - val_loss: 0.5190\n","Epoch 51/100\n","\u001b[1m327/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6247 - auc: 0.7122 - loss: 0.5623\n","Epoch 51: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6246 - auc: 0.7119 - loss: 0.5619 - val_acc: 0.8263 - val_auc: 0.4529 - val_loss: 0.5193\n","Epoch 52/100\n","\u001b[1m336/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6277 - auc: 0.7120 - loss: 0.5504\n","Epoch 52: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6277 - auc: 0.7119 - loss: 0.5504 - val_acc: 0.8503 - val_auc: 0.4561 - val_loss: 0.5197\n","Epoch 53/100\n","\u001b[1m333/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6377 - auc: 0.7169 - loss: 0.5506\n","Epoch 53: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6377 - auc: 0.7169 - loss: 0.5505 - val_acc: 0.8862 - val_auc: 0.4334 - val_loss: 0.5025\n","Epoch 54/100\n","\u001b[1m338/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6516 - auc: 0.6902 - loss: 0.5456\n","Epoch 54: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6516 - auc: 0.6904 - loss: 0.5456 - val_acc: 0.8743 - val_auc: 0.4325 - val_loss: 0.5070\n","Epoch 55/100\n","\u001b[1m327/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6233 - auc: 0.6894 - loss: 0.5622\n","Epoch 55: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6233 - auc: 0.6898 - loss: 0.5618 - val_acc: 0.8862 - val_auc: 0.4503 - val_loss: 0.5212\n","Epoch 56/100\n","\u001b[1m331/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6734 - auc: 0.7384 - loss: 0.5183\n","Epoch 56: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6724 - auc: 0.7375 - loss: 0.5190 - val_acc: 0.9162 - val_auc: 0.4357 - val_loss: 0.5261\n","Epoch 57/100\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6320 - auc: 0.7287 - loss: 0.5397\n","Epoch 57: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6321 - auc: 0.7287 - loss: 0.5397 - val_acc: 0.8862 - val_auc: 0.4487 - val_loss: 0.5095\n","Epoch 58/100\n","\u001b[1m326/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6290 - auc: 0.7127 - loss: 0.5412\n","Epoch 58: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6289 - auc: 0.7126 - loss: 0.5414 - val_acc: 0.8922 - val_auc: 0.4513 - val_loss: 0.5276\n","Epoch 59/100\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6432 - auc: 0.7134 - loss: 0.5410\n","Epoch 59: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6432 - auc: 0.7134 - loss: 0.5411 - val_acc: 0.8922 - val_auc: 0.4487 - val_loss: 0.5104\n","Epoch 60/100\n","\u001b[1m330/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6240 - auc: 0.7286 - loss: 0.5408\n","Epoch 60: val_loss did not improve from 0.49407\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6244 - auc: 0.7281 - loss: 0.5409 - val_acc: 0.8922 - val_auc: 0.4561 - val_loss: 0.5070\n","Epoch 61/100\n","\u001b[1m327/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6414 - auc: 0.7485 - loss: 0.5223\n","Epoch 61: val_loss improved from 0.49407 to 0.49400, saving model to best_fold_07.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6409 - auc: 0.7469 - loss: 0.5231 - val_acc: 0.8922 - val_auc: 0.4500 - val_loss: 0.4940\n","Epoch 62/100\n","\u001b[1m330/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6300 - auc: 0.7020 - loss: 0.5537\n","Epoch 62: val_loss did not improve from 0.49400\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6307 - auc: 0.7024 - loss: 0.5534 - val_acc: 0.8922 - val_auc: 0.4443 - val_loss: 0.5139\n","Epoch 63/100\n","\u001b[1m327/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6164 - auc: 0.6934 - loss: 0.5508\n","Epoch 63: val_loss did not improve from 0.49400\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6168 - auc: 0.6939 - loss: 0.5505 - val_acc: 0.8922 - val_auc: 0.4417 - val_loss: 0.5241\n","Epoch 64/100\n","\u001b[1m332/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6557 - auc: 0.7332 - loss: 0.5227\n","Epoch 64: val_loss improved from 0.49400 to 0.49277, saving model to best_fold_07.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6555 - auc: 0.7325 - loss: 0.5231 - val_acc: 0.9102 - val_auc: 0.4519 - val_loss: 0.4928\n","Epoch 65/100\n","\u001b[1m326/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6309 - auc: 0.7152 - loss: 0.5394\n","Epoch 65: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6315 - auc: 0.7154 - loss: 0.5395 - val_acc: 0.9162 - val_auc: 0.4433 - val_loss: 0.4992\n","Epoch 66/100\n","\u001b[1m338/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6418 - auc: 0.7182 - loss: 0.5416\n","Epoch 66: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6418 - auc: 0.7182 - loss: 0.5415 - val_acc: 0.8802 - val_auc: 0.4662 - val_loss: 0.5311\n","Epoch 67/100\n","\u001b[1m326/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6583 - auc: 0.7252 - loss: 0.5523\n","Epoch 67: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6581 - auc: 0.7252 - loss: 0.5519 - val_acc: 0.8802 - val_auc: 0.4634 - val_loss: 0.5078\n","Epoch 68/100\n","\u001b[1m337/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6660 - auc: 0.7438 - loss: 0.5260\n","Epoch 68: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6659 - auc: 0.7435 - loss: 0.5261 - val_acc: 0.8922 - val_auc: 0.4494 - val_loss: 0.5035\n","Epoch 69/100\n","\u001b[1m332/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6589 - auc: 0.7454 - loss: 0.5308\n","Epoch 69: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6587 - auc: 0.7449 - loss: 0.5310 - val_acc: 0.9162 - val_auc: 0.4513 - val_loss: 0.5300\n","Epoch 70/100\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6465 - auc: 0.7204 - loss: 0.5415\n","Epoch 70: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6465 - auc: 0.7204 - loss: 0.5415 - val_acc: 0.9102 - val_auc: 0.4567 - val_loss: 0.5519\n","Epoch 71/100\n","\u001b[1m334/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6547 - auc: 0.7213 - loss: 0.5403\n","Epoch 71: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6547 - auc: 0.7216 - loss: 0.5402 - val_acc: 0.8982 - val_auc: 0.4694 - val_loss: 0.5487\n","Epoch 72/100\n","\u001b[1m330/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6308 - auc: 0.7254 - loss: 0.5335\n","Epoch 72: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6311 - auc: 0.7254 - loss: 0.5336 - val_acc: 0.9162 - val_auc: 0.4455 - val_loss: 0.5175\n","Epoch 73/100\n","\u001b[1m335/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6399 - auc: 0.7152 - loss: 0.5475\n","Epoch 73: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6402 - auc: 0.7155 - loss: 0.5474 - val_acc: 0.9222 - val_auc: 0.4487 - val_loss: 0.5300\n","Epoch 74/100\n","\u001b[1m332/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6361 - auc: 0.7094 - loss: 0.5537\n","Epoch 74: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6363 - auc: 0.7099 - loss: 0.5533 - val_acc: 0.9162 - val_auc: 0.4478 - val_loss: 0.5260\n","Epoch 75/100\n","\u001b[1m331/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6561 - auc: 0.7389 - loss: 0.5350\n","Epoch 75: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6561 - auc: 0.7393 - loss: 0.5350 - val_acc: 0.8862 - val_auc: 0.5013 - val_loss: 0.5288\n","Epoch 76/100\n","\u001b[1m338/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6325 - auc: 0.6793 - loss: 0.5557\n","Epoch 76: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6326 - auc: 0.6796 - loss: 0.5556 - val_acc: 0.9401 - val_auc: 0.4570 - val_loss: 0.5339\n","Epoch 77/100\n","\u001b[1m332/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6805 - auc: 0.7537 - loss: 0.5275\n","Epoch 77: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6802 - auc: 0.7534 - loss: 0.5277 - val_acc: 0.8982 - val_auc: 0.5248 - val_loss: 0.5138\n","Epoch 78/100\n","\u001b[1m336/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6834 - auc: 0.7667 - loss: 0.5281\n","Epoch 78: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6831 - auc: 0.7665 - loss: 0.5281 - val_acc: 0.9281 - val_auc: 0.5083 - val_loss: 0.5354\n","Epoch 79/100\n","\u001b[1m334/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6646 - auc: 0.7584 - loss: 0.5216\n","Epoch 79: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6647 - auc: 0.7582 - loss: 0.5218 - val_acc: 0.9102 - val_auc: 0.5334 - val_loss: 0.5196\n","Epoch 80/100\n","\u001b[1m334/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6492 - auc: 0.7461 - loss: 0.5357\n","Epoch 80: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6498 - auc: 0.7462 - loss: 0.5356 - val_acc: 0.8862 - val_auc: 0.5436 - val_loss: 0.5051\n","Epoch 81/100\n","\u001b[1m332/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6746 - auc: 0.7329 - loss: 0.5371\n","Epoch 81: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6747 - auc: 0.7333 - loss: 0.5369 - val_acc: 0.9162 - val_auc: 0.5290 - val_loss: 0.5450\n","Epoch 82/100\n","\u001b[1m331/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6943 - auc: 0.7514 - loss: 0.5360\n","Epoch 82: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6942 - auc: 0.7516 - loss: 0.5358 - val_acc: 0.5808 - val_auc: 0.4831 - val_loss: 0.6283\n","Epoch 83/100\n","\u001b[1m334/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6745 - auc: 0.7392 - loss: 0.5488\n","Epoch 83: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6744 - auc: 0.7394 - loss: 0.5485 - val_acc: 0.8802 - val_auc: 0.5070 - val_loss: 0.5677\n","Epoch 84/100\n","\u001b[1m337/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7044 - auc: 0.7671 - loss: 0.5085\n","Epoch 84: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7041 - auc: 0.7670 - loss: 0.5087 - val_acc: 0.8503 - val_auc: 0.5357 - val_loss: 0.5402\n","Epoch 85/100\n","\u001b[1m334/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6933 - auc: 0.7824 - loss: 0.5068\n","Epoch 85: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6933 - auc: 0.7822 - loss: 0.5071 - val_acc: 0.6168 - val_auc: 0.5697 - val_loss: 0.5629\n","Epoch 86/100\n","\u001b[1m334/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6823 - auc: 0.7782 - loss: 0.5140\n","Epoch 86: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6824 - auc: 0.7780 - loss: 0.5142 - val_acc: 0.6826 - val_auc: 0.5255 - val_loss: 0.5850\n","Epoch 87/100\n","\u001b[1m332/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6942 - auc: 0.7653 - loss: 0.5183\n","Epoch 87: val_loss did not improve from 0.49277\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6940 - auc: 0.7652 - loss: 0.5184 - val_acc: 0.8383 - val_auc: 0.5452 - val_loss: 0.5309\n","Epoch 88/100\n","\u001b[1m332/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6727 - auc: 0.7647 - loss: 0.5214\n","Epoch 88: val_loss improved from 0.49277 to 0.45537, saving model to best_fold_07.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6729 - auc: 0.7648 - loss: 0.5215 - val_acc: 0.9281 - val_auc: 0.4997 - val_loss: 0.4554\n","Epoch 89/100\n","\u001b[1m338/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6814 - auc: 0.7446 - loss: 0.5364\n","Epoch 89: val_loss did not improve from 0.45537\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6814 - auc: 0.7447 - loss: 0.5363 - val_acc: 0.7126 - val_auc: 0.5424 - val_loss: 0.5558\n","Epoch 90/100\n","\u001b[1m331/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6813 - auc: 0.7625 - loss: 0.5209\n","Epoch 90: val_loss did not improve from 0.45537\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6812 - auc: 0.7626 - loss: 0.5209 - val_acc: 0.8862 - val_auc: 0.5172 - val_loss: 0.4761\n","Epoch 91/100\n","\u001b[1m334/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6665 - auc: 0.7480 - loss: 0.5361\n","Epoch 91: val_loss did not improve from 0.45537\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6667 - auc: 0.7483 - loss: 0.5360 - val_acc: 0.8862 - val_auc: 0.5261 - val_loss: 0.5279\n","Epoch 92/100\n","\u001b[1m329/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7260 - auc: 0.7899 - loss: 0.4990\n","Epoch 92: val_loss did not improve from 0.45537\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7251 - auc: 0.7892 - loss: 0.4998 - val_acc: 0.9162 - val_auc: 0.5220 - val_loss: 0.4907\n","Epoch 93/100\n","\u001b[1m338/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6825 - auc: 0.7768 - loss: 0.5171\n","Epoch 93: val_loss did not improve from 0.45537\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6825 - auc: 0.7768 - loss: 0.5171 - val_acc: 0.8922 - val_auc: 0.5258 - val_loss: 0.5050\n","Epoch 94/100\n","\u001b[1m329/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6921 - auc: 0.7583 - loss: 0.5188\n","Epoch 94: val_loss did not improve from 0.45537\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6919 - auc: 0.7584 - loss: 0.5189 - val_acc: 0.8443 - val_auc: 0.5404 - val_loss: 0.5242\n","Epoch 95/100\n","\u001b[1m338/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6893 - auc: 0.7689 - loss: 0.5202\n","Epoch 95: val_loss did not improve from 0.45537\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6893 - auc: 0.7688 - loss: 0.5202 - val_acc: 0.8743 - val_auc: 0.5389 - val_loss: 0.5055\n","Epoch 96/100\n","\u001b[1m333/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7081 - auc: 0.7883 - loss: 0.5066\n","Epoch 96: val_loss did not improve from 0.45537\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7077 - auc: 0.7879 - loss: 0.5068 - val_acc: 0.9281 - val_auc: 0.5159 - val_loss: 0.4851\n","Epoch 97/100\n","\u001b[1m335/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6890 - auc: 0.7654 - loss: 0.5303\n","Epoch 97: val_loss did not improve from 0.45537\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6892 - auc: 0.7655 - loss: 0.5302 - val_acc: 0.9222 - val_auc: 0.5175 - val_loss: 0.5046\n","Epoch 98/100\n","\u001b[1m332/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7053 - auc: 0.7814 - loss: 0.5027\n","Epoch 98: val_loss did not improve from 0.45537\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7051 - auc: 0.7811 - loss: 0.5030 - val_acc: 0.7246 - val_auc: 0.5379 - val_loss: 0.5682\n","Epoch 99/100\n","\u001b[1m331/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7029 - auc: 0.7878 - loss: 0.5077\n","Epoch 99: val_loss did not improve from 0.45537\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7026 - auc: 0.7872 - loss: 0.5080 - val_acc: 0.8922 - val_auc: 0.5226 - val_loss: 0.5164\n","Epoch 100/100\n","\u001b[1m331/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6563 - auc: 0.7503 - loss: 0.5357\n","Epoch 100: val_loss did not improve from 0.45537\n","\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6568 - auc: 0.7509 - loss: 0.5351 - val_acc: 0.9162 - val_auc: 0.5140 - val_loss: 0.4866\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 7 | TEST ACC=0.9412 | TEST AUC=0.7500 | n=17\n","Confusion matrix:\n"," [[16  0]\n"," [ 1  0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.941     1.000     0.970        16\n","           1      0.000     0.000     0.000         1\n","\n","    accuracy                          0.941        17\n","   macro avg      0.471     0.500     0.485        17\n","weighted avg      0.886     0.941     0.913        17\n","\n","\n","--- Fold 8/14 ---\n"," train | ids:   36 | files:   994 | pos files:  366 | neg files:  628\n","   val | ids:    5 | files:   153 | pos files:   10 | neg files:  143\n","  test | ids:    3 | files:    53 | pos files:   29 | neg files:   24\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.6413 - auc: 0.4665 - loss: 0.6854\n","Epoch 1: val_loss improved from inf to 0.56604, saving model to best_fold_08.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - acc: 0.6410 - auc: 0.4679 - loss: 0.6851 - val_acc: 0.9346 - val_auc: 0.0122 - val_loss: 0.5660\n","Epoch 2/100\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6252 - auc: 0.5639 - loss: 0.6591\n","Epoch 2: val_loss improved from 0.56604 to 0.53357, saving model to best_fold_08.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6252 - auc: 0.5638 - loss: 0.6591 - val_acc: 0.9346 - val_auc: 0.0157 - val_loss: 0.5336\n","Epoch 3/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6385 - auc: 0.6087 - loss: 0.6469\n","Epoch 3: val_loss improved from 0.53357 to 0.49792, saving model to best_fold_08.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6384 - auc: 0.6086 - loss: 0.6470 - val_acc: 0.9346 - val_auc: 0.0189 - val_loss: 0.4979\n","Epoch 4/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6472 - auc: 0.5829 - loss: 0.6403\n","Epoch 4: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6468 - auc: 0.5839 - loss: 0.6404 - val_acc: 0.9346 - val_auc: 0.0829 - val_loss: 0.5106\n","Epoch 5/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6430 - auc: 0.6592 - loss: 0.6247\n","Epoch 5: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6428 - auc: 0.6592 - loss: 0.6249 - val_acc: 0.9346 - val_auc: 0.1703 - val_loss: 0.5393\n","Epoch 6/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6535 - auc: 0.6629 - loss: 0.6149\n","Epoch 6: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6534 - auc: 0.6630 - loss: 0.6150 - val_acc: 0.8824 - val_auc: 0.2245 - val_loss: 0.5745\n","Epoch 7/100\n","\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6659 - auc: 0.6898 - loss: 0.6010\n","Epoch 7: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6652 - auc: 0.6897 - loss: 0.6009 - val_acc: 0.5817 - val_auc: 0.2448 - val_loss: 0.6482\n","Epoch 8/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6097 - auc: 0.6762 - loss: 0.5911\n","Epoch 8: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6100 - auc: 0.6765 - loss: 0.5910 - val_acc: 0.6078 - val_auc: 0.2528 - val_loss: 0.6242\n","Epoch 9/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6145 - auc: 0.6814 - loss: 0.5820\n","Epoch 9: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6152 - auc: 0.6824 - loss: 0.5816 - val_acc: 0.7386 - val_auc: 0.2566 - val_loss: 0.5452\n","Epoch 10/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6185 - auc: 0.6927 - loss: 0.5628\n","Epoch 10: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6184 - auc: 0.6927 - loss: 0.5629 - val_acc: 0.6797 - val_auc: 0.2517 - val_loss: 0.6036\n","Epoch 11/100\n","\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6399 - auc: 0.6834 - loss: 0.5549\n","Epoch 11: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6394 - auc: 0.6837 - loss: 0.5551 - val_acc: 0.6078 - val_auc: 0.2545 - val_loss: 0.6109\n","Epoch 12/100\n","\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6206 - auc: 0.7077 - loss: 0.5530\n","Epoch 12: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6202 - auc: 0.7072 - loss: 0.5530 - val_acc: 0.4771 - val_auc: 0.2608 - val_loss: 0.6414\n","Epoch 13/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6005 - auc: 0.6798 - loss: 0.5529\n","Epoch 13: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6008 - auc: 0.6801 - loss: 0.5528 - val_acc: 0.5425 - val_auc: 0.2626 - val_loss: 0.6318\n","Epoch 14/100\n","\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6053 - auc: 0.6685 - loss: 0.5554\n","Epoch 14: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6058 - auc: 0.6695 - loss: 0.5550 - val_acc: 0.5621 - val_auc: 0.2643 - val_loss: 0.6365\n","Epoch 15/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6152 - auc: 0.7008 - loss: 0.5328\n","Epoch 15: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6151 - auc: 0.7009 - loss: 0.5331 - val_acc: 0.4248 - val_auc: 0.2972 - val_loss: 0.7036\n","Epoch 16/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6509 - auc: 0.7424 - loss: 0.5279\n","Epoch 16: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6505 - auc: 0.7420 - loss: 0.5281 - val_acc: 0.6013 - val_auc: 0.2675 - val_loss: 0.6528\n","Epoch 17/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5953 - auc: 0.6870 - loss: 0.5699\n","Epoch 17: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5956 - auc: 0.6873 - loss: 0.5696 - val_acc: 0.7386 - val_auc: 0.2850 - val_loss: 0.6368\n","Epoch 18/100\n","\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6171 - auc: 0.6914 - loss: 0.5506\n","Epoch 18: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6172 - auc: 0.6917 - loss: 0.5505 - val_acc: 0.6536 - val_auc: 0.2780 - val_loss: 0.6556\n","Epoch 19/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5848 - auc: 0.6787 - loss: 0.5622\n","Epoch 19: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5855 - auc: 0.6793 - loss: 0.5617 - val_acc: 0.6078 - val_auc: 0.2948 - val_loss: 0.6799\n","Epoch 20/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6196 - auc: 0.6957 - loss: 0.5553\n","Epoch 20: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6197 - auc: 0.6959 - loss: 0.5551 - val_acc: 0.6601 - val_auc: 0.3045 - val_loss: 0.6694\n","Epoch 21/100\n","\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6050 - auc: 0.6633 - loss: 0.5539\n","Epoch 21: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6061 - auc: 0.6648 - loss: 0.5535 - val_acc: 0.7843 - val_auc: 0.3213 - val_loss: 0.6476\n","Epoch 22/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6233 - auc: 0.7044 - loss: 0.5420\n","Epoch 22: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6236 - auc: 0.7044 - loss: 0.5421 - val_acc: 0.7190 - val_auc: 0.3017 - val_loss: 0.6365\n","Epoch 23/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6181 - auc: 0.6907 - loss: 0.5574\n","Epoch 23: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6183 - auc: 0.6912 - loss: 0.5571 - val_acc: 0.7843 - val_auc: 0.3150 - val_loss: 0.6465\n","Epoch 24/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6375 - auc: 0.7110 - loss: 0.5319\n","Epoch 24: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6372 - auc: 0.7109 - loss: 0.5322 - val_acc: 0.7190 - val_auc: 0.3059 - val_loss: 0.6425\n","Epoch 25/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6076 - auc: 0.7199 - loss: 0.5283\n","Epoch 25: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6077 - auc: 0.7198 - loss: 0.5284 - val_acc: 0.8105 - val_auc: 0.3402 - val_loss: 0.6462\n","Epoch 26/100\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6198 - auc: 0.7125 - loss: 0.5236\n","Epoch 26: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6198 - auc: 0.7124 - loss: 0.5237 - val_acc: 0.7908 - val_auc: 0.3497 - val_loss: 0.6574\n","Epoch 27/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6382 - auc: 0.7150 - loss: 0.5399\n","Epoch 27: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6382 - auc: 0.7150 - loss: 0.5399 - val_acc: 0.7647 - val_auc: 0.3203 - val_loss: 0.6476\n","Epoch 28/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6267 - auc: 0.7069 - loss: 0.5471\n","Epoch 28: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6274 - auc: 0.7078 - loss: 0.5467 - val_acc: 0.8758 - val_auc: 0.3552 - val_loss: 0.6534\n","Epoch 29/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6053 - auc: 0.7031 - loss: 0.5831\n","Epoch 29: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6057 - auc: 0.7033 - loss: 0.5820 - val_acc: 0.9085 - val_auc: 0.3385 - val_loss: 0.6460\n","Epoch 30/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6867 - auc: 0.7336 - loss: 0.5218\n","Epoch 30: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6859 - auc: 0.7331 - loss: 0.5222 - val_acc: 0.7386 - val_auc: 0.3538 - val_loss: 0.6402\n","Epoch 31/100\n","\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6268 - auc: 0.7036 - loss: 0.5401\n","Epoch 31: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6269 - auc: 0.7037 - loss: 0.5400 - val_acc: 0.7712 - val_auc: 0.3668 - val_loss: 0.6558\n","Epoch 32/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6309 - auc: 0.7053 - loss: 0.5477\n","Epoch 32: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6309 - auc: 0.7053 - loss: 0.5473 - val_acc: 0.8889 - val_auc: 0.3598 - val_loss: 0.6446\n","Epoch 33/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6431 - auc: 0.7203 - loss: 0.5216\n","Epoch 33: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6430 - auc: 0.7201 - loss: 0.5219 - val_acc: 0.8889 - val_auc: 0.3549 - val_loss: 0.6729\n","Epoch 34/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6637 - auc: 0.6938 - loss: 0.5209\n","Epoch 34: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6631 - auc: 0.6948 - loss: 0.5213 - val_acc: 0.7451 - val_auc: 0.3727 - val_loss: 0.6557\n","Epoch 35/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6402 - auc: 0.7274 - loss: 0.5492\n","Epoch 35: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6400 - auc: 0.7271 - loss: 0.5490 - val_acc: 0.7778 - val_auc: 0.3605 - val_loss: 0.6324\n","Epoch 36/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6282 - auc: 0.7118 - loss: 0.5337\n","Epoch 36: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6283 - auc: 0.7117 - loss: 0.5337 - val_acc: 0.7647 - val_auc: 0.3545 - val_loss: 0.6577\n","Epoch 37/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5987 - auc: 0.6630 - loss: 0.5505\n","Epoch 37: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5991 - auc: 0.6636 - loss: 0.5502 - val_acc: 0.7647 - val_auc: 0.3682 - val_loss: 0.6525\n","Epoch 38/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6541 - auc: 0.7354 - loss: 0.5073\n","Epoch 38: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6537 - auc: 0.7350 - loss: 0.5077 - val_acc: 0.8562 - val_auc: 0.3857 - val_loss: 0.6225\n","Epoch 39/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6453 - auc: 0.7348 - loss: 0.5305\n","Epoch 39: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6455 - auc: 0.7346 - loss: 0.5304 - val_acc: 0.9085 - val_auc: 0.3647 - val_loss: 0.6596\n","Epoch 40/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6482 - auc: 0.7336 - loss: 0.5200\n","Epoch 40: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6482 - auc: 0.7333 - loss: 0.5201 - val_acc: 0.9085 - val_auc: 0.3437 - val_loss: 0.6710\n","Epoch 41/100\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6399 - auc: 0.6891 - loss: 0.5290\n","Epoch 41: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6399 - auc: 0.6892 - loss: 0.5290 - val_acc: 0.8889 - val_auc: 0.3717 - val_loss: 0.6803\n","Epoch 42/100\n","\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6309 - auc: 0.7183 - loss: 0.5343\n","Epoch 42: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6313 - auc: 0.7183 - loss: 0.5341 - val_acc: 0.9020 - val_auc: 0.3706 - val_loss: 0.6387\n","Epoch 43/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6499 - auc: 0.7190 - loss: 0.5341\n","Epoch 43: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6496 - auc: 0.7192 - loss: 0.5337 - val_acc: 0.8889 - val_auc: 0.3647 - val_loss: 0.6555\n","Epoch 44/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6678 - auc: 0.7423 - loss: 0.5192\n","Epoch 44: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6678 - auc: 0.7422 - loss: 0.5192 - val_acc: 0.9085 - val_auc: 0.3643 - val_loss: 0.6742\n","Epoch 45/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6525 - auc: 0.7267 - loss: 0.5349\n","Epoch 45: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6525 - auc: 0.7266 - loss: 0.5347 - val_acc: 0.9020 - val_auc: 0.3713 - val_loss: 0.6802\n","Epoch 46/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6578 - auc: 0.7440 - loss: 0.4874\n","Epoch 46: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6574 - auc: 0.7434 - loss: 0.4881 - val_acc: 0.8889 - val_auc: 0.3860 - val_loss: 0.6383\n","Epoch 47/100\n","\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6388 - auc: 0.7047 - loss: 0.5246\n","Epoch 47: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6388 - auc: 0.7047 - loss: 0.5246 - val_acc: 0.9085 - val_auc: 0.3818 - val_loss: 0.7393\n","Epoch 48/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6661 - auc: 0.7176 - loss: 0.5204\n","Epoch 48: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6660 - auc: 0.7177 - loss: 0.5204 - val_acc: 0.9346 - val_auc: 0.3745 - val_loss: 0.6624\n","Epoch 49/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6565 - auc: 0.7384 - loss: 0.5178\n","Epoch 49: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6565 - auc: 0.7381 - loss: 0.5178 - val_acc: 0.8889 - val_auc: 0.3969 - val_loss: 0.6589\n","Epoch 50/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6799 - auc: 0.7653 - loss: 0.5034\n","Epoch 50: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6796 - auc: 0.7649 - loss: 0.5036 - val_acc: 0.9085 - val_auc: 0.3759 - val_loss: 0.6538\n","Epoch 51/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6565 - auc: 0.7162 - loss: 0.5198\n","Epoch 51: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6563 - auc: 0.7162 - loss: 0.5198 - val_acc: 0.9346 - val_auc: 0.3014 - val_loss: 0.6508\n","Epoch 52/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6784 - auc: 0.7101 - loss: 0.5296\n","Epoch 52: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6782 - auc: 0.7104 - loss: 0.5293 - val_acc: 0.9216 - val_auc: 0.3818 - val_loss: 0.7328\n","Epoch 53/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6545 - auc: 0.7139 - loss: 0.5169\n","Epoch 53: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6543 - auc: 0.7138 - loss: 0.5168 - val_acc: 0.9346 - val_auc: 0.3804 - val_loss: 0.7101\n","Epoch 54/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6570 - auc: 0.7455 - loss: 0.5118\n","Epoch 54: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6571 - auc: 0.7453 - loss: 0.5119 - val_acc: 0.9346 - val_auc: 0.3815 - val_loss: 0.6966\n","Epoch 55/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6677 - auc: 0.7344 - loss: 0.5172\n","Epoch 55: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6676 - auc: 0.7342 - loss: 0.5173 - val_acc: 0.9346 - val_auc: 0.3857 - val_loss: 0.6479\n","Epoch 56/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6521 - auc: 0.7176 - loss: 0.5273\n","Epoch 56: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6521 - auc: 0.7177 - loss: 0.5272 - val_acc: 0.9150 - val_auc: 0.4035 - val_loss: 0.6752\n","Epoch 57/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6975 - auc: 0.7531 - loss: 0.5037\n","Epoch 57: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6974 - auc: 0.7530 - loss: 0.5038 - val_acc: 0.9346 - val_auc: 0.3713 - val_loss: 0.6581\n","Epoch 58/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6436 - auc: 0.7136 - loss: 0.5188\n","Epoch 58: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6440 - auc: 0.7139 - loss: 0.5187 - val_acc: 0.9020 - val_auc: 0.5154 - val_loss: 0.6369\n","Epoch 59/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6528 - auc: 0.7553 - loss: 0.5132\n","Epoch 59: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6532 - auc: 0.7552 - loss: 0.5133 - val_acc: 0.9346 - val_auc: 0.4892 - val_loss: 0.6529\n","Epoch 60/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6670 - auc: 0.7437 - loss: 0.4977\n","Epoch 60: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6669 - auc: 0.7436 - loss: 0.4980 - val_acc: 0.9346 - val_auc: 0.4808 - val_loss: 0.6474\n","Epoch 61/100\n","\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6535 - auc: 0.7088 - loss: 0.5320\n","Epoch 61: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6536 - auc: 0.7091 - loss: 0.5318 - val_acc: 0.9346 - val_auc: 0.5024 - val_loss: 0.6574\n","Epoch 62/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6740 - auc: 0.7503 - loss: 0.4959\n","Epoch 62: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6736 - auc: 0.7497 - loss: 0.4966 - val_acc: 0.9346 - val_auc: 0.4227 - val_loss: 0.6499\n","Epoch 63/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6901 - auc: 0.7307 - loss: 0.5130\n","Epoch 63: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6898 - auc: 0.7313 - loss: 0.5131 - val_acc: 0.9346 - val_auc: 0.4007 - val_loss: 0.7624\n","Epoch 64/100\n","\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6717 - auc: 0.7212 - loss: 0.5102\n","Epoch 64: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6717 - auc: 0.7217 - loss: 0.5103 - val_acc: 0.8366 - val_auc: 0.3906 - val_loss: 0.7060\n","Epoch 65/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6655 - auc: 0.7408 - loss: 0.5042\n","Epoch 65: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6657 - auc: 0.7406 - loss: 0.5044 - val_acc: 0.9346 - val_auc: 0.5080 - val_loss: 0.6289\n","Epoch 66/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7083 - auc: 0.7540 - loss: 0.4928\n","Epoch 66: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7081 - auc: 0.7541 - loss: 0.4929 - val_acc: 0.9346 - val_auc: 0.5346 - val_loss: 0.6188\n","Epoch 67/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7017 - auc: 0.7453 - loss: 0.5263\n","Epoch 67: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7015 - auc: 0.7454 - loss: 0.5261 - val_acc: 0.9281 - val_auc: 0.4951 - val_loss: 0.6593\n","Epoch 68/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6864 - auc: 0.7502 - loss: 0.4990\n","Epoch 68: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6863 - auc: 0.7502 - loss: 0.4991 - val_acc: 0.8889 - val_auc: 0.4839 - val_loss: 0.6607\n","Epoch 69/100\n","\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6767 - auc: 0.7515 - loss: 0.5081\n","Epoch 69: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6767 - auc: 0.7514 - loss: 0.5081 - val_acc: 0.9020 - val_auc: 0.4332 - val_loss: 0.7045\n","Epoch 70/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6856 - auc: 0.7557 - loss: 0.5097\n","Epoch 70: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6857 - auc: 0.7555 - loss: 0.5097 - val_acc: 0.8954 - val_auc: 0.4920 - val_loss: 0.6756\n","Epoch 71/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6565 - auc: 0.7181 - loss: 0.5488\n","Epoch 71: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6573 - auc: 0.7191 - loss: 0.5478 - val_acc: 0.9085 - val_auc: 0.4587 - val_loss: 0.6828\n","Epoch 72/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6798 - auc: 0.7600 - loss: 0.5130\n","Epoch 72: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6799 - auc: 0.7600 - loss: 0.5128 - val_acc: 0.9346 - val_auc: 0.5133 - val_loss: 0.6821\n","Epoch 73/100\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6720 - auc: 0.7581 - loss: 0.5144\n","Epoch 73: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6721 - auc: 0.7582 - loss: 0.5144 - val_acc: 0.6863 - val_auc: 0.4794 - val_loss: 0.7266\n","Epoch 74/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7089 - auc: 0.7577 - loss: 0.5073\n","Epoch 74: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7087 - auc: 0.7578 - loss: 0.5073 - val_acc: 0.9020 - val_auc: 0.5168 - val_loss: 0.6622\n","Epoch 75/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6506 - auc: 0.7124 - loss: 0.5277\n","Epoch 75: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6510 - auc: 0.7129 - loss: 0.5275 - val_acc: 0.8758 - val_auc: 0.4951 - val_loss: 0.6466\n","Epoch 76/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6697 - auc: 0.7341 - loss: 0.5168\n","Epoch 76: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6696 - auc: 0.7347 - loss: 0.5165 - val_acc: 0.8693 - val_auc: 0.4997 - val_loss: 0.6807\n","Epoch 77/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6744 - auc: 0.7651 - loss: 0.5052\n","Epoch 77: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6746 - auc: 0.7652 - loss: 0.5052 - val_acc: 0.8170 - val_auc: 0.5325 - val_loss: 0.6603\n","Epoch 78/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7044 - auc: 0.7784 - loss: 0.4916\n","Epoch 78: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7043 - auc: 0.7781 - loss: 0.4918 - val_acc: 0.9150 - val_auc: 0.5094 - val_loss: 0.6517\n","Epoch 79/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6904 - auc: 0.7914 - loss: 0.4948\n","Epoch 79: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6904 - auc: 0.7910 - loss: 0.4950 - val_acc: 0.8431 - val_auc: 0.5378 - val_loss: 0.6749\n","Epoch 80/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7129 - auc: 0.7805 - loss: 0.4962\n","Epoch 80: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7128 - auc: 0.7804 - loss: 0.4963 - val_acc: 0.8627 - val_auc: 0.5073 - val_loss: 0.7207\n","Epoch 81/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6970 - auc: 0.7727 - loss: 0.4958\n","Epoch 81: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6965 - auc: 0.7721 - loss: 0.4961 - val_acc: 0.8366 - val_auc: 0.4731 - val_loss: 0.7905\n","Epoch 82/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6936 - auc: 0.7890 - loss: 0.4903\n","Epoch 82: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6938 - auc: 0.7885 - loss: 0.4907 - val_acc: 0.8824 - val_auc: 0.5031 - val_loss: 0.6664\n","Epoch 83/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6984 - auc: 0.7501 - loss: 0.5108\n","Epoch 83: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6983 - auc: 0.7509 - loss: 0.5106 - val_acc: 0.8301 - val_auc: 0.5101 - val_loss: 0.7656\n","Epoch 84/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7000 - auc: 0.7884 - loss: 0.4911\n","Epoch 84: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7000 - auc: 0.7884 - loss: 0.4914 - val_acc: 0.8627 - val_auc: 0.5140 - val_loss: 0.6647\n","Epoch 85/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7016 - auc: 0.7893 - loss: 0.4812\n","Epoch 85: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7015 - auc: 0.7889 - loss: 0.4814 - val_acc: 0.9346 - val_auc: 0.5010 - val_loss: 0.6443\n","Epoch 86/100\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6735 - auc: 0.7553 - loss: 0.5040\n","Epoch 86: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6736 - auc: 0.7553 - loss: 0.5040 - val_acc: 0.8627 - val_auc: 0.5580 - val_loss: 0.6099\n","Epoch 87/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6855 - auc: 0.7686 - loss: 0.4909\n","Epoch 87: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6860 - auc: 0.7686 - loss: 0.4913 - val_acc: 0.8627 - val_auc: 0.5479 - val_loss: 0.6129\n","Epoch 88/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7181 - auc: 0.7965 - loss: 0.4925\n","Epoch 88: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7179 - auc: 0.7963 - loss: 0.4925 - val_acc: 0.9020 - val_auc: 0.4885 - val_loss: 0.6453\n","Epoch 89/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7231 - auc: 0.8066 - loss: 0.4865\n","Epoch 89: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7231 - auc: 0.8062 - loss: 0.4868 - val_acc: 0.9346 - val_auc: 0.5171 - val_loss: 0.5518\n","Epoch 90/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7265 - auc: 0.7832 - loss: 0.4887\n","Epoch 90: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7264 - auc: 0.7833 - loss: 0.4887 - val_acc: 0.8693 - val_auc: 0.5315 - val_loss: 0.5965\n","Epoch 91/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6856 - auc: 0.7809 - loss: 0.5004\n","Epoch 91: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6861 - auc: 0.7811 - loss: 0.5001 - val_acc: 0.9281 - val_auc: 0.4860 - val_loss: 0.6231\n","Epoch 92/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7330 - auc: 0.7917 - loss: 0.4751\n","Epoch 92: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7329 - auc: 0.7917 - loss: 0.4752 - val_acc: 0.9216 - val_auc: 0.4986 - val_loss: 0.6512\n","Epoch 93/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7305 - auc: 0.8145 - loss: 0.4666\n","Epoch 93: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7308 - auc: 0.8139 - loss: 0.4669 - val_acc: 0.8627 - val_auc: 0.4783 - val_loss: 0.6378\n","Epoch 94/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7135 - auc: 0.7620 - loss: 0.4977\n","Epoch 94: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7136 - auc: 0.7621 - loss: 0.4977 - val_acc: 0.8824 - val_auc: 0.5448 - val_loss: 0.6738\n","Epoch 95/100\n","\u001b[1m321/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7474 - auc: 0.8000 - loss: 0.4800\n","Epoch 95: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7466 - auc: 0.8000 - loss: 0.4802 - val_acc: 0.8889 - val_auc: 0.4864 - val_loss: 0.6460\n","Epoch 96/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7239 - auc: 0.7870 - loss: 0.4800\n","Epoch 96: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7241 - auc: 0.7873 - loss: 0.4799 - val_acc: 0.8562 - val_auc: 0.5171 - val_loss: 0.6793\n","Epoch 97/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7274 - auc: 0.7891 - loss: 0.4903\n","Epoch 97: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7276 - auc: 0.7893 - loss: 0.4899 - val_acc: 0.8105 - val_auc: 0.4517 - val_loss: 0.7617\n","Epoch 98/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7078 - auc: 0.7875 - loss: 0.4873\n","Epoch 98: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7083 - auc: 0.7878 - loss: 0.4872 - val_acc: 0.9216 - val_auc: 0.5094 - val_loss: 0.6130\n","Epoch 99/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7186 - auc: 0.7866 - loss: 0.4924\n","Epoch 99: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7192 - auc: 0.7870 - loss: 0.4920 - val_acc: 0.9150 - val_auc: 0.4790 - val_loss: 0.6112\n","Epoch 100/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7596 - auc: 0.8284 - loss: 0.4590\n","Epoch 100: val_loss did not improve from 0.49792\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7593 - auc: 0.8283 - loss: 0.4591 - val_acc: 0.6209 - val_auc: 0.4094 - val_loss: 0.9360\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:tensorflow:5 out of the last 46 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b0925f04900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 8 | TEST ACC=0.4528 | TEST AUC=0.6034 | n=53\n","Confusion matrix:\n"," [[24  0]\n"," [29  0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.453     1.000     0.623        24\n","           1      0.000     0.000     0.000        29\n","\n","    accuracy                          0.453        53\n","   macro avg      0.226     0.500     0.312        53\n","weighted avg      0.205     0.453     0.282        53\n","\n","\n","--- Fold 9/14 ---\n"," train | ids:   36 | files:   902 | pos files:  347 | neg files:  555\n","   val | ids:    5 | files:   182 | pos files:   39 | neg files:  143\n","  test | ids:    3 | files:   116 | pos files:   19 | neg files:   97\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - acc: 0.5668 - auc: 0.4917 - loss: 0.6899\n","Epoch 1: val_loss improved from inf to 0.64442, saving model to best_fold_09.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 26ms/step - acc: 0.5672 - auc: 0.4917 - loss: 0.6899 - val_acc: 0.7857 - val_auc: 0.4378 - val_loss: 0.6444\n","Epoch 2/100\n","\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6120 - auc: 0.4995 - loss: 0.6705\n","Epoch 2: val_loss improved from 0.64442 to 0.60225, saving model to best_fold_09.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6121 - auc: 0.5000 - loss: 0.6704 - val_acc: 0.7857 - val_auc: 0.3658 - val_loss: 0.6022\n","Epoch 3/100\n","\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6259 - auc: 0.5958 - loss: 0.6527\n","Epoch 3: val_loss did not improve from 0.60225\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6258 - auc: 0.5959 - loss: 0.6527 - val_acc: 0.7857 - val_auc: 0.3992 - val_loss: 0.6068\n","Epoch 4/100\n","\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5849 - auc: 0.6529 - loss: 0.6614\n","Epoch 4: val_loss improved from 0.60225 to 0.57961, saving model to best_fold_09.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.5853 - auc: 0.6529 - loss: 0.6612 - val_acc: 0.7857 - val_auc: 0.4300 - val_loss: 0.5796\n","Epoch 5/100\n","\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5794 - auc: 0.6846 - loss: 0.6499\n","Epoch 5: val_loss did not improve from 0.57961\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5809 - auc: 0.6837 - loss: 0.6492 - val_acc: 0.7857 - val_auc: 0.5039 - val_loss: 0.5884\n","Epoch 6/100\n","\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6464 - auc: 0.6782 - loss: 0.6095\n","Epoch 6: val_loss did not improve from 0.57961\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6458 - auc: 0.6788 - loss: 0.6097 - val_acc: 0.7418 - val_auc: 0.5439 - val_loss: 0.6131\n","Epoch 7/100\n","\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6309 - auc: 0.6958 - loss: 0.6168\n","Epoch 7: val_loss did not improve from 0.57961\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6310 - auc: 0.6959 - loss: 0.6167 - val_acc: 0.5989 - val_auc: 0.5497 - val_loss: 0.6323\n","Epoch 8/100\n","\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6575 - auc: 0.7135 - loss: 0.5906\n","Epoch 8: val_loss improved from 0.57961 to 0.56272, saving model to best_fold_09.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6574 - auc: 0.7135 - loss: 0.5905 - val_acc: 0.6978 - val_auc: 0.5723 - val_loss: 0.5627\n","Epoch 9/100\n","\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6336 - auc: 0.7067 - loss: 0.5794\n","Epoch 9: val_loss did not improve from 0.56272\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6335 - auc: 0.7070 - loss: 0.5795 - val_acc: 0.5824 - val_auc: 0.5728 - val_loss: 0.6013\n","Epoch 10/100\n","\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6256 - auc: 0.7062 - loss: 0.5974\n","Epoch 10: val_loss did not improve from 0.56272\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6259 - auc: 0.7066 - loss: 0.5969 - val_acc: 0.6099 - val_auc: 0.5738 - val_loss: 0.5830\n","Epoch 11/100\n","\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6439 - auc: 0.7327 - loss: 0.5702\n","Epoch 11: val_loss did not improve from 0.56272\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6440 - auc: 0.7324 - loss: 0.5703 - val_acc: 0.5000 - val_auc: 0.5659 - val_loss: 0.6119\n","Epoch 12/100\n","\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6482 - auc: 0.7286 - loss: 0.5567\n","Epoch 12: val_loss did not improve from 0.56272\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6481 - auc: 0.7285 - loss: 0.5570 - val_acc: 0.5440 - val_auc: 0.5744 - val_loss: 0.5986\n","Epoch 13/100\n","\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6357 - auc: 0.7460 - loss: 0.5623\n","Epoch 13: val_loss did not improve from 0.56272\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6353 - auc: 0.7447 - loss: 0.5629 - val_acc: 0.5769 - val_auc: 0.5760 - val_loss: 0.5716\n","Epoch 14/100\n","\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6433 - auc: 0.6856 - loss: 0.5797\n","Epoch 14: val_loss improved from 0.56272 to 0.55633, saving model to best_fold_09.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6435 - auc: 0.6862 - loss: 0.5796 - val_acc: 0.5714 - val_auc: 0.5777 - val_loss: 0.5563\n","Epoch 15/100\n","\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6388 - auc: 0.7012 - loss: 0.5972\n","Epoch 15: val_loss did not improve from 0.55633\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6396 - auc: 0.7025 - loss: 0.5960 - val_acc: 0.5275 - val_auc: 0.5807 - val_loss: 0.5705\n","Epoch 16/100\n","\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6393 - auc: 0.7239 - loss: 0.5776\n","Epoch 16: val_loss improved from 0.55633 to 0.53968, saving model to best_fold_09.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6393 - auc: 0.7239 - loss: 0.5775 - val_acc: 0.6429 - val_auc: 0.5837 - val_loss: 0.5397\n","Epoch 17/100\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6497 - auc: 0.7359 - loss: 0.5569\n","Epoch 17: val_loss improved from 0.53968 to 0.52729, saving model to best_fold_09.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6497 - auc: 0.7359 - loss: 0.5570 - val_acc: 0.6374 - val_auc: 0.5825 - val_loss: 0.5273\n","Epoch 18/100\n","\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6662 - auc: 0.7194 - loss: 0.5895\n","Epoch 18: val_loss did not improve from 0.52729\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6660 - auc: 0.7198 - loss: 0.5889 - val_acc: 0.5824 - val_auc: 0.5843 - val_loss: 0.5580\n","Epoch 19/100\n","\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6635 - auc: 0.7166 - loss: 0.5558\n","Epoch 19: val_loss did not improve from 0.52729\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6635 - auc: 0.7167 - loss: 0.5558 - val_acc: 0.5440 - val_auc: 0.5862 - val_loss: 0.5550\n","Epoch 20/100\n","\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6369 - auc: 0.7198 - loss: 0.5539\n","Epoch 20: val_loss did not improve from 0.52729\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6374 - auc: 0.7202 - loss: 0.5544 - val_acc: 0.5385 - val_auc: 0.5846 - val_loss: 0.5515\n","Epoch 21/100\n","\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6960 - auc: 0.7732 - loss: 0.5341\n","Epoch 21: val_loss did not improve from 0.52729\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6958 - auc: 0.7730 - loss: 0.5343 - val_acc: 0.5934 - val_auc: 0.5805 - val_loss: 0.5338\n","Epoch 22/100\n","\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6695 - auc: 0.7367 - loss: 0.5546\n","Epoch 22: val_loss improved from 0.52729 to 0.51285, saving model to best_fold_09.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6697 - auc: 0.7369 - loss: 0.5546 - val_acc: 0.7637 - val_auc: 0.5608 - val_loss: 0.5128\n","Epoch 23/100\n","\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6487 - auc: 0.7074 - loss: 0.6076\n","Epoch 23: val_loss did not improve from 0.51285\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6493 - auc: 0.7083 - loss: 0.6062 - val_acc: 0.5934 - val_auc: 0.5630 - val_loss: 0.5143\n","Epoch 24/100\n","\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6608 - auc: 0.7108 - loss: 0.5857\n","Epoch 24: val_loss did not improve from 0.51285\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6617 - auc: 0.7122 - loss: 0.5846 - val_acc: 0.5604 - val_auc: 0.5598 - val_loss: 0.5226\n","Epoch 25/100\n","\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6686 - auc: 0.7342 - loss: 0.5640\n","Epoch 25: val_loss improved from 0.51285 to 0.50801, saving model to best_fold_09.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6695 - auc: 0.7347 - loss: 0.5638 - val_acc: 0.5989 - val_auc: 0.5583 - val_loss: 0.5080\n","Epoch 26/100\n","\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6643 - auc: 0.7347 - loss: 0.5752\n","Epoch 26: val_loss did not improve from 0.50801\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6644 - auc: 0.7348 - loss: 0.5751 - val_acc: 0.5934 - val_auc: 0.5586 - val_loss: 0.5117\n","Epoch 27/100\n","\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7010 - auc: 0.7579 - loss: 0.5503\n","Epoch 27: val_loss did not improve from 0.50801\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7006 - auc: 0.7577 - loss: 0.5505 - val_acc: 0.5000 - val_auc: 0.5657 - val_loss: 0.5512\n","Epoch 28/100\n","\u001b[1m292/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6644 - auc: 0.7309 - loss: 0.5539\n","Epoch 28: val_loss did not improve from 0.50801\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6649 - auc: 0.7313 - loss: 0.5539 - val_acc: 0.5604 - val_auc: 0.5673 - val_loss: 0.5251\n","Epoch 29/100\n","\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6691 - auc: 0.7454 - loss: 0.5532\n","Epoch 29: val_loss did not improve from 0.50801\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6691 - auc: 0.7454 - loss: 0.5532 - val_acc: 0.5055 - val_auc: 0.5741 - val_loss: 0.5412\n","Epoch 30/100\n","\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6647 - auc: 0.7549 - loss: 0.5478\n","Epoch 30: val_loss did not improve from 0.50801\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6650 - auc: 0.7548 - loss: 0.5479 - val_acc: 0.5659 - val_auc: 0.5727 - val_loss: 0.5251\n","Epoch 31/100\n","\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6713 - auc: 0.7500 - loss: 0.5561\n","Epoch 31: val_loss did not improve from 0.50801\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6715 - auc: 0.7500 - loss: 0.5561 - val_acc: 0.5989 - val_auc: 0.5699 - val_loss: 0.5104\n","Epoch 32/100\n","\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6999 - auc: 0.7525 - loss: 0.5551\n","Epoch 32: val_loss improved from 0.50801 to 0.50264, saving model to best_fold_09.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6999 - auc: 0.7527 - loss: 0.5550 - val_acc: 0.6209 - val_auc: 0.5713 - val_loss: 0.5026\n","Epoch 33/100\n","\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6865 - auc: 0.7681 - loss: 0.5419\n","Epoch 33: val_loss did not improve from 0.50264\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6867 - auc: 0.7681 - loss: 0.5420 - val_acc: 0.5824 - val_auc: 0.5774 - val_loss: 0.5290\n","Epoch 34/100\n","\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7027 - auc: 0.7705 - loss: 0.5353\n","Epoch 34: val_loss did not improve from 0.50264\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7026 - auc: 0.7705 - loss: 0.5354 - val_acc: 0.6154 - val_auc: 0.5817 - val_loss: 0.5075\n","Epoch 35/100\n","\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6992 - auc: 0.7698 - loss: 0.5517\n","Epoch 35: val_loss did not improve from 0.50264\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6992 - auc: 0.7697 - loss: 0.5517 - val_acc: 0.5495 - val_auc: 0.5940 - val_loss: 0.5446\n","Epoch 36/100\n","\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7144 - auc: 0.7703 - loss: 0.5462\n","Epoch 36: val_loss did not improve from 0.50264\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7143 - auc: 0.7706 - loss: 0.5459 - val_acc: 0.6044 - val_auc: 0.5950 - val_loss: 0.5190\n","Epoch 37/100\n","\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6766 - auc: 0.7471 - loss: 0.5523\n","Epoch 37: val_loss did not improve from 0.50264\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6779 - auc: 0.7484 - loss: 0.5516 - val_acc: 0.5934 - val_auc: 0.6093 - val_loss: 0.5378\n","Epoch 38/100\n","\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7081 - auc: 0.7761 - loss: 0.5292\n","Epoch 38: val_loss did not improve from 0.50264\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7077 - auc: 0.7761 - loss: 0.5296 - val_acc: 0.5824 - val_auc: 0.6221 - val_loss: 0.5358\n","Epoch 39/100\n","\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7063 - auc: 0.7795 - loss: 0.5546\n","Epoch 39: val_loss did not improve from 0.50264\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7064 - auc: 0.7797 - loss: 0.5538 - val_acc: 0.5824 - val_auc: 0.6309 - val_loss: 0.5360\n","Epoch 40/100\n","\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7249 - auc: 0.7929 - loss: 0.5129\n","Epoch 40: val_loss did not improve from 0.50264\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7247 - auc: 0.7929 - loss: 0.5134 - val_acc: 0.5604 - val_auc: 0.6500 - val_loss: 0.5551\n","Epoch 41/100\n","\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7220 - auc: 0.7547 - loss: 0.5288\n","Epoch 41: val_loss did not improve from 0.50264\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7219 - auc: 0.7553 - loss: 0.5288 - val_acc: 0.5495 - val_auc: 0.6651 - val_loss: 0.5553\n","Epoch 42/100\n","\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6594 - auc: 0.7541 - loss: 0.5609\n","Epoch 42: val_loss improved from 0.50264 to 0.48537, saving model to best_fold_09.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6600 - auc: 0.7546 - loss: 0.5604 - val_acc: 0.7747 - val_auc: 0.6205 - val_loss: 0.4854\n","Epoch 43/100\n","\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7230 - auc: 0.7970 - loss: 0.5182\n","Epoch 43: val_loss did not improve from 0.48537\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7226 - auc: 0.7965 - loss: 0.5185 - val_acc: 0.5824 - val_auc: 0.6635 - val_loss: 0.5272\n","Epoch 44/100\n","\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6999 - auc: 0.7790 - loss: 0.5459\n","Epoch 44: val_loss did not improve from 0.48537\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7002 - auc: 0.7793 - loss: 0.5455 - val_acc: 0.5659 - val_auc: 0.6812 - val_loss: 0.5452\n","Epoch 45/100\n","\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6945 - auc: 0.7522 - loss: 0.5623\n","Epoch 45: val_loss did not improve from 0.48537\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6952 - auc: 0.7531 - loss: 0.5614 - val_acc: 0.5769 - val_auc: 0.6790 - val_loss: 0.5402\n","Epoch 46/100\n","\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7420 - auc: 0.8046 - loss: 0.5071\n","Epoch 46: val_loss did not improve from 0.48537\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7419 - auc: 0.8045 - loss: 0.5072 - val_acc: 0.5659 - val_auc: 0.7003 - val_loss: 0.5474\n","Epoch 47/100\n","\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6982 - auc: 0.7550 - loss: 0.5469\n","Epoch 47: val_loss did not improve from 0.48537\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6984 - auc: 0.7553 - loss: 0.5467 - val_acc: 0.5165 - val_auc: 0.7192 - val_loss: 0.6927\n","Epoch 48/100\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7264 - auc: 0.8079 - loss: 0.5007\n","Epoch 48: val_loss did not improve from 0.48537\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7264 - auc: 0.8079 - loss: 0.5008 - val_acc: 0.6758 - val_auc: 0.6814 - val_loss: 0.4989\n","Epoch 49/100\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7155 - auc: 0.7992 - loss: 0.5212\n","Epoch 49: val_loss did not improve from 0.48537\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7155 - auc: 0.7992 - loss: 0.5212 - val_acc: 0.6209 - val_auc: 0.6873 - val_loss: 0.5140\n","Epoch 50/100\n","\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7490 - auc: 0.8104 - loss: 0.5109\n","Epoch 50: val_loss did not improve from 0.48537\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7488 - auc: 0.8103 - loss: 0.5109 - val_acc: 0.7308 - val_auc: 0.6833 - val_loss: 0.4959\n","Epoch 51/100\n","\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7075 - auc: 0.8027 - loss: 0.5223\n","Epoch 51: val_loss improved from 0.48537 to 0.47496, saving model to best_fold_09.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.7076 - auc: 0.8026 - loss: 0.5221 - val_acc: 0.7747 - val_auc: 0.6708 - val_loss: 0.4750\n","Epoch 52/100\n","\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7047 - auc: 0.7859 - loss: 0.5286\n","Epoch 52: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7048 - auc: 0.7860 - loss: 0.5285 - val_acc: 0.5824 - val_auc: 0.6938 - val_loss: 0.5432\n","Epoch 53/100\n","\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7109 - auc: 0.7887 - loss: 0.5251\n","Epoch 53: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7111 - auc: 0.7893 - loss: 0.5243 - val_acc: 0.5714 - val_auc: 0.7192 - val_loss: 0.5730\n","Epoch 54/100\n","\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6995 - auc: 0.7894 - loss: 0.5231\n","Epoch 54: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6998 - auc: 0.7894 - loss: 0.5229 - val_acc: 0.5714 - val_auc: 0.7116 - val_loss: 0.5797\n","Epoch 55/100\n","\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7198 - auc: 0.8004 - loss: 0.5179\n","Epoch 55: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7203 - auc: 0.8006 - loss: 0.5176 - val_acc: 0.5769 - val_auc: 0.6954 - val_loss: 0.5460\n","Epoch 56/100\n","\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7434 - auc: 0.8044 - loss: 0.5100\n","Epoch 56: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7430 - auc: 0.8045 - loss: 0.5100 - val_acc: 0.6593 - val_auc: 0.7061 - val_loss: 0.5049\n","Epoch 57/100\n","\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7168 - auc: 0.7892 - loss: 0.5332\n","Epoch 57: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7172 - auc: 0.7898 - loss: 0.5320 - val_acc: 0.5824 - val_auc: 0.7126 - val_loss: 0.5605\n","Epoch 58/100\n","\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7517 - auc: 0.8108 - loss: 0.4757\n","Epoch 58: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7514 - auc: 0.8106 - loss: 0.4763 - val_acc: 0.5934 - val_auc: 0.7120 - val_loss: 0.5532\n","Epoch 59/100\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7504 - auc: 0.8255 - loss: 0.4760\n","Epoch 59: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7503 - auc: 0.8255 - loss: 0.4760 - val_acc: 0.6923 - val_auc: 0.6988 - val_loss: 0.5058\n","Epoch 60/100\n","\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7544 - auc: 0.8174 - loss: 0.4839\n","Epoch 60: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7537 - auc: 0.8172 - loss: 0.4847 - val_acc: 0.6264 - val_auc: 0.7091 - val_loss: 0.5227\n","Epoch 61/100\n","\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7309 - auc: 0.8016 - loss: 0.5113\n","Epoch 61: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7308 - auc: 0.8015 - loss: 0.5113 - val_acc: 0.6978 - val_auc: 0.7025 - val_loss: 0.5051\n","Epoch 62/100\n","\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7450 - auc: 0.8268 - loss: 0.4736\n","Epoch 62: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7443 - auc: 0.8262 - loss: 0.4746 - val_acc: 0.7033 - val_auc: 0.7052 - val_loss: 0.5031\n","Epoch 63/100\n","\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7291 - auc: 0.8029 - loss: 0.5009\n","Epoch 63: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7291 - auc: 0.8031 - loss: 0.5008 - val_acc: 0.7473 - val_auc: 0.6865 - val_loss: 0.4915\n","Epoch 64/100\n","\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7208 - auc: 0.8182 - loss: 0.4990\n","Epoch 64: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7208 - auc: 0.8179 - loss: 0.4990 - val_acc: 0.7637 - val_auc: 0.6961 - val_loss: 0.4826\n","Epoch 65/100\n","\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7321 - auc: 0.8047 - loss: 0.5012\n","Epoch 65: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7320 - auc: 0.8047 - loss: 0.5012 - val_acc: 0.7692 - val_auc: 0.6944 - val_loss: 0.4812\n","Epoch 66/100\n","\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7583 - auc: 0.8357 - loss: 0.4667\n","Epoch 66: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7571 - auc: 0.8350 - loss: 0.4678 - val_acc: 0.6978 - val_auc: 0.6982 - val_loss: 0.5093\n","Epoch 67/100\n","\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7192 - auc: 0.8012 - loss: 0.5025\n","Epoch 67: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7200 - auc: 0.8016 - loss: 0.5023 - val_acc: 0.6044 - val_auc: 0.7132 - val_loss: 0.5594\n","Epoch 68/100\n","\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7505 - auc: 0.8290 - loss: 0.4733\n","Epoch 68: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7500 - auc: 0.8285 - loss: 0.4738 - val_acc: 0.6648 - val_auc: 0.7119 - val_loss: 0.5249\n","Epoch 69/100\n","\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7480 - auc: 0.8181 - loss: 0.4954\n","Epoch 69: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7472 - auc: 0.8178 - loss: 0.4955 - val_acc: 0.7747 - val_auc: 0.7084 - val_loss: 0.4874\n","Epoch 70/100\n","\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7423 - auc: 0.8062 - loss: 0.4990\n","Epoch 70: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7418 - auc: 0.8061 - loss: 0.4992 - val_acc: 0.6154 - val_auc: 0.7333 - val_loss: 0.5457\n","Epoch 71/100\n","\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7295 - auc: 0.7943 - loss: 0.5065\n","Epoch 71: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7293 - auc: 0.7945 - loss: 0.5064 - val_acc: 0.5495 - val_auc: 0.6859 - val_loss: 0.6166\n","Epoch 72/100\n","\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7164 - auc: 0.7989 - loss: 0.5030\n","Epoch 72: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7166 - auc: 0.7990 - loss: 0.5030 - val_acc: 0.7198 - val_auc: 0.6970 - val_loss: 0.5174\n","Epoch 73/100\n","\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7072 - auc: 0.8144 - loss: 0.4806\n","Epoch 73: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7076 - auc: 0.8140 - loss: 0.4811 - val_acc: 0.6868 - val_auc: 0.6872 - val_loss: 0.5387\n","Epoch 74/100\n","\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7198 - auc: 0.8141 - loss: 0.4938\n","Epoch 74: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7201 - auc: 0.8139 - loss: 0.4938 - val_acc: 0.7692 - val_auc: 0.6751 - val_loss: 0.5026\n","Epoch 75/100\n","\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7377 - auc: 0.8038 - loss: 0.4867\n","Epoch 75: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7377 - auc: 0.8039 - loss: 0.4868 - val_acc: 0.7582 - val_auc: 0.6966 - val_loss: 0.5176\n","Epoch 76/100\n","\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7393 - auc: 0.8180 - loss: 0.4781\n","Epoch 76: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7391 - auc: 0.8180 - loss: 0.4784 - val_acc: 0.6429 - val_auc: 0.6941 - val_loss: 0.5690\n","Epoch 77/100\n","\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7418 - auc: 0.8205 - loss: 0.4744\n","Epoch 77: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7418 - auc: 0.8203 - loss: 0.4747 - val_acc: 0.5824 - val_auc: 0.7532 - val_loss: 0.6310\n","Epoch 78/100\n","\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7699 - auc: 0.8362 - loss: 0.4821\n","Epoch 78: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7697 - auc: 0.8360 - loss: 0.4821 - val_acc: 0.7747 - val_auc: 0.6805 - val_loss: 0.5283\n","Epoch 79/100\n","\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7207 - auc: 0.8064 - loss: 0.4968\n","Epoch 79: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7208 - auc: 0.8065 - loss: 0.4968 - val_acc: 0.7692 - val_auc: 0.6725 - val_loss: 0.5410\n","Epoch 80/100\n","\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7464 - auc: 0.8177 - loss: 0.4762\n","Epoch 80: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7461 - auc: 0.8178 - loss: 0.4764 - val_acc: 0.5714 - val_auc: 0.7048 - val_loss: 0.7289\n","Epoch 81/100\n","\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7351 - auc: 0.8163 - loss: 0.4791\n","Epoch 81: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7352 - auc: 0.8163 - loss: 0.4792 - val_acc: 0.7582 - val_auc: 0.6495 - val_loss: 0.4809\n","Epoch 82/100\n","\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7092 - auc: 0.7919 - loss: 0.5103\n","Epoch 82: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7094 - auc: 0.7923 - loss: 0.5099 - val_acc: 0.6813 - val_auc: 0.6988 - val_loss: 0.5532\n","Epoch 83/100\n","\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7460 - auc: 0.8196 - loss: 0.4766\n","Epoch 83: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7456 - auc: 0.8192 - loss: 0.4769 - val_acc: 0.7473 - val_auc: 0.6472 - val_loss: 0.5223\n","Epoch 84/100\n","\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7564 - auc: 0.8256 - loss: 0.4723\n","Epoch 84: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7560 - auc: 0.8252 - loss: 0.4731 - val_acc: 0.7473 - val_auc: 0.7267 - val_loss: 0.5178\n","Epoch 85/100\n","\u001b[1m295/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7456 - auc: 0.8129 - loss: 0.4854\n","Epoch 85: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7455 - auc: 0.8129 - loss: 0.4855 - val_acc: 0.7527 - val_auc: 0.6955 - val_loss: 0.5166\n","Epoch 86/100\n","\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7435 - auc: 0.8201 - loss: 0.4785\n","Epoch 86: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7434 - auc: 0.8199 - loss: 0.4787 - val_acc: 0.7637 - val_auc: 0.7254 - val_loss: 0.5330\n","Epoch 87/100\n","\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7283 - auc: 0.7991 - loss: 0.4931\n","Epoch 87: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7285 - auc: 0.7996 - loss: 0.4928 - val_acc: 0.7637 - val_auc: 0.6729 - val_loss: 0.4905\n","Epoch 88/100\n","\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7193 - auc: 0.7932 - loss: 0.5034\n","Epoch 88: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7202 - auc: 0.7940 - loss: 0.5026 - val_acc: 0.7527 - val_auc: 0.6814 - val_loss: 0.5724\n","Epoch 89/100\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7369 - auc: 0.8157 - loss: 0.4781\n","Epoch 89: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7369 - auc: 0.8157 - loss: 0.4781 - val_acc: 0.7582 - val_auc: 0.6742 - val_loss: 0.5299\n","Epoch 90/100\n","\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7378 - auc: 0.8131 - loss: 0.4975\n","Epoch 90: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7379 - auc: 0.8132 - loss: 0.4974 - val_acc: 0.7582 - val_auc: 0.7188 - val_loss: 0.5302\n","Epoch 91/100\n","\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7228 - auc: 0.8007 - loss: 0.5125\n","Epoch 91: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7230 - auc: 0.8009 - loss: 0.5117 - val_acc: 0.6868 - val_auc: 0.6806 - val_loss: 0.5905\n","Epoch 92/100\n","\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6974 - auc: 0.8014 - loss: 0.4977\n","Epoch 92: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6976 - auc: 0.8015 - loss: 0.4976 - val_acc: 0.7692 - val_auc: 0.7291 - val_loss: 0.5385\n","Epoch 93/100\n","\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7529 - auc: 0.8254 - loss: 0.4740\n","Epoch 93: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7528 - auc: 0.8253 - loss: 0.4741 - val_acc: 0.7582 - val_auc: 0.6834 - val_loss: 0.5331\n","Epoch 94/100\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7654 - auc: 0.8258 - loss: 0.4660\n","Epoch 94: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7653 - auc: 0.8257 - loss: 0.4661 - val_acc: 0.7527 - val_auc: 0.7084 - val_loss: 0.5226\n","Epoch 95/100\n","\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7477 - auc: 0.8249 - loss: 0.4729\n","Epoch 95: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7476 - auc: 0.8248 - loss: 0.4730 - val_acc: 0.7582 - val_auc: 0.6733 - val_loss: 0.5649\n","Epoch 96/100\n","\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7474 - auc: 0.8146 - loss: 0.4888\n","Epoch 96: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7472 - auc: 0.8147 - loss: 0.4886 - val_acc: 0.7747 - val_auc: 0.7344 - val_loss: 0.5439\n","Epoch 97/100\n","\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7555 - auc: 0.8216 - loss: 0.4689\n","Epoch 97: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7546 - auc: 0.8217 - loss: 0.4693 - val_acc: 0.7527 - val_auc: 0.6708 - val_loss: 0.4997\n","Epoch 98/100\n","\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7396 - auc: 0.8231 - loss: 0.4766\n","Epoch 98: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7396 - auc: 0.8230 - loss: 0.4767 - val_acc: 0.7582 - val_auc: 0.6707 - val_loss: 0.5191\n","Epoch 99/100\n","\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7459 - auc: 0.8363 - loss: 0.4764\n","Epoch 99: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7459 - auc: 0.8360 - loss: 0.4767 - val_acc: 0.7473 - val_auc: 0.6512 - val_loss: 0.5031\n","Epoch 100/100\n","\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7210 - auc: 0.7933 - loss: 0.5239\n","Epoch 100: val_loss did not improve from 0.47496\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7216 - auc: 0.7938 - loss: 0.5231 - val_acc: 0.7473 - val_auc: 0.6411 - val_loss: 0.5758\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 9 | TEST ACC=0.6810 | TEST AUC=0.3565 | n=116\n","Confusion matrix:\n"," [[79 18]\n"," [19  0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.806     0.814     0.810        97\n","           1      0.000     0.000     0.000        19\n","\n","    accuracy                          0.681       116\n","   macro avg      0.403     0.407     0.405       116\n","weighted avg      0.674     0.681     0.678       116\n","\n","\n","--- Fold 10/14 ---\n"," train | ids:   36 | files:  1088 | pos files:  365 | neg files:  723\n","   val | ids:    5 | files:   107 | pos files:   39 | neg files:   68\n","  test | ids:    3 | files:     5 | pos files:    1 | neg files:    4\n","Epoch 1/100\n","\u001b[1m350/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.6261 - auc: 0.5126 - loss: 0.6834\n","Epoch 1: val_loss improved from inf to 0.65764, saving model to best_fold_10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - acc: 0.6273 - auc: 0.5122 - loss: 0.6829 - val_acc: 0.6355 - val_auc: 0.3944 - val_loss: 0.6576\n","Epoch 2/100\n","\u001b[1m351/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6861 - auc: 0.4251 - loss: 0.6341\n","Epoch 2: val_loss improved from 0.65764 to 0.65596, saving model to best_fold_10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6853 - auc: 0.4254 - loss: 0.6345 - val_acc: 0.6355 - val_auc: 0.4110 - val_loss: 0.6560\n","Epoch 3/100\n","\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6719 - auc: 0.4712 - loss: 0.6368\n","Epoch 3: val_loss improved from 0.65596 to 0.65534, saving model to best_fold_10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6718 - auc: 0.4714 - loss: 0.6369 - val_acc: 0.6355 - val_auc: 0.4137 - val_loss: 0.6553\n","Epoch 4/100\n","\u001b[1m359/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6653 - auc: 0.4773 - loss: 0.6403\n","Epoch 4: val_loss improved from 0.65534 to 0.65458, saving model to best_fold_10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6652 - auc: 0.4779 - loss: 0.6403 - val_acc: 0.6355 - val_auc: 0.4448 - val_loss: 0.6546\n","Epoch 5/100\n","\u001b[1m354/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6780 - auc: 0.4961 - loss: 0.6312\n","Epoch 5: val_loss improved from 0.65458 to 0.65365, saving model to best_fold_10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6776 - auc: 0.4965 - loss: 0.6314 - val_acc: 0.6355 - val_auc: 0.4877 - val_loss: 0.6536\n","Epoch 6/100\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6622 - auc: 0.5601 - loss: 0.6344\n","Epoch 6: val_loss improved from 0.65365 to 0.65288, saving model to best_fold_10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6622 - auc: 0.5602 - loss: 0.6344 - val_acc: 0.6355 - val_auc: 0.5345 - val_loss: 0.6529\n","Epoch 7/100\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6914 - auc: 0.5903 - loss: 0.6094\n","Epoch 7: val_loss improved from 0.65288 to 0.65036, saving model to best_fold_10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6914 - auc: 0.5903 - loss: 0.6094 - val_acc: 0.6355 - val_auc: 0.5728 - val_loss: 0.6504\n","Epoch 8/100\n","\u001b[1m353/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6618 - auc: 0.6148 - loss: 0.6254\n","Epoch 8: val_loss improved from 0.65036 to 0.64811, saving model to best_fold_10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6618 - auc: 0.6148 - loss: 0.6253 - val_acc: 0.6355 - val_auc: 0.5865 - val_loss: 0.6481\n","Epoch 9/100\n","\u001b[1m357/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6605 - auc: 0.6547 - loss: 0.6154\n","Epoch 9: val_loss did not improve from 0.64811\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6606 - auc: 0.6543 - loss: 0.6154 - val_acc: 0.6355 - val_auc: 0.5818 - val_loss: 0.6546\n","Epoch 10/100\n","\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6255 - auc: 0.6542 - loss: 0.6320\n","Epoch 10: val_loss did not improve from 0.64811\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6261 - auc: 0.6543 - loss: 0.6315 - val_acc: 0.6355 - val_auc: 0.5722 - val_loss: 0.6545\n","Epoch 11/100\n","\u001b[1m355/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6653 - auc: 0.6643 - loss: 0.6017\n","Epoch 11: val_loss improved from 0.64811 to 0.63612, saving model to best_fold_10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6653 - auc: 0.6644 - loss: 0.6016 - val_acc: 0.6355 - val_auc: 0.5728 - val_loss: 0.6361\n","Epoch 12/100\n","\u001b[1m361/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6929 - auc: 0.6573 - loss: 0.5891\n","Epoch 12: val_loss improved from 0.63612 to 0.63320, saving model to best_fold_10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6928 - auc: 0.6575 - loss: 0.5892 - val_acc: 0.6355 - val_auc: 0.5709 - val_loss: 0.6332\n","Epoch 13/100\n","\u001b[1m356/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7002 - auc: 0.7078 - loss: 0.5750\n","Epoch 13: val_loss improved from 0.63320 to 0.62806, saving model to best_fold_10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7000 - auc: 0.7072 - loss: 0.5754 - val_acc: 0.5981 - val_auc: 0.5628 - val_loss: 0.6281\n","Epoch 14/100\n","\u001b[1m360/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7034 - auc: 0.6844 - loss: 0.5878\n","Epoch 14: val_loss improved from 0.62806 to 0.62538, saving model to best_fold_10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7033 - auc: 0.6844 - loss: 0.5878 - val_acc: 0.5794 - val_auc: 0.5535 - val_loss: 0.6254\n","Epoch 15/100\n","\u001b[1m360/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6653 - auc: 0.6747 - loss: 0.5953\n","Epoch 15: val_loss improved from 0.62538 to 0.62244, saving model to best_fold_10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6656 - auc: 0.6749 - loss: 0.5951 - val_acc: 0.5701 - val_auc: 0.5505 - val_loss: 0.6224\n","Epoch 16/100\n","\u001b[1m354/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6681 - auc: 0.6949 - loss: 0.5905\n","Epoch 16: val_loss did not improve from 0.62244\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6687 - auc: 0.6950 - loss: 0.5901 - val_acc: 0.6355 - val_auc: 0.5494 - val_loss: 0.6519\n","Epoch 17/100\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7012 - auc: 0.7101 - loss: 0.5783\n","Epoch 17: val_loss improved from 0.62244 to 0.61398, saving model to best_fold_10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7012 - auc: 0.7101 - loss: 0.5783 - val_acc: 0.5701 - val_auc: 0.5294 - val_loss: 0.6140\n","Epoch 18/100\n","\u001b[1m352/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6903 - auc: 0.6950 - loss: 0.5696\n","Epoch 18: val_loss did not improve from 0.61398\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6904 - auc: 0.6952 - loss: 0.5696 - val_acc: 0.5701 - val_auc: 0.5196 - val_loss: 0.6154\n","Epoch 19/100\n","\u001b[1m356/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6824 - auc: 0.7115 - loss: 0.5717\n","Epoch 19: val_loss improved from 0.61398 to 0.60987, saving model to best_fold_10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6826 - auc: 0.7113 - loss: 0.5716 - val_acc: 0.5981 - val_auc: 0.5026 - val_loss: 0.6099\n","Epoch 20/100\n","\u001b[1m352/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6968 - auc: 0.6773 - loss: 0.5692\n","Epoch 20: val_loss did not improve from 0.60987\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6963 - auc: 0.6784 - loss: 0.5689 - val_acc: 0.5701 - val_auc: 0.4877 - val_loss: 0.6128\n","Epoch 21/100\n","\u001b[1m350/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6735 - auc: 0.7193 - loss: 0.5675\n","Epoch 21: val_loss improved from 0.60987 to 0.60760, saving model to best_fold_10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6742 - auc: 0.7189 - loss: 0.5671 - val_acc: 0.5701 - val_auc: 0.4796 - val_loss: 0.6076\n","Epoch 22/100\n","\u001b[1m355/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7085 - auc: 0.7073 - loss: 0.5433\n","Epoch 22: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7082 - auc: 0.7075 - loss: 0.5436 - val_acc: 0.4953 - val_auc: 0.4845 - val_loss: 0.6274\n","Epoch 23/100\n","\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6727 - auc: 0.6953 - loss: 0.5728\n","Epoch 23: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6730 - auc: 0.6955 - loss: 0.5725 - val_acc: 0.6355 - val_auc: 0.4778 - val_loss: 0.6339\n","Epoch 24/100\n","\u001b[1m353/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6449 - auc: 0.7115 - loss: 0.5723\n","Epoch 24: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6457 - auc: 0.7115 - loss: 0.5717 - val_acc: 0.6262 - val_auc: 0.4687 - val_loss: 0.6150\n","Epoch 25/100\n","\u001b[1m355/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6927 - auc: 0.7278 - loss: 0.5399\n","Epoch 25: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6928 - auc: 0.7275 - loss: 0.5400 - val_acc: 0.5981 - val_auc: 0.4702 - val_loss: 0.6245\n","Epoch 26/100\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7149 - auc: 0.7051 - loss: 0.5385\n","Epoch 26: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7148 - auc: 0.7051 - loss: 0.5385 - val_acc: 0.5981 - val_auc: 0.4689 - val_loss: 0.6229\n","Epoch 27/100\n","\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7021 - auc: 0.7213 - loss: 0.5343\n","Epoch 27: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7019 - auc: 0.7212 - loss: 0.5345 - val_acc: 0.5981 - val_auc: 0.4640 - val_loss: 0.6259\n","Epoch 28/100\n","\u001b[1m357/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7076 - auc: 0.6958 - loss: 0.5385\n","Epoch 28: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7075 - auc: 0.6962 - loss: 0.5385 - val_acc: 0.5607 - val_auc: 0.4663 - val_loss: 0.6187\n","Epoch 29/100\n","\u001b[1m359/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7030 - auc: 0.7160 - loss: 0.5328\n","Epoch 29: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7029 - auc: 0.7161 - loss: 0.5328 - val_acc: 0.5607 - val_auc: 0.4649 - val_loss: 0.6366\n","Epoch 30/100\n","\u001b[1m360/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7134 - auc: 0.7249 - loss: 0.5221\n","Epoch 30: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7132 - auc: 0.7248 - loss: 0.5223 - val_acc: 0.5701 - val_auc: 0.4598 - val_loss: 0.6295\n","Epoch 31/100\n","\u001b[1m362/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7216 - auc: 0.7318 - loss: 0.5129\n","Epoch 31: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7215 - auc: 0.7318 - loss: 0.5130 - val_acc: 0.5607 - val_auc: 0.4629 - val_loss: 0.6252\n","Epoch 32/100\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7099 - auc: 0.7235 - loss: 0.5361\n","Epoch 32: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7099 - auc: 0.7234 - loss: 0.5361 - val_acc: 0.5981 - val_auc: 0.4613 - val_loss: 0.6461\n","Epoch 33/100\n","\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7206 - auc: 0.7154 - loss: 0.5268\n","Epoch 33: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7203 - auc: 0.7155 - loss: 0.5268 - val_acc: 0.5607 - val_auc: 0.4619 - val_loss: 0.6404\n","Epoch 34/100\n","\u001b[1m351/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6794 - auc: 0.7213 - loss: 0.5333\n","Epoch 34: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6801 - auc: 0.7214 - loss: 0.5330 - val_acc: 0.5607 - val_auc: 0.4623 - val_loss: 0.6708\n","Epoch 35/100\n","\u001b[1m349/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6680 - auc: 0.7389 - loss: 0.5541\n","Epoch 35: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6692 - auc: 0.7388 - loss: 0.5531 - val_acc: 0.5981 - val_auc: 0.4589 - val_loss: 0.6616\n","Epoch 36/100\n","\u001b[1m360/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6961 - auc: 0.7196 - loss: 0.5376\n","Epoch 36: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6962 - auc: 0.7196 - loss: 0.5375 - val_acc: 0.6262 - val_auc: 0.4608 - val_loss: 0.6754\n","Epoch 37/100\n","\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6906 - auc: 0.7132 - loss: 0.5364\n","Epoch 37: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6908 - auc: 0.7135 - loss: 0.5362 - val_acc: 0.5514 - val_auc: 0.4640 - val_loss: 0.6760\n","Epoch 38/100\n","\u001b[1m362/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7119 - auc: 0.7251 - loss: 0.5176\n","Epoch 38: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7118 - auc: 0.7252 - loss: 0.5177 - val_acc: 0.5701 - val_auc: 0.4506 - val_loss: 0.6535\n","Epoch 39/100\n","\u001b[1m352/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7210 - auc: 0.7167 - loss: 0.5115\n","Epoch 39: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7204 - auc: 0.7169 - loss: 0.5119 - val_acc: 0.5514 - val_auc: 0.4683 - val_loss: 0.6736\n","Epoch 40/100\n","\u001b[1m355/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7047 - auc: 0.7205 - loss: 0.5334\n","Epoch 40: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7046 - auc: 0.7206 - loss: 0.5331 - val_acc: 0.5701 - val_auc: 0.4542 - val_loss: 0.6567\n","Epoch 41/100\n","\u001b[1m352/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6910 - auc: 0.7472 - loss: 0.5211\n","Epoch 41: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6913 - auc: 0.7467 - loss: 0.5209 - val_acc: 0.6075 - val_auc: 0.4485 - val_loss: 0.6910\n","Epoch 42/100\n","\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7222 - auc: 0.7087 - loss: 0.5160\n","Epoch 42: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7219 - auc: 0.7091 - loss: 0.5161 - val_acc: 0.6355 - val_auc: 0.4570 - val_loss: 0.7175\n","Epoch 43/100\n","\u001b[1m356/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7085 - auc: 0.7211 - loss: 0.5282\n","Epoch 43: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7085 - auc: 0.7215 - loss: 0.5280 - val_acc: 0.6355 - val_auc: 0.4551 - val_loss: 0.6919\n","Epoch 44/100\n","\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7206 - auc: 0.7179 - loss: 0.5091\n","Epoch 44: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7202 - auc: 0.7179 - loss: 0.5093 - val_acc: 0.6262 - val_auc: 0.4525 - val_loss: 0.6868\n","Epoch 45/100\n","\u001b[1m359/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7092 - auc: 0.7488 - loss: 0.5046\n","Epoch 45: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7092 - auc: 0.7485 - loss: 0.5047 - val_acc: 0.6355 - val_auc: 0.4542 - val_loss: 0.6939\n","Epoch 46/100\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7153 - auc: 0.7377 - loss: 0.5004\n","Epoch 46: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7153 - auc: 0.7378 - loss: 0.5005 - val_acc: 0.6355 - val_auc: 0.4438 - val_loss: 0.6882\n","Epoch 47/100\n","\u001b[1m353/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7245 - auc: 0.7489 - loss: 0.5043\n","Epoch 47: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7241 - auc: 0.7484 - loss: 0.5047 - val_acc: 0.6075 - val_auc: 0.4368 - val_loss: 0.7054\n","Epoch 48/100\n","\u001b[1m353/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7052 - auc: 0.7666 - loss: 0.4947\n","Epoch 48: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7053 - auc: 0.7660 - loss: 0.4951 - val_acc: 0.6075 - val_auc: 0.4374 - val_loss: 0.7105\n","Epoch 49/100\n","\u001b[1m353/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7296 - auc: 0.7170 - loss: 0.5039\n","Epoch 49: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7288 - auc: 0.7172 - loss: 0.5044 - val_acc: 0.5981 - val_auc: 0.4423 - val_loss: 0.7081\n","Epoch 50/100\n","\u001b[1m349/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7195 - auc: 0.7564 - loss: 0.4996\n","Epoch 50: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7191 - auc: 0.7555 - loss: 0.5003 - val_acc: 0.6355 - val_auc: 0.4442 - val_loss: 0.7233\n","Epoch 51/100\n","\u001b[1m356/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6758 - auc: 0.7365 - loss: 0.5197\n","Epoch 51: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6764 - auc: 0.7362 - loss: 0.5195 - val_acc: 0.6355 - val_auc: 0.4291 - val_loss: 0.7427\n","Epoch 52/100\n","\u001b[1m356/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7228 - auc: 0.7421 - loss: 0.4896\n","Epoch 52: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7224 - auc: 0.7418 - loss: 0.4900 - val_acc: 0.5981 - val_auc: 0.4433 - val_loss: 0.7102\n","Epoch 53/100\n","\u001b[1m356/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7076 - auc: 0.7213 - loss: 0.5112\n","Epoch 53: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7076 - auc: 0.7216 - loss: 0.5112 - val_acc: 0.5888 - val_auc: 0.4419 - val_loss: 0.7322\n","Epoch 54/100\n","\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7136 - auc: 0.7305 - loss: 0.5005\n","Epoch 54: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7134 - auc: 0.7306 - loss: 0.5006 - val_acc: 0.6355 - val_auc: 0.4327 - val_loss: 0.7568\n","Epoch 55/100\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7040 - auc: 0.7364 - loss: 0.5079\n","Epoch 55: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7040 - auc: 0.7365 - loss: 0.5079 - val_acc: 0.6355 - val_auc: 0.4470 - val_loss: 0.7286\n","Epoch 56/100\n","\u001b[1m360/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7028 - auc: 0.7566 - loss: 0.5021\n","Epoch 56: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7028 - auc: 0.7563 - loss: 0.5022 - val_acc: 0.6355 - val_auc: 0.4372 - val_loss: 0.7516\n","Epoch 57/100\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6888 - auc: 0.7436 - loss: 0.5188\n","Epoch 57: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6888 - auc: 0.7436 - loss: 0.5188 - val_acc: 0.6075 - val_auc: 0.4504 - val_loss: 0.7121\n","Epoch 58/100\n","\u001b[1m357/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7026 - auc: 0.7228 - loss: 0.5149\n","Epoch 58: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7026 - auc: 0.7231 - loss: 0.5148 - val_acc: 0.6355 - val_auc: 0.4419 - val_loss: 0.7783\n","Epoch 59/100\n","\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7249 - auc: 0.7198 - loss: 0.5018\n","Epoch 59: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7246 - auc: 0.7202 - loss: 0.5019 - val_acc: 0.5981 - val_auc: 0.4744 - val_loss: 0.7735\n","Epoch 60/100\n","\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7173 - auc: 0.7393 - loss: 0.4889\n","Epoch 60: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7171 - auc: 0.7392 - loss: 0.4892 - val_acc: 0.5981 - val_auc: 0.4619 - val_loss: 0.7569\n","Epoch 61/100\n","\u001b[1m355/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7123 - auc: 0.7884 - loss: 0.4867\n","Epoch 61: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7122 - auc: 0.7874 - loss: 0.4872 - val_acc: 0.6355 - val_auc: 0.4512 - val_loss: 0.7912\n","Epoch 62/100\n","\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6875 - auc: 0.7101 - loss: 0.5272\n","Epoch 62: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6878 - auc: 0.7105 - loss: 0.5268 - val_acc: 0.6355 - val_auc: 0.4529 - val_loss: 0.8647\n","Epoch 63/100\n","\u001b[1m362/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7227 - auc: 0.7441 - loss: 0.5014\n","Epoch 63: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7226 - auc: 0.7441 - loss: 0.5014 - val_acc: 0.6355 - val_auc: 0.4730 - val_loss: 0.7617\n","Epoch 64/100\n","\u001b[1m350/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7023 - auc: 0.7378 - loss: 0.5047\n","Epoch 64: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7025 - auc: 0.7379 - loss: 0.5047 - val_acc: 0.6355 - val_auc: 0.4644 - val_loss: 0.7816\n","Epoch 65/100\n","\u001b[1m357/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7020 - auc: 0.7558 - loss: 0.5023\n","Epoch 65: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7022 - auc: 0.7556 - loss: 0.5023 - val_acc: 0.6355 - val_auc: 0.4942 - val_loss: 0.8360\n","Epoch 66/100\n","\u001b[1m356/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6881 - auc: 0.7524 - loss: 0.5169\n","Epoch 66: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6885 - auc: 0.7523 - loss: 0.5167 - val_acc: 0.6355 - val_auc: 0.5411 - val_loss: 0.8399\n","Epoch 67/100\n","\u001b[1m354/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7124 - auc: 0.7425 - loss: 0.5099\n","Epoch 67: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7122 - auc: 0.7429 - loss: 0.5099 - val_acc: 0.6355 - val_auc: 0.5713 - val_loss: 0.7819\n","Epoch 68/100\n","\u001b[1m356/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7041 - auc: 0.7530 - loss: 0.5072\n","Epoch 68: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7042 - auc: 0.7529 - loss: 0.5071 - val_acc: 0.6355 - val_auc: 0.6063 - val_loss: 0.8683\n","Epoch 69/100\n","\u001b[1m356/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7217 - auc: 0.7481 - loss: 0.4778\n","Epoch 69: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7214 - auc: 0.7479 - loss: 0.4783 - val_acc: 0.6355 - val_auc: 0.5396 - val_loss: 0.8180\n","Epoch 70/100\n","\u001b[1m353/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6884 - auc: 0.7081 - loss: 0.5254\n","Epoch 70: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6890 - auc: 0.7091 - loss: 0.5248 - val_acc: 0.6355 - val_auc: 0.4208 - val_loss: 0.8626\n","Epoch 71/100\n","\u001b[1m355/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7235 - auc: 0.7638 - loss: 0.4882\n","Epoch 71: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7231 - auc: 0.7636 - loss: 0.4886 - val_acc: 0.6355 - val_auc: 0.6401 - val_loss: 0.8583\n","Epoch 72/100\n","\u001b[1m354/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7052 - auc: 0.7604 - loss: 0.4978\n","Epoch 72: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7052 - auc: 0.7604 - loss: 0.4978 - val_acc: 0.6355 - val_auc: 0.6499 - val_loss: 0.8913\n","Epoch 73/100\n","\u001b[1m360/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6992 - auc: 0.7756 - loss: 0.4884\n","Epoch 73: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6993 - auc: 0.7754 - loss: 0.4886 - val_acc: 0.6355 - val_auc: 0.6410 - val_loss: 0.9448\n","Epoch 74/100\n","\u001b[1m361/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7002 - auc: 0.7378 - loss: 0.5138\n","Epoch 74: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7003 - auc: 0.7379 - loss: 0.5137 - val_acc: 0.5888 - val_auc: 0.5298 - val_loss: 0.9005\n","Epoch 75/100\n","\u001b[1m351/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7493 - auc: 0.7538 - loss: 0.4731\n","Epoch 75: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7479 - auc: 0.7538 - loss: 0.4742 - val_acc: 0.6355 - val_auc: 0.6235 - val_loss: 0.8882\n","Epoch 76/100\n","\u001b[1m353/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7352 - auc: 0.7704 - loss: 0.4909\n","Epoch 76: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7345 - auc: 0.7700 - loss: 0.4913 - val_acc: 0.6355 - val_auc: 0.6521 - val_loss: 0.9152\n","Epoch 77/100\n","\u001b[1m359/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7412 - auc: 0.7311 - loss: 0.4909\n","Epoch 77: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7408 - auc: 0.7314 - loss: 0.4910 - val_acc: 0.5234 - val_auc: 0.4691 - val_loss: 0.8448\n","Epoch 78/100\n","\u001b[1m355/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7141 - auc: 0.7510 - loss: 0.5087\n","Epoch 78: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7140 - auc: 0.7512 - loss: 0.5085 - val_acc: 0.6355 - val_auc: 0.6365 - val_loss: 0.9045\n","Epoch 79/100\n","\u001b[1m359/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7001 - auc: 0.7310 - loss: 0.5097\n","Epoch 79: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7002 - auc: 0.7315 - loss: 0.5095 - val_acc: 0.5888 - val_auc: 0.4957 - val_loss: 0.8737\n","Epoch 80/100\n","\u001b[1m350/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6908 - auc: 0.7734 - loss: 0.4907\n","Epoch 80: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6916 - auc: 0.7731 - loss: 0.4908 - val_acc: 0.6355 - val_auc: 0.6275 - val_loss: 0.9747\n","Epoch 81/100\n","\u001b[1m351/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7029 - auc: 0.7583 - loss: 0.5007\n","Epoch 81: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7031 - auc: 0.7583 - loss: 0.5008 - val_acc: 0.6355 - val_auc: 0.6265 - val_loss: 0.9138\n","Epoch 82/100\n","\u001b[1m360/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7174 - auc: 0.7786 - loss: 0.4887\n","Epoch 82: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7174 - auc: 0.7784 - loss: 0.4889 - val_acc: 0.5981 - val_auc: 0.5315 - val_loss: 0.8915\n","Epoch 83/100\n","\u001b[1m353/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6934 - auc: 0.7693 - loss: 0.5058\n","Epoch 83: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6940 - auc: 0.7693 - loss: 0.5055 - val_acc: 0.6355 - val_auc: 0.4896 - val_loss: 0.9509\n","Epoch 84/100\n","\u001b[1m357/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7031 - auc: 0.7794 - loss: 0.5006\n","Epoch 84: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7034 - auc: 0.7791 - loss: 0.5005 - val_acc: 0.6355 - val_auc: 0.5528 - val_loss: 0.9260\n","Epoch 85/100\n","\u001b[1m359/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7001 - auc: 0.7685 - loss: 0.5044\n","Epoch 85: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7004 - auc: 0.7685 - loss: 0.5043 - val_acc: 0.6355 - val_auc: 0.4553 - val_loss: 0.9784\n","Epoch 86/100\n","\u001b[1m362/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7391 - auc: 0.7657 - loss: 0.4904\n","Epoch 86: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7390 - auc: 0.7658 - loss: 0.4905 - val_acc: 0.6355 - val_auc: 0.5409 - val_loss: 0.9747\n","Epoch 87/100\n","\u001b[1m354/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7270 - auc: 0.7584 - loss: 0.4993\n","Epoch 87: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7270 - auc: 0.7587 - loss: 0.4991 - val_acc: 0.6355 - val_auc: 0.6184 - val_loss: 1.0418\n","Epoch 88/100\n","\u001b[1m361/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7140 - auc: 0.7562 - loss: 0.4952\n","Epoch 88: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7140 - auc: 0.7562 - loss: 0.4952 - val_acc: 0.6355 - val_auc: 0.5332 - val_loss: 0.9788\n","Epoch 89/100\n","\u001b[1m354/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7123 - auc: 0.7868 - loss: 0.4790\n","Epoch 89: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7127 - auc: 0.7864 - loss: 0.4793 - val_acc: 0.6449 - val_auc: 0.4979 - val_loss: 1.0447\n","Epoch 90/100\n","\u001b[1m353/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7301 - auc: 0.7846 - loss: 0.4884\n","Epoch 90: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7302 - auc: 0.7844 - loss: 0.4884 - val_acc: 0.6355 - val_auc: 0.6635 - val_loss: 1.0375\n","Epoch 91/100\n","\u001b[1m356/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7411 - auc: 0.7743 - loss: 0.4910\n","Epoch 91: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7411 - auc: 0.7743 - loss: 0.4908 - val_acc: 0.6355 - val_auc: 0.6175 - val_loss: 1.0914\n","Epoch 92/100\n","\u001b[1m354/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7509 - auc: 0.7936 - loss: 0.4579\n","Epoch 92: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7503 - auc: 0.7934 - loss: 0.4586 - val_acc: 0.6355 - val_auc: 0.6567 - val_loss: 1.0398\n","Epoch 93/100\n","\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7532 - auc: 0.7962 - loss: 0.4619\n","Epoch 93: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7529 - auc: 0.7960 - loss: 0.4622 - val_acc: 0.6355 - val_auc: 0.5143 - val_loss: 0.9830\n","Epoch 94/100\n","\u001b[1m350/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7388 - auc: 0.7738 - loss: 0.4793\n","Epoch 94: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7387 - auc: 0.7737 - loss: 0.4794 - val_acc: 0.6355 - val_auc: 0.6165 - val_loss: 1.0586\n","Epoch 95/100\n","\u001b[1m357/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7337 - auc: 0.7790 - loss: 0.4889\n","Epoch 95: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7337 - auc: 0.7790 - loss: 0.4888 - val_acc: 0.6355 - val_auc: 0.6312 - val_loss: 1.0820\n","Epoch 96/100\n","\u001b[1m354/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7257 - auc: 0.7797 - loss: 0.4946\n","Epoch 96: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7260 - auc: 0.7798 - loss: 0.4942 - val_acc: 0.6355 - val_auc: 0.5705 - val_loss: 0.9871\n","Epoch 97/100\n","\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7368 - auc: 0.7678 - loss: 0.4819\n","Epoch 97: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7368 - auc: 0.7679 - loss: 0.4819 - val_acc: 0.6355 - val_auc: 0.5984 - val_loss: 1.0142\n","Epoch 98/100\n","\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7431 - auc: 0.8031 - loss: 0.4699\n","Epoch 98: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7429 - auc: 0.8027 - loss: 0.4701 - val_acc: 0.6449 - val_auc: 0.6574 - val_loss: 1.1686\n","Epoch 99/100\n","\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7476 - auc: 0.8076 - loss: 0.4729\n","Epoch 99: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.7476 - auc: 0.8074 - loss: 0.4731 - val_acc: 0.6355 - val_auc: 0.6616 - val_loss: 1.0728\n","Epoch 100/100\n","\u001b[1m357/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7373 - auc: 0.7791 - loss: 0.4857\n","Epoch 100: val_loss did not improve from 0.60760\n","\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7374 - auc: 0.7792 - loss: 0.4855 - val_acc: 0.6355 - val_auc: 0.5400 - val_loss: 1.0182\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 10 | TEST ACC=0.8000 | TEST AUC=1.0000 | n=5\n","Confusion matrix:\n"," [[4 0]\n"," [1 0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.800     1.000     0.889         4\n","           1      0.000     0.000     0.000         1\n","\n","    accuracy                          0.800         5\n","   macro avg      0.400     0.500     0.444         5\n","weighted avg      0.640     0.800     0.711         5\n","\n","\n","--- Fold 11/14 ---\n"," train | ids:   36 | files:  1007 | pos files:  362 | neg files:  645\n","   val | ids:    5 | files:   135 | pos files:    5 | neg files:  130\n","  test | ids:    3 | files:    58 | pos files:   38 | neg files:   20\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m323/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6278 - auc: 0.4930 - loss: 0.6850\n","Epoch 1: val_loss improved from inf to 0.48585, saving model to best_fold_11.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - acc: 0.6284 - auc: 0.4934 - loss: 0.6845 - val_acc: 0.9630 - val_auc: 0.0692 - val_loss: 0.4859\n","Epoch 2/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6330 - auc: 0.5328 - loss: 0.6556\n","Epoch 2: val_loss improved from 0.48585 to 0.47424, saving model to best_fold_11.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6332 - auc: 0.5325 - loss: 0.6555 - val_acc: 0.9630 - val_auc: 0.1577 - val_loss: 0.4742\n","Epoch 3/100\n","\u001b[1m333/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6703 - auc: 0.5369 - loss: 0.6323\n","Epoch 3: val_loss did not improve from 0.47424\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6699 - auc: 0.5368 - loss: 0.6325 - val_acc: 0.9630 - val_auc: 0.1769 - val_loss: 0.4952\n","Epoch 4/100\n","\u001b[1m331/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6337 - auc: 0.5567 - loss: 0.6534\n","Epoch 4: val_loss improved from 0.47424 to 0.45667, saving model to best_fold_11.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6338 - auc: 0.5570 - loss: 0.6533 - val_acc: 0.9630 - val_auc: 0.1846 - val_loss: 0.4567\n","Epoch 5/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6436 - auc: 0.5678 - loss: 0.6455\n","Epoch 5: val_loss did not improve from 0.45667\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6436 - auc: 0.5683 - loss: 0.6455 - val_acc: 0.9630 - val_auc: 0.1938 - val_loss: 0.4653\n","Epoch 6/100\n","\u001b[1m331/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6459 - auc: 0.6191 - loss: 0.6354\n","Epoch 6: val_loss improved from 0.45667 to 0.41711, saving model to best_fold_11.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6458 - auc: 0.6192 - loss: 0.6354 - val_acc: 0.9630 - val_auc: 0.1969 - val_loss: 0.4171\n","Epoch 7/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6450 - auc: 0.6503 - loss: 0.6252\n","Epoch 7: val_loss did not improve from 0.41711\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6448 - auc: 0.6502 - loss: 0.6253 - val_acc: 0.9630 - val_auc: 0.2023 - val_loss: 0.4869\n","Epoch 8/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6285 - auc: 0.6437 - loss: 0.6318\n","Epoch 8: val_loss improved from 0.41711 to 0.40346, saving model to best_fold_11.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6288 - auc: 0.6439 - loss: 0.6315 - val_acc: 0.9630 - val_auc: 0.2123 - val_loss: 0.4035\n","Epoch 9/100\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6381 - auc: 0.6683 - loss: 0.6126\n","Epoch 9: val_loss improved from 0.40346 to 0.36682, saving model to best_fold_11.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6381 - auc: 0.6683 - loss: 0.6125 - val_acc: 0.9630 - val_auc: 0.2262 - val_loss: 0.3668\n","Epoch 10/100\n","\u001b[1m332/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6378 - auc: 0.6653 - loss: 0.6098\n","Epoch 10: val_loss did not improve from 0.36682\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6379 - auc: 0.6654 - loss: 0.6097 - val_acc: 0.9630 - val_auc: 0.2508 - val_loss: 0.3894\n","Epoch 11/100\n","\u001b[1m334/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6544 - auc: 0.6847 - loss: 0.5977\n","Epoch 11: val_loss did not improve from 0.36682\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6544 - auc: 0.6846 - loss: 0.5977 - val_acc: 0.9630 - val_auc: 0.2677 - val_loss: 0.3900\n","Epoch 12/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6769 - auc: 0.6964 - loss: 0.5798\n","Epoch 12: val_loss improved from 0.36682 to 0.35138, saving model to best_fold_11.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6765 - auc: 0.6960 - loss: 0.5800 - val_acc: 0.9630 - val_auc: 0.2623 - val_loss: 0.3514\n","Epoch 13/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6475 - auc: 0.6890 - loss: 0.5827\n","Epoch 13: val_loss did not improve from 0.35138\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6482 - auc: 0.6891 - loss: 0.5827 - val_acc: 0.9630 - val_auc: 0.2715 - val_loss: 0.3882\n","Epoch 14/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6660 - auc: 0.6860 - loss: 0.5829\n","Epoch 14: val_loss did not improve from 0.35138\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6660 - auc: 0.6861 - loss: 0.5828 - val_acc: 0.9630 - val_auc: 0.2754 - val_loss: 0.3550\n","Epoch 15/100\n","\u001b[1m329/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6784 - auc: 0.6746 - loss: 0.5775\n","Epoch 15: val_loss improved from 0.35138 to 0.35063, saving model to best_fold_11.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6782 - auc: 0.6749 - loss: 0.5775 - val_acc: 0.9630 - val_auc: 0.2892 - val_loss: 0.3506\n","Epoch 16/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6369 - auc: 0.6713 - loss: 0.5873\n","Epoch 16: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6376 - auc: 0.6718 - loss: 0.5869 - val_acc: 0.9630 - val_auc: 0.3062 - val_loss: 0.3776\n","Epoch 17/100\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6510 - auc: 0.6833 - loss: 0.5698\n","Epoch 17: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6510 - auc: 0.6833 - loss: 0.5698 - val_acc: 0.9630 - val_auc: 0.3238 - val_loss: 0.3806\n","Epoch 18/100\n","\u001b[1m333/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7044 - auc: 0.7170 - loss: 0.5538\n","Epoch 18: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7040 - auc: 0.7168 - loss: 0.5539 - val_acc: 0.9630 - val_auc: 0.3531 - val_loss: 0.3963\n","Epoch 19/100\n","\u001b[1m334/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6442 - auc: 0.6742 - loss: 0.5716\n","Epoch 19: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6444 - auc: 0.6744 - loss: 0.5715 - val_acc: 0.9630 - val_auc: 0.3585 - val_loss: 0.4146\n","Epoch 20/100\n","\u001b[1m331/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6709 - auc: 0.6983 - loss: 0.5574\n","Epoch 20: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6709 - auc: 0.6983 - loss: 0.5575 - val_acc: 0.9630 - val_auc: 0.3338 - val_loss: 0.4058\n","Epoch 21/100\n","\u001b[1m324/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6532 - auc: 0.6991 - loss: 0.5581\n","Epoch 21: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6535 - auc: 0.6992 - loss: 0.5582 - val_acc: 0.9630 - val_auc: 0.3677 - val_loss: 0.4194\n","Epoch 22/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6693 - auc: 0.6830 - loss: 0.5738\n","Epoch 22: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6691 - auc: 0.6835 - loss: 0.5733 - val_acc: 0.9630 - val_auc: 0.3738 - val_loss: 0.4372\n","Epoch 23/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6427 - auc: 0.6913 - loss: 0.5579\n","Epoch 23: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6431 - auc: 0.6914 - loss: 0.5579 - val_acc: 0.9556 - val_auc: 0.3215 - val_loss: 0.4255\n","Epoch 24/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7183 - auc: 0.7097 - loss: 0.5307\n","Epoch 24: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7170 - auc: 0.7096 - loss: 0.5312 - val_acc: 0.9630 - val_auc: 0.4108 - val_loss: 0.4690\n","Epoch 25/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6523 - auc: 0.7265 - loss: 0.5441\n","Epoch 25: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6526 - auc: 0.7258 - loss: 0.5442 - val_acc: 0.9630 - val_auc: 0.4108 - val_loss: 0.4846\n","Epoch 26/100\n","\u001b[1m324/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6405 - auc: 0.6953 - loss: 0.5566\n","Epoch 26: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6413 - auc: 0.6954 - loss: 0.5563 - val_acc: 0.9556 - val_auc: 0.4108 - val_loss: 0.4884\n","Epoch 27/100\n","\u001b[1m334/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6715 - auc: 0.7126 - loss: 0.5423\n","Epoch 27: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6715 - auc: 0.7125 - loss: 0.5423 - val_acc: 0.9630 - val_auc: 0.4269 - val_loss: 0.5234\n","Epoch 28/100\n","\u001b[1m325/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6553 - auc: 0.6865 - loss: 0.5554\n","Epoch 28: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6558 - auc: 0.6869 - loss: 0.5550 - val_acc: 0.9556 - val_auc: 0.4015 - val_loss: 0.4800\n","Epoch 29/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6722 - auc: 0.7108 - loss: 0.5490\n","Epoch 29: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6722 - auc: 0.7105 - loss: 0.5488 - val_acc: 0.9630 - val_auc: 0.4231 - val_loss: 0.5247\n","Epoch 30/100\n","\u001b[1m323/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6696 - auc: 0.7007 - loss: 0.5408\n","Epoch 30: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6695 - auc: 0.7010 - loss: 0.5407 - val_acc: 0.9630 - val_auc: 0.4169 - val_loss: 0.5349\n","Epoch 31/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6692 - auc: 0.6979 - loss: 0.5426\n","Epoch 31: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6694 - auc: 0.6980 - loss: 0.5424 - val_acc: 0.9630 - val_auc: 0.4138 - val_loss: 0.5380\n","Epoch 32/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6498 - auc: 0.6725 - loss: 0.5611\n","Epoch 32: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6502 - auc: 0.6731 - loss: 0.5606 - val_acc: 0.9630 - val_auc: 0.4177 - val_loss: 0.5706\n","Epoch 33/100\n","\u001b[1m335/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6804 - auc: 0.6718 - loss: 0.5437\n","Epoch 33: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6804 - auc: 0.6720 - loss: 0.5437 - val_acc: 0.9630 - val_auc: 0.4262 - val_loss: 0.6068\n","Epoch 34/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6893 - auc: 0.6987 - loss: 0.5273\n","Epoch 34: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6892 - auc: 0.6990 - loss: 0.5275 - val_acc: 0.9630 - val_auc: 0.4077 - val_loss: 0.4970\n","Epoch 35/100\n","\u001b[1m322/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6841 - auc: 0.6880 - loss: 0.5316\n","Epoch 35: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6841 - auc: 0.6888 - loss: 0.5318 - val_acc: 0.9556 - val_auc: 0.4108 - val_loss: 0.5243\n","Epoch 36/100\n","\u001b[1m335/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6740 - auc: 0.7268 - loss: 0.5248\n","Epoch 36: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6740 - auc: 0.7267 - loss: 0.5248 - val_acc: 0.9630 - val_auc: 0.4169 - val_loss: 0.5949\n","Epoch 37/100\n","\u001b[1m335/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6597 - auc: 0.7156 - loss: 0.5325\n","Epoch 37: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6598 - auc: 0.7156 - loss: 0.5325 - val_acc: 0.9630 - val_auc: 0.4169 - val_loss: 0.5595\n","Epoch 38/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6913 - auc: 0.7141 - loss: 0.5206\n","Epoch 38: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6908 - auc: 0.7141 - loss: 0.5209 - val_acc: 0.9630 - val_auc: 0.4131 - val_loss: 0.5650\n","Epoch 39/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6973 - auc: 0.7515 - loss: 0.5011\n","Epoch 39: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6966 - auc: 0.7504 - loss: 0.5018 - val_acc: 0.9630 - val_auc: 0.4262 - val_loss: 0.5904\n","Epoch 40/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6798 - auc: 0.7071 - loss: 0.5325\n","Epoch 40: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6798 - auc: 0.7074 - loss: 0.5324 - val_acc: 0.9630 - val_auc: 0.4169 - val_loss: 0.5390\n","Epoch 41/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6741 - auc: 0.7078 - loss: 0.5277\n","Epoch 41: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6742 - auc: 0.7079 - loss: 0.5276 - val_acc: 0.9630 - val_auc: 0.4123 - val_loss: 0.5173\n","Epoch 42/100\n","\u001b[1m331/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6745 - auc: 0.7055 - loss: 0.5382\n","Epoch 42: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6747 - auc: 0.7058 - loss: 0.5379 - val_acc: 0.9630 - val_auc: 0.4162 - val_loss: 0.5870\n","Epoch 43/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7169 - auc: 0.7398 - loss: 0.5036\n","Epoch 43: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7162 - auc: 0.7395 - loss: 0.5042 - val_acc: 0.9630 - val_auc: 0.4069 - val_loss: 0.4952\n","Epoch 44/100\n","\u001b[1m333/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6836 - auc: 0.7283 - loss: 0.5275\n","Epoch 44: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6836 - auc: 0.7282 - loss: 0.5275 - val_acc: 0.9630 - val_auc: 0.4192 - val_loss: 0.5297\n","Epoch 45/100\n","\u001b[1m329/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6834 - auc: 0.7258 - loss: 0.5321\n","Epoch 45: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6839 - auc: 0.7261 - loss: 0.5319 - val_acc: 0.9556 - val_auc: 0.4262 - val_loss: 0.5824\n","Epoch 46/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6732 - auc: 0.7286 - loss: 0.5350\n","Epoch 46: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6742 - auc: 0.7291 - loss: 0.5344 - val_acc: 0.9630 - val_auc: 0.4323 - val_loss: 0.6035\n","Epoch 47/100\n","\u001b[1m325/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7103 - auc: 0.7494 - loss: 0.5218\n","Epoch 47: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7101 - auc: 0.7496 - loss: 0.5216 - val_acc: 0.9333 - val_auc: 0.4146 - val_loss: 0.5809\n","Epoch 48/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7119 - auc: 0.7568 - loss: 0.5255\n","Epoch 48: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7123 - auc: 0.7572 - loss: 0.5250 - val_acc: 0.8963 - val_auc: 0.4308 - val_loss: 0.6333\n","Epoch 49/100\n","\u001b[1m331/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7142 - auc: 0.7795 - loss: 0.5099\n","Epoch 49: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7142 - auc: 0.7791 - loss: 0.5098 - val_acc: 0.8741 - val_auc: 0.4231 - val_loss: 0.5961\n","Epoch 50/100\n","\u001b[1m325/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7166 - auc: 0.7806 - loss: 0.4889\n","Epoch 50: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7167 - auc: 0.7799 - loss: 0.4892 - val_acc: 0.9037 - val_auc: 0.4492 - val_loss: 0.8066\n","Epoch 51/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7314 - auc: 0.7553 - loss: 0.4957\n","Epoch 51: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7314 - auc: 0.7558 - loss: 0.4957 - val_acc: 0.8370 - val_auc: 0.4108 - val_loss: 0.6689\n","Epoch 52/100\n","\u001b[1m334/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7466 - auc: 0.7922 - loss: 0.5054\n","Epoch 52: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7466 - auc: 0.7923 - loss: 0.5053 - val_acc: 0.7111 - val_auc: 0.4231 - val_loss: 0.8430\n","Epoch 53/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7256 - auc: 0.7839 - loss: 0.4915\n","Epoch 53: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7259 - auc: 0.7838 - loss: 0.4915 - val_acc: 0.8963 - val_auc: 0.4185 - val_loss: 0.6112\n","Epoch 54/100\n","\u001b[1m325/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7585 - auc: 0.7892 - loss: 0.4910\n","Epoch 54: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7580 - auc: 0.7890 - loss: 0.4908 - val_acc: 0.8815 - val_auc: 0.4085 - val_loss: 0.6894\n","Epoch 55/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7648 - auc: 0.7921 - loss: 0.4756\n","Epoch 55: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7638 - auc: 0.7916 - loss: 0.4759 - val_acc: 0.8815 - val_auc: 0.4231 - val_loss: 0.6839\n","Epoch 56/100\n","\u001b[1m324/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7372 - auc: 0.7948 - loss: 0.4635\n","Epoch 56: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7368 - auc: 0.7943 - loss: 0.4643 - val_acc: 0.8741 - val_auc: 0.4262 - val_loss: 0.7302\n","Epoch 57/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7336 - auc: 0.7750 - loss: 0.4885\n","Epoch 57: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7334 - auc: 0.7753 - loss: 0.4883 - val_acc: 0.8741 - val_auc: 0.4200 - val_loss: 0.7597\n","Epoch 58/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7290 - auc: 0.7770 - loss: 0.4819\n","Epoch 58: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7291 - auc: 0.7768 - loss: 0.4821 - val_acc: 0.8370 - val_auc: 0.4200 - val_loss: 0.8003\n","Epoch 59/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7415 - auc: 0.7915 - loss: 0.4728\n","Epoch 59: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7412 - auc: 0.7911 - loss: 0.4731 - val_acc: 0.9556 - val_auc: 0.4154 - val_loss: 0.5992\n","Epoch 60/100\n","\u001b[1m331/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7231 - auc: 0.7882 - loss: 0.4823\n","Epoch 60: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7232 - auc: 0.7881 - loss: 0.4823 - val_acc: 0.9333 - val_auc: 0.4115 - val_loss: 0.5566\n","Epoch 61/100\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7197 - auc: 0.7809 - loss: 0.4982\n","Epoch 61: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7197 - auc: 0.7809 - loss: 0.4981 - val_acc: 0.8667 - val_auc: 0.4308 - val_loss: 0.8120\n","Epoch 62/100\n","\u001b[1m332/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7036 - auc: 0.7338 - loss: 0.5166\n","Epoch 62: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7041 - auc: 0.7344 - loss: 0.5161 - val_acc: 0.9037 - val_auc: 0.4015 - val_loss: 0.5444\n","Epoch 63/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7600 - auc: 0.8016 - loss: 0.4653\n","Epoch 63: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7591 - auc: 0.8016 - loss: 0.4657 - val_acc: 0.9185 - val_auc: 0.4231 - val_loss: 0.6043\n","Epoch 64/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7207 - auc: 0.7704 - loss: 0.4948\n","Epoch 64: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7212 - auc: 0.7709 - loss: 0.4944 - val_acc: 0.8741 - val_auc: 0.4054 - val_loss: 0.6710\n","Epoch 65/100\n","\u001b[1m325/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7538 - auc: 0.8312 - loss: 0.4465\n","Epoch 65: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7535 - auc: 0.8298 - loss: 0.4475 - val_acc: 0.8815 - val_auc: 0.4154 - val_loss: 0.5786\n","Epoch 66/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7223 - auc: 0.7813 - loss: 0.4922\n","Epoch 66: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7226 - auc: 0.7813 - loss: 0.4919 - val_acc: 0.9556 - val_auc: 0.4031 - val_loss: 0.5577\n","Epoch 67/100\n","\u001b[1m324/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7249 - auc: 0.7511 - loss: 0.5117\n","Epoch 67: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7256 - auc: 0.7526 - loss: 0.5104 - val_acc: 0.8815 - val_auc: 0.4400 - val_loss: 0.8589\n","Epoch 68/100\n","\u001b[1m329/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7498 - auc: 0.8016 - loss: 0.4591\n","Epoch 68: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7494 - auc: 0.8011 - loss: 0.4596 - val_acc: 0.9259 - val_auc: 0.4000 - val_loss: 0.5454\n","Epoch 69/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7361 - auc: 0.8126 - loss: 0.4672\n","Epoch 69: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7362 - auc: 0.8121 - loss: 0.4675 - val_acc: 0.8963 - val_auc: 0.4108 - val_loss: 0.5968\n","Epoch 70/100\n","\u001b[1m333/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7446 - auc: 0.8075 - loss: 0.4706\n","Epoch 70: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7446 - auc: 0.8073 - loss: 0.4707 - val_acc: 0.8889 - val_auc: 0.4231 - val_loss: 0.6944\n","Epoch 71/100\n","\u001b[1m329/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7590 - auc: 0.8157 - loss: 0.4623\n","Epoch 71: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7588 - auc: 0.8152 - loss: 0.4625 - val_acc: 0.9111 - val_auc: 0.4154 - val_loss: 0.6641\n","Epoch 72/100\n","\u001b[1m332/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7728 - auc: 0.8127 - loss: 0.4464\n","Epoch 72: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7723 - auc: 0.8123 - loss: 0.4469 - val_acc: 0.9037 - val_auc: 0.4100 - val_loss: 0.5645\n","Epoch 73/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7501 - auc: 0.8102 - loss: 0.4576\n","Epoch 73: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7498 - auc: 0.8099 - loss: 0.4580 - val_acc: 0.9111 - val_auc: 0.4062 - val_loss: 0.5922\n","Epoch 74/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7214 - auc: 0.7812 - loss: 0.4814\n","Epoch 74: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7220 - auc: 0.7813 - loss: 0.4813 - val_acc: 0.9185 - val_auc: 0.4085 - val_loss: 0.5293\n","Epoch 75/100\n","\u001b[1m329/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7457 - auc: 0.8009 - loss: 0.4715\n","Epoch 75: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7455 - auc: 0.8006 - loss: 0.4716 - val_acc: 0.8444 - val_auc: 0.4031 - val_loss: 0.6341\n","Epoch 76/100\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7435 - auc: 0.7835 - loss: 0.4751\n","Epoch 76: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7435 - auc: 0.7836 - loss: 0.4751 - val_acc: 0.9111 - val_auc: 0.4085 - val_loss: 0.7036\n","Epoch 77/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7580 - auc: 0.7965 - loss: 0.4552\n","Epoch 77: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7577 - auc: 0.7964 - loss: 0.4555 - val_acc: 0.9111 - val_auc: 0.4000 - val_loss: 0.5820\n","Epoch 78/100\n","\u001b[1m332/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7304 - auc: 0.7844 - loss: 0.4670\n","Epoch 78: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7307 - auc: 0.7847 - loss: 0.4670 - val_acc: 0.8667 - val_auc: 0.4100 - val_loss: 0.6986\n","Epoch 79/100\n","\u001b[1m333/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7350 - auc: 0.7550 - loss: 0.4876\n","Epoch 79: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7352 - auc: 0.7553 - loss: 0.4873 - val_acc: 0.8963 - val_auc: 0.4200 - val_loss: 0.8417\n","Epoch 80/100\n","\u001b[1m333/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7496 - auc: 0.7937 - loss: 0.4600\n","Epoch 80: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7495 - auc: 0.7935 - loss: 0.4602 - val_acc: 0.8519 - val_auc: 0.4000 - val_loss: 0.6690\n","Epoch 81/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7600 - auc: 0.7903 - loss: 0.4543\n","Epoch 81: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7599 - auc: 0.7905 - loss: 0.4546 - val_acc: 0.8963 - val_auc: 0.4023 - val_loss: 0.6189\n","Epoch 82/100\n","\u001b[1m326/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7429 - auc: 0.7889 - loss: 0.4808\n","Epoch 82: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7431 - auc: 0.7891 - loss: 0.4804 - val_acc: 0.8741 - val_auc: 0.3969 - val_loss: 0.6740\n","Epoch 83/100\n","\u001b[1m325/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7562 - auc: 0.8177 - loss: 0.4595\n","Epoch 83: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7561 - auc: 0.8171 - loss: 0.4599 - val_acc: 0.8370 - val_auc: 0.4192 - val_loss: 0.7650\n","Epoch 84/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7338 - auc: 0.7801 - loss: 0.4803\n","Epoch 84: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7341 - auc: 0.7804 - loss: 0.4801 - val_acc: 0.8889 - val_auc: 0.4077 - val_loss: 0.6375\n","Epoch 85/100\n","\u001b[1m325/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7429 - auc: 0.8201 - loss: 0.4458\n","Epoch 85: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7429 - auc: 0.8196 - loss: 0.4462 - val_acc: 0.9259 - val_auc: 0.4046 - val_loss: 0.6039\n","Epoch 86/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7605 - auc: 0.7751 - loss: 0.4672\n","Epoch 86: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7602 - auc: 0.7756 - loss: 0.4671 - val_acc: 0.8074 - val_auc: 0.4077 - val_loss: 0.8336\n","Epoch 87/100\n","\u001b[1m335/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7414 - auc: 0.8086 - loss: 0.4588\n","Epoch 87: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7415 - auc: 0.8086 - loss: 0.4588 - val_acc: 0.8815 - val_auc: 0.4338 - val_loss: 0.8464\n","Epoch 88/100\n","\u001b[1m334/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7581 - auc: 0.8094 - loss: 0.4729\n","Epoch 88: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7581 - auc: 0.8094 - loss: 0.4727 - val_acc: 0.8296 - val_auc: 0.3954 - val_loss: 0.8226\n","Epoch 89/100\n","\u001b[1m332/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7655 - auc: 0.7962 - loss: 0.4671\n","Epoch 89: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7654 - auc: 0.7963 - loss: 0.4670 - val_acc: 0.8222 - val_auc: 0.3969 - val_loss: 0.8025\n","Epoch 90/100\n","\u001b[1m331/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7634 - auc: 0.8012 - loss: 0.4611\n","Epoch 90: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7633 - auc: 0.8012 - loss: 0.4611 - val_acc: 0.8667 - val_auc: 0.4077 - val_loss: 0.7372\n","Epoch 91/100\n","\u001b[1m329/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7348 - auc: 0.8051 - loss: 0.4764\n","Epoch 91: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7352 - auc: 0.8053 - loss: 0.4760 - val_acc: 0.8667 - val_auc: 0.3954 - val_loss: 0.7919\n","Epoch 92/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7599 - auc: 0.8095 - loss: 0.4561\n","Epoch 92: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7597 - auc: 0.8092 - loss: 0.4563 - val_acc: 0.8370 - val_auc: 0.3969 - val_loss: 0.7182\n","Epoch 93/100\n","\u001b[1m331/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7743 - auc: 0.8165 - loss: 0.4389\n","Epoch 93: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7741 - auc: 0.8164 - loss: 0.4392 - val_acc: 0.8667 - val_auc: 0.3962 - val_loss: 0.7125\n","Epoch 94/100\n","\u001b[1m327/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7562 - auc: 0.8079 - loss: 0.4498\n","Epoch 94: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7564 - auc: 0.8079 - loss: 0.4502 - val_acc: 0.7778 - val_auc: 0.3954 - val_loss: 0.7494\n","Epoch 95/100\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7413 - auc: 0.7719 - loss: 0.4803\n","Epoch 95: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7413 - auc: 0.7720 - loss: 0.4802 - val_acc: 0.8593 - val_auc: 0.3954 - val_loss: 0.6571\n","Epoch 96/100\n","\u001b[1m329/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7580 - auc: 0.8122 - loss: 0.4664\n","Epoch 96: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7580 - auc: 0.8125 - loss: 0.4663 - val_acc: 0.8296 - val_auc: 0.4077 - val_loss: 0.7738\n","Epoch 97/100\n","\u001b[1m330/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7410 - auc: 0.7876 - loss: 0.4748\n","Epoch 97: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7412 - auc: 0.7881 - loss: 0.4744 - val_acc: 0.8741 - val_auc: 0.3992 - val_loss: 0.6204\n","Epoch 98/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7774 - auc: 0.8211 - loss: 0.4340\n","Epoch 98: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7770 - auc: 0.8206 - loss: 0.4347 - val_acc: 0.8667 - val_auc: 0.3985 - val_loss: 0.6344\n","Epoch 99/100\n","\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7894 - auc: 0.8325 - loss: 0.4387\n","Epoch 99: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7888 - auc: 0.8316 - loss: 0.4394 - val_acc: 0.8519 - val_auc: 0.3962 - val_loss: 0.6553\n","Epoch 100/100\n","\u001b[1m333/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7616 - auc: 0.8007 - loss: 0.4649\n","Epoch 100: val_loss did not improve from 0.35063\n","\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7617 - auc: 0.8008 - loss: 0.4647 - val_acc: 0.9185 - val_auc: 0.4000 - val_loss: 0.6675\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:tensorflow:5 out of the last 42 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b09939822a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 11 | TEST ACC=0.1379 | TEST AUC=0.0724 | n=58\n","Confusion matrix:\n"," [[ 7 13]\n"," [37  1]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.159     0.350     0.219        20\n","           1      0.071     0.026     0.038        38\n","\n","    accuracy                          0.138        58\n","   macro avg      0.115     0.188     0.129        58\n","weighted avg      0.102     0.138     0.101        58\n","\n","\n","--- Fold 12/14 ---\n"," train | ids:   36 | files:   882 | pos files:  307 | neg files:  575\n","   val | ids:    5 | files:   169 | pos files:   39 | neg files:  130\n","  test | ids:    3 | files:   149 | pos files:   59 | neg files:   90\n","Epoch 1/100\n","\u001b[1m292/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6301 - auc: 0.4466 - loss: 0.6864\n","Epoch 1: val_loss improved from inf to 0.62978, saving model to best_fold_12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - acc: 0.6302 - auc: 0.4468 - loss: 0.6864 - val_acc: 0.7692 - val_auc: 0.4634 - val_loss: 0.6298\n","Epoch 2/100\n","\u001b[1m282/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6458 - auc: 0.4970 - loss: 0.6581\n","Epoch 2: val_loss improved from 0.62978 to 0.58038, saving model to best_fold_12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6460 - auc: 0.4967 - loss: 0.6579 - val_acc: 0.7692 - val_auc: 0.4486 - val_loss: 0.5804\n","Epoch 3/100\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6875 - auc: 0.4477 - loss: 0.6286\n","Epoch 3: val_loss did not improve from 0.58038\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6874 - auc: 0.4477 - loss: 0.6287 - val_acc: 0.7692 - val_auc: 0.4448 - val_loss: 0.5859\n","Epoch 4/100\n","\u001b[1m290/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6208 - auc: 0.4718 - loss: 0.6660\n","Epoch 4: val_loss improved from 0.58038 to 0.57521, saving model to best_fold_12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6213 - auc: 0.4722 - loss: 0.6657 - val_acc: 0.7692 - val_auc: 0.4685 - val_loss: 0.5752\n","Epoch 5/100\n","\u001b[1m288/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6405 - auc: 0.4691 - loss: 0.6556\n","Epoch 5: val_loss improved from 0.57521 to 0.57415, saving model to best_fold_12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6407 - auc: 0.4698 - loss: 0.6554 - val_acc: 0.7692 - val_auc: 0.5217 - val_loss: 0.5741\n","Epoch 6/100\n","\u001b[1m284/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6332 - auc: 0.4578 - loss: 0.6604\n","Epoch 6: val_loss improved from 0.57415 to 0.55707, saving model to best_fold_12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6339 - auc: 0.4590 - loss: 0.6600 - val_acc: 0.7692 - val_auc: 0.6324 - val_loss: 0.5571\n","Epoch 7/100\n","\u001b[1m283/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6312 - auc: 0.5032 - loss: 0.6610\n","Epoch 7: val_loss improved from 0.55707 to 0.55627, saving model to best_fold_12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6320 - auc: 0.5041 - loss: 0.6603 - val_acc: 0.7692 - val_auc: 0.7619 - val_loss: 0.5563\n","Epoch 8/100\n","\u001b[1m281/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6437 - auc: 0.5707 - loss: 0.6449\n","Epoch 8: val_loss improved from 0.55627 to 0.54583, saving model to best_fold_12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6442 - auc: 0.5697 - loss: 0.6446 - val_acc: 0.7692 - val_auc: 0.8160 - val_loss: 0.5458\n","Epoch 9/100\n","\u001b[1m281/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6323 - auc: 0.5909 - loss: 0.6470\n","Epoch 9: val_loss improved from 0.54583 to 0.52777, saving model to best_fold_12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6333 - auc: 0.5900 - loss: 0.6465 - val_acc: 0.7692 - val_auc: 0.8419 - val_loss: 0.5278\n","Epoch 10/100\n","\u001b[1m283/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6596 - auc: 0.5929 - loss: 0.6254\n","Epoch 10: val_loss improved from 0.52777 to 0.52152, saving model to best_fold_12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6592 - auc: 0.5923 - loss: 0.6257 - val_acc: 0.7692 - val_auc: 0.8564 - val_loss: 0.5215\n","Epoch 11/100\n","\u001b[1m282/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6298 - auc: 0.5802 - loss: 0.6412\n","Epoch 11: val_loss improved from 0.52152 to 0.48176, saving model to best_fold_12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6307 - auc: 0.5810 - loss: 0.6404 - val_acc: 0.7692 - val_auc: 0.8450 - val_loss: 0.4818\n","Epoch 12/100\n","\u001b[1m282/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6539 - auc: 0.5949 - loss: 0.6175\n","Epoch 12: val_loss improved from 0.48176 to 0.48060, saving model to best_fold_12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6537 - auc: 0.5952 - loss: 0.6174 - val_acc: 0.7692 - val_auc: 0.8373 - val_loss: 0.4806\n","Epoch 13/100\n","\u001b[1m291/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6590 - auc: 0.5753 - loss: 0.6098\n","Epoch 13: val_loss improved from 0.48060 to 0.45653, saving model to best_fold_12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6589 - auc: 0.5757 - loss: 0.6097 - val_acc: 0.7692 - val_auc: 0.8199 - val_loss: 0.4565\n","Epoch 14/100\n","\u001b[1m282/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6557 - auc: 0.6037 - loss: 0.5997\n","Epoch 14: val_loss improved from 0.45653 to 0.40179, saving model to best_fold_12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6554 - auc: 0.6038 - loss: 0.5997 - val_acc: 0.7692 - val_auc: 0.8260 - val_loss: 0.4018\n","Epoch 15/100\n","\u001b[1m281/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6263 - auc: 0.6064 - loss: 0.6146\n","Epoch 15: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6275 - auc: 0.6072 - loss: 0.6135 - val_acc: 0.7692 - val_auc: 0.8160 - val_loss: 0.4195\n","Epoch 16/100\n","\u001b[1m293/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6483 - auc: 0.6487 - loss: 0.5789\n","Epoch 16: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6483 - auc: 0.6486 - loss: 0.5789 - val_acc: 0.7692 - val_auc: 0.8095 - val_loss: 0.4185\n","Epoch 17/100\n","\u001b[1m284/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6305 - auc: 0.6251 - loss: 0.5998\n","Epoch 17: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6314 - auc: 0.6259 - loss: 0.5991 - val_acc: 0.7692 - val_auc: 0.8301 - val_loss: 0.4052\n","Epoch 18/100\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6738 - auc: 0.6375 - loss: 0.5591\n","Epoch 18: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6738 - auc: 0.6375 - loss: 0.5592 - val_acc: 0.7692 - val_auc: 0.8073 - val_loss: 0.4327\n","Epoch 19/100\n","\u001b[1m283/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6116 - auc: 0.6466 - loss: 0.6071\n","Epoch 19: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6134 - auc: 0.6467 - loss: 0.6059 - val_acc: 0.7692 - val_auc: 0.8330 - val_loss: 0.4122\n","Epoch 20/100\n","\u001b[1m293/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6473 - auc: 0.6507 - loss: 0.5647\n","Epoch 20: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6473 - auc: 0.6506 - loss: 0.5647 - val_acc: 0.7692 - val_auc: 0.8376 - val_loss: 0.4192\n","Epoch 21/100\n","\u001b[1m284/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6475 - auc: 0.6515 - loss: 0.5876\n","Epoch 21: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6477 - auc: 0.6520 - loss: 0.5870 - val_acc: 0.7692 - val_auc: 0.8461 - val_loss: 0.4348\n","Epoch 22/100\n","\u001b[1m289/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6525 - auc: 0.6447 - loss: 0.5656\n","Epoch 22: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6525 - auc: 0.6445 - loss: 0.5659 - val_acc: 0.7692 - val_auc: 0.8453 - val_loss: 0.4465\n","Epoch 23/100\n","\u001b[1m287/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6622 - auc: 0.6560 - loss: 0.5726\n","Epoch 23: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6619 - auc: 0.6562 - loss: 0.5726 - val_acc: 0.7692 - val_auc: 0.8214 - val_loss: 0.4252\n","Epoch 24/100\n","\u001b[1m286/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6495 - auc: 0.6493 - loss: 0.5748\n","Epoch 24: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6496 - auc: 0.6495 - loss: 0.5747 - val_acc: 0.7692 - val_auc: 0.8332 - val_loss: 0.4368\n","Epoch 25/100\n","\u001b[1m283/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6738 - auc: 0.6514 - loss: 0.5593\n","Epoch 25: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6730 - auc: 0.6525 - loss: 0.5598 - val_acc: 0.7692 - val_auc: 0.8421 - val_loss: 0.4512\n","Epoch 26/100\n","\u001b[1m287/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6254 - auc: 0.6864 - loss: 0.5673\n","Epoch 26: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6261 - auc: 0.6860 - loss: 0.5674 - val_acc: 0.7692 - val_auc: 0.8403 - val_loss: 0.4459\n","Epoch 27/100\n","\u001b[1m284/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6252 - auc: 0.6723 - loss: 0.6112\n","Epoch 27: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6261 - auc: 0.6723 - loss: 0.6098 - val_acc: 0.7692 - val_auc: 0.8423 - val_loss: 0.4558\n","Epoch 28/100\n","\u001b[1m282/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6402 - auc: 0.6655 - loss: 0.5784\n","Epoch 28: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6408 - auc: 0.6659 - loss: 0.5778 - val_acc: 0.7692 - val_auc: 0.8332 - val_loss: 0.4648\n","Epoch 29/100\n","\u001b[1m283/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6249 - auc: 0.6701 - loss: 0.5885\n","Epoch 29: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6260 - auc: 0.6706 - loss: 0.5878 - val_acc: 0.7692 - val_auc: 0.8380 - val_loss: 0.4697\n","Epoch 30/100\n","\u001b[1m293/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6606 - auc: 0.7194 - loss: 0.5506\n","Epoch 30: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6605 - auc: 0.7192 - loss: 0.5507 - val_acc: 0.7692 - val_auc: 0.8244 - val_loss: 0.4546\n","Epoch 31/100\n","\u001b[1m289/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6622 - auc: 0.6984 - loss: 0.5768\n","Epoch 31: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6620 - auc: 0.6986 - loss: 0.5764 - val_acc: 0.7692 - val_auc: 0.8345 - val_loss: 0.4904\n","Epoch 32/100\n","\u001b[1m287/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6539 - auc: 0.7269 - loss: 0.5607\n","Epoch 32: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6538 - auc: 0.7268 - loss: 0.5608 - val_acc: 0.7692 - val_auc: 0.8272 - val_loss: 0.4837\n","Epoch 33/100\n","\u001b[1m281/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6839 - auc: 0.7399 - loss: 0.5325\n","Epoch 33: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6827 - auc: 0.7394 - loss: 0.5337 - val_acc: 0.7574 - val_auc: 0.8029 - val_loss: 0.4401\n","Epoch 34/100\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6778 - auc: 0.7270 - loss: 0.5483\n","Epoch 34: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6777 - auc: 0.7270 - loss: 0.5484 - val_acc: 0.7456 - val_auc: 0.7925 - val_loss: 0.4432\n","Epoch 35/100\n","\u001b[1m293/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6655 - auc: 0.7217 - loss: 0.5707\n","Epoch 35: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6656 - auc: 0.7219 - loss: 0.5707 - val_acc: 0.7633 - val_auc: 0.7849 - val_loss: 0.4576\n","Epoch 36/100\n","\u001b[1m283/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6983 - auc: 0.7478 - loss: 0.5790\n","Epoch 36: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6985 - auc: 0.7472 - loss: 0.5782 - val_acc: 0.7278 - val_auc: 0.7799 - val_loss: 0.4922\n","Epoch 37/100\n","\u001b[1m281/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6947 - auc: 0.7604 - loss: 0.5621\n","Epoch 37: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6957 - auc: 0.7605 - loss: 0.5616 - val_acc: 0.7692 - val_auc: 0.8168 - val_loss: 0.5506\n","Epoch 38/100\n","\u001b[1m285/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6952 - auc: 0.7151 - loss: 0.5721\n","Epoch 38: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6958 - auc: 0.7162 - loss: 0.5713 - val_acc: 0.7278 - val_auc: 0.7738 - val_loss: 0.4887\n","Epoch 39/100\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6899 - auc: 0.7277 - loss: 0.5604\n","Epoch 39: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6900 - auc: 0.7277 - loss: 0.5604 - val_acc: 0.7278 - val_auc: 0.7590 - val_loss: 0.5062\n","Epoch 40/100\n","\u001b[1m290/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6964 - auc: 0.7398 - loss: 0.5449\n","Epoch 40: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6964 - auc: 0.7401 - loss: 0.5448 - val_acc: 0.7337 - val_auc: 0.7629 - val_loss: 0.4810\n","Epoch 41/100\n","\u001b[1m290/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7253 - auc: 0.7390 - loss: 0.5518\n","Epoch 41: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7253 - auc: 0.7396 - loss: 0.5515 - val_acc: 0.7160 - val_auc: 0.7557 - val_loss: 0.5076\n","Epoch 42/100\n","\u001b[1m292/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7150 - auc: 0.7542 - loss: 0.5555\n","Epoch 42: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7151 - auc: 0.7544 - loss: 0.5552 - val_acc: 0.7101 - val_auc: 0.7592 - val_loss: 0.5495\n","Epoch 43/100\n","\u001b[1m285/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7142 - auc: 0.7853 - loss: 0.5328\n","Epoch 43: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7145 - auc: 0.7851 - loss: 0.5326 - val_acc: 0.7101 - val_auc: 0.7633 - val_loss: 0.5188\n","Epoch 44/100\n","\u001b[1m282/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6970 - auc: 0.7533 - loss: 0.5638\n","Epoch 44: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6978 - auc: 0.7537 - loss: 0.5625 - val_acc: 0.7160 - val_auc: 0.7579 - val_loss: 0.5296\n","Epoch 45/100\n","\u001b[1m283/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7159 - auc: 0.7734 - loss: 0.5332\n","Epoch 45: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7165 - auc: 0.7734 - loss: 0.5330 - val_acc: 0.7278 - val_auc: 0.7550 - val_loss: 0.5212\n","Epoch 46/100\n","\u001b[1m284/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7396 - auc: 0.7734 - loss: 0.5200\n","Epoch 46: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7393 - auc: 0.7733 - loss: 0.5202 - val_acc: 0.6923 - val_auc: 0.7475 - val_loss: 0.5526\n","Epoch 47/100\n","\u001b[1m283/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7524 - auc: 0.7852 - loss: 0.5198\n","Epoch 47: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7516 - auc: 0.7846 - loss: 0.5200 - val_acc: 0.6923 - val_auc: 0.7536 - val_loss: 0.5566\n","Epoch 48/100\n","\u001b[1m282/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7202 - auc: 0.7945 - loss: 0.5153\n","Epoch 48: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7206 - auc: 0.7936 - loss: 0.5156 - val_acc: 0.6923 - val_auc: 0.7523 - val_loss: 0.5574\n","Epoch 49/100\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7529 - auc: 0.7739 - loss: 0.5112\n","Epoch 49: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7528 - auc: 0.7739 - loss: 0.5112 - val_acc: 0.7101 - val_auc: 0.7555 - val_loss: 0.5800\n","Epoch 50/100\n","\u001b[1m286/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7305 - auc: 0.7766 - loss: 0.5077\n","Epoch 50: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7307 - auc: 0.7768 - loss: 0.5080 - val_acc: 0.6864 - val_auc: 0.7450 - val_loss: 0.5696\n","Epoch 51/100\n","\u001b[1m286/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7624 - auc: 0.8012 - loss: 0.4968\n","Epoch 51: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7618 - auc: 0.8007 - loss: 0.4974 - val_acc: 0.6923 - val_auc: 0.7489 - val_loss: 0.5509\n","Epoch 52/100\n","\u001b[1m281/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7636 - auc: 0.7821 - loss: 0.5028\n","Epoch 52: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7626 - auc: 0.7820 - loss: 0.5034 - val_acc: 0.6923 - val_auc: 0.7420 - val_loss: 0.5964\n","Epoch 53/100\n","\u001b[1m284/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7473 - auc: 0.7840 - loss: 0.5091\n","Epoch 53: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7475 - auc: 0.7843 - loss: 0.5092 - val_acc: 0.6982 - val_auc: 0.7464 - val_loss: 0.6307\n","Epoch 54/100\n","\u001b[1m281/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7137 - auc: 0.7768 - loss: 0.5096\n","Epoch 54: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7145 - auc: 0.7766 - loss: 0.5102 - val_acc: 0.7101 - val_auc: 0.7493 - val_loss: 0.5944\n","Epoch 55/100\n","\u001b[1m284/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7334 - auc: 0.7771 - loss: 0.5247\n","Epoch 55: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7337 - auc: 0.7775 - loss: 0.5243 - val_acc: 0.6864 - val_auc: 0.7418 - val_loss: 0.5768\n","Epoch 56/100\n","\u001b[1m288/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7409 - auc: 0.7729 - loss: 0.5274\n","Epoch 56: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7409 - auc: 0.7731 - loss: 0.5270 - val_acc: 0.6982 - val_auc: 0.7299 - val_loss: 0.6168\n","Epoch 57/100\n","\u001b[1m287/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7146 - auc: 0.7682 - loss: 0.5287\n","Epoch 57: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7153 - auc: 0.7687 - loss: 0.5283 - val_acc: 0.6982 - val_auc: 0.7321 - val_loss: 0.6289\n","Epoch 58/100\n","\u001b[1m283/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7628 - auc: 0.8169 - loss: 0.4889\n","Epoch 58: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7622 - auc: 0.8159 - loss: 0.4896 - val_acc: 0.6864 - val_auc: 0.7361 - val_loss: 0.6281\n","Epoch 59/100\n","\u001b[1m288/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7354 - auc: 0.7788 - loss: 0.5267\n","Epoch 59: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7355 - auc: 0.7790 - loss: 0.5264 - val_acc: 0.7101 - val_auc: 0.7558 - val_loss: 0.5527\n","Epoch 60/100\n","\u001b[1m288/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7477 - auc: 0.8039 - loss: 0.5168\n","Epoch 60: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7476 - auc: 0.8038 - loss: 0.5167 - val_acc: 0.7041 - val_auc: 0.7514 - val_loss: 0.5947\n","Epoch 61/100\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7620 - auc: 0.7938 - loss: 0.5001\n","Epoch 61: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7620 - auc: 0.7938 - loss: 0.5001 - val_acc: 0.6982 - val_auc: 0.7465 - val_loss: 0.6070\n","Epoch 62/100\n","\u001b[1m292/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7059 - auc: 0.7698 - loss: 0.5337\n","Epoch 62: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7063 - auc: 0.7699 - loss: 0.5335 - val_acc: 0.7041 - val_auc: 0.7460 - val_loss: 0.5848\n","Epoch 63/100\n","\u001b[1m282/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7570 - auc: 0.7956 - loss: 0.4965\n","Epoch 63: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7565 - auc: 0.7955 - loss: 0.4969 - val_acc: 0.6982 - val_auc: 0.7477 - val_loss: 0.5423\n","Epoch 64/100\n","\u001b[1m292/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7569 - auc: 0.7821 - loss: 0.5100\n","Epoch 64: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7569 - auc: 0.7821 - loss: 0.5099 - val_acc: 0.6923 - val_auc: 0.7421 - val_loss: 0.6387\n","Epoch 65/100\n","\u001b[1m283/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7408 - auc: 0.7743 - loss: 0.5287\n","Epoch 65: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7408 - auc: 0.7750 - loss: 0.5279 - val_acc: 0.6864 - val_auc: 0.7412 - val_loss: 0.5892\n","Epoch 66/100\n","\u001b[1m284/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7582 - auc: 0.8333 - loss: 0.4758\n","Epoch 66: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7577 - auc: 0.8320 - loss: 0.4768 - val_acc: 0.7101 - val_auc: 0.7573 - val_loss: 0.5569\n","Epoch 67/100\n","\u001b[1m281/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7370 - auc: 0.7972 - loss: 0.5041\n","Epoch 67: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7369 - auc: 0.7966 - loss: 0.5046 - val_acc: 0.7101 - val_auc: 0.7306 - val_loss: 0.6548\n","Epoch 68/100\n","\u001b[1m290/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7278 - auc: 0.7693 - loss: 0.5229\n","Epoch 68: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7282 - auc: 0.7697 - loss: 0.5226 - val_acc: 0.7041 - val_auc: 0.7230 - val_loss: 0.6825\n","Epoch 69/100\n","\u001b[1m289/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7529 - auc: 0.7933 - loss: 0.4970\n","Epoch 69: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7530 - auc: 0.7933 - loss: 0.4972 - val_acc: 0.6923 - val_auc: 0.7372 - val_loss: 0.6248\n","Epoch 70/100\n","\u001b[1m281/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7540 - auc: 0.7836 - loss: 0.4976\n","Epoch 70: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7540 - auc: 0.7845 - loss: 0.4975 - val_acc: 0.6982 - val_auc: 0.7370 - val_loss: 0.6564\n","Epoch 71/100\n","\u001b[1m285/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7440 - auc: 0.7991 - loss: 0.5039\n","Epoch 71: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7441 - auc: 0.7991 - loss: 0.5039 - val_acc: 0.7041 - val_auc: 0.7460 - val_loss: 0.6021\n","Epoch 72/100\n","\u001b[1m293/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7301 - auc: 0.7885 - loss: 0.5221\n","Epoch 72: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7302 - auc: 0.7886 - loss: 0.5220 - val_acc: 0.7101 - val_auc: 0.7264 - val_loss: 0.6630\n","Epoch 73/100\n","\u001b[1m284/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7513 - auc: 0.7977 - loss: 0.5088\n","Epoch 73: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7516 - auc: 0.7976 - loss: 0.5086 - val_acc: 0.6982 - val_auc: 0.7522 - val_loss: 0.5545\n","Epoch 74/100\n","\u001b[1m286/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7410 - auc: 0.8001 - loss: 0.4812\n","Epoch 74: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7413 - auc: 0.8003 - loss: 0.4817 - val_acc: 0.6982 - val_auc: 0.7301 - val_loss: 0.6603\n","Epoch 75/100\n","\u001b[1m283/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7525 - auc: 0.8112 - loss: 0.4869\n","Epoch 75: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7522 - auc: 0.8106 - loss: 0.4875 - val_acc: 0.6923 - val_auc: 0.7258 - val_loss: 0.6814\n","Epoch 76/100\n","\u001b[1m283/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7393 - auc: 0.7924 - loss: 0.5132\n","Epoch 76: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7396 - auc: 0.7927 - loss: 0.5127 - val_acc: 0.6982 - val_auc: 0.6823 - val_loss: 0.7071\n","Epoch 77/100\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7326 - auc: 0.7933 - loss: 0.5163\n","Epoch 77: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7327 - auc: 0.7934 - loss: 0.5162 - val_acc: 0.6982 - val_auc: 0.7295 - val_loss: 0.6647\n","Epoch 78/100\n","\u001b[1m284/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7600 - auc: 0.8276 - loss: 0.4719\n","Epoch 78: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.7600 - auc: 0.8267 - loss: 0.4727 - val_acc: 0.7101 - val_auc: 0.7434 - val_loss: 0.6205\n","Epoch 79/100\n","\u001b[1m293/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7759 - auc: 0.8178 - loss: 0.4734\n","Epoch 79: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.7757 - auc: 0.8177 - loss: 0.4735 - val_acc: 0.7101 - val_auc: 0.7448 - val_loss: 0.6349\n","Epoch 80/100\n","\u001b[1m286/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7678 - auc: 0.8169 - loss: 0.4561\n","Epoch 80: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7671 - auc: 0.8165 - loss: 0.4573 - val_acc: 0.7041 - val_auc: 0.7418 - val_loss: 0.6596\n","Epoch 81/100\n","\u001b[1m292/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7478 - auc: 0.8266 - loss: 0.4861\n","Epoch 81: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7479 - auc: 0.8264 - loss: 0.4862 - val_acc: 0.7278 - val_auc: 0.7203 - val_loss: 0.6831\n","Epoch 82/100\n","\u001b[1m289/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7602 - auc: 0.7961 - loss: 0.4942\n","Epoch 82: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7599 - auc: 0.7961 - loss: 0.4943 - val_acc: 0.7101 - val_auc: 0.7489 - val_loss: 0.5669\n","Epoch 83/100\n","\u001b[1m287/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7323 - auc: 0.7890 - loss: 0.5040\n","Epoch 83: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7327 - auc: 0.7892 - loss: 0.5039 - val_acc: 0.6923 - val_auc: 0.7123 - val_loss: 0.7045\n","Epoch 84/100\n","\u001b[1m292/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7804 - auc: 0.8093 - loss: 0.4720\n","Epoch 84: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7803 - auc: 0.8093 - loss: 0.4722 - val_acc: 0.6805 - val_auc: 0.7165 - val_loss: 0.7165\n","Epoch 85/100\n","\u001b[1m281/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7783 - auc: 0.8098 - loss: 0.4990\n","Epoch 85: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7775 - auc: 0.8095 - loss: 0.4986 - val_acc: 0.7101 - val_auc: 0.7496 - val_loss: 0.5786\n","Epoch 86/100\n","\u001b[1m293/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7632 - auc: 0.8140 - loss: 0.4820\n","Epoch 86: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7631 - auc: 0.8140 - loss: 0.4821 - val_acc: 0.7160 - val_auc: 0.7072 - val_loss: 0.7456\n","Epoch 87/100\n","\u001b[1m290/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7356 - auc: 0.7920 - loss: 0.5033\n","Epoch 87: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.7359 - auc: 0.7924 - loss: 0.5032 - val_acc: 0.6864 - val_auc: 0.6662 - val_loss: 0.7823\n","Epoch 88/100\n","\u001b[1m281/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7388 - auc: 0.7999 - loss: 0.4912\n","Epoch 88: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.7392 - auc: 0.8002 - loss: 0.4914 - val_acc: 0.7160 - val_auc: 0.6860 - val_loss: 0.7279\n","Epoch 89/100\n","\u001b[1m283/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7486 - auc: 0.8225 - loss: 0.4988\n","Epoch 89: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7489 - auc: 0.8222 - loss: 0.4983 - val_acc: 0.7160 - val_auc: 0.7086 - val_loss: 0.7021\n","Epoch 90/100\n","\u001b[1m281/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7570 - auc: 0.8114 - loss: 0.4993\n","Epoch 90: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7565 - auc: 0.8111 - loss: 0.4990 - val_acc: 0.7278 - val_auc: 0.6900 - val_loss: 0.7344\n","Epoch 91/100\n","\u001b[1m292/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7073 - auc: 0.7831 - loss: 0.5302\n","Epoch 91: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7077 - auc: 0.7834 - loss: 0.5297 - val_acc: 0.7219 - val_auc: 0.7502 - val_loss: 0.6229\n","Epoch 92/100\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7212 - auc: 0.7912 - loss: 0.5171\n","Epoch 92: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7213 - auc: 0.7912 - loss: 0.5170 - val_acc: 0.7101 - val_auc: 0.7243 - val_loss: 0.7148\n","Epoch 93/100\n","\u001b[1m292/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7837 - auc: 0.8227 - loss: 0.4627\n","Epoch 93: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7834 - auc: 0.8226 - loss: 0.4630 - val_acc: 0.7160 - val_auc: 0.7337 - val_loss: 0.6934\n","Epoch 94/100\n","\u001b[1m282/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7520 - auc: 0.8029 - loss: 0.4822\n","Epoch 94: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7517 - auc: 0.8031 - loss: 0.4826 - val_acc: 0.7160 - val_auc: 0.7263 - val_loss: 0.6861\n","Epoch 95/100\n","\u001b[1m281/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7556 - auc: 0.8185 - loss: 0.4730\n","Epoch 95: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7553 - auc: 0.8182 - loss: 0.4737 - val_acc: 0.7041 - val_auc: 0.6683 - val_loss: 0.7704\n","Epoch 96/100\n","\u001b[1m292/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7619 - auc: 0.7934 - loss: 0.4982\n","Epoch 96: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7618 - auc: 0.7936 - loss: 0.4981 - val_acc: 0.7278 - val_auc: 0.7121 - val_loss: 0.7110\n","Epoch 97/100\n","\u001b[1m287/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7402 - auc: 0.7949 - loss: 0.4975\n","Epoch 97: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7404 - auc: 0.7953 - loss: 0.4973 - val_acc: 0.7101 - val_auc: 0.6638 - val_loss: 0.8078\n","Epoch 98/100\n","\u001b[1m283/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7540 - auc: 0.7957 - loss: 0.4918\n","Epoch 98: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7539 - auc: 0.7963 - loss: 0.4917 - val_acc: 0.7160 - val_auc: 0.7247 - val_loss: 0.7151\n","Epoch 99/100\n","\u001b[1m292/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7596 - auc: 0.8128 - loss: 0.4906\n","Epoch 99: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7594 - auc: 0.8128 - loss: 0.4906 - val_acc: 0.7219 - val_auc: 0.7366 - val_loss: 0.6731\n","Epoch 100/100\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7598 - auc: 0.8295 - loss: 0.4638\n","Epoch 100: val_loss did not improve from 0.40179\n","\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7598 - auc: 0.8295 - loss: 0.4639 - val_acc: 0.7219 - val_auc: 0.6902 - val_loss: 0.7459\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 12 | TEST ACC=0.6040 | TEST AUC=0.6269 | n=149\n","Confusion matrix:\n"," [[90  0]\n"," [59  0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.604     1.000     0.753        90\n","           1      0.000     0.000     0.000        59\n","\n","    accuracy                          0.604       149\n","   macro avg      0.302     0.500     0.377       149\n","weighted avg      0.365     0.604     0.455       149\n","\n","\n","--- Fold 13/14 ---\n"," train | ids:   36 | files:   921 | pos files:  324 | neg files:  597\n","   val | ids:    5 | files:   182 | pos files:   39 | neg files:  143\n","  test | ids:    3 | files:    97 | pos files:   42 | neg files:   55\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m297/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6458 - auc: 0.5121 - loss: 0.6771\n","Epoch 1: val_loss improved from inf to 0.58487, saving model to best_fold_13.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - acc: 0.6459 - auc: 0.5122 - loss: 0.6767 - val_acc: 0.7857 - val_auc: 0.3593 - val_loss: 0.5849\n","Epoch 2/100\n","\u001b[1m300/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6331 - auc: 0.6066 - loss: 0.6494\n","Epoch 2: val_loss improved from 0.58487 to 0.56079, saving model to best_fold_13.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6335 - auc: 0.6066 - loss: 0.6491 - val_acc: 0.7857 - val_auc: 0.3759 - val_loss: 0.5608\n","Epoch 3/100\n","\u001b[1m299/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6435 - auc: 0.6931 - loss: 0.6298\n","Epoch 3: val_loss did not improve from 0.56079\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6437 - auc: 0.6919 - loss: 0.6298 - val_acc: 0.7857 - val_auc: 0.4629 - val_loss: 0.5718\n","Epoch 4/100\n","\u001b[1m295/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6374 - auc: 0.6822 - loss: 0.6264\n","Epoch 4: val_loss did not improve from 0.56079\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6378 - auc: 0.6829 - loss: 0.6258 - val_acc: 0.7857 - val_auc: 0.5447 - val_loss: 0.5958\n","Epoch 5/100\n","\u001b[1m297/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6369 - auc: 0.6876 - loss: 0.6115\n","Epoch 5: val_loss did not improve from 0.56079\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6374 - auc: 0.6884 - loss: 0.6109 - val_acc: 0.7857 - val_auc: 0.5633 - val_loss: 0.5925\n","Epoch 6/100\n","\u001b[1m306/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6790 - auc: 0.7058 - loss: 0.5934\n","Epoch 6: val_loss did not improve from 0.56079\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6791 - auc: 0.7059 - loss: 0.5933 - val_acc: 0.7198 - val_auc: 0.5623 - val_loss: 0.5864\n","Epoch 7/100\n","\u001b[1m303/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7139 - auc: 0.7402 - loss: 0.5765\n","Epoch 7: val_loss did not improve from 0.56079\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7137 - auc: 0.7401 - loss: 0.5765 - val_acc: 0.6868 - val_auc: 0.5712 - val_loss: 0.5643\n","Epoch 8/100\n","\u001b[1m305/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6874 - auc: 0.7053 - loss: 0.5860\n","Epoch 8: val_loss did not improve from 0.56079\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6875 - auc: 0.7055 - loss: 0.5859 - val_acc: 0.6703 - val_auc: 0.5728 - val_loss: 0.5655\n","Epoch 9/100\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6881 - auc: 0.7055 - loss: 0.5737\n","Epoch 9: val_loss did not improve from 0.56079\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6881 - auc: 0.7056 - loss: 0.5737 - val_acc: 0.6593 - val_auc: 0.5718 - val_loss: 0.5722\n","Epoch 10/100\n","\u001b[1m302/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6886 - auc: 0.7317 - loss: 0.5817\n","Epoch 10: val_loss improved from 0.56079 to 0.52777, saving model to best_fold_13.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6888 - auc: 0.7318 - loss: 0.5814 - val_acc: 0.7473 - val_auc: 0.5801 - val_loss: 0.5278\n","Epoch 11/100\n","\u001b[1m300/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6966 - auc: 0.7503 - loss: 0.5635\n","Epoch 11: val_loss did not improve from 0.52777\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6970 - auc: 0.7500 - loss: 0.5634 - val_acc: 0.6319 - val_auc: 0.5706 - val_loss: 0.5597\n","Epoch 12/100\n","\u001b[1m301/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7143 - auc: 0.7541 - loss: 0.5509\n","Epoch 12: val_loss did not improve from 0.52777\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7140 - auc: 0.7537 - loss: 0.5511 - val_acc: 0.6429 - val_auc: 0.5724 - val_loss: 0.5837\n","Epoch 13/100\n","\u001b[1m299/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6971 - auc: 0.7429 - loss: 0.5652\n","Epoch 13: val_loss improved from 0.52777 to 0.51407, saving model to best_fold_13.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6971 - auc: 0.7428 - loss: 0.5650 - val_acc: 0.7473 - val_auc: 0.5810 - val_loss: 0.5141\n","Epoch 14/100\n","\u001b[1m295/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6852 - auc: 0.7312 - loss: 0.5769\n","Epoch 14: val_loss did not improve from 0.51407\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6856 - auc: 0.7316 - loss: 0.5762 - val_acc: 0.6264 - val_auc: 0.5754 - val_loss: 0.5431\n","Epoch 15/100\n","\u001b[1m304/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6866 - auc: 0.7122 - loss: 0.5635\n","Epoch 15: val_loss did not improve from 0.51407\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6867 - auc: 0.7125 - loss: 0.5634 - val_acc: 0.6648 - val_auc: 0.5772 - val_loss: 0.5289\n","Epoch 16/100\n","\u001b[1m295/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6981 - auc: 0.7392 - loss: 0.5726\n","Epoch 16: val_loss did not improve from 0.51407\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6985 - auc: 0.7396 - loss: 0.5716 - val_acc: 0.6538 - val_auc: 0.5790 - val_loss: 0.5214\n","Epoch 17/100\n","\u001b[1m303/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7346 - auc: 0.7509 - loss: 0.5338\n","Epoch 17: val_loss did not improve from 0.51407\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7340 - auc: 0.7509 - loss: 0.5341 - val_acc: 0.6264 - val_auc: 0.5777 - val_loss: 0.5334\n","Epoch 18/100\n","\u001b[1m295/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7285 - auc: 0.7779 - loss: 0.5275\n","Epoch 18: val_loss did not improve from 0.51407\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7273 - auc: 0.7766 - loss: 0.5285 - val_acc: 0.6429 - val_auc: 0.5776 - val_loss: 0.5251\n","Epoch 19/100\n","\u001b[1m297/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7084 - auc: 0.7165 - loss: 0.5567\n","Epoch 19: val_loss did not improve from 0.51407\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7081 - auc: 0.7175 - loss: 0.5564 - val_acc: 0.6154 - val_auc: 0.5747 - val_loss: 0.5461\n","Epoch 20/100\n","\u001b[1m298/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6868 - auc: 0.7361 - loss: 0.5562\n","Epoch 20: val_loss improved from 0.51407 to 0.50652, saving model to best_fold_13.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6869 - auc: 0.7364 - loss: 0.5559 - val_acc: 0.7033 - val_auc: 0.5784 - val_loss: 0.5065\n","Epoch 21/100\n","\u001b[1m297/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6955 - auc: 0.7410 - loss: 0.5625\n","Epoch 21: val_loss did not improve from 0.50652\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6956 - auc: 0.7413 - loss: 0.5620 - val_acc: 0.6648 - val_auc: 0.5760 - val_loss: 0.5271\n","Epoch 22/100\n","\u001b[1m299/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6928 - auc: 0.7368 - loss: 0.5516\n","Epoch 22: val_loss did not improve from 0.50652\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6932 - auc: 0.7371 - loss: 0.5513 - val_acc: 0.6319 - val_auc: 0.5757 - val_loss: 0.5316\n","Epoch 23/100\n","\u001b[1m294/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7123 - auc: 0.7583 - loss: 0.5564\n","Epoch 23: val_loss improved from 0.50652 to 0.49310, saving model to best_fold_13.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.7122 - auc: 0.7577 - loss: 0.5560 - val_acc: 0.7527 - val_auc: 0.5772 - val_loss: 0.4931\n","Epoch 24/100\n","\u001b[1m303/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7104 - auc: 0.7289 - loss: 0.5428\n","Epoch 24: val_loss did not improve from 0.49310\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7103 - auc: 0.7291 - loss: 0.5428 - val_acc: 0.6374 - val_auc: 0.5744 - val_loss: 0.5232\n","Epoch 25/100\n","\u001b[1m306/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7072 - auc: 0.7412 - loss: 0.5509\n","Epoch 25: val_loss did not improve from 0.49310\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7073 - auc: 0.7412 - loss: 0.5509 - val_acc: 0.7363 - val_auc: 0.5758 - val_loss: 0.5001\n","Epoch 26/100\n","\u001b[1m298/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7255 - auc: 0.7510 - loss: 0.5456\n","Epoch 26: val_loss did not improve from 0.49310\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7251 - auc: 0.7510 - loss: 0.5454 - val_acc: 0.7198 - val_auc: 0.5741 - val_loss: 0.5081\n","Epoch 27/100\n","\u001b[1m296/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7356 - auc: 0.7599 - loss: 0.5252\n","Epoch 27: val_loss did not improve from 0.49310\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7348 - auc: 0.7594 - loss: 0.5258 - val_acc: 0.7143 - val_auc: 0.5706 - val_loss: 0.5032\n","Epoch 28/100\n","\u001b[1m299/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7173 - auc: 0.7706 - loss: 0.5144\n","Epoch 28: val_loss did not improve from 0.49310\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7171 - auc: 0.7701 - loss: 0.5149 - val_acc: 0.6648 - val_auc: 0.5683 - val_loss: 0.5195\n","Epoch 29/100\n","\u001b[1m304/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7119 - auc: 0.7564 - loss: 0.5391\n","Epoch 29: val_loss did not improve from 0.49310\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7119 - auc: 0.7565 - loss: 0.5390 - val_acc: 0.6978 - val_auc: 0.5663 - val_loss: 0.5086\n","Epoch 30/100\n","\u001b[1m301/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7068 - auc: 0.7399 - loss: 0.5400\n","Epoch 30: val_loss did not improve from 0.49310\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7067 - auc: 0.7401 - loss: 0.5400 - val_acc: 0.6264 - val_auc: 0.5672 - val_loss: 0.5444\n","Epoch 31/100\n","\u001b[1m303/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6857 - auc: 0.7355 - loss: 0.5625\n","Epoch 31: val_loss did not improve from 0.49310\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6860 - auc: 0.7358 - loss: 0.5621 - val_acc: 0.7253 - val_auc: 0.5593 - val_loss: 0.4977\n","Epoch 32/100\n","\u001b[1m299/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6868 - auc: 0.7427 - loss: 0.5562\n","Epoch 32: val_loss did not improve from 0.49310\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6877 - auc: 0.7430 - loss: 0.5556 - val_acc: 0.6264 - val_auc: 0.5666 - val_loss: 0.5371\n","Epoch 33/100\n","\u001b[1m303/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7144 - auc: 0.7354 - loss: 0.5508\n","Epoch 33: val_loss did not improve from 0.49310\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7143 - auc: 0.7357 - loss: 0.5505 - val_acc: 0.6648 - val_auc: 0.5562 - val_loss: 0.5108\n","Epoch 34/100\n","\u001b[1m301/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6940 - auc: 0.7399 - loss: 0.5407\n","Epoch 34: val_loss improved from 0.49310 to 0.48836, saving model to best_fold_13.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6943 - auc: 0.7401 - loss: 0.5406 - val_acc: 0.7473 - val_auc: 0.5369 - val_loss: 0.4884\n","Epoch 35/100\n","\u001b[1m294/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7301 - auc: 0.7208 - loss: 0.5282\n","Epoch 35: val_loss did not improve from 0.48836\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7294 - auc: 0.7224 - loss: 0.5285 - val_acc: 0.6868 - val_auc: 0.5349 - val_loss: 0.5049\n","Epoch 36/100\n","\u001b[1m300/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7069 - auc: 0.7377 - loss: 0.5261\n","Epoch 36: val_loss did not improve from 0.48836\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7069 - auc: 0.7381 - loss: 0.5264 - val_acc: 0.6923 - val_auc: 0.5352 - val_loss: 0.5028\n","Epoch 37/100\n","\u001b[1m301/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6686 - auc: 0.7386 - loss: 0.5472\n","Epoch 37: val_loss improved from 0.48836 to 0.48714, saving model to best_fold_13.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6693 - auc: 0.7389 - loss: 0.5468 - val_acc: 0.7527 - val_auc: 0.5301 - val_loss: 0.4871\n","Epoch 38/100\n","\u001b[1m304/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6667 - auc: 0.7347 - loss: 0.5682\n","Epoch 38: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6672 - auc: 0.7350 - loss: 0.5677 - val_acc: 0.6319 - val_auc: 0.5512 - val_loss: 0.5260\n","Epoch 39/100\n","\u001b[1m300/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7026 - auc: 0.7489 - loss: 0.5363\n","Epoch 39: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7027 - auc: 0.7490 - loss: 0.5363 - val_acc: 0.7363 - val_auc: 0.5298 - val_loss: 0.4952\n","Epoch 40/100\n","\u001b[1m299/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7155 - auc: 0.7525 - loss: 0.5382\n","Epoch 40: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7153 - auc: 0.7528 - loss: 0.5378 - val_acc: 0.6868 - val_auc: 0.5328 - val_loss: 0.5041\n","Epoch 41/100\n","\u001b[1m298/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6875 - auc: 0.7596 - loss: 0.5297\n","Epoch 41: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6882 - auc: 0.7595 - loss: 0.5297 - val_acc: 0.6923 - val_auc: 0.5410 - val_loss: 0.5037\n","Epoch 42/100\n","\u001b[1m305/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7311 - auc: 0.7919 - loss: 0.5003\n","Epoch 42: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7308 - auc: 0.7916 - loss: 0.5006 - val_acc: 0.6868 - val_auc: 0.5264 - val_loss: 0.5064\n","Epoch 43/100\n","\u001b[1m305/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7155 - auc: 0.7763 - loss: 0.5020\n","Epoch 43: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7154 - auc: 0.7762 - loss: 0.5023 - val_acc: 0.7363 - val_auc: 0.5211 - val_loss: 0.5020\n","Epoch 44/100\n","\u001b[1m302/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6931 - auc: 0.7485 - loss: 0.5274\n","Epoch 44: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6931 - auc: 0.7488 - loss: 0.5274 - val_acc: 0.6923 - val_auc: 0.5215 - val_loss: 0.5147\n","Epoch 45/100\n","\u001b[1m296/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7327 - auc: 0.7720 - loss: 0.5015\n","Epoch 45: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7320 - auc: 0.7716 - loss: 0.5025 - val_acc: 0.7363 - val_auc: 0.5188 - val_loss: 0.5004\n","Epoch 46/100\n","\u001b[1m296/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6925 - auc: 0.7607 - loss: 0.5235\n","Epoch 46: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6930 - auc: 0.7609 - loss: 0.5236 - val_acc: 0.7363 - val_auc: 0.5181 - val_loss: 0.5050\n","Epoch 47/100\n","\u001b[1m295/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7082 - auc: 0.7711 - loss: 0.5242\n","Epoch 47: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7085 - auc: 0.7711 - loss: 0.5242 - val_acc: 0.7363 - val_auc: 0.5171 - val_loss: 0.5066\n","Epoch 48/100\n","\u001b[1m299/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7210 - auc: 0.7670 - loss: 0.5068\n","Epoch 48: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7207 - auc: 0.7670 - loss: 0.5073 - val_acc: 0.6484 - val_auc: 0.5205 - val_loss: 0.5197\n","Epoch 49/100\n","\u001b[1m299/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7184 - auc: 0.7578 - loss: 0.5204\n","Epoch 49: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7184 - auc: 0.7581 - loss: 0.5203 - val_acc: 0.6978 - val_auc: 0.5204 - val_loss: 0.5097\n","Epoch 50/100\n","\u001b[1m295/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7243 - auc: 0.7812 - loss: 0.5146\n","Epoch 50: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7239 - auc: 0.7809 - loss: 0.5148 - val_acc: 0.7527 - val_auc: 0.5139 - val_loss: 0.5004\n","Epoch 51/100\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7271 - auc: 0.7853 - loss: 0.5172\n","Epoch 51: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7271 - auc: 0.7853 - loss: 0.5172 - val_acc: 0.7527 - val_auc: 0.5167 - val_loss: 0.5072\n","Epoch 52/100\n","\u001b[1m297/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6803 - auc: 0.7354 - loss: 0.5402\n","Epoch 52: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6811 - auc: 0.7366 - loss: 0.5394 - val_acc: 0.7418 - val_auc: 0.5174 - val_loss: 0.5147\n","Epoch 53/100\n","\u001b[1m297/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7258 - auc: 0.7850 - loss: 0.5052\n","Epoch 53: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7251 - auc: 0.7845 - loss: 0.5057 - val_acc: 0.6923 - val_auc: 0.5214 - val_loss: 0.5255\n","Epoch 54/100\n","\u001b[1m297/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7008 - auc: 0.7481 - loss: 0.5150\n","Epoch 54: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7011 - auc: 0.7488 - loss: 0.5152 - val_acc: 0.7363 - val_auc: 0.5204 - val_loss: 0.5369\n","Epoch 55/100\n","\u001b[1m300/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7181 - auc: 0.7862 - loss: 0.5019\n","Epoch 55: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7179 - auc: 0.7857 - loss: 0.5023 - val_acc: 0.7418 - val_auc: 0.5182 - val_loss: 0.5185\n","Epoch 56/100\n","\u001b[1m305/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7228 - auc: 0.7647 - loss: 0.5186\n","Epoch 56: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7227 - auc: 0.7648 - loss: 0.5185 - val_acc: 0.7418 - val_auc: 0.5178 - val_loss: 0.5323\n","Epoch 57/100\n","\u001b[1m300/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6897 - auc: 0.7324 - loss: 0.5525\n","Epoch 57: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6905 - auc: 0.7335 - loss: 0.5515 - val_acc: 0.7473 - val_auc: 0.5173 - val_loss: 0.5469\n","Epoch 58/100\n","\u001b[1m302/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6827 - auc: 0.7629 - loss: 0.5284\n","Epoch 58: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6832 - auc: 0.7631 - loss: 0.5281 - val_acc: 0.6813 - val_auc: 0.5187 - val_loss: 0.5560\n","Epoch 59/100\n","\u001b[1m301/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7192 - auc: 0.7661 - loss: 0.5143\n","Epoch 59: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7191 - auc: 0.7662 - loss: 0.5143 - val_acc: 0.7527 - val_auc: 0.5158 - val_loss: 0.5193\n","Epoch 60/100\n","\u001b[1m306/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7236 - auc: 0.7783 - loss: 0.5100\n","Epoch 60: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7235 - auc: 0.7782 - loss: 0.5100 - val_acc: 0.7527 - val_auc: 0.5134 - val_loss: 0.5145\n","Epoch 61/100\n","\u001b[1m295/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7233 - auc: 0.7386 - loss: 0.5249\n","Epoch 61: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7230 - auc: 0.7398 - loss: 0.5244 - val_acc: 0.6593 - val_auc: 0.5161 - val_loss: 0.5491\n","Epoch 62/100\n","\u001b[1m301/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7301 - auc: 0.8061 - loss: 0.4808\n","Epoch 62: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7296 - auc: 0.8055 - loss: 0.4815 - val_acc: 0.7418 - val_auc: 0.5102 - val_loss: 0.5430\n","Epoch 63/100\n","\u001b[1m302/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7251 - auc: 0.7608 - loss: 0.5106\n","Epoch 63: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7249 - auc: 0.7612 - loss: 0.5105 - val_acc: 0.7527 - val_auc: 0.5132 - val_loss: 0.5262\n","Epoch 64/100\n","\u001b[1m298/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7183 - auc: 0.7783 - loss: 0.5088\n","Epoch 64: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7180 - auc: 0.7781 - loss: 0.5090 - val_acc: 0.7253 - val_auc: 0.5136 - val_loss: 0.5373\n","Epoch 65/100\n","\u001b[1m298/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7366 - auc: 0.7800 - loss: 0.5063\n","Epoch 65: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7361 - auc: 0.7799 - loss: 0.5063 - val_acc: 0.7418 - val_auc: 0.5100 - val_loss: 0.5404\n","Epoch 66/100\n","\u001b[1m300/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6921 - auc: 0.7681 - loss: 0.5164\n","Epoch 66: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6926 - auc: 0.7682 - loss: 0.5163 - val_acc: 0.7198 - val_auc: 0.5142 - val_loss: 0.5655\n","Epoch 67/100\n","\u001b[1m301/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7126 - auc: 0.7793 - loss: 0.5179\n","Epoch 67: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7128 - auc: 0.7794 - loss: 0.5177 - val_acc: 0.7308 - val_auc: 0.5154 - val_loss: 0.5448\n","Epoch 68/100\n","\u001b[1m296/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7318 - auc: 0.7801 - loss: 0.5036\n","Epoch 68: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7311 - auc: 0.7801 - loss: 0.5037 - val_acc: 0.7363 - val_auc: 0.5105 - val_loss: 0.5874\n","Epoch 69/100\n","\u001b[1m306/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7261 - auc: 0.7742 - loss: 0.5130\n","Epoch 69: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7260 - auc: 0.7742 - loss: 0.5129 - val_acc: 0.6374 - val_auc: 0.5146 - val_loss: 0.6265\n","Epoch 70/100\n","\u001b[1m294/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7385 - auc: 0.7954 - loss: 0.4766\n","Epoch 70: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.7378 - auc: 0.7943 - loss: 0.4778 - val_acc: 0.7473 - val_auc: 0.5121 - val_loss: 0.5846\n","Epoch 71/100\n","\u001b[1m300/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6954 - auc: 0.7617 - loss: 0.5224\n","Epoch 71: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6958 - auc: 0.7619 - loss: 0.5220 - val_acc: 0.7473 - val_auc: 0.5016 - val_loss: 0.6129\n","Epoch 72/100\n","\u001b[1m296/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7186 - auc: 0.7961 - loss: 0.5077\n","Epoch 72: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7184 - auc: 0.7956 - loss: 0.5077 - val_acc: 0.7418 - val_auc: 0.5038 - val_loss: 0.5991\n","Epoch 73/100\n","\u001b[1m302/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7373 - auc: 0.7849 - loss: 0.5006\n","Epoch 73: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7367 - auc: 0.7847 - loss: 0.5007 - val_acc: 0.7527 - val_auc: 0.5073 - val_loss: 0.5724\n","Epoch 74/100\n","\u001b[1m297/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7151 - auc: 0.7908 - loss: 0.4956\n","Epoch 74: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7151 - auc: 0.7904 - loss: 0.4959 - val_acc: 0.7363 - val_auc: 0.5043 - val_loss: 0.5836\n","Epoch 75/100\n","\u001b[1m299/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7316 - auc: 0.7976 - loss: 0.4873\n","Epoch 75: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7311 - auc: 0.7971 - loss: 0.4878 - val_acc: 0.6648 - val_auc: 0.5165 - val_loss: 0.5545\n","Epoch 76/100\n","\u001b[1m306/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7178 - auc: 0.7694 - loss: 0.5110\n","Epoch 76: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7178 - auc: 0.7694 - loss: 0.5110 - val_acc: 0.7308 - val_auc: 0.4998 - val_loss: 0.6426\n","Epoch 77/100\n","\u001b[1m306/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7236 - auc: 0.7952 - loss: 0.4920\n","Epoch 77: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7236 - auc: 0.7951 - loss: 0.4920 - val_acc: 0.7363 - val_auc: 0.5089 - val_loss: 0.6546\n","Epoch 78/100\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7303 - auc: 0.7785 - loss: 0.5029\n","Epoch 78: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7302 - auc: 0.7785 - loss: 0.5029 - val_acc: 0.6648 - val_auc: 0.4914 - val_loss: 0.6269\n","Epoch 79/100\n","\u001b[1m293/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6904 - auc: 0.7681 - loss: 0.5118\n","Epoch 79: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6910 - auc: 0.7680 - loss: 0.5119 - val_acc: 0.7363 - val_auc: 0.5033 - val_loss: 0.6668\n","Epoch 80/100\n","\u001b[1m294/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7475 - auc: 0.8087 - loss: 0.4742\n","Epoch 80: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7466 - auc: 0.8077 - loss: 0.4752 - val_acc: 0.6813 - val_auc: 0.5221 - val_loss: 0.6677\n","Epoch 81/100\n","\u001b[1m294/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7062 - auc: 0.7867 - loss: 0.5119\n","Epoch 81: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7066 - auc: 0.7871 - loss: 0.5113 - val_acc: 0.6813 - val_auc: 0.5099 - val_loss: 0.6425\n","Epoch 82/100\n","\u001b[1m301/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6950 - auc: 0.7414 - loss: 0.5134\n","Epoch 82: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6953 - auc: 0.7421 - loss: 0.5132 - val_acc: 0.6923 - val_auc: 0.5048 - val_loss: 0.6178\n","Epoch 83/100\n","\u001b[1m298/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7421 - auc: 0.7992 - loss: 0.4969\n","Epoch 83: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7413 - auc: 0.7990 - loss: 0.4970 - val_acc: 0.7253 - val_auc: 0.5293 - val_loss: 0.6623\n","Epoch 84/100\n","\u001b[1m305/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7260 - auc: 0.7935 - loss: 0.5004\n","Epoch 84: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7260 - auc: 0.7935 - loss: 0.5004 - val_acc: 0.7308 - val_auc: 0.5299 - val_loss: 0.6967\n","Epoch 85/100\n","\u001b[1m302/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6881 - auc: 0.7450 - loss: 0.5426\n","Epoch 85: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6886 - auc: 0.7455 - loss: 0.5419 - val_acc: 0.7418 - val_auc: 0.5160 - val_loss: 0.6461\n","Epoch 86/100\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7195 - auc: 0.7725 - loss: 0.5052\n","Epoch 86: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7195 - auc: 0.7726 - loss: 0.5052 - val_acc: 0.7308 - val_auc: 0.5477 - val_loss: 0.7145\n","Epoch 87/100\n","\u001b[1m295/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7344 - auc: 0.8000 - loss: 0.4901\n","Epoch 87: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7337 - auc: 0.7995 - loss: 0.4906 - val_acc: 0.7473 - val_auc: 0.5373 - val_loss: 0.6059\n","Epoch 88/100\n","\u001b[1m294/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7079 - auc: 0.7730 - loss: 0.4999\n","Epoch 88: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7085 - auc: 0.7737 - loss: 0.4999 - val_acc: 0.7418 - val_auc: 0.5519 - val_loss: 0.6886\n","Epoch 89/100\n","\u001b[1m296/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7213 - auc: 0.8001 - loss: 0.4987\n","Epoch 89: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7211 - auc: 0.7994 - loss: 0.4989 - val_acc: 0.7253 - val_auc: 0.5503 - val_loss: 0.6336\n","Epoch 90/100\n","\u001b[1m300/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7399 - auc: 0.7787 - loss: 0.4910\n","Epoch 90: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7392 - auc: 0.7788 - loss: 0.4912 - val_acc: 0.7308 - val_auc: 0.5128 - val_loss: 0.7170\n","Epoch 91/100\n","\u001b[1m296/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7348 - auc: 0.7997 - loss: 0.4893\n","Epoch 91: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7345 - auc: 0.7991 - loss: 0.4898 - val_acc: 0.7363 - val_auc: 0.5219 - val_loss: 0.7484\n","Epoch 92/100\n","\u001b[1m301/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7345 - auc: 0.7848 - loss: 0.4945\n","Epoch 92: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7342 - auc: 0.7847 - loss: 0.4946 - val_acc: 0.7527 - val_auc: 0.5772 - val_loss: 0.6140\n","Epoch 93/100\n","\u001b[1m300/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7072 - auc: 0.7975 - loss: 0.4756\n","Epoch 93: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7071 - auc: 0.7970 - loss: 0.4762 - val_acc: 0.7473 - val_auc: 0.5316 - val_loss: 0.6693\n","Epoch 94/100\n","\u001b[1m296/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7396 - auc: 0.8101 - loss: 0.4794\n","Epoch 94: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7390 - auc: 0.8097 - loss: 0.4800 - val_acc: 0.7363 - val_auc: 0.5389 - val_loss: 0.6577\n","Epoch 95/100\n","\u001b[1m294/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7222 - auc: 0.7947 - loss: 0.4819\n","Epoch 95: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7222 - auc: 0.7946 - loss: 0.4825 - val_acc: 0.7363 - val_auc: 0.4971 - val_loss: 0.8519\n","Epoch 96/100\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7438 - auc: 0.8269 - loss: 0.4721\n","Epoch 96: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7437 - auc: 0.8268 - loss: 0.4722 - val_acc: 0.7473 - val_auc: 0.4928 - val_loss: 0.7146\n","Epoch 97/100\n","\u001b[1m296/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7235 - auc: 0.8135 - loss: 0.4776\n","Epoch 97: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7233 - auc: 0.8124 - loss: 0.4784 - val_acc: 0.6978 - val_auc: 0.4582 - val_loss: 0.7887\n","Epoch 98/100\n","\u001b[1m305/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7305 - auc: 0.7768 - loss: 0.4961\n","Epoch 98: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7304 - auc: 0.7769 - loss: 0.4961 - val_acc: 0.7527 - val_auc: 0.5451 - val_loss: 0.6392\n","Epoch 99/100\n","\u001b[1m297/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7264 - auc: 0.8083 - loss: 0.4717\n","Epoch 99: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7258 - auc: 0.8076 - loss: 0.4726 - val_acc: 0.7363 - val_auc: 0.5195 - val_loss: 0.7750\n","Epoch 100/100\n","\u001b[1m304/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7249 - auc: 0.7658 - loss: 0.5040\n","Epoch 100: val_loss did not improve from 0.48714\n","\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7249 - auc: 0.7662 - loss: 0.5039 - val_acc: 0.7088 - val_auc: 0.5046 - val_loss: 0.7235\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 13 | TEST ACC=0.2371 | TEST AUC=0.3091 | n=97\n","Confusion matrix:\n"," [[23 32]\n"," [42  0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.354     0.418     0.383        55\n","           1      0.000     0.000     0.000        42\n","\n","    accuracy                          0.237        97\n","   macro avg      0.177     0.209     0.192        97\n","weighted avg      0.201     0.237     0.217        97\n","\n","\n","--- Fold 14/14 ---\n"," train | ids:   36 | files:   950 | pos files:  357 | neg files:  593\n","   val | ids:    5 | files:   107 | pos files:   39 | neg files:   68\n","  test | ids:    3 | files:   143 | pos files:    9 | neg files:  134\n","Epoch 1/100\n","\u001b[1m316/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5569 - auc: 0.4988 - loss: 0.6905\n","Epoch 1: val_loss improved from inf to 0.67217, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - acc: 0.5572 - auc: 0.4989 - loss: 0.6905 - val_acc: 0.6355 - val_auc: 0.3635 - val_loss: 0.6722\n","Epoch 2/100\n","\u001b[1m306/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6563 - auc: 0.4573 - loss: 0.6604\n","Epoch 2: val_loss improved from 0.67217 to 0.65804, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6552 - auc: 0.4579 - loss: 0.6606 - val_acc: 0.6355 - val_auc: 0.4089 - val_loss: 0.6580\n","Epoch 3/100\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6142 - auc: 0.5391 - loss: 0.6652\n","Epoch 3: val_loss improved from 0.65804 to 0.65510, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6142 - auc: 0.5390 - loss: 0.6652 - val_acc: 0.6355 - val_auc: 0.4308 - val_loss: 0.6551\n","Epoch 4/100\n","\u001b[1m316/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6029 - auc: 0.5303 - loss: 0.6700\n","Epoch 4: val_loss improved from 0.65510 to 0.65422, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6030 - auc: 0.5303 - loss: 0.6700 - val_acc: 0.6355 - val_auc: 0.4710 - val_loss: 0.6542\n","Epoch 5/100\n","\u001b[1m314/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6215 - auc: 0.6117 - loss: 0.6529\n","Epoch 5: val_loss improved from 0.65422 to 0.65307, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6215 - auc: 0.6112 - loss: 0.6529 - val_acc: 0.6355 - val_auc: 0.5164 - val_loss: 0.6531\n","Epoch 6/100\n","\u001b[1m312/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5942 - auc: 0.5884 - loss: 0.6691\n","Epoch 6: val_loss improved from 0.65307 to 0.65139, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5947 - auc: 0.5885 - loss: 0.6688 - val_acc: 0.6355 - val_auc: 0.5518 - val_loss: 0.6514\n","Epoch 7/100\n","\u001b[1m316/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6156 - auc: 0.5945 - loss: 0.6543\n","Epoch 7: val_loss improved from 0.65139 to 0.64944, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6156 - auc: 0.5946 - loss: 0.6543 - val_acc: 0.6355 - val_auc: 0.5807 - val_loss: 0.6494\n","Epoch 8/100\n","\u001b[1m315/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6242 - auc: 0.6296 - loss: 0.6427\n","Epoch 8: val_loss improved from 0.64944 to 0.64261, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6242 - auc: 0.6295 - loss: 0.6427 - val_acc: 0.6355 - val_auc: 0.6033 - val_loss: 0.6426\n","Epoch 9/100\n","\u001b[1m315/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6148 - auc: 0.6238 - loss: 0.6451\n","Epoch 9: val_loss improved from 0.64261 to 0.64035, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6149 - auc: 0.6239 - loss: 0.6450 - val_acc: 0.6355 - val_auc: 0.6029 - val_loss: 0.6404\n","Epoch 10/100\n","\u001b[1m316/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6383 - auc: 0.6442 - loss: 0.6181\n","Epoch 10: val_loss improved from 0.64035 to 0.62229, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6382 - auc: 0.6442 - loss: 0.6181 - val_acc: 0.6355 - val_auc: 0.6158 - val_loss: 0.6223\n","Epoch 11/100\n","\u001b[1m315/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6251 - auc: 0.6307 - loss: 0.6271\n","Epoch 11: val_loss improved from 0.62229 to 0.60695, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6251 - auc: 0.6308 - loss: 0.6271 - val_acc: 0.6355 - val_auc: 0.6173 - val_loss: 0.6069\n","Epoch 12/100\n","\u001b[1m305/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6160 - auc: 0.6380 - loss: 0.6194\n","Epoch 12: val_loss did not improve from 0.60695\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6164 - auc: 0.6380 - loss: 0.6192 - val_acc: 0.6355 - val_auc: 0.5982 - val_loss: 0.6145\n","Epoch 13/100\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6412 - auc: 0.6660 - loss: 0.6085\n","Epoch 13: val_loss improved from 0.60695 to 0.58670, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6412 - auc: 0.6659 - loss: 0.6085 - val_acc: 0.6355 - val_auc: 0.5971 - val_loss: 0.5867\n","Epoch 14/100\n","\u001b[1m312/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6182 - auc: 0.6454 - loss: 0.6084\n","Epoch 14: val_loss improved from 0.58670 to 0.57841, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6184 - auc: 0.6455 - loss: 0.6084 - val_acc: 0.6355 - val_auc: 0.5999 - val_loss: 0.5784\n","Epoch 15/100\n","\u001b[1m310/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6307 - auc: 0.6315 - loss: 0.6050\n","Epoch 15: val_loss improved from 0.57841 to 0.57537, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6307 - auc: 0.6320 - loss: 0.6050 - val_acc: 0.6355 - val_auc: 0.6009 - val_loss: 0.5754\n","Epoch 16/100\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6372 - auc: 0.6719 - loss: 0.5862\n","Epoch 16: val_loss did not improve from 0.57537\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6371 - auc: 0.6718 - loss: 0.5862 - val_acc: 0.6355 - val_auc: 0.5994 - val_loss: 0.5759\n","Epoch 17/100\n","\u001b[1m313/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6328 - auc: 0.6616 - loss: 0.6096\n","Epoch 17: val_loss improved from 0.57537 to 0.56767, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6326 - auc: 0.6616 - loss: 0.6095 - val_acc: 0.6355 - val_auc: 0.5754 - val_loss: 0.5677\n","Epoch 18/100\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6380 - auc: 0.6715 - loss: 0.5895\n","Epoch 18: val_loss improved from 0.56767 to 0.56551, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6380 - auc: 0.6715 - loss: 0.5895 - val_acc: 0.6355 - val_auc: 0.5794 - val_loss: 0.5655\n","Epoch 19/100\n","\u001b[1m315/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6371 - auc: 0.6561 - loss: 0.6083\n","Epoch 19: val_loss improved from 0.56551 to 0.56496, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6371 - auc: 0.6561 - loss: 0.6082 - val_acc: 0.6355 - val_auc: 0.5764 - val_loss: 0.5650\n","Epoch 20/100\n","\u001b[1m305/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6404 - auc: 0.6469 - loss: 0.5952\n","Epoch 20: val_loss improved from 0.56496 to 0.56472, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6401 - auc: 0.6471 - loss: 0.5955 - val_acc: 0.6355 - val_auc: 0.5750 - val_loss: 0.5647\n","Epoch 21/100\n","\u001b[1m310/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6568 - auc: 0.6389 - loss: 0.5924\n","Epoch 21: val_loss did not improve from 0.56472\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6561 - auc: 0.6395 - loss: 0.5925 - val_acc: 0.6262 - val_auc: 0.5594 - val_loss: 0.5763\n","Epoch 22/100\n","\u001b[1m313/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6641 - auc: 0.6095 - loss: 0.6064\n","Epoch 22: val_loss improved from 0.56472 to 0.56049, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6638 - auc: 0.6102 - loss: 0.6064 - val_acc: 0.6355 - val_auc: 0.5622 - val_loss: 0.5605\n","Epoch 23/100\n","\u001b[1m311/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6634 - auc: 0.6669 - loss: 0.5922\n","Epoch 23: val_loss did not improve from 0.56049\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6632 - auc: 0.6669 - loss: 0.5923 - val_acc: 0.6355 - val_auc: 0.5473 - val_loss: 0.5611\n","Epoch 24/100\n","\u001b[1m313/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6435 - auc: 0.6553 - loss: 0.6085\n","Epoch 24: val_loss improved from 0.56049 to 0.56019, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6436 - auc: 0.6555 - loss: 0.6084 - val_acc: 0.6355 - val_auc: 0.5462 - val_loss: 0.5602\n","Epoch 25/100\n","\u001b[1m315/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6556 - auc: 0.6606 - loss: 0.5992\n","Epoch 25: val_loss improved from 0.56019 to 0.56008, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6556 - auc: 0.6606 - loss: 0.5992 - val_acc: 0.6355 - val_auc: 0.5172 - val_loss: 0.5601\n","Epoch 26/100\n","\u001b[1m312/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6583 - auc: 0.6418 - loss: 0.6094\n","Epoch 26: val_loss did not improve from 0.56008\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6583 - auc: 0.6424 - loss: 0.6091 - val_acc: 0.5701 - val_auc: 0.5222 - val_loss: 0.5641\n","Epoch 27/100\n","\u001b[1m314/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6350 - auc: 0.6277 - loss: 0.6166\n","Epoch 27: val_loss improved from 0.56008 to 0.55941, saving model to best_fold_14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6351 - auc: 0.6282 - loss: 0.6164 - val_acc: 0.5981 - val_auc: 0.4977 - val_loss: 0.5594\n","Epoch 28/100\n","\u001b[1m313/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6637 - auc: 0.6950 - loss: 0.5788\n","Epoch 28: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6634 - auc: 0.6948 - loss: 0.5790 - val_acc: 0.6355 - val_auc: 0.4955 - val_loss: 0.5594\n","Epoch 29/100\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6364 - auc: 0.6725 - loss: 0.5899\n","Epoch 29: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6365 - auc: 0.6725 - loss: 0.5900 - val_acc: 0.6355 - val_auc: 0.4942 - val_loss: 0.5613\n","Epoch 30/100\n","\u001b[1m312/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6287 - auc: 0.6732 - loss: 0.6080\n","Epoch 30: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6290 - auc: 0.6733 - loss: 0.6078 - val_acc: 0.6355 - val_auc: 0.4966 - val_loss: 0.5644\n","Epoch 31/100\n","\u001b[1m312/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6626 - auc: 0.6744 - loss: 0.5905\n","Epoch 31: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6624 - auc: 0.6746 - loss: 0.5906 - val_acc: 0.5981 - val_auc: 0.4966 - val_loss: 0.5634\n","Epoch 32/100\n","\u001b[1m307/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6973 - auc: 0.6627 - loss: 0.6068\n","Epoch 32: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6963 - auc: 0.6635 - loss: 0.6062 - val_acc: 0.5981 - val_auc: 0.4911 - val_loss: 0.5663\n","Epoch 33/100\n","\u001b[1m310/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6541 - auc: 0.7018 - loss: 0.5945\n","Epoch 33: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6540 - auc: 0.7013 - loss: 0.5946 - val_acc: 0.5981 - val_auc: 0.4872 - val_loss: 0.5699\n","Epoch 34/100\n","\u001b[1m316/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6804 - auc: 0.6654 - loss: 0.6074\n","Epoch 34: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6802 - auc: 0.6655 - loss: 0.6073 - val_acc: 0.5981 - val_auc: 0.4904 - val_loss: 0.5796\n","Epoch 35/100\n","\u001b[1m307/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6531 - auc: 0.7048 - loss: 0.5931\n","Epoch 35: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6532 - auc: 0.7043 - loss: 0.5932 - val_acc: 0.5514 - val_auc: 0.5072 - val_loss: 0.5759\n","Epoch 36/100\n","\u001b[1m308/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6395 - auc: 0.7016 - loss: 0.5916\n","Epoch 36: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6396 - auc: 0.7012 - loss: 0.5916 - val_acc: 0.5701 - val_auc: 0.5030 - val_loss: 0.5783\n","Epoch 37/100\n","\u001b[1m305/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6743 - auc: 0.6745 - loss: 0.5996\n","Epoch 37: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6739 - auc: 0.6750 - loss: 0.5991 - val_acc: 0.5607 - val_auc: 0.5096 - val_loss: 0.5796\n","Epoch 38/100\n","\u001b[1m308/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6601 - auc: 0.6980 - loss: 0.5902\n","Epoch 38: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6595 - auc: 0.6976 - loss: 0.5902 - val_acc: 0.5701 - val_auc: 0.5006 - val_loss: 0.5890\n","Epoch 39/100\n","\u001b[1m308/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6463 - auc: 0.6992 - loss: 0.5799\n","Epoch 39: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6461 - auc: 0.6991 - loss: 0.5800 - val_acc: 0.5607 - val_auc: 0.4934 - val_loss: 0.6072\n","Epoch 40/100\n","\u001b[1m316/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6313 - auc: 0.6931 - loss: 0.5976\n","Epoch 40: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6313 - auc: 0.6931 - loss: 0.5975 - val_acc: 0.5607 - val_auc: 0.5085 - val_loss: 0.6062\n","Epoch 41/100\n","\u001b[1m308/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6483 - auc: 0.7029 - loss: 0.5816\n","Epoch 41: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6484 - auc: 0.7027 - loss: 0.5817 - val_acc: 0.5607 - val_auc: 0.4992 - val_loss: 0.6113\n","Epoch 42/100\n","\u001b[1m315/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6302 - auc: 0.6640 - loss: 0.5888\n","Epoch 42: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6302 - auc: 0.6643 - loss: 0.5887 - val_acc: 0.5234 - val_auc: 0.5379 - val_loss: 0.6089\n","Epoch 43/100\n","\u001b[1m315/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6725 - auc: 0.7146 - loss: 0.5673\n","Epoch 43: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6724 - auc: 0.7145 - loss: 0.5674 - val_acc: 0.5701 - val_auc: 0.5015 - val_loss: 0.6282\n","Epoch 44/100\n","\u001b[1m311/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6289 - auc: 0.6897 - loss: 0.5798\n","Epoch 44: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6291 - auc: 0.6899 - loss: 0.5798 - val_acc: 0.5514 - val_auc: 0.5264 - val_loss: 0.6287\n","Epoch 45/100\n","\u001b[1m315/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6541 - auc: 0.7188 - loss: 0.5773\n","Epoch 45: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6541 - auc: 0.7187 - loss: 0.5773 - val_acc: 0.5701 - val_auc: 0.5232 - val_loss: 0.6340\n","Epoch 46/100\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6484 - auc: 0.7033 - loss: 0.5799\n","Epoch 46: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6484 - auc: 0.7033 - loss: 0.5799 - val_acc: 0.4953 - val_auc: 0.5494 - val_loss: 0.6191\n","Epoch 47/100\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6075 - auc: 0.6861 - loss: 0.5869\n","Epoch 47: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6076 - auc: 0.6861 - loss: 0.5869 - val_acc: 0.5701 - val_auc: 0.5398 - val_loss: 0.6435\n","Epoch 48/100\n","\u001b[1m305/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6771 - auc: 0.7287 - loss: 0.5829\n","Epoch 48: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6759 - auc: 0.7279 - loss: 0.5827 - val_acc: 0.5514 - val_auc: 0.6024 - val_loss: 0.6266\n","Epoch 49/100\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6261 - auc: 0.7033 - loss: 0.5852\n","Epoch 49: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6261 - auc: 0.7033 - loss: 0.5852 - val_acc: 0.5981 - val_auc: 0.5296 - val_loss: 0.6581\n","Epoch 50/100\n","\u001b[1m312/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6383 - auc: 0.7020 - loss: 0.5663\n","Epoch 50: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6386 - auc: 0.7021 - loss: 0.5665 - val_acc: 0.5981 - val_auc: 0.5217 - val_loss: 0.6609\n","Epoch 51/100\n","\u001b[1m316/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6440 - auc: 0.7120 - loss: 0.5789\n","Epoch 51: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6440 - auc: 0.7120 - loss: 0.5788 - val_acc: 0.5701 - val_auc: 0.5503 - val_loss: 0.6613\n","Epoch 52/100\n","\u001b[1m312/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6437 - auc: 0.7136 - loss: 0.5730\n","Epoch 52: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6440 - auc: 0.7137 - loss: 0.5731 - val_acc: 0.5421 - val_auc: 0.5567 - val_loss: 0.6607\n","Epoch 53/100\n","\u001b[1m313/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6620 - auc: 0.7328 - loss: 0.5580\n","Epoch 53: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6617 - auc: 0.7325 - loss: 0.5581 - val_acc: 0.6075 - val_auc: 0.5684 - val_loss: 0.6800\n","Epoch 54/100\n","\u001b[1m311/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6544 - auc: 0.7135 - loss: 0.5746\n","Epoch 54: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6546 - auc: 0.7136 - loss: 0.5746 - val_acc: 0.5514 - val_auc: 0.5814 - val_loss: 0.6715\n","Epoch 55/100\n","\u001b[1m313/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6552 - auc: 0.7275 - loss: 0.5574\n","Epoch 55: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6551 - auc: 0.7273 - loss: 0.5576 - val_acc: 0.5047 - val_auc: 0.6395 - val_loss: 0.6539\n","Epoch 56/100\n","\u001b[1m311/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6523 - auc: 0.7164 - loss: 0.5749\n","Epoch 56: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6523 - auc: 0.7165 - loss: 0.5748 - val_acc: 0.5234 - val_auc: 0.6176 - val_loss: 0.6768\n","Epoch 57/100\n","\u001b[1m305/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6481 - auc: 0.6986 - loss: 0.5585\n","Epoch 57: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6488 - auc: 0.6998 - loss: 0.5587 - val_acc: 0.4860 - val_auc: 0.6220 - val_loss: 0.6811\n","Epoch 58/100\n","\u001b[1m312/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6562 - auc: 0.7326 - loss: 0.5449\n","Epoch 58: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6562 - auc: 0.7324 - loss: 0.5453 - val_acc: 0.4860 - val_auc: 0.6423 - val_loss: 0.6592\n","Epoch 59/100\n","\u001b[1m308/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6456 - auc: 0.7265 - loss: 0.5725\n","Epoch 59: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6460 - auc: 0.7265 - loss: 0.5723 - val_acc: 0.6542 - val_auc: 0.6275 - val_loss: 0.6887\n","Epoch 60/100\n","\u001b[1m312/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6494 - auc: 0.7339 - loss: 0.5553\n","Epoch 60: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6496 - auc: 0.7337 - loss: 0.5555 - val_acc: 0.5981 - val_auc: 0.6329 - val_loss: 0.6907\n","Epoch 61/100\n","\u001b[1m314/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6597 - auc: 0.7190 - loss: 0.5525\n","Epoch 61: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6597 - auc: 0.7191 - loss: 0.5526 - val_acc: 0.6542 - val_auc: 0.6403 - val_loss: 0.6933\n","Epoch 62/100\n","\u001b[1m315/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6581 - auc: 0.7265 - loss: 0.5583\n","Epoch 62: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6581 - auc: 0.7264 - loss: 0.5582 - val_acc: 0.6355 - val_auc: 0.6552 - val_loss: 0.7049\n","Epoch 63/100\n","\u001b[1m312/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6516 - auc: 0.7097 - loss: 0.5616\n","Epoch 63: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6519 - auc: 0.7101 - loss: 0.5615 - val_acc: 0.5140 - val_auc: 0.6318 - val_loss: 0.7195\n","Epoch 64/100\n","\u001b[1m307/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6750 - auc: 0.7563 - loss: 0.5301\n","Epoch 64: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6748 - auc: 0.7557 - loss: 0.5309 - val_acc: 0.6449 - val_auc: 0.6484 - val_loss: 0.6984\n","Epoch 65/100\n","\u001b[1m308/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6629 - auc: 0.7409 - loss: 0.5583\n","Epoch 65: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6629 - auc: 0.7408 - loss: 0.5582 - val_acc: 0.6916 - val_auc: 0.6595 - val_loss: 0.6863\n","Epoch 66/100\n","\u001b[1m304/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6562 - auc: 0.7194 - loss: 0.5751\n","Epoch 66: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6566 - auc: 0.7198 - loss: 0.5744 - val_acc: 0.6636 - val_auc: 0.6497 - val_loss: 0.7097\n","Epoch 67/100\n","\u001b[1m316/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6688 - auc: 0.7128 - loss: 0.5533\n","Epoch 67: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6687 - auc: 0.7129 - loss: 0.5533 - val_acc: 0.7009 - val_auc: 0.6608 - val_loss: 0.7020\n","Epoch 68/100\n","\u001b[1m313/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6275 - auc: 0.7173 - loss: 0.5620\n","Epoch 68: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6280 - auc: 0.7174 - loss: 0.5618 - val_acc: 0.6729 - val_auc: 0.6565 - val_loss: 0.7084\n","Epoch 69/100\n","\u001b[1m309/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6403 - auc: 0.6954 - loss: 0.5716\n","Epoch 69: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6410 - auc: 0.6964 - loss: 0.5709 - val_acc: 0.6262 - val_auc: 0.6559 - val_loss: 0.7271\n","Epoch 70/100\n","\u001b[1m303/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6904 - auc: 0.7506 - loss: 0.5443\n","Epoch 70: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6902 - auc: 0.7503 - loss: 0.5445 - val_acc: 0.5234 - val_auc: 0.6469 - val_loss: 0.7279\n","Epoch 71/100\n","\u001b[1m313/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6609 - auc: 0.7140 - loss: 0.5718\n","Epoch 71: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6611 - auc: 0.7145 - loss: 0.5713 - val_acc: 0.7290 - val_auc: 0.6768 - val_loss: 0.7276\n","Epoch 72/100\n","\u001b[1m315/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6716 - auc: 0.7404 - loss: 0.5480\n","Epoch 72: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6716 - auc: 0.7404 - loss: 0.5480 - val_acc: 0.6355 - val_auc: 0.6621 - val_loss: 0.7543\n","Epoch 73/100\n","\u001b[1m313/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6826 - auc: 0.7356 - loss: 0.5599\n","Epoch 73: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6826 - auc: 0.7358 - loss: 0.5597 - val_acc: 0.6355 - val_auc: 0.6759 - val_loss: 0.7212\n","Epoch 74/100\n","\u001b[1m309/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6606 - auc: 0.7192 - loss: 0.5489\n","Epoch 74: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6608 - auc: 0.7196 - loss: 0.5488 - val_acc: 0.5327 - val_auc: 0.6650 - val_loss: 0.7338\n","Epoch 75/100\n","\u001b[1m314/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7066 - auc: 0.7581 - loss: 0.5353\n","Epoch 75: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7065 - auc: 0.7580 - loss: 0.5353 - val_acc: 0.7103 - val_auc: 0.6885 - val_loss: 0.7241\n","Epoch 76/100\n","\u001b[1m313/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6801 - auc: 0.7183 - loss: 0.5536\n","Epoch 76: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6800 - auc: 0.7186 - loss: 0.5534 - val_acc: 0.6636 - val_auc: 0.6425 - val_loss: 0.7598\n","Epoch 77/100\n","\u001b[1m309/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7008 - auc: 0.7712 - loss: 0.5232\n","Epoch 77: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7002 - auc: 0.7705 - loss: 0.5236 - val_acc: 0.7196 - val_auc: 0.6748 - val_loss: 0.7496\n","Epoch 78/100\n","\u001b[1m310/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6435 - auc: 0.7127 - loss: 0.5552\n","Epoch 78: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6443 - auc: 0.7133 - loss: 0.5550 - val_acc: 0.7196 - val_auc: 0.6840 - val_loss: 0.7292\n","Epoch 79/100\n","\u001b[1m316/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7219 - auc: 0.7691 - loss: 0.5183\n","Epoch 79: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7218 - auc: 0.7690 - loss: 0.5185 - val_acc: 0.7009 - val_auc: 0.6682 - val_loss: 0.7545\n","Epoch 80/100\n","\u001b[1m304/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6731 - auc: 0.7232 - loss: 0.5354\n","Epoch 80: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6733 - auc: 0.7242 - loss: 0.5354 - val_acc: 0.5047 - val_auc: 0.6925 - val_loss: 0.6991\n","Epoch 81/100\n","\u001b[1m304/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6815 - auc: 0.7471 - loss: 0.5404\n","Epoch 81: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6813 - auc: 0.7473 - loss: 0.5401 - val_acc: 0.7477 - val_auc: 0.6708 - val_loss: 0.7379\n","Epoch 82/100\n","\u001b[1m311/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6773 - auc: 0.7174 - loss: 0.5474\n","Epoch 82: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6775 - auc: 0.7180 - loss: 0.5472 - val_acc: 0.6449 - val_auc: 0.6431 - val_loss: 0.7545\n","Epoch 83/100\n","\u001b[1m308/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6696 - auc: 0.7469 - loss: 0.5367\n","Epoch 83: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6700 - auc: 0.7468 - loss: 0.5367 - val_acc: 0.6449 - val_auc: 0.6642 - val_loss: 0.7863\n","Epoch 84/100\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6841 - auc: 0.7484 - loss: 0.5329\n","Epoch 84: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6841 - auc: 0.7484 - loss: 0.5329 - val_acc: 0.5047 - val_auc: 0.6390 - val_loss: 0.8156\n","Epoch 85/100\n","\u001b[1m307/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7040 - auc: 0.7685 - loss: 0.5152\n","Epoch 85: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7032 - auc: 0.7678 - loss: 0.5159 - val_acc: 0.7009 - val_auc: 0.6733 - val_loss: 0.7802\n","Epoch 86/100\n","\u001b[1m313/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6828 - auc: 0.7500 - loss: 0.5287\n","Epoch 86: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6828 - auc: 0.7499 - loss: 0.5289 - val_acc: 0.6449 - val_auc: 0.6665 - val_loss: 0.7419\n","Epoch 87/100\n","\u001b[1m304/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6881 - auc: 0.7455 - loss: 0.5336\n","Epoch 87: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6882 - auc: 0.7457 - loss: 0.5336 - val_acc: 0.7009 - val_auc: 0.6816 - val_loss: 0.7758\n","Epoch 88/100\n","\u001b[1m305/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6744 - auc: 0.7186 - loss: 0.5333\n","Epoch 88: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6746 - auc: 0.7200 - loss: 0.5333 - val_acc: 0.7570 - val_auc: 0.6725 - val_loss: 0.7927\n","Epoch 89/100\n","\u001b[1m315/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6672 - auc: 0.7337 - loss: 0.5588\n","Epoch 89: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6674 - auc: 0.7339 - loss: 0.5585 - val_acc: 0.6729 - val_auc: 0.6555 - val_loss: 0.8402\n","Epoch 90/100\n","\u001b[1m309/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7097 - auc: 0.7506 - loss: 0.5348\n","Epoch 90: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7093 - auc: 0.7508 - loss: 0.5345 - val_acc: 0.7570 - val_auc: 0.6867 - val_loss: 0.7969\n","Epoch 91/100\n","\u001b[1m308/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6933 - auc: 0.7417 - loss: 0.5310\n","Epoch 91: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6932 - auc: 0.7423 - loss: 0.5309 - val_acc: 0.6636 - val_auc: 0.6520 - val_loss: 0.8216\n","Epoch 92/100\n","\u001b[1m314/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6710 - auc: 0.7454 - loss: 0.5616\n","Epoch 92: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6712 - auc: 0.7456 - loss: 0.5612 - val_acc: 0.6822 - val_auc: 0.6535 - val_loss: 0.8233\n","Epoch 93/100\n","\u001b[1m307/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6963 - auc: 0.7708 - loss: 0.5187\n","Epoch 93: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6966 - auc: 0.7706 - loss: 0.5188 - val_acc: 0.7103 - val_auc: 0.6819 - val_loss: 0.8179\n","Epoch 94/100\n","\u001b[1m313/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7211 - auc: 0.7830 - loss: 0.5044\n","Epoch 94: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7208 - auc: 0.7828 - loss: 0.5046 - val_acc: 0.6822 - val_auc: 0.6557 - val_loss: 0.8297\n","Epoch 95/100\n","\u001b[1m307/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6832 - auc: 0.7303 - loss: 0.5322\n","Epoch 95: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6834 - auc: 0.7310 - loss: 0.5322 - val_acc: 0.6822 - val_auc: 0.6810 - val_loss: 0.8439\n","Epoch 96/100\n","\u001b[1m310/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7332 - auc: 0.7373 - loss: 0.5173\n","Epoch 96: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7325 - auc: 0.7379 - loss: 0.5173 - val_acc: 0.5701 - val_auc: 0.6529 - val_loss: 0.8255\n","Epoch 97/100\n","\u001b[1m311/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6869 - auc: 0.7654 - loss: 0.5275\n","Epoch 97: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6872 - auc: 0.7654 - loss: 0.5273 - val_acc: 0.5140 - val_auc: 0.6476 - val_loss: 0.8181\n","Epoch 98/100\n","\u001b[1m313/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6835 - auc: 0.7551 - loss: 0.5315\n","Epoch 98: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6836 - auc: 0.7551 - loss: 0.5313 - val_acc: 0.7290 - val_auc: 0.6682 - val_loss: 0.8648\n","Epoch 99/100\n","\u001b[1m314/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7033 - auc: 0.7632 - loss: 0.5220\n","Epoch 99: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7033 - auc: 0.7631 - loss: 0.5220 - val_acc: 0.6449 - val_auc: 0.6836 - val_loss: 0.8642\n","Epoch 100/100\n","\u001b[1m309/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7235 - auc: 0.7431 - loss: 0.5212\n","Epoch 100: val_loss did not improve from 0.55941\n","\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7231 - auc: 0.7438 - loss: 0.5210 - val_acc: 0.7196 - val_auc: 0.6540 - val_loss: 0.8621\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 14 | TEST ACC=0.9371 | TEST AUC=0.6053 | n=143\n","Confusion matrix:\n"," [[134   0]\n"," [  9   0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.937     1.000     0.968       134\n","           1      0.000     0.000     0.000         9\n","\n","    accuracy                          0.937       143\n","   macro avg      0.469     0.500     0.484       143\n","weighted avg      0.878     0.937     0.907       143\n","\n","\n","Per-fold TEST ACC: [0.9249, 0.3306, 0.8947, 0.5278, 0.7917, 0.4609, 0.9412, 0.4528, 0.681, 0.8, 0.1379, 0.604, 0.2371, 0.9371]\n","Per-fold TEST AUC: [0.5143, 0.2704, 0.1471, 0.6664, 0.0, 0.893, 0.75, 0.6034, 0.3565, 1.0, 0.0724, 0.6269, 0.3091, 0.6053]\n","\n","Mean TEST ACC: 0.6230 ± 0.2622\n","Mean TEST AUC: 0.4868 ± 0.2925\n","\n","Saved TEST-only per-fold metrics to cv7_img_fold_metrics.csv\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["fold_test_aucs"],"metadata":{"id":"yUSkVV9BpHSa","executionInfo":{"status":"ok","timestamp":1760668615322,"user_tz":300,"elapsed":13,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b7fe22e-19b6-4bc4-b9e7-6c7934656758"},"id":"yUSkVV9BpHSa","execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.5142857142857143,\n"," 0.27037037037037037,\n"," 0.14705882352941177,\n"," 0.6664086687306502,\n"," 0.0,\n"," 0.893028024606972,\n"," 0.75,\n"," 0.603448275862069,\n"," 0.3564839934888768,\n"," 1.0,\n"," 0.07236842105263162,\n"," 0.6269303201506591,\n"," 0.3090909090909091,\n"," 0.6053067993366501]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["fold_test_accs"],"metadata":{"id":"KUgcBvQhpHVE","executionInfo":{"status":"ok","timestamp":1760668615332,"user_tz":300,"elapsed":9,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d62ad9e3-14d8-4900-bf56-44e25adb2819"},"id":"KUgcBvQhpHVE","execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.9248554913294798,\n"," 0.3305785123966942,\n"," 0.8947368421052632,\n"," 0.5277777777777778,\n"," 0.7916666666666666,\n"," 0.4608695652173913,\n"," 0.9411764705882353,\n"," 0.4528301886792453,\n"," 0.6810344827586207,\n"," 0.8,\n"," 0.13793103448275862,\n"," 0.6040268456375839,\n"," 0.23711340206185566,\n"," 0.9370629370629371]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":[],"metadata":{"id":"IrWZ5cUFpHXs","executionInfo":{"status":"ok","timestamp":1760668615340,"user_tz":300,"elapsed":5,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"IrWZ5cUFpHXs","execution_count":5,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sPOzCNAug4NW","executionInfo":{"status":"ok","timestamp":1760668615342,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"sPOzCNAug4NW","execution_count":5,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xxOkMiS4g4SL","executionInfo":{"status":"ok","timestamp":1760668615344,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"xxOkMiS4g4SL","execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":5,"id":"3wJQznZz-oll","metadata":{"id":"3wJQznZz-oll","executionInfo":{"status":"ok","timestamp":1760668615349,"user_tz":300,"elapsed":3,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"Gr4rUSqY-o79","metadata":{"id":"Gr4rUSqY-o79","executionInfo":{"status":"ok","timestamp":1760668615353,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"ksQMstdc-o-3","metadata":{"id":"ksQMstdc-o-3","executionInfo":{"status":"ok","timestamp":1760668615356,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"JSdB6j-a-pDF","metadata":{"id":"JSdB6j-a-pDF","executionInfo":{"status":"ok","timestamp":1760668615358,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"U7ouQnxD-pF_","metadata":{"id":"U7ouQnxD-pF_","executionInfo":{"status":"ok","timestamp":1760668615361,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"WnjxgEPK-pIJ","metadata":{"id":"WnjxgEPK-pIJ","executionInfo":{"status":"ok","timestamp":1760668615364,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"j28g8Lqp-pKy","metadata":{"id":"j28g8Lqp-pKy","executionInfo":{"status":"ok","timestamp":1760668615371,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"DJbv-4-G-pMn","metadata":{"id":"DJbv-4-G-pMn","executionInfo":{"status":"ok","timestamp":1760668615373,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"Cxtz-1Fo-pPP","metadata":{"id":"Cxtz-1Fo-pPP","executionInfo":{"status":"ok","timestamp":1760668615375,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"JinSNJgh-pRf","metadata":{"id":"JinSNJgh-pRf","executionInfo":{"status":"ok","timestamp":1760668615378,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"ywg21ljv-pcL","metadata":{"id":"ywg21ljv-pcL","executionInfo":{"status":"ok","timestamp":1760668615381,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"Jl01Xhpa-pfL","metadata":{"id":"Jl01Xhpa-pfL","executionInfo":{"status":"ok","timestamp":1760668615387,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"ErNrKHRm-pg_","metadata":{"id":"ErNrKHRm-pg_","executionInfo":{"status":"ok","timestamp":1760668615390,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"IElgvqQj-pit","metadata":{"id":"IElgvqQj-pit","executionInfo":{"status":"ok","timestamp":1760668615392,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"-TADzyG9-pnO","metadata":{"id":"-TADzyG9-pnO","executionInfo":{"status":"ok","timestamp":1760668615394,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"miiDblbz-ppC","metadata":{"id":"miiDblbz-ppC","executionInfo":{"status":"ok","timestamp":1760668615438,"user_tz":300,"elapsed":43,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"Bnp7fHxm-pqu","metadata":{"id":"Bnp7fHxm-pqu","executionInfo":{"status":"ok","timestamp":1760668615442,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"UiQbsLv47Xu-","metadata":{"id":"UiQbsLv47Xu-","executionInfo":{"status":"ok","timestamp":1760668615444,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"hhAiYZZVGIsM","metadata":{"id":"hhAiYZZVGIsM","executionInfo":{"status":"ok","timestamp":1760668615448,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"EWQ7UG7zGIuj","metadata":{"id":"EWQ7UG7zGIuj","executionInfo":{"status":"ok","timestamp":1760668615453,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"hUObArfBGIw5","metadata":{"id":"hUObArfBGIw5","executionInfo":{"status":"ok","timestamp":1760668615455,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"ln5ftwRAGI0C","metadata":{"id":"ln5ftwRAGI0C","executionInfo":{"status":"ok","timestamp":1760668615459,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"jgczkpH8GI2s","metadata":{"id":"jgczkpH8GI2s","executionInfo":{"status":"ok","timestamp":1760668615461,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"CFxtsYm4DJxo","metadata":{"id":"CFxtsYm4DJxo","executionInfo":{"status":"ok","timestamp":1760668615464,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"zIo_rXgnDJzw","metadata":{"id":"zIo_rXgnDJzw","executionInfo":{"status":"ok","timestamp":1760668615471,"user_tz":300,"elapsed":3,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"N4iBf4B0DJ14","metadata":{"id":"N4iBf4B0DJ14","executionInfo":{"status":"ok","timestamp":1760668615473,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"mGuWgjhCDJ5y","metadata":{"id":"mGuWgjhCDJ5y","executionInfo":{"status":"ok","timestamp":1760668615476,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"mtPQw2LIDJ8A","metadata":{"id":"mtPQw2LIDJ8A","executionInfo":{"status":"ok","timestamp":1760668615485,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"VRIqcx7HDJ9m","metadata":{"id":"VRIqcx7HDJ9m","executionInfo":{"status":"ok","timestamp":1760668615487,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"id":"HfhdGuLEDJ_u","metadata":{"id":"HfhdGuLEDJ_u","executionInfo":{"status":"ok","timestamp":1760668615489,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"virtual ENV","language":"python","name":"environment_instance"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":5}