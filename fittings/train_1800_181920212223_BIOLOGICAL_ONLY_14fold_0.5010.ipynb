{"cells":[{"cell_type":"code","execution_count":1,"id":"8f5a4f5b-bad9-49e3-8dd6-7304666df443","metadata":{"id":"8f5a4f5b-bad9-49e3-8dd6-7304666df443","executionInfo":{"status":"ok","timestamp":1760665630110,"user_tz":300,"elapsed":11350,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","import torchvision\n","import torchvision.transforms as transforms\n","import os\n","import argparse\n","from pathlib import Path\n","import re\n","import random\n","import math\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"id":"dr2Fm7p5mAAN","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28964,"status":"ok","timestamp":1760665659061,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"},"user_tz":300},"id":"dr2Fm7p5mAAN","outputId":"207c09de-533d-4040-f3aa-4a97a8162742"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":[],"metadata":{"id":"gUHWAH8qdC05","executionInfo":{"status":"ok","timestamp":1760665659067,"user_tz":300,"elapsed":4,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"gUHWAH8qdC05","execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L2wH-XagdC3h","executionInfo":{"status":"ok","timestamp":1760665659077,"user_tz":300,"elapsed":4,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"L2wH-XagdC3h","execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### Reading the BF data"],"metadata":{"id":"51Qe0XC1X2Ju"},"id":"51Qe0XC1X2Ju"},{"cell_type":"code","source":["bf_path = '/content/drive/MyDrive/ALL_CLEAN_DEIDEN_NAME AND ECMO DATA(Sheet1) (1) (version 2).csv'\n","cols = ['ID', 'age_days', 'weight', 'study_height', 'Diagnosis']\n","df = pd.read_csv(bf_path, usecols=cols)\n","\n","for col in ['weight', 'study_height', 'age_days']:\n","    s = pd.to_numeric(df[col], errors='coerce')\n","    mx = s.max(skipna=True)\n","    if pd.notna(mx) and mx != 0:\n","        df[col] = s / mx\n","    else:\n","        df[col] = s\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eI4st7P3X51D","executionInfo":{"status":"ok","timestamp":1760665660372,"user_tz":300,"elapsed":1292,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"outputId":"11a2d608-6ab8-4739-9140-10cde2d757c4"},"id":"eI4st7P3X51D","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["   ID  age_days            Diagnosis    weight  study_height\n","0   1  0.018213       Cardiac Arrest  0.042214      0.344538\n","1   2  0.072852       Cardiac Arrest  0.070000      0.431373\n","2   3  0.793776               Sepsis  0.403571      0.896359\n","3   4  0.000287  Respiratory Failure  0.022786      0.268908\n","4   5  0.000287  Respiratory Failure  0.023571      0.285714\n"]}]},{"cell_type":"code","source":["diag_clean = (\n","    df['Diagnosis']\n","      .astype('string')\n","      .str.strip()\n","      .str.replace(r'\\s+', ' ', regex=True)\n","      .fillna('Unknown')\n",")\n","\n","codes, uniques = pd.factorize(diag_clean, sort=True)\n","df['Diagnosis'] = codes.astype('int64')\n","diagnosis_mapping = {cat: int(i) for i, cat in enumerate(uniques)}\n","print(\"Diagnosis mapping (category -> code):\", diagnosis_mapping)\n","# Peek\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6KRSpwpSX53j","executionInfo":{"status":"ok","timestamp":1760665660406,"user_tz":300,"elapsed":29,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"outputId":"16145c8a-523c-42d3-8014-b5c1b72bf1e2"},"id":"6KRSpwpSX53j","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Diagnosis mapping (category -> code): {'Cardiac Arrest': 0, 'Cardiogenic Shock': 1, 'Respiratory Failure': 2, 'Sepsis': 3, 'Septic shock': 4}\n","   ID  age_days  Diagnosis    weight  study_height\n","0   1  0.018213          0  0.042214      0.344538\n","1   2  0.072852          0  0.070000      0.431373\n","2   3  0.793776          3  0.403571      0.896359\n","3   4  0.000287          2  0.022786      0.268908\n","4   5  0.000287          2  0.023571      0.285714\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lCBRlYUMKmvK","executionInfo":{"status":"ok","timestamp":1760665660415,"user_tz":300,"elapsed":6,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"lCBRlYUMKmvK","execution_count":4,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5Jnj3X_X5_P","executionInfo":{"status":"ok","timestamp":1760665660432,"user_tz":300,"elapsed":13,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"outputId":"8a0f10a0-9c34-493f-b628-49803677f678"},"id":"Z5Jnj3X_X5_P","execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(72, 5)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":[],"metadata":{"id":"Z-Q3ZaH-X6EY","executionInfo":{"status":"ok","timestamp":1760665660446,"user_tz":300,"elapsed":11,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"Z-Q3ZaH-X6EY","execution_count":5,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"REn1fKi1pHMT","executionInfo":{"status":"ok","timestamp":1760665660457,"user_tz":300,"elapsed":6,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"REn1fKi1pHMT","execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### No normalization!"],"metadata":{"id":"vCi0eO54p2NW"},"id":"vCi0eO54p2NW"},{"cell_type":"code","source":["from pathlib import Path\n","import re, random, math, os\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n","\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# =========================\n","# Config\n","# =========================\n","SPLIT_DIR = r\"/content/drive/MyDrive/CD/patient_data_clean_nozero_181920212223_1800\"\n","POS_PATIENTS = {1, 2, 16, 19, 21, 22, 25, 37, 39, 43, 44, 47, 50, 56, 58, 62, 65, 66, 73, 78}\n","\n","BATCH_SIZE       = 3\n","EPOCHS           = 100\n","LR               = 1e-4\n","SEED             = 1\n","K_FOLDS          = 14\n","\n","# =========================\n","# Repro\n","# =========================\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n","for g in tf.config.list_physical_devices('GPU'):\n","    try: tf.config.experimental.set_memory_growth(g, True)\n","    except Exception: pass\n","\n","# =========================\n","# Helpers\n","# =========================\n","PATIENT_NUM_RX = re.compile(r'^ID(\\d+)')  # e.g., \"ID76-2_...\" -> 76\n","def patient_num_from_path(pathlike):\n","    stem = Path(pathlike).stem\n","    m = PATIENT_NUM_RX.match(stem)\n","    return int(m.group(1)) if m else None\n","\n","def label_for_file(p: Path) -> int:\n","    pnum = patient_num_from_path(p)\n","    return 1 if (pnum is not None and pnum in POS_PATIENTS) else 0\n","\n","# =========================\n","# Load pre-existing 4-feature DataFrame: df (must be in memory)\n","# Must contain column 'ID' + 4 feature columns.\n","# =========================\n","feats_df = df.copy()  # uses your in-memory DataFrame\n","if \"ID\" not in feats_df.columns:\n","    raise RuntimeError(\"Your features DataFrame must contain column 'ID'.\")\n","\n","FEAT_COLS = [c for c in feats_df.columns if c != \"ID\"]\n","# if len(FEAT_COLS) != 4:\n","#     raise RuntimeError(f\"Expected exactly 4 feature columns, found {len(FEAT_COLS)}: {FEAT_COLS}\")\n","\n","feats_df[\"ID\"] = pd.to_numeric(feats_df[\"ID\"], errors=\"coerce\").astype(\"Int64\")\n","feats_df = feats_df.dropna(subset=[\"ID\"] + FEAT_COLS).copy()\n","feats_df[\"ID\"] = feats_df[\"ID\"].astype(int)\n","\n","ID_TO_FEAT = {\n","    int(row[\"ID\"]): row[FEAT_COLS].astype(\"float32\").to_numpy()\n","    for _, row in feats_df.iterrows()\n","}\n","FEAT_DIM = len(FEAT_COLS)\n","print('FEAT_DIM =', FEAT_DIM)\n","\n","# =========================\n","# List EEG files ONLY to define splits by patient ID (no EEG is loaded)\n","# =========================\n","split_dir = Path(SPLIT_DIR)\n","all_csvs = sorted(split_dir.glob(\"*.csv\"))\n","if not all_csvs:\n","    raise FileNotFoundError(f\"No CSV found in {SPLIT_DIR}\")\n","\n","id_to_files = {}\n","for f in all_csvs:\n","    pid = patient_num_from_path(f)\n","    if pid is None:\n","        continue\n","    id_to_files.setdefault(pid, []).append(f)\n","\n","all_ids = sorted(id_to_files.keys())\n","\n","valid_ids = [pid for pid in all_ids if pid in ID_TO_FEAT]\n","if not valid_ids:\n","    raise RuntimeError(\"No overlapping patient IDs between files and the 4-feature table.\")\n","if len(valid_ids) < len(all_ids):\n","    print(f\"Dropping {len(all_ids)-len(valid_ids)} patient IDs without 4-feature rows.\")\n","\n","labels_all = np.array([1 if pid in POS_PATIENTS else 0 for pid in valid_ids], dtype=int)\n","\n","print(\"Total valid IDs:\", len(valid_ids),\n","      \"| Pos IDs:\", labels_all.sum(),\n","      \"| Neg IDs:\", (1 - labels_all).sum())\n","\n","# =========================\n","# Data Sequence (tab-only)\n","# Each file becomes one sample with that patient's features.\n","# =========================\n","class TabSequence(keras.utils.Sequence):\n","    def __init__(self, files, batch_size=BATCH_SIZE, shuffle=True):\n","        super().__init__()\n","        self.files = [f for f in files if patient_num_from_path(f) in ID_TO_FEAT]\n","        self.batch_size = int(batch_size)\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        return math.ceil(len(self.files) / self.batch_size)\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.files))\n","        if self.shuffle:\n","            np.random.shuffle(self.indexes)\n","\n","    def __getitem__(self, idx):\n","        idxs = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n","        batch_files = [self.files[i] for i in idxs]\n","        B = len(batch_files)\n","\n","        X_tab = np.empty((B, FEAT_DIM), dtype=np.float32)\n","        y     = np.empty((B,), dtype=np.int32)\n","\n","        for i, f in enumerate(batch_files):\n","            pid = patient_num_from_path(f)\n","            X_tab[i] = ID_TO_FEAT[pid]\n","            y[i] = label_for_file(f)\n","\n","        return {\"tab_input\": X_tab}, y\n","\n","# =========================\n","# Tab-only Model: 4 -> 8 -> 8 -> 1\n","# =========================\n","def build_model(tab_dim=FEAT_DIM, lr=LR, dropout=0.2):\n","    tab_in = keras.Input(shape=(tab_dim,), name=\"tab_input\")\n","    t = layers.Dense(8, activation=\"relu\")(tab_in)\n","    t = layers.Dense(8, activation=\"relu\")(t)\n","    #t = layers.Dropout(dropout)(t)\n","    out = layers.Dense(1, activation=\"sigmoid\")(t)\n","\n","    model = keras.Model(inputs=tab_in, outputs=out)\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(learning_rate=lr),\n","        loss=\"binary_crossentropy\",\n","        metrics=[keras.metrics.BinaryAccuracy(name=\"acc\"),\n","                 keras.metrics.AUC(name=\"auc\")],\n","    )\n","    return model\n","\n","# =========================\n","# Utilities\n","# =========================\n","def safe_roc_auc(y_true, probs):\n","    try:\n","        return roc_auc_score(y_true, probs)\n","    except ValueError:\n","        return float('nan')\n","\n","def plot_roc(y_true, probs, title, out_png):\n","    try:\n","        fpr, tpr, _ = roc_curve(y_true, probs)\n","        plt.figure()\n","        auc = safe_roc_auc(y_true, probs)\n","        plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n","        plt.plot([0,1],[0,1], linestyle=\"--\", linewidth=1)\n","        plt.xlabel(\"False Positive Rate\")\n","        plt.ylabel(\"True Positive Rate\")\n","        plt.title(title)\n","        plt.legend(loc=\"lower right\")\n","        plt.grid(True, alpha=0.3)\n","        plt.tight_layout()\n","        plt.savefig(out_png, dpi=200)\n","        plt.close()\n","    except Exception as e:\n","        print(f\"(Warning) ROC plot failed ({title}): {e}\")\n","\n","# =========================\n","# 5-fold Cross-Validation by patient ID (stratified)\n","# =========================\n","skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=SEED)\n","\n","fold_val_aucs, fold_val_accs = [], []\n","fold_test_aucs, fold_test_accs = [], []\n","fold_sizes = []\n","\n","for fold_idx, (train_index, test_index) in enumerate(skf.split(valid_ids, labels_all), start=1):\n","    ids_train_full = [valid_ids[i] for i in train_index]\n","    ids_test       = [valid_ids[i] for i in test_index]\n","\n","    # small validation split from training IDs (stratified, by ID)\n","    train_labels_full = np.array([1 if pid in POS_PATIENTS else 0 for pid in ids_train_full], dtype=int)\n","    ids_tr, ids_val = train_test_split(\n","        ids_train_full, test_size=0.10, random_state=SEED,\n","        stratify=train_labels_full\n","    )\n","\n","    # Build file lists for this fold\n","    train_files = [f for pid in ids_tr  for f in id_to_files[pid]]\n","    val_files   = [f for pid in ids_val for f in id_to_files[pid]]\n","    test_files  = [f for pid in ids_test for f in id_to_files[pid]]\n","\n","    print(f\"\\n--- Fold {fold_idx}/{K_FOLDS} ---\")\n","    def split_summary(name, ids, files):\n","        ys = np.array([label_for_file(f) for f in files], dtype=int)\n","        print(f\"{name:>6} | ids: {len(ids):4d} | files: {len(files):4d} | pos: {(ys==1).sum():4d} | neg: {(ys==0).sum():4d}\")\n","    split_summary(\"train\", ids_tr,  train_files)\n","    split_summary(\"val\",   ids_val, val_files)\n","    split_summary(\"test\",  ids_test, test_files)\n","\n","    fold_sizes.append((len(train_files), len(val_files), len(test_files)))\n","\n","    # Generators\n","    train_gen = TabSequence(train_files, batch_size=BATCH_SIZE, shuffle=True)\n","    val_gen   = TabSequence(val_files,   batch_size=BATCH_SIZE, shuffle=False)\n","\n","    # Model + training\n","    model = build_model()\n","    best_path = f\"best_tab_only_fold{fold_idx}.h5\"\n","    ckpt = keras.callbacks.ModelCheckpoint(\n","        best_path, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1\n","    )\n","\n","    history = model.fit(\n","        train_gen,\n","        validation_data=val_gen,\n","        epochs=EPOCHS,\n","        callbacks=[ckpt],\n","        verbose=1,\n","    )\n","\n","    # Load best\n","    best_model = keras.models.load_model(best_path)\n","\n","    # ====== VALIDATION METRICS ======\n","    val_probs = best_model.predict(val_gen, verbose=0).ravel().astype(float)\n","    val_ytrue = np.array([label_for_file(f) for f in val_gen.files], dtype=int)\n","    val_auc = safe_roc_auc(val_ytrue, val_probs)\n","    val_acc = accuracy_score(val_ytrue, (val_probs >= 0.5).astype(int))\n","    fold_val_aucs.append(val_auc)\n","    fold_val_accs.append(val_acc)\n","    print(f\"Fold {fold_idx} | VAL  | AUC={val_auc:.4f} | ACC={val_acc:.4f} | n={len(val_ytrue)}\")\n","    plot_roc(val_ytrue, val_probs,\n","             title=f\"ROC — VAL Fold {fold_idx:02d} (n={len(val_ytrue)})\",\n","             out_png=f\"roc_val_fold_{fold_idx:02d}.png\")\n","\n","    # ====== TEST METRICS ======\n","    test_files2 = [f for f in test_files if patient_num_from_path(f) in ID_TO_FEAT]\n","    X_tab_test = np.empty((len(test_files2), FEAT_DIM), dtype=np.float32)\n","    for i, f in enumerate(test_files2):\n","        X_tab_test[i] = ID_TO_FEAT[patient_num_from_path(f)]\n","    y_true = np.array([label_for_file(f) for f in test_files2], dtype=int)\n","\n","    probs = best_model.predict({\"tab_input\": X_tab_test}, verbose=0).ravel().astype(float)\n","    test_auc = safe_roc_auc(y_true, probs)\n","    test_acc = accuracy_score(y_true, (probs >= 0.5).astype(int))\n","    fold_test_aucs.append(test_auc)\n","    fold_test_accs.append(test_acc)\n","    print(f\"Fold {fold_idx} | TEST | AUC={test_auc:.4f} | ACC={test_acc:.4f} | n={len(y_true)}\")\n","    plot_roc(y_true, probs,\n","             title=f\"ROC — TEST Fold {fold_idx:02d} (n={len(y_true)})\",\n","             out_png=f\"roc_test_fold_{fold_idx:02d}.png\")\n","\n","# =========================\n","# Results across folds\n","# =========================\n","def mean_std(arr):\n","    arr = np.asarray(arr, dtype=float)\n","    return np.nanmean(arr), np.nanstd(arr)\n","\n","mAUC_val, sAUC_val = mean_std(fold_val_aucs)\n","mACC_val, sACC_val = mean_std(fold_val_accs)\n","mAUC_tst, sAUC_tst = mean_std(fold_test_aucs)\n","mACC_tst, sACC_tst = mean_std(fold_test_accs)\n","\n","print(\"\\nPer-fold VAL  AUCs:\", [None if np.isnan(x) else round(x,4) for x in fold_val_aucs])\n","print(\"Per-fold VAL  ACCs:\", [round(x,4) for x in fold_val_accs])\n","print(\"Per-fold TEST AUCs:\", [None if np.isnan(x) else round(x,4) for x in fold_test_aucs])\n","print(\"Per-fold TEST ACCs:\", [round(x,4) for x in fold_test_accs])\n","\n","print(f\"\\nVAL  AUC: {mAUC_val:.4f} ± {sAUC_val:.4f} | ACC: {mACC_val:.4f} ± {sACC_val:.4f}\")\n","print(f\"TEST AUC: {mAUC_tst:.4f} ± {sAUC_tst:.4f} | ACC: {mACC_tst:.4f} ± {sACC_tst:.4f}\")\n","\n","# Save fold-wise metrics\n","rows = []\n","for i, (tr_n, va_n, te_n) in enumerate(fold_sizes, start=1):\n","    rows.append({\n","        \"fold\": i,\n","        \"train_files\": tr_n,\n","        \"val_files\": va_n,\n","        \"test_files\": te_n,\n","        \"val_auc\": fold_val_aucs[i-1],\n","        \"val_acc\": fold_val_accs[i-1],\n","        \"test_auc\": fold_test_aucs[i-1],\n","        \"test_acc\": fold_test_accs[i-1],\n","    })\n","metrics_df = pd.DataFrame(rows)\n","metrics_df.to_csv(\"cv_tabonly_fold_metrics.csv\", index=False)\n","print(\"\\nSaved metrics to cv_tabonly_fold_metrics.csv and ROC plots to roc_val_fold_XX.png / roc_test_fold_XX.png\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lD7pVdaPpHPi","outputId":"9001cf1e-56ca-49fe-b7a2-e91c8bb0c3cc","executionInfo":{"status":"ok","timestamp":1760666878846,"user_tz":300,"elapsed":1218386,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"lD7pVdaPpHPi","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["FEAT_DIM = 4\n","Dropping 1 patient IDs without 4-feature rows.\n","Total valid IDs: 43 | Pos IDs: 14 | Neg IDs: 29\n","\n","--- Fold 1/14 ---\n"," train | ids:   35 | files:  898 | pos:  323 | neg:  575\n","   val | ids:    4 | files:  113 | pos:   77 | neg:   36\n","  test | ids:    4 | files:  179 | pos:    5 | neg:  174\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m284/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.6402 - auc: 0.4801 - loss: 0.6590\n","Epoch 1: val_loss improved from inf to 0.80996, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - acc: 0.6402 - auc: 0.4842 - loss: 0.6587 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 0.8100\n","Epoch 2/100\n","\u001b[1m283/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6342 - auc: 0.7288 - loss: 0.6382\n","Epoch 2: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6346 - auc: 0.7309 - loss: 0.6377 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 0.8795\n","Epoch 3/100\n","\u001b[1m285/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6501 - auc: 0.8474 - loss: 0.6018\n","Epoch 3: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6495 - auc: 0.8466 - loss: 0.6021 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 0.9320\n","Epoch 4/100\n","\u001b[1m277/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6408 - auc: 0.8629 - loss: 0.5945\n","Epoch 4: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6407 - auc: 0.8618 - loss: 0.5946 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 0.9755\n","Epoch 5/100\n","\u001b[1m282/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6353 - auc: 0.8527 - loss: 0.5897\n","Epoch 5: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6355 - auc: 0.8525 - loss: 0.5896 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.0132\n","Epoch 6/100\n","\u001b[1m294/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6493 - auc: 0.8632 - loss: 0.5740\n","Epoch 6: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6490 - auc: 0.8629 - loss: 0.5742 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.0498\n","Epoch 7/100\n","\u001b[1m289/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6468 - auc: 0.8538 - loss: 0.5707\n","Epoch 7: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6466 - auc: 0.8538 - loss: 0.5708 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.0832\n","Epoch 8/100\n","\u001b[1m288/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6062 - auc: 0.8481 - loss: 0.5876\n","Epoch 8: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6076 - auc: 0.8481 - loss: 0.5868 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.1128\n","Epoch 9/100\n","\u001b[1m285/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6367 - auc: 0.8451 - loss: 0.5646\n","Epoch 9: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6368 - auc: 0.8450 - loss: 0.5645 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.1429\n","Epoch 10/100\n","\u001b[1m290/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6523 - auc: 0.8305 - loss: 0.5539\n","Epoch 10: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6519 - auc: 0.8313 - loss: 0.5539 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.1770\n","Epoch 11/100\n","\u001b[1m294/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6520 - auc: 0.8207 - loss: 0.5509\n","Epoch 11: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6518 - auc: 0.8214 - loss: 0.5508 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 1.2097\n","Epoch 12/100\n","\u001b[1m294/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6461 - auc: 0.8473 - loss: 0.5382\n","Epoch 12: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6460 - auc: 0.8475 - loss: 0.5383 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.2426\n","Epoch 13/100\n","\u001b[1m297/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6462 - auc: 0.8690 - loss: 0.5262\n","Epoch 13: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6461 - auc: 0.8688 - loss: 0.5263 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.2810\n","Epoch 14/100\n","\u001b[1m294/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6398 - auc: 0.8420 - loss: 0.5330\n","Epoch 14: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6398 - auc: 0.8423 - loss: 0.5329 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.3190\n","Epoch 15/100\n","\u001b[1m290/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6395 - auc: 0.8335 - loss: 0.5278\n","Epoch 15: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6397 - auc: 0.8344 - loss: 0.5275 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.3550\n","Epoch 16/100\n","\u001b[1m291/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7135 - auc: 0.8707 - loss: 0.5056\n","Epoch 16: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7134 - auc: 0.8707 - loss: 0.5059 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.3823\n","Epoch 17/100\n","\u001b[1m290/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7164 - auc: 0.8701 - loss: 0.5104\n","Epoch 17: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7163 - auc: 0.8703 - loss: 0.5102 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.4233\n","Epoch 18/100\n","\u001b[1m288/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7200 - auc: 0.8792 - loss: 0.5033\n","Epoch 18: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7204 - auc: 0.8790 - loss: 0.5031 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.4620\n","Epoch 19/100\n","\u001b[1m287/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7522 - auc: 0.8697 - loss: 0.4873\n","Epoch 19: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7535 - auc: 0.8702 - loss: 0.4876 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.5011\n","Epoch 20/100\n","\u001b[1m289/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8728 - auc: 0.9009 - loss: 0.4830\n","Epoch 20: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8720 - auc: 0.9002 - loss: 0.4832 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.5454\n","Epoch 21/100\n","\u001b[1m276/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8419 - auc: 0.8797 - loss: 0.4907\n","Epoch 21: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8430 - auc: 0.8803 - loss: 0.4899 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.5875\n","Epoch 22/100\n","\u001b[1m290/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8504 - auc: 0.8859 - loss: 0.4922\n","Epoch 22: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8506 - auc: 0.8861 - loss: 0.4916 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.6425\n","Epoch 23/100\n","\u001b[1m293/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8537 - auc: 0.8694 - loss: 0.4708\n","Epoch 23: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8537 - auc: 0.8700 - loss: 0.4708 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 1.6751\n","Epoch 24/100\n","\u001b[1m297/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8696 - auc: 0.8963 - loss: 0.4510\n","Epoch 24: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8693 - auc: 0.8963 - loss: 0.4511 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.7218\n","Epoch 25/100\n","\u001b[1m296/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8392 - auc: 0.9042 - loss: 0.4664\n","Epoch 25: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8394 - auc: 0.9043 - loss: 0.4662 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.7638\n","Epoch 26/100\n","\u001b[1m297/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8351 - auc: 0.9141 - loss: 0.4752\n","Epoch 26: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8353 - auc: 0.9142 - loss: 0.4748 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.8087\n","Epoch 27/100\n","\u001b[1m295/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8537 - auc: 0.9202 - loss: 0.4422\n","Epoch 27: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8537 - auc: 0.9202 - loss: 0.4422 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.8532\n","Epoch 28/100\n","\u001b[1m295/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8578 - auc: 0.9240 - loss: 0.4467\n","Epoch 28: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8577 - auc: 0.9240 - loss: 0.4465 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.8925\n","Epoch 29/100\n","\u001b[1m286/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8614 - auc: 0.9357 - loss: 0.4267\n","Epoch 29: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8610 - auc: 0.9353 - loss: 0.4272 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 1.9326\n","Epoch 30/100\n","\u001b[1m287/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8491 - auc: 0.9399 - loss: 0.4289\n","Epoch 30: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8494 - auc: 0.9395 - loss: 0.4287 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 1.9808\n","Epoch 31/100\n","\u001b[1m294/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8469 - auc: 0.9314 - loss: 0.4385\n","Epoch 31: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8471 - auc: 0.9315 - loss: 0.4381 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 2.0232\n","Epoch 32/100\n","\u001b[1m294/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8500 - auc: 0.9312 - loss: 0.4155\n","Epoch 32: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8501 - auc: 0.9312 - loss: 0.4155 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 2.0691\n","Epoch 33/100\n","\u001b[1m285/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8611 - auc: 0.9400 - loss: 0.4145\n","Epoch 33: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8608 - auc: 0.9397 - loss: 0.4143 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 2.1140\n","Epoch 34/100\n","\u001b[1m293/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8498 - auc: 0.9421 - loss: 0.4033\n","Epoch 34: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8499 - auc: 0.9423 - loss: 0.4034 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 2.1545\n","Epoch 35/100\n","\u001b[1m286/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8360 - auc: 0.9565 - loss: 0.4205\n","Epoch 35: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8370 - auc: 0.9574 - loss: 0.4195 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 2.1972\n","Epoch 36/100\n","\u001b[1m291/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8515 - auc: 0.9681 - loss: 0.4120\n","Epoch 36: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8516 - auc: 0.9683 - loss: 0.4116 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 2.2366\n","Epoch 37/100\n","\u001b[1m290/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8365 - auc: 0.9582 - loss: 0.4173\n","Epoch 37: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8371 - auc: 0.9588 - loss: 0.4164 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 2.2781\n","Epoch 38/100\n","\u001b[1m286/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8579 - auc: 0.9774 - loss: 0.3861\n","Epoch 38: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8577 - auc: 0.9773 - loss: 0.3862 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 2.3143\n","Epoch 39/100\n","\u001b[1m297/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8593 - auc: 0.9778 - loss: 0.3760\n","Epoch 39: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8593 - auc: 0.9778 - loss: 0.3761 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 2.3546\n","Epoch 40/100\n","\u001b[1m290/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8811 - auc: 0.9852 - loss: 0.3536\n","Epoch 40: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8802 - auc: 0.9848 - loss: 0.3544 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 2.3949\n","Epoch 41/100\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8297 - auc: 0.9724 - loss: 0.3934\n","Epoch 41: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8298 - auc: 0.9724 - loss: 0.3933 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 2.4368\n","Epoch 42/100\n","\u001b[1m298/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8644 - auc: 0.9543 - loss: 0.3705\n","Epoch 42: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8643 - auc: 0.9545 - loss: 0.3705 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 2.4714\n","Epoch 43/100\n","\u001b[1m287/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8458 - auc: 0.9780 - loss: 0.3674\n","Epoch 43: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8462 - auc: 0.9779 - loss: 0.3670 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 2.5123\n","Epoch 44/100\n","\u001b[1m293/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8277 - auc: 0.9637 - loss: 0.3822\n","Epoch 44: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8284 - auc: 0.9641 - loss: 0.3815 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 2.5502\n","Epoch 45/100\n","\u001b[1m288/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8674 - auc: 0.9812 - loss: 0.3389\n","Epoch 45: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8668 - auc: 0.9809 - loss: 0.3395 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 2.5752\n","Epoch 46/100\n","\u001b[1m290/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8449 - auc: 0.9762 - loss: 0.3473\n","Epoch 46: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8452 - auc: 0.9761 - loss: 0.3472 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 2.6137\n","Epoch 47/100\n","\u001b[1m293/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8489 - auc: 0.9640 - loss: 0.3611\n","Epoch 47: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8491 - auc: 0.9644 - loss: 0.3606 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 2.6491\n","Epoch 48/100\n","\u001b[1m295/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8577 - auc: 0.9815 - loss: 0.3337\n","Epoch 48: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8576 - auc: 0.9814 - loss: 0.3338 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 2.6744\n","Epoch 49/100\n","\u001b[1m298/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8555 - auc: 0.9702 - loss: 0.3420\n","Epoch 49: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8555 - auc: 0.9702 - loss: 0.3419 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 2.7086\n","Epoch 50/100\n","\u001b[1m294/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8656 - auc: 0.9720 - loss: 0.3222\n","Epoch 50: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8653 - auc: 0.9720 - loss: 0.3224 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 2.7407\n","Epoch 51/100\n","\u001b[1m289/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8623 - auc: 0.9721 - loss: 0.3209\n","Epoch 51: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8621 - auc: 0.9722 - loss: 0.3210 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 2.7702\n","Epoch 52/100\n","\u001b[1m278/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8527 - auc: 0.9780 - loss: 0.3138\n","Epoch 52: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8531 - auc: 0.9776 - loss: 0.3140 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 2.7964\n","Epoch 53/100\n","\u001b[1m284/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8546 - auc: 0.9504 - loss: 0.3509\n","Epoch 53: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8545 - auc: 0.9516 - loss: 0.3490 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 2.8129\n","Epoch 54/100\n","\u001b[1m284/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8483 - auc: 0.9784 - loss: 0.3073\n","Epoch 54: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8486 - auc: 0.9781 - loss: 0.3075 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 2.8504\n","Epoch 55/100\n","\u001b[1m290/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8461 - auc: 0.9689 - loss: 0.3055\n","Epoch 55: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8464 - auc: 0.9690 - loss: 0.3056 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 2.8756\n","Epoch 56/100\n","\u001b[1m297/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8900 - auc: 0.9753 - loss: 0.2722\n","Epoch 56: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8896 - auc: 0.9753 - loss: 0.2726 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 2.9006\n","Epoch 57/100\n","\u001b[1m293/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8572 - auc: 0.9634 - loss: 0.2982\n","Epoch 57: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8571 - auc: 0.9636 - loss: 0.2982 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 2.9260\n","Epoch 58/100\n","\u001b[1m293/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8566 - auc: 0.9588 - loss: 0.2991\n","Epoch 58: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8566 - auc: 0.9592 - loss: 0.2990 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 2.9523\n","Epoch 59/100\n","\u001b[1m281/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8609 - auc: 0.9673 - loss: 0.2857\n","Epoch 59: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8605 - auc: 0.9676 - loss: 0.2862 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 2.9751\n","Epoch 60/100\n","\u001b[1m299/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8563 - auc: 0.9788 - loss: 0.2821\n","Epoch 60: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8563 - auc: 0.9787 - loss: 0.2821 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 2.9940\n","Epoch 61/100\n","\u001b[1m292/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8612 - auc: 0.9811 - loss: 0.2633\n","Epoch 61: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8610 - auc: 0.9809 - loss: 0.2638 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.0185\n","Epoch 62/100\n","\u001b[1m295/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9322 - auc: 0.9713 - loss: 0.2711\n","Epoch 62: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9323 - auc: 0.9713 - loss: 0.2713 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.0343\n","Epoch 63/100\n","\u001b[1m296/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9495 - auc: 0.9782 - loss: 0.2552\n","Epoch 63: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9494 - auc: 0.9781 - loss: 0.2556 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.0606\n","Epoch 64/100\n","\u001b[1m289/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9452 - auc: 0.9763 - loss: 0.2623\n","Epoch 64: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9452 - auc: 0.9761 - loss: 0.2627 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.0887\n","Epoch 65/100\n","\u001b[1m292/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9521 - auc: 0.9805 - loss: 0.2576\n","Epoch 65: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9518 - auc: 0.9802 - loss: 0.2580 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.1043\n","Epoch 66/100\n","\u001b[1m295/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9315 - auc: 0.9475 - loss: 0.3163\n","Epoch 66: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9318 - auc: 0.9480 - loss: 0.3154 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.1296\n","Epoch 67/100\n","\u001b[1m289/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9488 - auc: 0.9706 - loss: 0.2551\n","Epoch 67: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9487 - auc: 0.9707 - loss: 0.2555 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.1359\n","Epoch 68/100\n","\u001b[1m289/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9466 - auc: 0.9708 - loss: 0.2501\n","Epoch 68: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9466 - auc: 0.9708 - loss: 0.2505 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.1539\n","Epoch 69/100\n","\u001b[1m284/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9512 - auc: 0.9829 - loss: 0.2364\n","Epoch 69: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9507 - auc: 0.9823 - loss: 0.2377 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.1758\n","Epoch 70/100\n","\u001b[1m276/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9447 - auc: 0.9700 - loss: 0.2514\n","Epoch 70: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9441 - auc: 0.9704 - loss: 0.2515 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 3.1916\n","Epoch 71/100\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9274 - auc: 0.9705 - loss: 0.2640\n","Epoch 71: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9274 - auc: 0.9705 - loss: 0.2640 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 3.2153\n","Epoch 72/100\n","\u001b[1m297/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9226 - auc: 0.9787 - loss: 0.2316\n","Epoch 72: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9226 - auc: 0.9786 - loss: 0.2318 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 3.2267\n","Epoch 73/100\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9142 - auc: 0.9693 - loss: 0.2577\n","Epoch 73: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9143 - auc: 0.9694 - loss: 0.2577 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 3.2431\n","Epoch 74/100\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9281 - auc: 0.9796 - loss: 0.2356\n","Epoch 74: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9281 - auc: 0.9796 - loss: 0.2357 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 3.2619\n","Epoch 75/100\n","\u001b[1m273/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9178 - auc: 0.9788 - loss: 0.2434\n","Epoch 75: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9185 - auc: 0.9784 - loss: 0.2433 - val_acc: 0.3186 - val_auc: 0.0000e+00 - val_loss: 3.2735\n","Epoch 76/100\n","\u001b[1m295/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9326 - auc: 0.9709 - loss: 0.2530\n","Epoch 76: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9324 - auc: 0.9710 - loss: 0.2528 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.2881\n","Epoch 77/100\n","\u001b[1m286/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9267 - auc: 0.9649 - loss: 0.2597\n","Epoch 77: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9265 - auc: 0.9653 - loss: 0.2586 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.3025\n","Epoch 78/100\n","\u001b[1m289/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9175 - auc: 0.9499 - loss: 0.2715\n","Epoch 78: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9177 - auc: 0.9509 - loss: 0.2701 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.3121\n","Epoch 79/100\n","\u001b[1m281/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9311 - auc: 0.9762 - loss: 0.2187\n","Epoch 79: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9304 - auc: 0.9760 - loss: 0.2197 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.3258\n","Epoch 80/100\n","\u001b[1m282/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9310 - auc: 0.9740 - loss: 0.2288\n","Epoch 80: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9304 - auc: 0.9740 - loss: 0.2290 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.3336\n","Epoch 81/100\n","\u001b[1m279/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9080 - auc: 0.9672 - loss: 0.2335\n","Epoch 81: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9091 - auc: 0.9677 - loss: 0.2332 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.3506\n","Epoch 82/100\n","\u001b[1m279/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9315 - auc: 0.9778 - loss: 0.2284\n","Epoch 82: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9308 - auc: 0.9775 - loss: 0.2284 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.3659\n","Epoch 83/100\n","\u001b[1m286/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9335 - auc: 0.9646 - loss: 0.2207\n","Epoch 83: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9329 - auc: 0.9652 - loss: 0.2209 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.3749\n","Epoch 84/100\n","\u001b[1m283/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9283 - auc: 0.9782 - loss: 0.2113\n","Epoch 84: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9279 - auc: 0.9780 - loss: 0.2121 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.3926\n","Epoch 85/100\n","\u001b[1m277/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9010 - auc: 0.9637 - loss: 0.2526\n","Epoch 85: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9027 - auc: 0.9646 - loss: 0.2502 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.4000\n","Epoch 86/100\n","\u001b[1m279/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9324 - auc: 0.9613 - loss: 0.2291\n","Epoch 86: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9317 - auc: 0.9623 - loss: 0.2284 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.4060\n","Epoch 87/100\n","\u001b[1m296/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9225 - auc: 0.9524 - loss: 0.2559\n","Epoch 87: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9226 - auc: 0.9528 - loss: 0.2553 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.4251\n","Epoch 88/100\n","\u001b[1m286/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9212 - auc: 0.9864 - loss: 0.1923\n","Epoch 88: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9212 - auc: 0.9858 - loss: 0.1936 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.4265\n","Epoch 89/100\n","\u001b[1m283/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9151 - auc: 0.9702 - loss: 0.2202\n","Epoch 89: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9156 - auc: 0.9705 - loss: 0.2199 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.4491\n","Epoch 90/100\n","\u001b[1m279/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9318 - auc: 0.9828 - loss: 0.1938\n","Epoch 90: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9311 - auc: 0.9822 - loss: 0.1952 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.4523\n","Epoch 91/100\n","\u001b[1m281/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9153 - auc: 0.9699 - loss: 0.2359\n","Epoch 91: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9158 - auc: 0.9702 - loss: 0.2344 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.4533\n","Epoch 92/100\n","\u001b[1m291/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9024 - auc: 0.9586 - loss: 0.2509\n","Epoch 92: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9031 - auc: 0.9591 - loss: 0.2496 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.4704\n","Epoch 93/100\n","\u001b[1m291/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9175 - auc: 0.9677 - loss: 0.2235\n","Epoch 93: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9177 - auc: 0.9680 - loss: 0.2231 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.4756\n","Epoch 94/100\n","\u001b[1m293/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9080 - auc: 0.9701 - loss: 0.2250\n","Epoch 94: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9084 - auc: 0.9702 - loss: 0.2246 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.4839\n","Epoch 95/100\n","\u001b[1m286/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9285 - auc: 0.9789 - loss: 0.2072\n","Epoch 95: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9283 - auc: 0.9788 - loss: 0.2072 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.4974\n","Epoch 96/100\n","\u001b[1m289/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9206 - auc: 0.9705 - loss: 0.2222\n","Epoch 96: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9207 - auc: 0.9707 - loss: 0.2216 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.5067\n","Epoch 97/100\n","\u001b[1m292/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9127 - auc: 0.9613 - loss: 0.2197\n","Epoch 97: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9130 - auc: 0.9617 - loss: 0.2194 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.5193\n","Epoch 98/100\n","\u001b[1m291/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9191 - auc: 0.9756 - loss: 0.2034\n","Epoch 98: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9193 - auc: 0.9756 - loss: 0.2035 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.5199\n","Epoch 99/100\n","\u001b[1m297/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9141 - auc: 0.9765 - loss: 0.2079\n","Epoch 99: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9142 - auc: 0.9765 - loss: 0.2078 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.5387\n","Epoch 100/100\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9164 - auc: 0.9725 - loss: 0.2052\n","Epoch 100: val_loss did not improve from 0.80996\n","\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9164 - auc: 0.9725 - loss: 0.2052 - val_acc: 0.3186 - val_auc: 0.3194 - val_loss: 3.5346\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 1 | VAL  | AUC=0.0000 | ACC=0.3186 | n=113\n","Fold 1 | TEST | AUC=0.0805 | ACC=0.9721 | n=179\n","\n","--- Fold 2/14 ---\n"," train | ids:   36 | files:  958 | pos:  247 | neg:  711\n","   val | ids:    4 | files:  118 | pos:   77 | neg:   41\n","  test | ids:    3 | files:  114 | pos:   81 | neg:   33\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m301/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2207 - auc: 0.2136 - loss: 0.8945\n","Epoch 1: val_loss improved from inf to 0.63035, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - acc: 0.2191 - auc: 0.2136 - loss: 0.8919 - val_acc: 0.6525 - val_auc: 1.0000 - val_loss: 0.6303\n","Epoch 2/100\n","\u001b[1m310/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.2587 - auc: 0.4346 - loss: 0.7254\n","Epoch 2: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.2618 - auc: 0.4394 - loss: 0.7248 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.6758\n","Epoch 3/100\n","\u001b[1m318/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7080 - auc: 0.7660 - loss: 0.6705\n","Epoch 3: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7083 - auc: 0.7664 - loss: 0.6705 - val_acc: 0.3475 - val_auc: 0.8537 - val_loss: 0.7086\n","Epoch 4/100\n","\u001b[1m316/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7696 - auc: 0.8317 - loss: 0.6445\n","Epoch 4: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7695 - auc: 0.8317 - loss: 0.6444 - val_acc: 0.3475 - val_auc: 0.3537 - val_loss: 0.7303\n","Epoch 5/100\n","\u001b[1m316/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7984 - auc: 0.8348 - loss: 0.6210\n","Epoch 5: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7985 - auc: 0.8348 - loss: 0.6209 - val_acc: 0.3475 - val_auc: 0.6951 - val_loss: 0.7464\n","Epoch 6/100\n","\u001b[1m316/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8596 - auc: 0.8256 - loss: 0.5914\n","Epoch 6: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8598 - auc: 0.8258 - loss: 0.5913 - val_acc: 0.3475 - val_auc: 0.6951 - val_loss: 0.7654\n","Epoch 7/100\n","\u001b[1m294/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8646 - auc: 0.8286 - loss: 0.5660\n","Epoch 7: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8654 - auc: 0.8308 - loss: 0.5652 - val_acc: 0.3475 - val_auc: 0.6951 - val_loss: 0.7893\n","Epoch 8/100\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8812 - auc: 0.8432 - loss: 0.5307\n","Epoch 8: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8812 - auc: 0.8433 - loss: 0.5307 - val_acc: 0.3475 - val_auc: 0.6951 - val_loss: 0.8175\n","Epoch 9/100\n","\u001b[1m311/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8707 - auc: 0.8569 - loss: 0.5044\n","Epoch 9: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8709 - auc: 0.8571 - loss: 0.5042 - val_acc: 0.3475 - val_auc: 0.8537 - val_loss: 0.8511\n","Epoch 10/100\n","\u001b[1m307/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8901 - auc: 0.8893 - loss: 0.4669\n","Epoch 10: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8895 - auc: 0.8878 - loss: 0.4671 - val_acc: 0.3475 - val_auc: 0.8537 - val_loss: 0.8884\n","Epoch 11/100\n","\u001b[1m300/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8748 - auc: 0.8651 - loss: 0.4512\n","Epoch 11: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8750 - auc: 0.8653 - loss: 0.4505 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.9289\n","Epoch 12/100\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9324 - auc: 0.8744 - loss: 0.4138\n","Epoch 12: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9324 - auc: 0.8744 - loss: 0.4138 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.9711\n","Epoch 13/100\n","\u001b[1m295/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9327 - auc: 0.8320 - loss: 0.4064\n","Epoch 13: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9335 - auc: 0.8342 - loss: 0.4054 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0136\n","Epoch 14/100\n","\u001b[1m295/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9406 - auc: 0.8394 - loss: 0.3838\n","Epoch 14: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9407 - auc: 0.8410 - loss: 0.3833 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0551\n","Epoch 15/100\n","\u001b[1m294/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9513 - auc: 0.8894 - loss: 0.3428\n","Epoch 15: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9506 - auc: 0.8867 - loss: 0.3440 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0973\n","Epoch 16/100\n","\u001b[1m297/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9480 - auc: 0.8396 - loss: 0.3365\n","Epoch 16: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9477 - auc: 0.8411 - loss: 0.3370 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.1355\n","Epoch 17/100\n","\u001b[1m296/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9398 - auc: 0.8329 - loss: 0.3400\n","Epoch 17: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9400 - auc: 0.8346 - loss: 0.3394 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.1706\n","Epoch 18/100\n","\u001b[1m318/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9379 - auc: 0.8184 - loss: 0.3301\n","Epoch 18: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9379 - auc: 0.8187 - loss: 0.3300 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.2033\n","Epoch 19/100\n","\u001b[1m319/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9383 - auc: 0.8655 - loss: 0.3182\n","Epoch 19: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9383 - auc: 0.8654 - loss: 0.3181 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.2329\n","Epoch 20/100\n","\u001b[1m319/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9358 - auc: 0.8497 - loss: 0.3124\n","Epoch 20: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9359 - auc: 0.8498 - loss: 0.3123 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.2607\n","Epoch 21/100\n","\u001b[1m319/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9412 - auc: 0.8297 - loss: 0.2854\n","Epoch 21: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9412 - auc: 0.8299 - loss: 0.2854 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.2826\n","Epoch 22/100\n","\u001b[1m296/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9454 - auc: 0.8590 - loss: 0.2759\n","Epoch 22: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9453 - auc: 0.8590 - loss: 0.2761 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.3048\n","Epoch 23/100\n","\u001b[1m298/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9334 - auc: 0.8624 - loss: 0.3024\n","Epoch 23: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9341 - auc: 0.8622 - loss: 0.3006 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.3211\n","Epoch 24/100\n","\u001b[1m296/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9425 - auc: 0.8605 - loss: 0.2729\n","Epoch 24: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9425 - auc: 0.8593 - loss: 0.2729 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.3370\n","Epoch 25/100\n","\u001b[1m313/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9435 - auc: 0.8430 - loss: 0.2632\n","Epoch 25: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9435 - auc: 0.8432 - loss: 0.2633 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.3505\n","Epoch 26/100\n","\u001b[1m313/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9374 - auc: 0.8511 - loss: 0.2725\n","Epoch 26: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9376 - auc: 0.8513 - loss: 0.2723 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.3635\n","Epoch 27/100\n","\u001b[1m308/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9463 - auc: 0.8475 - loss: 0.2532\n","Epoch 27: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9462 - auc: 0.8472 - loss: 0.2534 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.3747\n","Epoch 28/100\n","\u001b[1m296/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9385 - auc: 0.8412 - loss: 0.2664\n","Epoch 28: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9388 - auc: 0.8420 - loss: 0.2655 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.3852\n","Epoch 29/100\n","\u001b[1m313/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9395 - auc: 0.8788 - loss: 0.2554\n","Epoch 29: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9396 - auc: 0.8786 - loss: 0.2553 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.3944\n","Epoch 30/100\n","\u001b[1m315/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9477 - auc: 0.8745 - loss: 0.2379\n","Epoch 30: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9476 - auc: 0.8741 - loss: 0.2381 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.3991\n","Epoch 31/100\n","\u001b[1m315/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9446 - auc: 0.8535 - loss: 0.2373\n","Epoch 31: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9446 - auc: 0.8533 - loss: 0.2374 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4044\n","Epoch 32/100\n","\u001b[1m312/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9349 - auc: 0.8596 - loss: 0.2526\n","Epoch 32: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9351 - auc: 0.8592 - loss: 0.2524 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4114\n","Epoch 33/100\n","\u001b[1m319/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9438 - auc: 0.8432 - loss: 0.2426\n","Epoch 33: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9438 - auc: 0.8432 - loss: 0.2426 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4219\n","Epoch 34/100\n","\u001b[1m295/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9381 - auc: 0.8579 - loss: 0.2503\n","Epoch 34: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9384 - auc: 0.8572 - loss: 0.2497 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4212\n","Epoch 35/100\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9567 - auc: 0.8908 - loss: 0.2049\n","Epoch 35: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9566 - auc: 0.8907 - loss: 0.2050 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4268\n","Epoch 36/100\n","\u001b[1m296/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9336 - auc: 0.8469 - loss: 0.2606\n","Epoch 36: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9343 - auc: 0.8477 - loss: 0.2588 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4320\n","Epoch 37/100\n","\u001b[1m316/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9237 - auc: 0.8377 - loss: 0.2865\n","Epoch 37: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9240 - auc: 0.8381 - loss: 0.2858 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4368\n","Epoch 38/100\n","\u001b[1m299/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9328 - auc: 0.8441 - loss: 0.2643\n","Epoch 38: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9334 - auc: 0.8451 - loss: 0.2625 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4423\n","Epoch 39/100\n","\u001b[1m297/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9377 - auc: 0.8492 - loss: 0.2470\n","Epoch 39: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9381 - auc: 0.8496 - loss: 0.2462 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4455\n","Epoch 40/100\n","\u001b[1m319/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9517 - auc: 0.8705 - loss: 0.2087\n","Epoch 40: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9517 - auc: 0.8704 - loss: 0.2088 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4495\n","Epoch 41/100\n","\u001b[1m310/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9401 - auc: 0.8655 - loss: 0.2339\n","Epoch 41: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9402 - auc: 0.8652 - loss: 0.2338 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4516\n","Epoch 42/100\n","\u001b[1m313/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9466 - auc: 0.8405 - loss: 0.2230\n","Epoch 42: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9465 - auc: 0.8408 - loss: 0.2233 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4521\n","Epoch 43/100\n","\u001b[1m311/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9445 - auc: 0.8723 - loss: 0.2234\n","Epoch 43: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9444 - auc: 0.8717 - loss: 0.2237 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4552\n","Epoch 44/100\n","\u001b[1m304/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9387 - auc: 0.8476 - loss: 0.2431\n","Epoch 44: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9390 - auc: 0.8479 - loss: 0.2424 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4592\n","Epoch 45/100\n","\u001b[1m303/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9400 - auc: 0.8338 - loss: 0.2438\n","Epoch 45: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9402 - auc: 0.8350 - loss: 0.2430 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4574\n","Epoch 46/100\n","\u001b[1m295/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9386 - auc: 0.8432 - loss: 0.2370\n","Epoch 46: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9389 - auc: 0.8441 - loss: 0.2365 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4603\n","Epoch 47/100\n","\u001b[1m318/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9367 - auc: 0.8320 - loss: 0.2477\n","Epoch 47: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9368 - auc: 0.8322 - loss: 0.2476 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4617\n","Epoch 48/100\n","\u001b[1m319/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9414 - auc: 0.8651 - loss: 0.2296\n","Epoch 48: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9414 - auc: 0.8650 - loss: 0.2296 - val_acc: 0.3475 - val_auc: 0.9878 - val_loss: 1.4621\n","Epoch 49/100\n","\u001b[1m295/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9476 - auc: 0.8766 - loss: 0.2130\n","Epoch 49: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9471 - auc: 0.8749 - loss: 0.2144 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4632\n","Epoch 50/100\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9319 - auc: 0.8173 - loss: 0.2624\n","Epoch 50: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9320 - auc: 0.8174 - loss: 0.2623 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4654\n","Epoch 51/100\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9456 - auc: 0.8636 - loss: 0.2224\n","Epoch 51: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9456 - auc: 0.8635 - loss: 0.2224 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4675\n","Epoch 52/100\n","\u001b[1m313/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9343 - auc: 0.8387 - loss: 0.2482\n","Epoch 52: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9345 - auc: 0.8392 - loss: 0.2477 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4666\n","Epoch 53/100\n","\u001b[1m319/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9416 - auc: 0.8569 - loss: 0.2331\n","Epoch 53: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9416 - auc: 0.8569 - loss: 0.2331 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4667\n","Epoch 54/100\n","\u001b[1m318/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9435 - auc: 0.8366 - loss: 0.2279\n","Epoch 54: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9435 - auc: 0.8368 - loss: 0.2279 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4702\n","Epoch 55/100\n","\u001b[1m295/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9443 - auc: 0.8599 - loss: 0.2238\n","Epoch 55: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9442 - auc: 0.8600 - loss: 0.2239 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4707\n","Epoch 56/100\n","\u001b[1m317/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9461 - auc: 0.8636 - loss: 0.2172\n","Epoch 56: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9460 - auc: 0.8635 - loss: 0.2173 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4700\n","Epoch 57/100\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9329 - auc: 0.8535 - loss: 0.2497\n","Epoch 57: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9330 - auc: 0.8535 - loss: 0.2496 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4714\n","Epoch 58/100\n","\u001b[1m312/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9487 - auc: 0.8767 - loss: 0.2113\n","Epoch 58: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9485 - auc: 0.8763 - loss: 0.2117 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4723\n","Epoch 59/100\n","\u001b[1m295/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9427 - auc: 0.8458 - loss: 0.2283\n","Epoch 59: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9427 - auc: 0.8468 - loss: 0.2282 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4722\n","Epoch 60/100\n","\u001b[1m298/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9500 - auc: 0.8825 - loss: 0.2049\n","Epoch 60: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9494 - auc: 0.8808 - loss: 0.2067 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4709\n","Epoch 61/100\n","\u001b[1m296/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9384 - auc: 0.8669 - loss: 0.2327\n","Epoch 61: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9387 - auc: 0.8664 - loss: 0.2322 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4734\n","Epoch 62/100\n","\u001b[1m295/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9450 - auc: 0.8754 - loss: 0.2174\n","Epoch 62: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9448 - auc: 0.8743 - loss: 0.2182 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4738\n","Epoch 63/100\n","\u001b[1m319/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9519 - auc: 0.8871 - loss: 0.2008\n","Epoch 63: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9519 - auc: 0.8869 - loss: 0.2010 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4739\n","Epoch 64/100\n","\u001b[1m297/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9456 - auc: 0.8496 - loss: 0.2210\n","Epoch 64: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9454 - auc: 0.8506 - loss: 0.2214 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4741\n","Epoch 65/100\n","\u001b[1m299/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9368 - auc: 0.8717 - loss: 0.2339\n","Epoch 65: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9372 - auc: 0.8709 - loss: 0.2335 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4751\n","Epoch 66/100\n","\u001b[1m298/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9380 - auc: 0.8526 - loss: 0.2392\n","Epoch 66: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9382 - auc: 0.8528 - loss: 0.2385 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4753\n","Epoch 67/100\n","\u001b[1m318/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9576 - auc: 0.8968 - loss: 0.1858\n","Epoch 67: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9574 - auc: 0.8965 - loss: 0.1862 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4770\n","Epoch 68/100\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9387 - auc: 0.8578 - loss: 0.2357\n","Epoch 68: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9387 - auc: 0.8578 - loss: 0.2356 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4759\n","Epoch 69/100\n","\u001b[1m295/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9503 - auc: 0.8731 - loss: 0.2087\n","Epoch 69: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9499 - auc: 0.8727 - loss: 0.2097 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4779\n","Epoch 70/100\n","\u001b[1m296/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9443 - auc: 0.8694 - loss: 0.2171\n","Epoch 70: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9441 - auc: 0.8688 - loss: 0.2180 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4754\n","Epoch 71/100\n","\u001b[1m295/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9373 - auc: 0.8413 - loss: 0.2376\n","Epoch 71: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9377 - auc: 0.8426 - loss: 0.2368 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4766\n","Epoch 72/100\n","\u001b[1m317/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9401 - auc: 0.8573 - loss: 0.2280\n","Epoch 72: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9401 - auc: 0.8573 - loss: 0.2280 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4749\n","Epoch 73/100\n","\u001b[1m319/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9512 - auc: 0.8837 - loss: 0.2014\n","Epoch 73: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9511 - auc: 0.8836 - loss: 0.2016 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4788\n","Epoch 74/100\n","\u001b[1m306/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9431 - auc: 0.8666 - loss: 0.2227\n","Epoch 74: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9432 - auc: 0.8666 - loss: 0.2226 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4802\n","Epoch 75/100\n","\u001b[1m311/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9569 - auc: 0.8923 - loss: 0.1862\n","Epoch 75: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9565 - auc: 0.8915 - loss: 0.1873 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4798\n","Epoch 76/100\n","\u001b[1m314/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9540 - auc: 0.8820 - loss: 0.1977\n","Epoch 76: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9537 - auc: 0.8816 - loss: 0.1983 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4757\n","Epoch 77/100\n","\u001b[1m318/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9445 - auc: 0.8818 - loss: 0.2143\n","Epoch 77: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9445 - auc: 0.8816 - loss: 0.2144 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4804\n","Epoch 78/100\n","\u001b[1m317/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9340 - auc: 0.8240 - loss: 0.2508\n","Epoch 78: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9341 - auc: 0.8244 - loss: 0.2505 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4743\n","Epoch 79/100\n","\u001b[1m295/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9341 - auc: 0.8387 - loss: 0.2434\n","Epoch 79: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9346 - auc: 0.8396 - loss: 0.2422 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4779\n","Epoch 80/100\n","\u001b[1m295/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9496 - auc: 0.8840 - loss: 0.2031\n","Epoch 80: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9491 - auc: 0.8821 - loss: 0.2047 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4808\n","Epoch 81/100\n","\u001b[1m298/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9267 - auc: 0.8221 - loss: 0.2674\n","Epoch 81: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9278 - auc: 0.8236 - loss: 0.2645 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4794\n","Epoch 82/100\n","\u001b[1m303/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9475 - auc: 0.8789 - loss: 0.2087\n","Epoch 82: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9472 - auc: 0.8774 - loss: 0.2097 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4788\n","Epoch 83/100\n","\u001b[1m301/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9457 - auc: 0.8689 - loss: 0.2125\n","Epoch 83: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9457 - auc: 0.8689 - loss: 0.2127 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4855\n","Epoch 84/100\n","\u001b[1m298/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9464 - auc: 0.8714 - loss: 0.2131\n","Epoch 84: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9461 - auc: 0.8704 - loss: 0.2139 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4806\n","Epoch 85/100\n","\u001b[1m298/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9626 - auc: 0.8811 - loss: 0.1740\n","Epoch 85: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9614 - auc: 0.8801 - loss: 0.1770 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4829\n","Epoch 86/100\n","\u001b[1m298/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9495 - auc: 0.8901 - loss: 0.1982\n","Epoch 86: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9490 - auc: 0.8875 - loss: 0.2001 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4787\n","Epoch 87/100\n","\u001b[1m317/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9510 - auc: 0.8564 - loss: 0.2021\n","Epoch 87: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9509 - auc: 0.8562 - loss: 0.2024 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4784\n","Epoch 88/100\n","\u001b[1m318/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9477 - auc: 0.8585 - loss: 0.2109\n","Epoch 88: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9477 - auc: 0.8583 - loss: 0.2110 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4826\n","Epoch 89/100\n","\u001b[1m314/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9544 - auc: 0.8654 - loss: 0.1919\n","Epoch 89: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9541 - auc: 0.8651 - loss: 0.1925 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4813\n","Epoch 90/100\n","\u001b[1m307/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9516 - auc: 0.8533 - loss: 0.2031\n","Epoch 90: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9512 - auc: 0.8529 - loss: 0.2039 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4812\n","Epoch 91/100\n","\u001b[1m319/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9276 - auc: 0.8367 - loss: 0.2605\n","Epoch 91: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9277 - auc: 0.8368 - loss: 0.2602 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4825\n","Epoch 92/100\n","\u001b[1m294/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9415 - auc: 0.8469 - loss: 0.2246\n","Epoch 92: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9416 - auc: 0.8467 - loss: 0.2245 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4828\n","Epoch 93/100\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9402 - auc: 0.8174 - loss: 0.2317\n","Epoch 93: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9402 - auc: 0.8174 - loss: 0.2317 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4829\n","Epoch 94/100\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9317 - auc: 0.8192 - loss: 0.2540\n","Epoch 94: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9317 - auc: 0.8193 - loss: 0.2539 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4841\n","Epoch 95/100\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9492 - auc: 0.8596 - loss: 0.2052\n","Epoch 95: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9492 - auc: 0.8596 - loss: 0.2053 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4837\n","Epoch 96/100\n","\u001b[1m299/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9535 - auc: 0.8620 - loss: 0.1945\n","Epoch 96: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9527 - auc: 0.8605 - loss: 0.1966 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4837\n","Epoch 97/100\n","\u001b[1m315/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9379 - auc: 0.8300 - loss: 0.2359\n","Epoch 97: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9380 - auc: 0.8305 - loss: 0.2357 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4850\n","Epoch 98/100\n","\u001b[1m319/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9408 - auc: 0.8286 - loss: 0.2281\n","Epoch 98: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9408 - auc: 0.8288 - loss: 0.2280 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4868\n","Epoch 99/100\n","\u001b[1m294/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9449 - auc: 0.8610 - loss: 0.2102\n","Epoch 99: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9448 - auc: 0.8598 - loss: 0.2109 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4866\n","Epoch 100/100\n","\u001b[1m315/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9385 - auc: 0.8429 - loss: 0.2357\n","Epoch 100: val_loss did not improve from 0.63035\n","\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9385 - auc: 0.8431 - loss: 0.2355 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.4860\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:tensorflow:5 out of the last 45 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7dc4848ade40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 2 | VAL  | AUC=1.0000 | ACC=0.6525 | n=118\n","Fold 2 | TEST | AUC=1.0000 | ACC=0.7105 | n=114\n","\n","--- Fold 3/14 ---\n"," train | ids:   36 | files:  931 | pos:  322 | neg:  609\n","   val | ids:    4 | files:  218 | pos:   77 | neg:  141\n","  test | ids:    3 | files:   41 | pos:    6 | neg:   35\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.7862 - auc: 0.6587 - loss: 0.6582\n","Epoch 1: val_loss improved from inf to 0.66154, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - acc: 0.7862 - auc: 0.6587 - loss: 0.6582 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6615\n","Epoch 2/100\n","\u001b[1m290/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7907 - auc: 0.6792 - loss: 0.6387\n","Epoch 2: val_loss improved from 0.66154 to 0.65088, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7914 - auc: 0.6774 - loss: 0.6385 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6509\n","Epoch 3/100\n","\u001b[1m306/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8493 - auc: 0.6728 - loss: 0.6241\n","Epoch 3: val_loss improved from 0.65088 to 0.64113, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8495 - auc: 0.6726 - loss: 0.6241 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6411\n","Epoch 4/100\n","\u001b[1m308/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8689 - auc: 0.6702 - loss: 0.6088\n","Epoch 4: val_loss improved from 0.64113 to 0.63527, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8688 - auc: 0.6701 - loss: 0.6088 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6353\n","Epoch 5/100\n","\u001b[1m294/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8450 - auc: 0.6414 - loss: 0.6087\n","Epoch 5: val_loss improved from 0.63527 to 0.63032, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8458 - auc: 0.6426 - loss: 0.6081 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6303\n","Epoch 6/100\n","\u001b[1m288/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8752 - auc: 0.6639 - loss: 0.5854\n","Epoch 6: val_loss improved from 0.63032 to 0.62763, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8740 - auc: 0.6635 - loss: 0.5857 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6276\n","Epoch 7/100\n","\u001b[1m292/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8750 - auc: 0.6609 - loss: 0.5710\n","Epoch 7: val_loss improved from 0.62763 to 0.62534, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8742 - auc: 0.6608 - loss: 0.5716 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6253\n","Epoch 8/100\n","\u001b[1m294/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8766 - auc: 0.6885 - loss: 0.5653\n","Epoch 8: val_loss improved from 0.62534 to 0.62472, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8758 - auc: 0.6868 - loss: 0.5656 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6247\n","Epoch 9/100\n","\u001b[1m297/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8478 - auc: 0.6491 - loss: 0.5795\n","Epoch 9: val_loss improved from 0.62472 to 0.62439, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8483 - auc: 0.6496 - loss: 0.5789 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6244\n","Epoch 10/100\n","\u001b[1m297/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8345 - auc: 0.5914 - loss: 0.5789\n","Epoch 10: val_loss improved from 0.62439 to 0.62405, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8358 - auc: 0.5946 - loss: 0.5779 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6240\n","Epoch 11/100\n","\u001b[1m287/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8656 - auc: 0.6879 - loss: 0.5502\n","Epoch 11: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8653 - auc: 0.6864 - loss: 0.5502 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6243\n","Epoch 12/100\n","\u001b[1m290/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8463 - auc: 0.6496 - loss: 0.5599\n","Epoch 12: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8473 - auc: 0.6502 - loss: 0.5590 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6243\n","Epoch 13/100\n","\u001b[1m291/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8471 - auc: 0.6380 - loss: 0.5508\n","Epoch 13: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8479 - auc: 0.6394 - loss: 0.5502 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6251\n","Epoch 14/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8575 - auc: 0.6489 - loss: 0.5388\n","Epoch 14: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8575 - auc: 0.6490 - loss: 0.5388 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6256\n","Epoch 15/100\n","\u001b[1m292/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8923 - auc: 0.7204 - loss: 0.4980\n","Epoch 15: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8903 - auc: 0.7166 - loss: 0.5002 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6261\n","Epoch 16/100\n","\u001b[1m293/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8564 - auc: 0.6545 - loss: 0.5340\n","Epoch 16: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8567 - auc: 0.6550 - loss: 0.5336 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6263\n","Epoch 17/100\n","\u001b[1m298/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8683 - auc: 0.6719 - loss: 0.5131\n","Epoch 17: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8680 - auc: 0.6715 - loss: 0.5136 - val_acc: 0.6468 - val_auc: 0.9149 - val_loss: 0.6271\n","Epoch 18/100\n","\u001b[1m294/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8544 - auc: 0.6710 - loss: 0.5279\n","Epoch 18: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8543 - auc: 0.6705 - loss: 0.5275 - val_acc: 0.6468 - val_auc: 0.9574 - val_loss: 0.6274\n","Epoch 19/100\n","\u001b[1m294/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8543 - auc: 0.6973 - loss: 0.5031\n","Epoch 19: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8535 - auc: 0.6953 - loss: 0.5039 - val_acc: 0.6468 - val_auc: 0.9574 - val_loss: 0.6271\n","Epoch 20/100\n","\u001b[1m286/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8536 - auc: 0.6388 - loss: 0.5237\n","Epoch 20: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8541 - auc: 0.6407 - loss: 0.5230 - val_acc: 0.6468 - val_auc: 0.9574 - val_loss: 0.6273\n","Epoch 21/100\n","\u001b[1m289/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8311 - auc: 0.6434 - loss: 0.5162\n","Epoch 21: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8300 - auc: 0.6446 - loss: 0.5158 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6275\n","Epoch 22/100\n","\u001b[1m293/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8250 - auc: 0.6151 - loss: 0.5316\n","Epoch 22: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8266 - auc: 0.6178 - loss: 0.5303 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6272\n","Epoch 23/100\n","\u001b[1m293/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8320 - auc: 0.6261 - loss: 0.5058\n","Epoch 23: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8320 - auc: 0.6282 - loss: 0.5059 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6267\n","Epoch 24/100\n","\u001b[1m297/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7924 - auc: 0.6970 - loss: 0.5006\n","Epoch 24: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7922 - auc: 0.6955 - loss: 0.5006 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6264\n","Epoch 25/100\n","\u001b[1m291/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8716 - auc: 0.6736 - loss: 0.4811\n","Epoch 25: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8707 - auc: 0.6722 - loss: 0.4824 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6258\n","Epoch 26/100\n","\u001b[1m293/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8434 - auc: 0.6353 - loss: 0.5074\n","Epoch 26: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8438 - auc: 0.6366 - loss: 0.5068 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6258\n","Epoch 27/100\n","\u001b[1m287/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8778 - auc: 0.6802 - loss: 0.4757\n","Epoch 27: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8764 - auc: 0.6786 - loss: 0.4772 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6258\n","Epoch 28/100\n","\u001b[1m288/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8608 - auc: 0.6376 - loss: 0.4915\n","Epoch 28: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8609 - auc: 0.6398 - loss: 0.4913 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6260\n","Epoch 29/100\n","\u001b[1m288/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8664 - auc: 0.6741 - loss: 0.4791\n","Epoch 29: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8660 - auc: 0.6729 - loss: 0.4797 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6261\n","Epoch 30/100\n","\u001b[1m294/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8562 - auc: 0.6380 - loss: 0.4966\n","Epoch 30: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8564 - auc: 0.6389 - loss: 0.4961 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6260\n","Epoch 31/100\n","\u001b[1m294/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8697 - auc: 0.6536 - loss: 0.4704\n","Epoch 31: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8693 - auc: 0.6543 - loss: 0.4709 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6263\n","Epoch 32/100\n","\u001b[1m297/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8476 - auc: 0.6085 - loss: 0.4966\n","Epoch 32: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8482 - auc: 0.6111 - loss: 0.4957 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6259\n","Epoch 33/100\n","\u001b[1m296/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8659 - auc: 0.6772 - loss: 0.4661\n","Epoch 33: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8656 - auc: 0.6770 - loss: 0.4666 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6255\n","Epoch 34/100\n","\u001b[1m299/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8496 - auc: 0.7082 - loss: 0.4818\n","Epoch 34: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8501 - auc: 0.7080 - loss: 0.4814 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6254\n","Epoch 35/100\n","\u001b[1m293/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8699 - auc: 0.7249 - loss: 0.4579\n","Epoch 35: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8692 - auc: 0.7242 - loss: 0.4586 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6248\n","Epoch 36/100\n","\u001b[1m288/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8585 - auc: 0.7302 - loss: 0.4602\n","Epoch 36: val_loss did not improve from 0.62405\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8585 - auc: 0.7297 - loss: 0.4607 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6242\n","Epoch 37/100\n","\u001b[1m289/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8841 - auc: 0.7401 - loss: 0.4346\n","Epoch 37: val_loss improved from 0.62405 to 0.62228, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8823 - auc: 0.7391 - loss: 0.4367 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6223\n","Epoch 38/100\n","\u001b[1m306/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8718 - auc: 0.7579 - loss: 0.4351\n","Epoch 38: val_loss improved from 0.62228 to 0.62143, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8716 - auc: 0.7575 - loss: 0.4355 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6214\n","Epoch 39/100\n","\u001b[1m303/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8658 - auc: 0.7707 - loss: 0.4420\n","Epoch 39: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8656 - auc: 0.7699 - loss: 0.4423 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6221\n","Epoch 40/100\n","\u001b[1m310/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8736 - auc: 0.7636 - loss: 0.4374\n","Epoch 40: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8735 - auc: 0.7634 - loss: 0.4375 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6230\n","Epoch 41/100\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8711 - auc: 0.7462 - loss: 0.4363\n","Epoch 41: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8711 - auc: 0.7462 - loss: 0.4364 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6237\n","Epoch 42/100\n","\u001b[1m290/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8701 - auc: 0.7423 - loss: 0.4309\n","Epoch 42: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8693 - auc: 0.7424 - loss: 0.4319 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6245\n","Epoch 43/100\n","\u001b[1m295/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8533 - auc: 0.7287 - loss: 0.4508\n","Epoch 43: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8537 - auc: 0.7296 - loss: 0.4502 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6253\n","Epoch 44/100\n","\u001b[1m304/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8464 - auc: 0.7260 - loss: 0.4554\n","Epoch 44: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8468 - auc: 0.7265 - loss: 0.4549 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6265\n","Epoch 45/100\n","\u001b[1m288/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8496 - auc: 0.7338 - loss: 0.4464\n","Epoch 45: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8503 - auc: 0.7348 - loss: 0.4454 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6270\n","Epoch 46/100\n","\u001b[1m286/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8645 - auc: 0.7614 - loss: 0.4208\n","Epoch 46: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8640 - auc: 0.7603 - loss: 0.4215 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6280\n","Epoch 47/100\n","\u001b[1m310/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8582 - auc: 0.7549 - loss: 0.4257\n","Epoch 47: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8582 - auc: 0.7549 - loss: 0.4257 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6290\n","Epoch 48/100\n","\u001b[1m288/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8424 - auc: 0.7385 - loss: 0.4417\n","Epoch 48: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8436 - auc: 0.7395 - loss: 0.4401 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6301\n","Epoch 49/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8662 - auc: 0.7328 - loss: 0.4093\n","Epoch 49: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8661 - auc: 0.7330 - loss: 0.4093 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6314\n","Epoch 50/100\n","\u001b[1m302/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8745 - auc: 0.7670 - loss: 0.3942\n","Epoch 50: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8740 - auc: 0.7668 - loss: 0.3948 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6321\n","Epoch 51/100\n","\u001b[1m307/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8669 - auc: 0.7942 - loss: 0.3961\n","Epoch 51: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8668 - auc: 0.7939 - loss: 0.3963 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6329\n","Epoch 52/100\n","\u001b[1m305/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8408 - auc: 0.7875 - loss: 0.4271\n","Epoch 52: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8413 - auc: 0.7878 - loss: 0.4266 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6346\n","Epoch 53/100\n","\u001b[1m301/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8711 - auc: 0.8238 - loss: 0.3842\n","Epoch 53: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8708 - auc: 0.8231 - loss: 0.3847 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6362\n","Epoch 54/100\n","\u001b[1m306/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8657 - auc: 0.7913 - loss: 0.3926\n","Epoch 54: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8656 - auc: 0.7916 - loss: 0.3926 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6374\n","Epoch 55/100\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8501 - auc: 0.8365 - loss: 0.3991\n","Epoch 55: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8501 - auc: 0.8365 - loss: 0.3991 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6396\n","Epoch 56/100\n","\u001b[1m303/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8602 - auc: 0.8735 - loss: 0.3843\n","Epoch 56: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8602 - auc: 0.8738 - loss: 0.3843 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6409\n","Epoch 57/100\n","\u001b[1m300/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8703 - auc: 0.8973 - loss: 0.3728\n","Epoch 57: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8699 - auc: 0.8975 - loss: 0.3731 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6424\n","Epoch 58/100\n","\u001b[1m294/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8580 - auc: 0.8935 - loss: 0.3837\n","Epoch 58: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8582 - auc: 0.8946 - loss: 0.3833 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6442\n","Epoch 59/100\n","\u001b[1m296/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8629 - auc: 0.9059 - loss: 0.3751\n","Epoch 59: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8627 - auc: 0.9062 - loss: 0.3750 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6461\n","Epoch 60/100\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8838 - auc: 0.9206 - loss: 0.3417\n","Epoch 60: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8837 - auc: 0.9206 - loss: 0.3418 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6478\n","Epoch 61/100\n","\u001b[1m308/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8354 - auc: 0.8924 - loss: 0.3965\n","Epoch 61: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8357 - auc: 0.8926 - loss: 0.3961 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6512\n","Epoch 62/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8703 - auc: 0.9006 - loss: 0.3553\n","Epoch 62: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8702 - auc: 0.9008 - loss: 0.3554 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6532\n","Epoch 63/100\n","\u001b[1m307/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8556 - auc: 0.9238 - loss: 0.3660\n","Epoch 63: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8557 - auc: 0.9238 - loss: 0.3658 - val_acc: 0.6468 - val_auc: 1.0000 - val_loss: 0.6555\n","Epoch 64/100\n","\u001b[1m310/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8495 - auc: 0.9141 - loss: 0.3679\n","Epoch 64: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8496 - auc: 0.9141 - loss: 0.3679 - val_acc: 0.6468 - val_auc: 0.6809 - val_loss: 0.6577\n","Epoch 65/100\n","\u001b[1m307/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8733 - auc: 0.9185 - loss: 0.3383\n","Epoch 65: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8731 - auc: 0.9187 - loss: 0.3385 - val_acc: 0.6468 - val_auc: 0.6809 - val_loss: 0.6608\n","Epoch 66/100\n","\u001b[1m290/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8619 - auc: 0.9249 - loss: 0.3460\n","Epoch 66: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8616 - auc: 0.9254 - loss: 0.3462 - val_acc: 0.6468 - val_auc: 0.6809 - val_loss: 0.6627\n","Epoch 67/100\n","\u001b[1m307/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8421 - auc: 0.9314 - loss: 0.3633\n","Epoch 67: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8424 - auc: 0.9314 - loss: 0.3630 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.6661\n","Epoch 68/100\n","\u001b[1m308/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8601 - auc: 0.9462 - loss: 0.3342\n","Epoch 68: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8601 - auc: 0.9461 - loss: 0.3343 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.6697\n","Epoch 69/100\n","\u001b[1m306/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8497 - auc: 0.9202 - loss: 0.3506\n","Epoch 69: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8499 - auc: 0.9205 - loss: 0.3503 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.6733\n","Epoch 70/100\n","\u001b[1m305/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8332 - auc: 0.9265 - loss: 0.3646\n","Epoch 70: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8339 - auc: 0.9267 - loss: 0.3639 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.6770\n","Epoch 71/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8771 - auc: 0.9498 - loss: 0.3039\n","Epoch 71: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8770 - auc: 0.9496 - loss: 0.3041 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.6805\n","Epoch 72/100\n","\u001b[1m290/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8754 - auc: 0.9441 - loss: 0.3031\n","Epoch 72: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8744 - auc: 0.9436 - loss: 0.3046 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.6831\n","Epoch 73/100\n","\u001b[1m301/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8649 - auc: 0.9452 - loss: 0.3071\n","Epoch 73: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8647 - auc: 0.9449 - loss: 0.3077 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.6867\n","Epoch 74/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8649 - auc: 0.9326 - loss: 0.3133\n","Epoch 74: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8649 - auc: 0.9327 - loss: 0.3134 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.6906\n","Epoch 75/100\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8601 - auc: 0.9310 - loss: 0.3196\n","Epoch 75: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8601 - auc: 0.9310 - loss: 0.3196 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.6935\n","Epoch 76/100\n","\u001b[1m308/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8411 - auc: 0.9287 - loss: 0.3373\n","Epoch 76: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8414 - auc: 0.9288 - loss: 0.3370 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.6980\n","Epoch 77/100\n","\u001b[1m302/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8574 - auc: 0.9273 - loss: 0.3148\n","Epoch 77: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8575 - auc: 0.9275 - loss: 0.3146 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7008\n","Epoch 78/100\n","\u001b[1m305/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8521 - auc: 0.9338 - loss: 0.3139\n","Epoch 78: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8523 - auc: 0.9338 - loss: 0.3137 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7046\n","Epoch 79/100\n","\u001b[1m308/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8492 - auc: 0.9228 - loss: 0.3195\n","Epoch 79: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8494 - auc: 0.9230 - loss: 0.3193 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7084\n","Epoch 80/100\n","\u001b[1m286/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8495 - auc: 0.9429 - loss: 0.3104\n","Epoch 80: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8504 - auc: 0.9428 - loss: 0.3095 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7118\n","Epoch 81/100\n","\u001b[1m286/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8399 - auc: 0.9425 - loss: 0.3190\n","Epoch 81: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8416 - auc: 0.9431 - loss: 0.3172 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7166\n","Epoch 82/100\n","\u001b[1m287/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8479 - auc: 0.9476 - loss: 0.3109\n","Epoch 82: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8490 - auc: 0.9484 - loss: 0.3093 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7206\n","Epoch 83/100\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8568 - auc: 0.9576 - loss: 0.2959\n","Epoch 83: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8568 - auc: 0.9576 - loss: 0.2959 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7262\n","Epoch 84/100\n","\u001b[1m289/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8529 - auc: 0.9476 - loss: 0.3118\n","Epoch 84: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8535 - auc: 0.9488 - loss: 0.3101 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7304\n","Epoch 85/100\n","\u001b[1m301/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8606 - auc: 0.9639 - loss: 0.2894\n","Epoch 85: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8606 - auc: 0.9640 - loss: 0.2892 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7339\n","Epoch 86/100\n","\u001b[1m307/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8683 - auc: 0.9616 - loss: 0.2778\n","Epoch 86: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8681 - auc: 0.9617 - loss: 0.2779 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7389\n","Epoch 87/100\n","\u001b[1m296/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8522 - auc: 0.9694 - loss: 0.2871\n","Epoch 87: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8526 - auc: 0.9692 - loss: 0.2867 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7442\n","Epoch 88/100\n","\u001b[1m307/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8617 - auc: 0.9655 - loss: 0.2779\n","Epoch 88: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8617 - auc: 0.9655 - loss: 0.2779 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7484\n","Epoch 89/100\n","\u001b[1m287/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8561 - auc: 0.9763 - loss: 0.2766\n","Epoch 89: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8565 - auc: 0.9755 - loss: 0.2764 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7548\n","Epoch 90/100\n","\u001b[1m304/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8644 - auc: 0.9647 - loss: 0.2634\n","Epoch 90: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8643 - auc: 0.9647 - loss: 0.2637 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7586\n","Epoch 91/100\n","\u001b[1m305/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8518 - auc: 0.9570 - loss: 0.2918\n","Epoch 91: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8520 - auc: 0.9572 - loss: 0.2913 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7622\n","Epoch 92/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8624 - auc: 0.9533 - loss: 0.2808\n","Epoch 92: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8625 - auc: 0.9534 - loss: 0.2806 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7669\n","Epoch 93/100\n","\u001b[1m286/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9229 - auc: 0.9575 - loss: 0.2856\n","Epoch 93: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9236 - auc: 0.9582 - loss: 0.2841 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7733\n","Epoch 94/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9263 - auc: 0.9568 - loss: 0.2892\n","Epoch 94: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9265 - auc: 0.9569 - loss: 0.2890 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7783\n","Epoch 95/100\n","\u001b[1m301/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9489 - auc: 0.9719 - loss: 0.2318\n","Epoch 95: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9481 - auc: 0.9717 - loss: 0.2328 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7815\n","Epoch 96/100\n","\u001b[1m303/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9422 - auc: 0.9550 - loss: 0.2784\n","Epoch 96: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9423 - auc: 0.9553 - loss: 0.2779 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7879\n","Epoch 97/100\n","\u001b[1m307/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9422 - auc: 0.9618 - loss: 0.2696\n","Epoch 97: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9423 - auc: 0.9619 - loss: 0.2694 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.7953\n","Epoch 98/100\n","\u001b[1m306/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9476 - auc: 0.9589 - loss: 0.2573\n","Epoch 98: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9477 - auc: 0.9590 - loss: 0.2573 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.8001\n","Epoch 99/100\n","\u001b[1m305/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9548 - auc: 0.9618 - loss: 0.2484\n","Epoch 99: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9546 - auc: 0.9619 - loss: 0.2485 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.8022\n","Epoch 100/100\n","\u001b[1m306/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9299 - auc: 0.9711 - loss: 0.2519\n","Epoch 100: val_loss did not improve from 0.62143\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9298 - auc: 0.9709 - loss: 0.2519 - val_acc: 0.6468 - val_auc: 0.3617 - val_loss: 0.8098\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:tensorflow:5 out of the last 45 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7dc450125bc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 3 | VAL  | AUC=1.0000 | ACC=0.6468 | n=218\n","Fold 3 | TEST | AUC=0.8000 | ACC=0.8537 | n=41\n","\n","--- Fold 4/14 ---\n"," train | ids:   36 | files:  978 | pos:  294 | neg:  684\n","   val | ids:    4 | files:  129 | pos:   77 | neg:   52\n","  test | ids:    3 | files:   83 | pos:   34 | neg:   49\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m324/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.2754 - auc: 0.4228 - loss: 1.0791\n","Epoch 1: val_loss improved from inf to 0.75389, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - acc: 0.2754 - auc: 0.4225 - loss: 1.0788 - val_acc: 0.5969 - val_auc: 0.2308 - val_loss: 0.7539\n","Epoch 2/100\n","\u001b[1m324/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.2482 - auc: 0.3763 - loss: 0.9293\n","Epoch 2: val_loss improved from 0.75389 to 0.72327, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.2484 - auc: 0.3766 - loss: 0.9289 - val_acc: 0.5969 - val_auc: 0.4615 - val_loss: 0.7233\n","Epoch 3/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.2919 - auc: 0.4962 - loss: 0.8017\n","Epoch 3: val_loss improved from 0.72327 to 0.71101, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.2919 - auc: 0.4963 - loss: 0.8016 - val_acc: 0.5969 - val_auc: 0.2404 - val_loss: 0.7110\n","Epoch 4/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3886 - auc: 0.6270 - loss: 0.7163\n","Epoch 4: val_loss improved from 0.71101 to 0.71062, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.3941 - auc: 0.6307 - loss: 0.7149 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 0.7106\n","Epoch 5/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8748 - auc: 0.8542 - loss: 0.6499\n","Epoch 5: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8750 - auc: 0.8559 - loss: 0.6492 - val_acc: 0.4031 - val_auc: 0.5096 - val_loss: 0.7215\n","Epoch 6/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8405 - auc: 0.9069 - loss: 0.6090\n","Epoch 6: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8404 - auc: 0.9067 - loss: 0.6090 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.7260\n","Epoch 7/100\n","\u001b[1m303/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8295 - auc: 0.8875 - loss: 0.5897\n","Epoch 7: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8289 - auc: 0.8840 - loss: 0.5897 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.7326\n","Epoch 8/100\n","\u001b[1m302/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8169 - auc: 0.7545 - loss: 0.5825\n","Epoch 8: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8175 - auc: 0.7567 - loss: 0.5818 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.7403\n","Epoch 9/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8336 - auc: 0.7869 - loss: 0.5605\n","Epoch 9: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8336 - auc: 0.7867 - loss: 0.5605 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.7500\n","Epoch 10/100\n","\u001b[1m322/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8532 - auc: 0.7823 - loss: 0.5401\n","Epoch 10: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8529 - auc: 0.7817 - loss: 0.5402 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.7600\n","Epoch 11/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8418 - auc: 0.7614 - loss: 0.5338\n","Epoch 11: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8416 - auc: 0.7607 - loss: 0.5339 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.7709\n","Epoch 12/100\n","\u001b[1m302/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8281 - auc: 0.7472 - loss: 0.5324\n","Epoch 12: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8284 - auc: 0.7455 - loss: 0.5322 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.7825\n","Epoch 13/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8320 - auc: 0.7143 - loss: 0.5229\n","Epoch 13: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8320 - auc: 0.7144 - loss: 0.5229 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.7935\n","Epoch 14/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8415 - auc: 0.7351 - loss: 0.5090\n","Epoch 14: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8412 - auc: 0.7344 - loss: 0.5090 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.8055\n","Epoch 15/100\n","\u001b[1m305/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8566 - auc: 0.6919 - loss: 0.4848\n","Epoch 15: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8548 - auc: 0.6926 - loss: 0.4862 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.8167\n","Epoch 16/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8438 - auc: 0.6986 - loss: 0.4819\n","Epoch 16: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8435 - auc: 0.6988 - loss: 0.4822 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.8284\n","Epoch 17/100\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8365 - auc: 0.7259 - loss: 0.4848\n","Epoch 17: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8365 - auc: 0.7259 - loss: 0.4848 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.8401\n","Epoch 18/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8347 - auc: 0.7084 - loss: 0.4811\n","Epoch 18: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8345 - auc: 0.7085 - loss: 0.4811 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.8522\n","Epoch 19/100\n","\u001b[1m305/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8475 - auc: 0.7124 - loss: 0.4620\n","Epoch 19: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8463 - auc: 0.7120 - loss: 0.4630 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.8597\n","Epoch 20/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8370 - auc: 0.7363 - loss: 0.4653\n","Epoch 20: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8366 - auc: 0.7355 - loss: 0.4656 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.8714\n","Epoch 21/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8304 - auc: 0.7095 - loss: 0.4702\n","Epoch 21: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8303 - auc: 0.7103 - loss: 0.4700 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.8783\n","Epoch 22/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8357 - auc: 0.7207 - loss: 0.4621\n","Epoch 22: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8355 - auc: 0.7215 - loss: 0.4619 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.8863\n","Epoch 23/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8347 - auc: 0.7745 - loss: 0.4471\n","Epoch 23: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8345 - auc: 0.7727 - loss: 0.4475 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.8940\n","Epoch 24/100\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8433 - auc: 0.7820 - loss: 0.4334\n","Epoch 24: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8432 - auc: 0.7819 - loss: 0.4334 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.8994\n","Epoch 25/100\n","\u001b[1m323/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8698 - auc: 0.7648 - loss: 0.4268\n","Epoch 25: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8696 - auc: 0.7646 - loss: 0.4270 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.8991\n","Epoch 26/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8326 - auc: 0.7526 - loss: 0.4719\n","Epoch 26: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8328 - auc: 0.7528 - loss: 0.4717 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.9142\n","Epoch 27/100\n","\u001b[1m303/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8586 - auc: 0.7890 - loss: 0.4385\n","Epoch 27: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8586 - auc: 0.7878 - loss: 0.4385 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.9172\n","Epoch 28/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8544 - auc: 0.7559 - loss: 0.4408\n","Epoch 28: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8544 - auc: 0.7561 - loss: 0.4407 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.9230\n","Epoch 29/100\n","\u001b[1m310/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8747 - auc: 0.7954 - loss: 0.4074\n","Epoch 29: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8740 - auc: 0.7947 - loss: 0.4085 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.9251\n","Epoch 30/100\n","\u001b[1m314/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8811 - auc: 0.8001 - loss: 0.4040\n","Epoch 30: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8803 - auc: 0.7998 - loss: 0.4047 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.9273\n","Epoch 31/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8698 - auc: 0.8056 - loss: 0.4152\n","Epoch 31: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8692 - auc: 0.8067 - loss: 0.4156 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.9367\n","Epoch 32/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8683 - auc: 0.8276 - loss: 0.4041\n","Epoch 32: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8680 - auc: 0.8272 - loss: 0.4046 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.9446\n","Epoch 33/100\n","\u001b[1m306/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8497 - auc: 0.8184 - loss: 0.4295\n","Epoch 33: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8504 - auc: 0.8185 - loss: 0.4284 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.9482\n","Epoch 34/100\n","\u001b[1m310/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8447 - auc: 0.8279 - loss: 0.4317\n","Epoch 34: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8455 - auc: 0.8284 - loss: 0.4307 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.9527\n","Epoch 35/100\n","\u001b[1m306/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8536 - auc: 0.8412 - loss: 0.4152\n","Epoch 35: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8540 - auc: 0.8415 - loss: 0.4147 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.9579\n","Epoch 36/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8597 - auc: 0.8729 - loss: 0.4057\n","Epoch 36: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8596 - auc: 0.8729 - loss: 0.4057 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.9641\n","Epoch 37/100\n","\u001b[1m323/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8579 - auc: 0.8752 - loss: 0.4039\n","Epoch 37: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8579 - auc: 0.8754 - loss: 0.4039 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.9684\n","Epoch 38/100\n","\u001b[1m322/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8505 - auc: 0.8915 - loss: 0.4117\n","Epoch 38: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8506 - auc: 0.8917 - loss: 0.4114 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.9764\n","Epoch 39/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8626 - auc: 0.9135 - loss: 0.3906\n","Epoch 39: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8626 - auc: 0.9136 - loss: 0.3906 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.9764\n","Epoch 40/100\n","\u001b[1m303/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8587 - auc: 0.9230 - loss: 0.3903\n","Epoch 40: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8587 - auc: 0.9230 - loss: 0.3904 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.9824\n","Epoch 41/100\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8574 - auc: 0.9307 - loss: 0.3883\n","Epoch 41: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8574 - auc: 0.9307 - loss: 0.3883 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 0.9879\n","Epoch 42/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8528 - auc: 0.9130 - loss: 0.3957\n","Epoch 42: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8533 - auc: 0.9139 - loss: 0.3950 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 0.9961\n","Epoch 43/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8404 - auc: 0.9339 - loss: 0.4054\n","Epoch 43: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8416 - auc: 0.9341 - loss: 0.4040 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 1.0018\n","Epoch 44/100\n","\u001b[1m306/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8555 - auc: 0.9483 - loss: 0.3822\n","Epoch 44: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8558 - auc: 0.9480 - loss: 0.3820 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 1.0107\n","Epoch 45/100\n","\u001b[1m306/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8655 - auc: 0.9342 - loss: 0.3703\n","Epoch 45: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8651 - auc: 0.9348 - loss: 0.3706 - val_acc: 0.4031 - val_auc: 1.0000 - val_loss: 1.0077\n","Epoch 46/100\n","\u001b[1m305/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8563 - auc: 0.9509 - loss: 0.3799\n","Epoch 46: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8567 - auc: 0.9506 - loss: 0.3794 - val_acc: 0.4031 - val_auc: 0.7788 - val_loss: 1.0129\n","Epoch 47/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8534 - auc: 0.9606 - loss: 0.3782\n","Epoch 47: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8537 - auc: 0.9603 - loss: 0.3778 - val_acc: 0.4031 - val_auc: 0.5096 - val_loss: 1.0226\n","Epoch 48/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8669 - auc: 0.9718 - loss: 0.3654\n","Epoch 48: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8666 - auc: 0.9711 - loss: 0.3655 - val_acc: 0.4031 - val_auc: 0.7308 - val_loss: 1.0273\n","Epoch 49/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8647 - auc: 0.9382 - loss: 0.3677\n","Epoch 49: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8644 - auc: 0.9394 - loss: 0.3676 - val_acc: 0.4031 - val_auc: 0.2404 - val_loss: 1.0361\n","Epoch 50/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8573 - auc: 0.9672 - loss: 0.3680\n","Epoch 50: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8575 - auc: 0.9669 - loss: 0.3677 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.0452\n","Epoch 51/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8645 - auc: 0.9571 - loss: 0.3560\n","Epoch 51: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8643 - auc: 0.9569 - loss: 0.3563 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.0447\n","Epoch 52/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8625 - auc: 0.9331 - loss: 0.3623\n","Epoch 52: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8623 - auc: 0.9341 - loss: 0.3622 - val_acc: 0.4031 - val_auc: 0.2404 - val_loss: 1.0524\n","Epoch 53/100\n","\u001b[1m306/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8627 - auc: 0.9662 - loss: 0.3544\n","Epoch 53: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8624 - auc: 0.9654 - loss: 0.3547 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.0580\n","Epoch 54/100\n","\u001b[1m301/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8575 - auc: 0.9481 - loss: 0.3575\n","Epoch 54: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8577 - auc: 0.9483 - loss: 0.3573 - val_acc: 0.4031 - val_auc: 0.2404 - val_loss: 1.0680\n","Epoch 55/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8639 - auc: 0.9371 - loss: 0.3507\n","Epoch 55: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8638 - auc: 0.9380 - loss: 0.3507 - val_acc: 0.4031 - val_auc: 0.2404 - val_loss: 1.0800\n","Epoch 56/100\n","\u001b[1m305/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8533 - auc: 0.9360 - loss: 0.3593\n","Epoch 56: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8537 - auc: 0.9372 - loss: 0.3588 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.0839\n","Epoch 57/100\n","\u001b[1m306/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8545 - auc: 0.9684 - loss: 0.3499\n","Epoch 57: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8549 - auc: 0.9678 - loss: 0.3498 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.0906\n","Epoch 58/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8670 - auc: 0.9372 - loss: 0.3454\n","Epoch 58: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8667 - auc: 0.9379 - loss: 0.3454 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.0915\n","Epoch 59/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8390 - auc: 0.9474 - loss: 0.3678\n","Epoch 59: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8396 - auc: 0.9475 - loss: 0.3671 - val_acc: 0.4031 - val_auc: 0.2404 - val_loss: 1.1076\n","Epoch 60/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8439 - auc: 0.9618 - loss: 0.3614\n","Epoch 60: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8446 - auc: 0.9616 - loss: 0.3606 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.1154\n","Epoch 61/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8632 - auc: 0.9594 - loss: 0.3354\n","Epoch 61: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8630 - auc: 0.9594 - loss: 0.3357 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.1159\n","Epoch 62/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8722 - auc: 0.9445 - loss: 0.3290\n","Epoch 62: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8718 - auc: 0.9448 - loss: 0.3294 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.1214\n","Epoch 63/100\n","\u001b[1m310/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8651 - auc: 0.9479 - loss: 0.3320\n","Epoch 63: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8648 - auc: 0.9481 - loss: 0.3323 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.1312\n","Epoch 64/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8717 - auc: 0.9554 - loss: 0.3226\n","Epoch 64: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8711 - auc: 0.9554 - loss: 0.3232 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.1376\n","Epoch 65/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8534 - auc: 0.9505 - loss: 0.3414\n","Epoch 65: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8537 - auc: 0.9505 - loss: 0.3411 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.1479\n","Epoch 66/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8659 - auc: 0.9555 - loss: 0.3297\n","Epoch 66: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8656 - auc: 0.9555 - loss: 0.3297 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.1525\n","Epoch 67/100\n","\u001b[1m304/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8609 - auc: 0.9571 - loss: 0.3309\n","Epoch 67: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8608 - auc: 0.9568 - loss: 0.3310 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.1647\n","Epoch 68/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8534 - auc: 0.9400 - loss: 0.3408\n","Epoch 68: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8535 - auc: 0.9401 - loss: 0.3407 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.1686\n","Epoch 69/100\n","\u001b[1m323/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8558 - auc: 0.9435 - loss: 0.3366\n","Epoch 69: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8559 - auc: 0.9436 - loss: 0.3365 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.1745\n","Epoch 70/100\n","\u001b[1m324/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8618 - auc: 0.9383 - loss: 0.3310\n","Epoch 70: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8617 - auc: 0.9384 - loss: 0.3309 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.1831\n","Epoch 71/100\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8648 - auc: 0.9690 - loss: 0.3070\n","Epoch 71: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8648 - auc: 0.9690 - loss: 0.3070 - val_acc: 0.4031 - val_auc: 0.2404 - val_loss: 1.1957\n","Epoch 72/100\n","\u001b[1m323/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8550 - auc: 0.9438 - loss: 0.3325\n","Epoch 72: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8550 - auc: 0.9440 - loss: 0.3324 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.2018\n","Epoch 73/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8689 - auc: 0.9575 - loss: 0.3141\n","Epoch 73: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8684 - auc: 0.9574 - loss: 0.3144 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.2026\n","Epoch 74/100\n","\u001b[1m314/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8565 - auc: 0.9458 - loss: 0.3264\n","Epoch 74: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8567 - auc: 0.9460 - loss: 0.3261 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.2208\n","Epoch 75/100\n","\u001b[1m304/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8719 - auc: 0.9650 - loss: 0.3026\n","Epoch 75: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8712 - auc: 0.9644 - loss: 0.3034 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.2234\n","Epoch 76/100\n","\u001b[1m310/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8363 - auc: 0.9542 - loss: 0.3384\n","Epoch 76: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8376 - auc: 0.9540 - loss: 0.3372 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.2455\n","Epoch 77/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8656 - auc: 0.9611 - loss: 0.3000\n","Epoch 77: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8654 - auc: 0.9604 - loss: 0.3007 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.2479\n","Epoch 78/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8546 - auc: 0.9598 - loss: 0.3163\n","Epoch 78: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8549 - auc: 0.9597 - loss: 0.3160 - val_acc: 0.4031 - val_auc: 0.2404 - val_loss: 1.2506\n","Epoch 79/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8591 - auc: 0.9515 - loss: 0.3123\n","Epoch 79: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8592 - auc: 0.9515 - loss: 0.3122 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.2606\n","Epoch 80/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8754 - auc: 0.9635 - loss: 0.2857\n","Epoch 80: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8747 - auc: 0.9630 - loss: 0.2868 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.2609\n","Epoch 81/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8692 - auc: 0.9559 - loss: 0.3019\n","Epoch 81: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8690 - auc: 0.9558 - loss: 0.3021 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.2618\n","Epoch 82/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8530 - auc: 0.9660 - loss: 0.3044\n","Epoch 82: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8533 - auc: 0.9652 - loss: 0.3046 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.2887\n","Epoch 83/100\n","\u001b[1m306/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8601 - auc: 0.9560 - loss: 0.3065\n","Epoch 83: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8601 - auc: 0.9557 - loss: 0.3064 - val_acc: 0.4031 - val_auc: 0.2404 - val_loss: 1.2919\n","Epoch 84/100\n","\u001b[1m306/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8728 - auc: 0.9555 - loss: 0.2929\n","Epoch 84: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8721 - auc: 0.9553 - loss: 0.2937 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.2904\n","Epoch 85/100\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8517 - auc: 0.9398 - loss: 0.3227\n","Epoch 85: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8518 - auc: 0.9399 - loss: 0.3227 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.3026\n","Epoch 86/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8807 - auc: 0.9544 - loss: 0.2827\n","Epoch 86: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8796 - auc: 0.9544 - loss: 0.2837 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.3044\n","Epoch 87/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8676 - auc: 0.9605 - loss: 0.2897\n","Epoch 87: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8674 - auc: 0.9602 - loss: 0.2901 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.3134\n","Epoch 88/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8706 - auc: 0.9514 - loss: 0.2889\n","Epoch 88: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8702 - auc: 0.9514 - loss: 0.2893 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.3325\n","Epoch 89/100\n","\u001b[1m306/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8655 - auc: 0.9415 - loss: 0.2989\n","Epoch 89: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8652 - auc: 0.9422 - loss: 0.2989 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.3328\n","Epoch 90/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8570 - auc: 0.9531 - loss: 0.3054\n","Epoch 90: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8572 - auc: 0.9530 - loss: 0.3049 - val_acc: 0.4031 - val_auc: 0.2404 - val_loss: 1.3438\n","Epoch 91/100\n","\u001b[1m306/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8533 - auc: 0.9560 - loss: 0.3006\n","Epoch 91: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8538 - auc: 0.9558 - loss: 0.3002 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.3507\n","Epoch 92/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8615 - auc: 0.9552 - loss: 0.2868\n","Epoch 92: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8615 - auc: 0.9550 - loss: 0.2872 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.3514\n","Epoch 93/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8752 - auc: 0.9550 - loss: 0.2778\n","Epoch 93: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8747 - auc: 0.9550 - loss: 0.2782 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.3602\n","Epoch 94/100\n","\u001b[1m313/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8746 - auc: 0.9576 - loss: 0.2770\n","Epoch 94: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8741 - auc: 0.9572 - loss: 0.2776 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.3716\n","Epoch 95/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8395 - auc: 0.9529 - loss: 0.3080\n","Epoch 95: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8402 - auc: 0.9529 - loss: 0.3075 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.3964\n","Epoch 96/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8601 - auc: 0.9545 - loss: 0.2883\n","Epoch 96: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8601 - auc: 0.9543 - loss: 0.2884 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.4008\n","Epoch 97/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8623 - auc: 0.9547 - loss: 0.2862\n","Epoch 97: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8623 - auc: 0.9545 - loss: 0.2864 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.4083\n","Epoch 98/100\n","\u001b[1m324/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8699 - auc: 0.9504 - loss: 0.2765\n","Epoch 98: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8698 - auc: 0.9504 - loss: 0.2766 - val_acc: 0.4031 - val_auc: 0.4615 - val_loss: 1.4040\n","Epoch 99/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8718 - auc: 0.9469 - loss: 0.2769\n","Epoch 99: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8713 - auc: 0.9473 - loss: 0.2773 - val_acc: 0.4031 - val_auc: 0.2404 - val_loss: 1.4169\n","Epoch 100/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8731 - auc: 0.9487 - loss: 0.2753\n","Epoch 100: val_loss did not improve from 0.71062\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8728 - auc: 0.9488 - loss: 0.2756 - val_acc: 0.4031 - val_auc: 0.2404 - val_loss: 1.4148\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 4 | VAL  | AUC=0.4615 | ACC=0.4031 | n=129\n","Fold 4 | TEST | AUC=0.2449 | ACC=0.5904 | n=83\n","\n","--- Fold 5/14 ---\n"," train | ids:   36 | files:  932 | pos:  324 | neg:  608\n","   val | ids:    4 | files:  234 | pos:   77 | neg:  157\n","  test | ids:    3 | files:   24 | pos:    4 | neg:   20\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m288/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.6040 - auc: 0.5304 - loss: 0.6629\n","Epoch 1: val_loss improved from inf to 0.57292, saving model to best_tab_only_fold5.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - acc: 0.6067 - auc: 0.5316 - loss: 0.6624 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5729\n","Epoch 2/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6578 - auc: 0.6316 - loss: 0.6346\n","Epoch 2: val_loss improved from 0.57292 to 0.55619, saving model to best_tab_only_fold5.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6578 - auc: 0.6320 - loss: 0.6346 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5562\n","Epoch 3/100\n","\u001b[1m308/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6441 - auc: 0.6974 - loss: 0.6272\n","Epoch 3: val_loss improved from 0.55619 to 0.55062, saving model to best_tab_only_fold5.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6442 - auc: 0.6975 - loss: 0.6271 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5506\n","Epoch 4/100\n","\u001b[1m304/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6489 - auc: 0.6843 - loss: 0.6197\n","Epoch 4: val_loss improved from 0.55062 to 0.54974, saving model to best_tab_only_fold5.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6490 - auc: 0.6846 - loss: 0.6195 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5497\n","Epoch 5/100\n","\u001b[1m307/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6806 - auc: 0.6699 - loss: 0.6092\n","Epoch 5: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6808 - auc: 0.6703 - loss: 0.6091 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5519\n","Epoch 6/100\n","\u001b[1m308/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7229 - auc: 0.7021 - loss: 0.5902\n","Epoch 6: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7229 - auc: 0.7017 - loss: 0.5903 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5545\n","Epoch 7/100\n","\u001b[1m307/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7229 - auc: 0.6687 - loss: 0.5957\n","Epoch 7: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7229 - auc: 0.6688 - loss: 0.5957 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5569\n","Epoch 8/100\n","\u001b[1m296/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6931 - auc: 0.6706 - loss: 0.6131\n","Epoch 8: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6944 - auc: 0.6710 - loss: 0.6120 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5593\n","Epoch 9/100\n","\u001b[1m296/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7226 - auc: 0.6743 - loss: 0.5914\n","Epoch 9: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7226 - auc: 0.6749 - loss: 0.5912 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5614\n","Epoch 10/100\n","\u001b[1m297/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7228 - auc: 0.7299 - loss: 0.5764\n","Epoch 10: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7225 - auc: 0.7277 - loss: 0.5769 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5640\n","Epoch 11/100\n","\u001b[1m305/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6974 - auc: 0.7129 - loss: 0.5882\n","Epoch 11: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6979 - auc: 0.7122 - loss: 0.5881 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5663\n","Epoch 12/100\n","\u001b[1m302/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7269 - auc: 0.7138 - loss: 0.5741\n","Epoch 12: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7266 - auc: 0.7130 - loss: 0.5742 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5683\n","Epoch 13/100\n","\u001b[1m307/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7165 - auc: 0.7118 - loss: 0.5795\n","Epoch 13: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7167 - auc: 0.7113 - loss: 0.5794 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5700\n","Epoch 14/100\n","\u001b[1m302/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7629 - auc: 0.6895 - loss: 0.5568\n","Epoch 14: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7629 - auc: 0.6895 - loss: 0.5572 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5717\n","Epoch 15/100\n","\u001b[1m307/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8158 - auc: 0.7121 - loss: 0.5510\n","Epoch 15: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8155 - auc: 0.7119 - loss: 0.5512 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5731\n","Epoch 16/100\n","\u001b[1m306/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8527 - auc: 0.6825 - loss: 0.5566\n","Epoch 16: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8527 - auc: 0.6829 - loss: 0.5568 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5742\n","Epoch 17/100\n","\u001b[1m310/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8487 - auc: 0.6935 - loss: 0.5645\n","Epoch 17: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8487 - auc: 0.6936 - loss: 0.5645 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5760\n","Epoch 18/100\n","\u001b[1m288/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8780 - auc: 0.7551 - loss: 0.5454\n","Epoch 18: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8766 - auc: 0.7515 - loss: 0.5463 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5776\n","Epoch 19/100\n","\u001b[1m310/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8660 - auc: 0.7047 - loss: 0.5489\n","Epoch 19: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8660 - auc: 0.7047 - loss: 0.5489 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5791\n","Epoch 20/100\n","\u001b[1m308/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8711 - auc: 0.7254 - loss: 0.5396\n","Epoch 20: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8709 - auc: 0.7253 - loss: 0.5397 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5799\n","Epoch 21/100\n","\u001b[1m297/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8624 - auc: 0.7225 - loss: 0.5410\n","Epoch 21: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8621 - auc: 0.7221 - loss: 0.5411 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5798\n","Epoch 22/100\n","\u001b[1m302/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8502 - auc: 0.7242 - loss: 0.5464\n","Epoch 22: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8505 - auc: 0.7241 - loss: 0.5460 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5803\n","Epoch 23/100\n","\u001b[1m294/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8818 - auc: 0.7640 - loss: 0.5052\n","Epoch 23: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8804 - auc: 0.7617 - loss: 0.5064 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5806\n","Epoch 24/100\n","\u001b[1m302/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8754 - auc: 0.7468 - loss: 0.4990\n","Epoch 24: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8749 - auc: 0.7464 - loss: 0.4995 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5814\n","Epoch 25/100\n","\u001b[1m307/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8675 - auc: 0.7339 - loss: 0.4981\n","Epoch 25: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8673 - auc: 0.7338 - loss: 0.4983 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5816\n","Epoch 26/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8550 - auc: 0.7285 - loss: 0.5089\n","Epoch 26: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8550 - auc: 0.7286 - loss: 0.5088 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5822\n","Epoch 27/100\n","\u001b[1m304/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8623 - auc: 0.7543 - loss: 0.4855\n","Epoch 27: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8622 - auc: 0.7538 - loss: 0.4857 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5834\n","Epoch 28/100\n","\u001b[1m307/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8564 - auc: 0.7558 - loss: 0.4909\n","Epoch 28: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8564 - auc: 0.7555 - loss: 0.4908 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5842\n","Epoch 29/100\n","\u001b[1m310/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8509 - auc: 0.7166 - loss: 0.4835\n","Epoch 29: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8509 - auc: 0.7168 - loss: 0.4834 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5856\n","Epoch 30/100\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8607 - auc: 0.7283 - loss: 0.4712\n","Epoch 30: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8606 - auc: 0.7284 - loss: 0.4712 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5873\n","Epoch 31/100\n","\u001b[1m310/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8772 - auc: 0.7572 - loss: 0.4422\n","Epoch 31: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8771 - auc: 0.7570 - loss: 0.4423 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5896\n","Epoch 32/100\n","\u001b[1m304/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8529 - auc: 0.7342 - loss: 0.4604\n","Epoch 32: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8530 - auc: 0.7345 - loss: 0.4602 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5906\n","Epoch 33/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8625 - auc: 0.7623 - loss: 0.4420\n","Epoch 33: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8625 - auc: 0.7623 - loss: 0.4421 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5923\n","Epoch 34/100\n","\u001b[1m298/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8581 - auc: 0.7974 - loss: 0.4391\n","Epoch 34: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8581 - auc: 0.7985 - loss: 0.4391 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5939\n","Epoch 35/100\n","\u001b[1m289/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8639 - auc: 0.8543 - loss: 0.4263\n","Epoch 35: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8634 - auc: 0.8550 - loss: 0.4267 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5961\n","Epoch 36/100\n","\u001b[1m293/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8495 - auc: 0.8950 - loss: 0.4330\n","Epoch 36: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8501 - auc: 0.8951 - loss: 0.4324 - val_acc: 0.6709 - val_auc: 0.7134 - val_loss: 0.5980\n","Epoch 37/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8508 - auc: 0.9015 - loss: 0.4276\n","Epoch 37: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8509 - auc: 0.9016 - loss: 0.4275 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6001\n","Epoch 38/100\n","\u001b[1m301/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8523 - auc: 0.9138 - loss: 0.4176\n","Epoch 38: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8525 - auc: 0.9140 - loss: 0.4174 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6025\n","Epoch 39/100\n","\u001b[1m296/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8571 - auc: 0.9112 - loss: 0.4071\n","Epoch 39: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8572 - auc: 0.9119 - loss: 0.4069 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6051\n","Epoch 40/100\n","\u001b[1m296/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8789 - auc: 0.9120 - loss: 0.3813\n","Epoch 40: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8778 - auc: 0.9125 - loss: 0.3823 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6077\n","Epoch 41/100\n","\u001b[1m297/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8702 - auc: 0.9368 - loss: 0.3752\n","Epoch 41: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8697 - auc: 0.9359 - loss: 0.3759 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6105\n","Epoch 42/100\n","\u001b[1m295/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8365 - auc: 0.9213 - loss: 0.4063\n","Epoch 42: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8376 - auc: 0.9213 - loss: 0.4051 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6134\n","Epoch 43/100\n","\u001b[1m294/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8711 - auc: 0.9243 - loss: 0.3658\n","Epoch 43: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8704 - auc: 0.9241 - loss: 0.3666 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6169\n","Epoch 44/100\n","\u001b[1m304/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8459 - auc: 0.9046 - loss: 0.3884\n","Epoch 44: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8462 - auc: 0.9051 - loss: 0.3881 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6207\n","Epoch 45/100\n","\u001b[1m308/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8474 - auc: 0.9186 - loss: 0.3775\n","Epoch 45: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8475 - auc: 0.9186 - loss: 0.3774 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6236\n","Epoch 46/100\n","\u001b[1m303/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8623 - auc: 0.9100 - loss: 0.3623\n","Epoch 46: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8622 - auc: 0.9104 - loss: 0.3622 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6279\n","Epoch 47/100\n","\u001b[1m306/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8555 - auc: 0.9201 - loss: 0.3627\n","Epoch 47: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8555 - auc: 0.9201 - loss: 0.3626 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6308\n","Epoch 48/100\n","\u001b[1m305/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8501 - auc: 0.9282 - loss: 0.3565\n","Epoch 48: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8503 - auc: 0.9283 - loss: 0.3564 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6349\n","Epoch 49/100\n","\u001b[1m302/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8874 - auc: 0.9487 - loss: 0.3172\n","Epoch 49: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8865 - auc: 0.9481 - loss: 0.3181 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6386\n","Epoch 50/100\n","\u001b[1m296/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8516 - auc: 0.9283 - loss: 0.3507\n","Epoch 50: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8519 - auc: 0.9286 - loss: 0.3503 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6428\n","Epoch 51/100\n","\u001b[1m310/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8569 - auc: 0.9074 - loss: 0.3471\n","Epoch 51: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8569 - auc: 0.9076 - loss: 0.3471 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6473\n","Epoch 52/100\n","\u001b[1m305/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8554 - auc: 0.9285 - loss: 0.3432\n","Epoch 52: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8555 - auc: 0.9288 - loss: 0.3429 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6512\n","Epoch 53/100\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8571 - auc: 0.9297 - loss: 0.3401\n","Epoch 53: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8571 - auc: 0.9298 - loss: 0.3400 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6551\n","Epoch 54/100\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8387 - auc: 0.9529 - loss: 0.3437\n","Epoch 54: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8388 - auc: 0.9529 - loss: 0.3437 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6601\n","Epoch 55/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8618 - auc: 0.9553 - loss: 0.3271\n","Epoch 55: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8617 - auc: 0.9554 - loss: 0.3271 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6646\n","Epoch 56/100\n","\u001b[1m286/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8662 - auc: 0.9720 - loss: 0.3014\n","Epoch 56: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8654 - auc: 0.9715 - loss: 0.3029 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6692\n","Epoch 57/100\n","\u001b[1m306/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8576 - auc: 0.9628 - loss: 0.3164\n","Epoch 57: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8577 - auc: 0.9630 - loss: 0.3163 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6745\n","Epoch 58/100\n","\u001b[1m308/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8678 - auc: 0.9685 - loss: 0.2973\n","Epoch 58: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8676 - auc: 0.9685 - loss: 0.2974 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6794\n","Epoch 59/100\n","\u001b[1m308/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8476 - auc: 0.9663 - loss: 0.3171\n","Epoch 59: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8477 - auc: 0.9663 - loss: 0.3169 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6845\n","Epoch 60/100\n","\u001b[1m308/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8546 - auc: 0.9718 - loss: 0.3047\n","Epoch 60: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8546 - auc: 0.9718 - loss: 0.3047 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6896\n","Epoch 61/100\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8572 - auc: 0.9590 - loss: 0.3066\n","Epoch 61: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8572 - auc: 0.9591 - loss: 0.3065 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6943\n","Epoch 62/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8515 - auc: 0.9600 - loss: 0.3050\n","Epoch 62: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8516 - auc: 0.9601 - loss: 0.3049 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.7005\n","Epoch 63/100\n","\u001b[1m303/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8515 - auc: 0.9629 - loss: 0.3001\n","Epoch 63: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8516 - auc: 0.9630 - loss: 0.2999 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.7061\n","Epoch 64/100\n","\u001b[1m306/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8572 - auc: 0.9585 - loss: 0.2944\n","Epoch 64: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8572 - auc: 0.9587 - loss: 0.2943 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.7115\n","Epoch 65/100\n","\u001b[1m296/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8596 - auc: 0.9705 - loss: 0.2819\n","Epoch 65: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8595 - auc: 0.9702 - loss: 0.2821 - val_acc: 0.6709 - val_auc: 0.3376 - val_loss: 0.7175\n","Epoch 66/100\n","\u001b[1m306/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8738 - auc: 0.9622 - loss: 0.2718\n","Epoch 66: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8735 - auc: 0.9623 - loss: 0.2720 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7230\n","Epoch 67/100\n","\u001b[1m288/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8686 - auc: 0.9748 - loss: 0.2879\n","Epoch 67: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8691 - auc: 0.9742 - loss: 0.2870 - val_acc: 0.6709 - val_auc: 0.3376 - val_loss: 0.7295\n","Epoch 68/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8741 - auc: 0.9718 - loss: 0.2651\n","Epoch 68: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8742 - auc: 0.9717 - loss: 0.2652 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7350\n","Epoch 69/100\n","\u001b[1m308/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8951 - auc: 0.9630 - loss: 0.2791\n","Epoch 69: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8954 - auc: 0.9630 - loss: 0.2790 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7411\n","Epoch 70/100\n","\u001b[1m304/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8967 - auc: 0.9699 - loss: 0.2734\n","Epoch 70: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8972 - auc: 0.9698 - loss: 0.2734 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7469\n","Epoch 71/100\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9316 - auc: 0.9624 - loss: 0.2714\n","Epoch 71: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9317 - auc: 0.9624 - loss: 0.2714 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7537\n","Epoch 72/100\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9446 - auc: 0.9568 - loss: 0.2593\n","Epoch 72: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9446 - auc: 0.9569 - loss: 0.2593 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7603\n","Epoch 73/100\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9467 - auc: 0.9582 - loss: 0.2618\n","Epoch 73: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9467 - auc: 0.9582 - loss: 0.2618 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7667\n","Epoch 74/100\n","\u001b[1m290/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9467 - auc: 0.9647 - loss: 0.2530\n","Epoch 74: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9467 - auc: 0.9646 - loss: 0.2533 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7724\n","Epoch 75/100\n","\u001b[1m287/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9490 - auc: 0.9673 - loss: 0.2463\n","Epoch 75: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9489 - auc: 0.9672 - loss: 0.2470 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7795\n","Epoch 76/100\n","\u001b[1m289/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9403 - auc: 0.9562 - loss: 0.2630\n","Epoch 76: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9406 - auc: 0.9567 - loss: 0.2626 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7846\n","Epoch 77/100\n","\u001b[1m286/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9305 - auc: 0.9481 - loss: 0.2734\n","Epoch 77: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9316 - auc: 0.9491 - loss: 0.2720 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7921\n","Epoch 78/100\n","\u001b[1m308/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9596 - auc: 0.9676 - loss: 0.2358\n","Epoch 78: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9594 - auc: 0.9675 - loss: 0.2360 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7985\n","Epoch 79/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9426 - auc: 0.9683 - loss: 0.2488\n","Epoch 79: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9426 - auc: 0.9682 - loss: 0.2488 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8040\n","Epoch 80/100\n","\u001b[1m298/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9346 - auc: 0.9599 - loss: 0.2567\n","Epoch 80: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9351 - auc: 0.9601 - loss: 0.2563 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8114\n","Epoch 81/100\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9647 - auc: 0.9785 - loss: 0.2159\n","Epoch 81: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9647 - auc: 0.9784 - loss: 0.2159 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8181\n","Epoch 82/100\n","\u001b[1m306/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9458 - auc: 0.9588 - loss: 0.2375\n","Epoch 82: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9458 - auc: 0.9589 - loss: 0.2376 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8240\n","Epoch 83/100\n","\u001b[1m310/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9274 - auc: 0.9603 - loss: 0.2668\n","Epoch 83: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9275 - auc: 0.9603 - loss: 0.2666 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8316\n","Epoch 84/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9409 - auc: 0.9528 - loss: 0.2364\n","Epoch 84: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9409 - auc: 0.9528 - loss: 0.2364 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8380\n","Epoch 85/100\n","\u001b[1m287/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9560 - auc: 0.9649 - loss: 0.2182\n","Epoch 85: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9551 - auc: 0.9646 - loss: 0.2197 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8416\n","Epoch 86/100\n","\u001b[1m308/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9459 - auc: 0.9546 - loss: 0.2364\n","Epoch 86: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9459 - auc: 0.9547 - loss: 0.2364 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8481\n","Epoch 87/100\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9511 - auc: 0.9634 - loss: 0.2292\n","Epoch 87: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9511 - auc: 0.9634 - loss: 0.2292 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8567\n","Epoch 88/100\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9330 - auc: 0.9574 - loss: 0.2503\n","Epoch 88: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9331 - auc: 0.9574 - loss: 0.2502 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8621\n","Epoch 89/100\n","\u001b[1m307/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9384 - auc: 0.9655 - loss: 0.2365\n","Epoch 89: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9385 - auc: 0.9655 - loss: 0.2365 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8681\n","Epoch 90/100\n","\u001b[1m287/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9502 - auc: 0.9602 - loss: 0.2168\n","Epoch 90: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9498 - auc: 0.9603 - loss: 0.2177 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8740\n","Epoch 91/100\n","\u001b[1m287/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9630 - auc: 0.9582 - loss: 0.2121\n","Epoch 91: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9618 - auc: 0.9585 - loss: 0.2131 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8794\n","Epoch 92/100\n","\u001b[1m309/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9496 - auc: 0.9558 - loss: 0.2248\n","Epoch 92: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9496 - auc: 0.9559 - loss: 0.2248 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8856\n","Epoch 93/100\n","\u001b[1m308/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9495 - auc: 0.9642 - loss: 0.2230\n","Epoch 93: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9494 - auc: 0.9641 - loss: 0.2230 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8900\n","Epoch 94/100\n","\u001b[1m297/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9449 - auc: 0.9640 - loss: 0.2197\n","Epoch 94: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9449 - auc: 0.9638 - loss: 0.2199 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8969\n","Epoch 95/100\n","\u001b[1m307/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9463 - auc: 0.9305 - loss: 0.2285\n","Epoch 95: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9463 - auc: 0.9310 - loss: 0.2283 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.9013\n","Epoch 96/100\n","\u001b[1m286/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9367 - auc: 0.9556 - loss: 0.2393\n","Epoch 96: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9374 - auc: 0.9562 - loss: 0.2378 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.9071\n","Epoch 97/100\n","\u001b[1m310/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9443 - auc: 0.9606 - loss: 0.2265\n","Epoch 97: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9443 - auc: 0.9606 - loss: 0.2265 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.9129\n","Epoch 98/100\n","\u001b[1m286/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9432 - auc: 0.9619 - loss: 0.2244\n","Epoch 98: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9434 - auc: 0.9618 - loss: 0.2239 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.9191\n","Epoch 99/100\n","\u001b[1m310/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9434 - auc: 0.9649 - loss: 0.2142\n","Epoch 99: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9435 - auc: 0.9649 - loss: 0.2142 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.9238\n","Epoch 100/100\n","\u001b[1m290/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9437 - auc: 0.9495 - loss: 0.2201\n","Epoch 100: val_loss did not improve from 0.54974\n","\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9438 - auc: 0.9502 - loss: 0.2199 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.9294\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 5 | VAL  | AUC=1.0000 | ACC=0.6709 | n=234\n","Fold 5 | TEST | AUC=1.0000 | ACC=0.8333 | n=24\n","\n","--- Fold 6/14 ---\n"," train | ids:   36 | files:  987 | pos:  269 | neg:  718\n","   val | ids:    4 | files:  100 | pos:   59 | neg:   41\n","  test | ids:    3 | files:  103 | pos:   77 | neg:   26\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m314/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5629 - auc: 0.6120 - loss: 0.7101\n","Epoch 1: val_loss improved from inf to 0.63049, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - acc: 0.5673 - auc: 0.6110 - loss: 0.7084 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.6305\n","Epoch 2/100\n","\u001b[1m308/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7979 - auc: 0.6403 - loss: 0.5887\n","Epoch 2: val_loss improved from 0.63049 to 0.58123, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7975 - auc: 0.6387 - loss: 0.5887 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.5812\n","Epoch 3/100\n","\u001b[1m308/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7970 - auc: 0.6209 - loss: 0.5646\n","Epoch 3: val_loss improved from 0.58123 to 0.56045, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7972 - auc: 0.6196 - loss: 0.5642 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.5604\n","Epoch 4/100\n","\u001b[1m304/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8176 - auc: 0.5658 - loss: 0.5373\n","Epoch 4: val_loss improved from 0.56045 to 0.55244, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8160 - auc: 0.5678 - loss: 0.5383 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.5524\n","Epoch 5/100\n","\u001b[1m311/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8090 - auc: 0.6356 - loss: 0.5311\n","Epoch 5: val_loss improved from 0.55244 to 0.54658, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8083 - auc: 0.6333 - loss: 0.5319 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.5466\n","Epoch 6/100\n","\u001b[1m306/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7998 - auc: 0.6491 - loss: 0.5268\n","Epoch 6: val_loss improved from 0.54658 to 0.54283, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7997 - auc: 0.6466 - loss: 0.5276 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.5428\n","Epoch 7/100\n","\u001b[1m309/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7832 - auc: 0.5874 - loss: 0.5493\n","Epoch 7: val_loss improved from 0.54283 to 0.53965, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7843 - auc: 0.5888 - loss: 0.5484 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.5396\n","Epoch 8/100\n","\u001b[1m306/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7824 - auc: 0.5948 - loss: 0.5513\n","Epoch 8: val_loss improved from 0.53965 to 0.53644, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7835 - auc: 0.5961 - loss: 0.5500 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.5364\n","Epoch 9/100\n","\u001b[1m308/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7972 - auc: 0.5750 - loss: 0.5541\n","Epoch 9: val_loss improved from 0.53644 to 0.53181, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7972 - auc: 0.5775 - loss: 0.5526 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.5318\n","Epoch 10/100\n","\u001b[1m306/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7893 - auc: 0.5780 - loss: 0.5428\n","Epoch 10: val_loss improved from 0.53181 to 0.52923, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7897 - auc: 0.5803 - loss: 0.5420 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.5292\n","Epoch 11/100\n","\u001b[1m316/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8035 - auc: 0.6391 - loss: 0.5126\n","Epoch 11: val_loss improved from 0.52923 to 0.52678, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8033 - auc: 0.6379 - loss: 0.5132 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.5268\n","Epoch 12/100\n","\u001b[1m311/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7964 - auc: 0.6415 - loss: 0.5222\n","Epoch 12: val_loss improved from 0.52678 to 0.52332, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7966 - auc: 0.6398 - loss: 0.5221 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.5233\n","Epoch 13/100\n","\u001b[1m315/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8084 - auc: 0.6244 - loss: 0.5012\n","Epoch 13: val_loss improved from 0.52332 to 0.52062, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8081 - auc: 0.6238 - loss: 0.5019 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.5206\n","Epoch 14/100\n","\u001b[1m313/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7917 - auc: 0.6231 - loss: 0.5326\n","Epoch 14: val_loss improved from 0.52062 to 0.51726, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7920 - auc: 0.6229 - loss: 0.5320 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.5173\n","Epoch 15/100\n","\u001b[1m312/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8030 - auc: 0.6381 - loss: 0.4983\n","Epoch 15: val_loss improved from 0.51726 to 0.51341, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8027 - auc: 0.6375 - loss: 0.4992 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.5134\n","Epoch 16/100\n","\u001b[1m310/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8036 - auc: 0.6272 - loss: 0.5061\n","Epoch 16: val_loss improved from 0.51341 to 0.50774, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8034 - auc: 0.6279 - loss: 0.5065 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.5077\n","Epoch 17/100\n","\u001b[1m308/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8146 - auc: 0.6810 - loss: 0.4903\n","Epoch 17: val_loss improved from 0.50774 to 0.50145, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8146 - auc: 0.6803 - loss: 0.4912 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.5014\n","Epoch 18/100\n","\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8250 - auc: 0.7288 - loss: 0.5063\n","Epoch 18: val_loss improved from 0.50145 to 0.49345, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8251 - auc: 0.7288 - loss: 0.5062 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4935\n","Epoch 19/100\n","\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8427 - auc: 0.7661 - loss: 0.4740\n","Epoch 19: val_loss improved from 0.49345 to 0.48775, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8425 - auc: 0.7660 - loss: 0.4742 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4878\n","Epoch 20/100\n","\u001b[1m311/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8477 - auc: 0.7734 - loss: 0.4892\n","Epoch 20: val_loss improved from 0.48775 to 0.48115, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8479 - auc: 0.7736 - loss: 0.4894 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4812\n","Epoch 21/100\n","\u001b[1m308/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8649 - auc: 0.7633 - loss: 0.4842\n","Epoch 21: val_loss improved from 0.48115 to 0.47546, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8649 - auc: 0.7649 - loss: 0.4840 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4755\n","Epoch 22/100\n","\u001b[1m312/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8498 - auc: 0.8012 - loss: 0.4856\n","Epoch 22: val_loss improved from 0.47546 to 0.46837, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8503 - auc: 0.8006 - loss: 0.4854 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4684\n","Epoch 23/100\n","\u001b[1m310/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8720 - auc: 0.8109 - loss: 0.4625\n","Epoch 23: val_loss improved from 0.46837 to 0.46188, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8714 - auc: 0.8102 - loss: 0.4632 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4619\n","Epoch 24/100\n","\u001b[1m310/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8422 - auc: 0.7596 - loss: 0.4927\n","Epoch 24: val_loss improved from 0.46188 to 0.45624, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8432 - auc: 0.7619 - loss: 0.4916 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4562\n","Epoch 25/100\n","\u001b[1m305/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8688 - auc: 0.8297 - loss: 0.4590\n","Epoch 25: val_loss improved from 0.45624 to 0.45074, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8685 - auc: 0.8275 - loss: 0.4594 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4507\n","Epoch 26/100\n","\u001b[1m315/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8473 - auc: 0.7758 - loss: 0.4753\n","Epoch 26: val_loss improved from 0.45074 to 0.44438, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8481 - auc: 0.7773 - loss: 0.4746 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4444\n","Epoch 27/100\n","\u001b[1m315/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8856 - auc: 0.8402 - loss: 0.4311\n","Epoch 27: val_loss improved from 0.44438 to 0.44423, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8845 - auc: 0.8390 - loss: 0.4324 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4442\n","Epoch 28/100\n","\u001b[1m312/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8599 - auc: 0.8383 - loss: 0.4653\n","Epoch 28: val_loss improved from 0.44423 to 0.43668, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8599 - auc: 0.8373 - loss: 0.4648 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4367\n","Epoch 29/100\n","\u001b[1m316/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8546 - auc: 0.8253 - loss: 0.4664\n","Epoch 29: val_loss improved from 0.43668 to 0.43022, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8549 - auc: 0.8258 - loss: 0.4657 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4302\n","Epoch 30/100\n","\u001b[1m315/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8739 - auc: 0.8542 - loss: 0.4303\n","Epoch 30: val_loss improved from 0.43022 to 0.42540, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8734 - auc: 0.8541 - loss: 0.4310 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4254\n","Epoch 31/100\n","\u001b[1m309/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8649 - auc: 0.9063 - loss: 0.4444\n","Epoch 31: val_loss improved from 0.42540 to 0.41819, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8647 - auc: 0.9045 - loss: 0.4442 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4182\n","Epoch 32/100\n","\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8597 - auc: 0.8862 - loss: 0.4414\n","Epoch 32: val_loss improved from 0.41819 to 0.41369, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8597 - auc: 0.8862 - loss: 0.4414 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4137\n","Epoch 33/100\n","\u001b[1m320/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8570 - auc: 0.8924 - loss: 0.4414\n","Epoch 33: val_loss improved from 0.41369 to 0.40905, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8572 - auc: 0.8928 - loss: 0.4412 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4090\n","Epoch 34/100\n","\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8621 - auc: 0.9163 - loss: 0.4242\n","Epoch 34: val_loss improved from 0.40905 to 0.40462, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8621 - auc: 0.9162 - loss: 0.4242 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.4046\n","Epoch 35/100\n","\u001b[1m317/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8714 - auc: 0.9081 - loss: 0.4113\n","Epoch 35: val_loss improved from 0.40462 to 0.39788, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8710 - auc: 0.9079 - loss: 0.4119 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3979\n","Epoch 36/100\n","\u001b[1m314/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8627 - auc: 0.8995 - loss: 0.4298\n","Epoch 36: val_loss improved from 0.39788 to 0.39194, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8626 - auc: 0.8995 - loss: 0.4295 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3919\n","Epoch 37/100\n","\u001b[1m316/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8763 - auc: 0.9093 - loss: 0.4078\n","Epoch 37: val_loss improved from 0.39194 to 0.38878, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8757 - auc: 0.9090 - loss: 0.4083 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3888\n","Epoch 38/100\n","\u001b[1m310/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8492 - auc: 0.8731 - loss: 0.4356\n","Epoch 38: val_loss improved from 0.38878 to 0.37909, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8499 - auc: 0.8750 - loss: 0.4343 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3791\n","Epoch 39/100\n","\u001b[1m310/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8597 - auc: 0.9191 - loss: 0.4066\n","Epoch 39: val_loss improved from 0.37909 to 0.37399, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8598 - auc: 0.9181 - loss: 0.4068 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3740\n","Epoch 40/100\n","\u001b[1m308/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8709 - auc: 0.9181 - loss: 0.3939\n","Epoch 40: val_loss improved from 0.37399 to 0.37083, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8703 - auc: 0.9173 - loss: 0.3946 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3708\n","Epoch 41/100\n","\u001b[1m309/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8581 - auc: 0.9287 - loss: 0.4033\n","Epoch 41: val_loss improved from 0.37083 to 0.36417, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8584 - auc: 0.9278 - loss: 0.4031 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3642\n","Epoch 42/100\n","\u001b[1m313/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8692 - auc: 0.9000 - loss: 0.3972\n","Epoch 42: val_loss improved from 0.36417 to 0.36151, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8688 - auc: 0.9007 - loss: 0.3973 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3615\n","Epoch 43/100\n","\u001b[1m311/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8730 - auc: 0.9229 - loss: 0.3973\n","Epoch 43: val_loss improved from 0.36151 to 0.35637, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8724 - auc: 0.9232 - loss: 0.3971 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3564\n","Epoch 44/100\n","\u001b[1m310/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8499 - auc: 0.9270 - loss: 0.3967\n","Epoch 44: val_loss improved from 0.35637 to 0.34443, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8507 - auc: 0.9272 - loss: 0.3961 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3444\n","Epoch 45/100\n","\u001b[1m312/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8742 - auc: 0.9222 - loss: 0.3870\n","Epoch 45: val_loss improved from 0.34443 to 0.34230, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8736 - auc: 0.9226 - loss: 0.3870 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3423\n","Epoch 46/100\n","\u001b[1m305/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8752 - auc: 0.9344 - loss: 0.3706\n","Epoch 46: val_loss improved from 0.34230 to 0.33940, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8742 - auc: 0.9343 - loss: 0.3716 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3394\n","Epoch 47/100\n","\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8545 - auc: 0.9212 - loss: 0.3918\n","Epoch 47: val_loss improved from 0.33940 to 0.33223, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8547 - auc: 0.9214 - loss: 0.3916 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3322\n","Epoch 48/100\n","\u001b[1m305/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8647 - auc: 0.9292 - loss: 0.3734\n","Epoch 48: val_loss improved from 0.33223 to 0.32386, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8646 - auc: 0.9292 - loss: 0.3735 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3239\n","Epoch 49/100\n","\u001b[1m313/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8710 - auc: 0.9365 - loss: 0.3629\n","Epoch 49: val_loss improved from 0.32386 to 0.32159, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8706 - auc: 0.9363 - loss: 0.3633 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3216\n","Epoch 50/100\n","\u001b[1m318/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8507 - auc: 0.9398 - loss: 0.3797\n","Epoch 50: val_loss improved from 0.32159 to 0.31194, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8511 - auc: 0.9396 - loss: 0.3794 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3119\n","Epoch 51/100\n","\u001b[1m317/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8775 - auc: 0.9428 - loss: 0.3446\n","Epoch 51: val_loss improved from 0.31194 to 0.31157, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8769 - auc: 0.9425 - loss: 0.3453 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3116\n","Epoch 52/100\n","\u001b[1m306/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8568 - auc: 0.9522 - loss: 0.3632\n","Epoch 52: val_loss improved from 0.31157 to 0.30132, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8571 - auc: 0.9513 - loss: 0.3632 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.3013\n","Epoch 53/100\n","\u001b[1m309/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8485 - auc: 0.9391 - loss: 0.3676\n","Epoch 53: val_loss improved from 0.30132 to 0.29617, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8493 - auc: 0.9390 - loss: 0.3672 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2962\n","Epoch 54/100\n","\u001b[1m313/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8396 - auc: 0.9403 - loss: 0.3725\n","Epoch 54: val_loss improved from 0.29617 to 0.28810, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8407 - auc: 0.9402 - loss: 0.3717 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2881\n","Epoch 55/100\n","\u001b[1m313/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8746 - auc: 0.9308 - loss: 0.3464\n","Epoch 55: val_loss improved from 0.28810 to 0.28662, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8739 - auc: 0.9312 - loss: 0.3468 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2866\n","Epoch 56/100\n","\u001b[1m312/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8656 - auc: 0.9526 - loss: 0.3405\n","Epoch 56: val_loss improved from 0.28662 to 0.28382, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8654 - auc: 0.9523 - loss: 0.3410 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2838\n","Epoch 57/100\n","\u001b[1m318/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8683 - auc: 0.9531 - loss: 0.3387\n","Epoch 57: val_loss improved from 0.28382 to 0.27927, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8681 - auc: 0.9529 - loss: 0.3390 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2793\n","Epoch 58/100\n","\u001b[1m309/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8462 - auc: 0.9404 - loss: 0.3560\n","Epoch 58: val_loss improved from 0.27927 to 0.27237, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8470 - auc: 0.9408 - loss: 0.3554 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2724\n","Epoch 59/100\n","\u001b[1m308/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8794 - auc: 0.9537 - loss: 0.3285\n","Epoch 59: val_loss improved from 0.27237 to 0.26977, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8782 - auc: 0.9530 - loss: 0.3294 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2698\n","Epoch 60/100\n","\u001b[1m308/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8580 - auc: 0.9239 - loss: 0.3521\n","Epoch 60: val_loss improved from 0.26977 to 0.26266, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8585 - auc: 0.9256 - loss: 0.3509 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2627\n","Epoch 61/100\n","\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8579 - auc: 0.9625 - loss: 0.3174\n","Epoch 61: val_loss improved from 0.26266 to 0.25727, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8579 - auc: 0.9622 - loss: 0.3177 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2573\n","Epoch 62/100\n","\u001b[1m307/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8554 - auc: 0.9532 - loss: 0.3362\n","Epoch 62: val_loss improved from 0.25727 to 0.25503, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8557 - auc: 0.9527 - loss: 0.3360 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2550\n","Epoch 63/100\n","\u001b[1m321/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8538 - auc: 0.9508 - loss: 0.3373\n","Epoch 63: val_loss improved from 0.25503 to 0.24766, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8541 - auc: 0.9507 - loss: 0.3370 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2477\n","Epoch 64/100\n","\u001b[1m311/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8761 - auc: 0.9479 - loss: 0.3111\n","Epoch 64: val_loss improved from 0.24766 to 0.24628, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8753 - auc: 0.9478 - loss: 0.3119 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2463\n","Epoch 65/100\n","\u001b[1m308/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8557 - auc: 0.9462 - loss: 0.3288\n","Epoch 65: val_loss improved from 0.24628 to 0.24051, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8563 - auc: 0.9462 - loss: 0.3284 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2405\n","Epoch 66/100\n","\u001b[1m315/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8659 - auc: 0.9526 - loss: 0.3075\n","Epoch 66: val_loss improved from 0.24051 to 0.23704, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8658 - auc: 0.9523 - loss: 0.3080 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2370\n","Epoch 67/100\n","\u001b[1m316/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8665 - auc: 0.9523 - loss: 0.3107\n","Epoch 67: val_loss improved from 0.23704 to 0.23242, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8663 - auc: 0.9520 - loss: 0.3110 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2324\n","Epoch 68/100\n","\u001b[1m317/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8537 - auc: 0.9524 - loss: 0.3120\n","Epoch 68: val_loss improved from 0.23242 to 0.22721, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8541 - auc: 0.9521 - loss: 0.3120 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2272\n","Epoch 69/100\n","\u001b[1m318/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8757 - auc: 0.9508 - loss: 0.3217\n","Epoch 69: val_loss improved from 0.22721 to 0.22297, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8766 - auc: 0.9506 - loss: 0.3213 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2230\n","Epoch 70/100\n","\u001b[1m317/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8651 - auc: 0.9210 - loss: 0.3241\n","Epoch 70: val_loss improved from 0.22297 to 0.21796, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8651 - auc: 0.9220 - loss: 0.3235 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2180\n","Epoch 71/100\n","\u001b[1m314/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8804 - auc: 0.9385 - loss: 0.3178\n","Epoch 71: val_loss improved from 0.21796 to 0.21474, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8807 - auc: 0.9389 - loss: 0.3173 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2147\n","Epoch 72/100\n","\u001b[1m313/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8826 - auc: 0.9548 - loss: 0.2852\n","Epoch 72: val_loss did not improve from 0.21474\n","\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8819 - auc: 0.9545 - loss: 0.2862 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2209\n","Epoch 73/100\n","\u001b[1m318/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9314 - auc: 0.9454 - loss: 0.3085\n","Epoch 73: val_loss improved from 0.21474 to 0.21152, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9308 - auc: 0.9454 - loss: 0.3083 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2115\n","Epoch 74/100\n","\u001b[1m315/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9101 - auc: 0.9362 - loss: 0.3000\n","Epoch 74: val_loss improved from 0.21152 to 0.20769, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9102 - auc: 0.9367 - loss: 0.3000 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2077\n","Epoch 75/100\n","\u001b[1m312/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9248 - auc: 0.9541 - loss: 0.2925\n","Epoch 75: val_loss improved from 0.20769 to 0.20474, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9242 - auc: 0.9539 - loss: 0.2927 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.2047\n","Epoch 76/100\n","\u001b[1m315/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9374 - auc: 0.9639 - loss: 0.2894\n","Epoch 76: val_loss improved from 0.20474 to 0.19957, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9374 - auc: 0.9631 - loss: 0.2898 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1996\n","Epoch 77/100\n","\u001b[1m317/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9384 - auc: 0.9505 - loss: 0.2966\n","Epoch 77: val_loss improved from 0.19957 to 0.18915, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9383 - auc: 0.9504 - loss: 0.2965 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1892\n","Epoch 78/100\n","\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8980 - auc: 0.9641 - loss: 0.2807\n","Epoch 78: val_loss improved from 0.18915 to 0.18671, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8981 - auc: 0.9638 - loss: 0.2808 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1867\n","Epoch 79/100\n","\u001b[1m316/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9442 - auc: 0.9416 - loss: 0.2894\n","Epoch 79: val_loss improved from 0.18671 to 0.18476, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9440 - auc: 0.9418 - loss: 0.2894 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1848\n","Epoch 80/100\n","\u001b[1m318/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9480 - auc: 0.9573 - loss: 0.2736\n","Epoch 80: val_loss improved from 0.18476 to 0.18022, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9476 - auc: 0.9569 - loss: 0.2741 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1802\n","Epoch 81/100\n","\u001b[1m321/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9247 - auc: 0.9397 - loss: 0.2880\n","Epoch 81: val_loss improved from 0.18022 to 0.17619, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9251 - auc: 0.9399 - loss: 0.2879 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1762\n","Epoch 82/100\n","\u001b[1m317/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9473 - auc: 0.9499 - loss: 0.2753\n","Epoch 82: val_loss did not improve from 0.17619\n","\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9466 - auc: 0.9499 - loss: 0.2755 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1770\n","Epoch 83/100\n","\u001b[1m318/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9335 - auc: 0.9320 - loss: 0.2823\n","Epoch 83: val_loss improved from 0.17619 to 0.17438, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9334 - auc: 0.9325 - loss: 0.2823 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1744\n","Epoch 84/100\n","\u001b[1m320/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9316 - auc: 0.9542 - loss: 0.2627\n","Epoch 84: val_loss improved from 0.17438 to 0.16774, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9314 - auc: 0.9540 - loss: 0.2631 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1677\n","Epoch 85/100\n","\u001b[1m317/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9404 - auc: 0.9600 - loss: 0.2467\n","Epoch 85: val_loss did not improve from 0.16774\n","\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9403 - auc: 0.9595 - loss: 0.2478 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1696\n","Epoch 86/100\n","\u001b[1m322/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9415 - auc: 0.9632 - loss: 0.2430\n","Epoch 86: val_loss did not improve from 0.16774\n","\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9412 - auc: 0.9628 - loss: 0.2438 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1688\n","Epoch 87/100\n","\u001b[1m321/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9248 - auc: 0.9317 - loss: 0.2879\n","Epoch 87: val_loss improved from 0.16774 to 0.16401, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9249 - auc: 0.9322 - loss: 0.2875 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1640\n","Epoch 88/100\n","\u001b[1m312/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9089 - auc: 0.9275 - loss: 0.3063\n","Epoch 88: val_loss improved from 0.16401 to 0.15589, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9098 - auc: 0.9286 - loss: 0.3044 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1559\n","Epoch 89/100\n","\u001b[1m317/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9187 - auc: 0.9572 - loss: 0.2753\n","Epoch 89: val_loss improved from 0.15589 to 0.15256, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9189 - auc: 0.9567 - loss: 0.2751 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1526\n","Epoch 90/100\n","\u001b[1m311/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9433 - auc: 0.9555 - loss: 0.2505\n","Epoch 90: val_loss did not improve from 0.15256\n","\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9426 - auc: 0.9549 - loss: 0.2517 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1578\n","Epoch 91/100\n","\u001b[1m307/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9381 - auc: 0.9489 - loss: 0.2560\n","Epoch 91: val_loss did not improve from 0.15256\n","\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9373 - auc: 0.9488 - loss: 0.2567 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1532\n","Epoch 92/100\n","\u001b[1m305/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9244 - auc: 0.9601 - loss: 0.2556\n","Epoch 92: val_loss improved from 0.15256 to 0.14785, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9244 - auc: 0.9591 - loss: 0.2563 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1479\n","Epoch 93/100\n","\u001b[1m312/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9289 - auc: 0.9516 - loss: 0.2583\n","Epoch 93: val_loss improved from 0.14785 to 0.14338, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9287 - auc: 0.9514 - loss: 0.2587 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1434\n","Epoch 94/100\n","\u001b[1m304/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9294 - auc: 0.9380 - loss: 0.2657\n","Epoch 94: val_loss did not improve from 0.14338\n","\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9296 - auc: 0.9390 - loss: 0.2651 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1456\n","Epoch 95/100\n","\u001b[1m321/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9279 - auc: 0.9352 - loss: 0.2647\n","Epoch 95: val_loss improved from 0.14338 to 0.14097, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9279 - auc: 0.9355 - loss: 0.2646 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1410\n","Epoch 96/100\n","\u001b[1m312/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9353 - auc: 0.9628 - loss: 0.2467\n","Epoch 96: val_loss improved from 0.14097 to 0.13854, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9348 - auc: 0.9619 - loss: 0.2473 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1385\n","Epoch 97/100\n","\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9159 - auc: 0.9381 - loss: 0.2694\n","Epoch 97: val_loss improved from 0.13854 to 0.13463, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9161 - auc: 0.9383 - loss: 0.2692 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1346\n","Epoch 98/100\n","\u001b[1m321/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9332 - auc: 0.9653 - loss: 0.2412\n","Epoch 98: val_loss improved from 0.13463 to 0.13259, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9330 - auc: 0.9648 - loss: 0.2417 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1326\n","Epoch 99/100\n","\u001b[1m316/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9087 - auc: 0.9377 - loss: 0.2839\n","Epoch 99: val_loss improved from 0.13259 to 0.13243, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9095 - auc: 0.9382 - loss: 0.2827 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1324\n","Epoch 100/100\n","\u001b[1m318/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9350 - auc: 0.9666 - loss: 0.2273\n","Epoch 100: val_loss did not improve from 0.13243\n","\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9346 - auc: 0.9659 - loss: 0.2283 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.1353\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 6 | VAL  | AUC=1.0000 | ACC=1.0000 | n=100\n","Fold 6 | TEST | AUC=0.0385 | ACC=0.2524 | n=103\n","\n","--- Fold 7/14 ---\n"," train | ids:   36 | files:  940 | pos:  327 | neg:  613\n","   val | ids:    4 | files:  234 | pos:   77 | neg:  157\n","  test | ids:    3 | files:   16 | pos:    1 | neg:   15\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m301/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.3475 - auc: 0.6230 - loss: 0.7190\n","Epoch 1: val_loss improved from inf to 0.73139, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - acc: 0.3474 - auc: 0.6229 - loss: 0.7189 - val_acc: 0.3291 - val_auc: 0.0000e+00 - val_loss: 0.7314\n","Epoch 2/100\n","\u001b[1m302/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3535 - auc: 0.6858 - loss: 0.7017\n","Epoch 2: val_loss improved from 0.73139 to 0.71402, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.3536 - auc: 0.6870 - loss: 0.7016 - val_acc: 0.0000e+00 - val_auc: 0.0000e+00 - val_loss: 0.7140\n","Epoch 3/100\n","\u001b[1m312/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5712 - auc: 0.7246 - loss: 0.6871\n","Epoch 3: val_loss improved from 0.71402 to 0.70055, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.5714 - auc: 0.7249 - loss: 0.6871 - val_acc: 0.3846 - val_auc: 0.0000e+00 - val_loss: 0.7005\n","Epoch 4/100\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7097 - auc: 0.7664 - loss: 0.6769\n","Epoch 4: val_loss improved from 0.70055 to 0.68950, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7097 - auc: 0.7664 - loss: 0.6769 - val_acc: 0.5043 - val_auc: 0.0000e+00 - val_loss: 0.6895\n","Epoch 5/100\n","\u001b[1m290/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7380 - auc: 0.7368 - loss: 0.6638\n","Epoch 5: val_loss improved from 0.68950 to 0.68025, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7365 - auc: 0.7340 - loss: 0.6637 - val_acc: 0.6709 - val_auc: 0.2866 - val_loss: 0.6802\n","Epoch 6/100\n","\u001b[1m311/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7369 - auc: 0.7112 - loss: 0.6561\n","Epoch 6: val_loss improved from 0.68025 to 0.67034, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7372 - auc: 0.7111 - loss: 0.6561 - val_acc: 0.6709 - val_auc: 0.6624 - val_loss: 0.6703\n","Epoch 7/100\n","\u001b[1m304/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8030 - auc: 0.6166 - loss: 0.6377\n","Epoch 7: val_loss improved from 0.67034 to 0.65772, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8041 - auc: 0.6188 - loss: 0.6373 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6577\n","Epoch 8/100\n","\u001b[1m311/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8409 - auc: 0.6436 - loss: 0.6145\n","Epoch 8: val_loss improved from 0.65772 to 0.64678, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8410 - auc: 0.6439 - loss: 0.6144 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6468\n","Epoch 9/100\n","\u001b[1m313/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8246 - auc: 0.6199 - loss: 0.5973\n","Epoch 9: val_loss improved from 0.64678 to 0.63597, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8248 - auc: 0.6202 - loss: 0.5972 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6360\n","Epoch 10/100\n","\u001b[1m290/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8442 - auc: 0.6328 - loss: 0.5785\n","Epoch 10: val_loss improved from 0.63597 to 0.62600, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8452 - auc: 0.6349 - loss: 0.5776 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6260\n","Epoch 11/100\n","\u001b[1m291/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8656 - auc: 0.6584 - loss: 0.5483\n","Epoch 11: val_loss improved from 0.62600 to 0.61724, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8651 - auc: 0.6578 - loss: 0.5483 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6172\n","Epoch 12/100\n","\u001b[1m289/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8504 - auc: 0.6575 - loss: 0.5399\n","Epoch 12: val_loss improved from 0.61724 to 0.61033, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8509 - auc: 0.6573 - loss: 0.5395 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6103\n","Epoch 13/100\n","\u001b[1m313/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8617 - auc: 0.6359 - loss: 0.5248\n","Epoch 13: val_loss improved from 0.61033 to 0.60458, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8616 - auc: 0.6360 - loss: 0.5247 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6046\n","Epoch 14/100\n","\u001b[1m311/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8359 - auc: 0.6615 - loss: 0.5207\n","Epoch 14: val_loss improved from 0.60458 to 0.60012, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8361 - auc: 0.6614 - loss: 0.5206 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6001\n","Epoch 15/100\n","\u001b[1m307/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8622 - auc: 0.6372 - loss: 0.4987\n","Epoch 15: val_loss improved from 0.60012 to 0.59652, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8620 - auc: 0.6374 - loss: 0.4987 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5965\n","Epoch 16/100\n","\u001b[1m302/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8655 - auc: 0.6304 - loss: 0.4829\n","Epoch 16: val_loss improved from 0.59652 to 0.59473, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8652 - auc: 0.6311 - loss: 0.4830 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5947\n","Epoch 17/100\n","\u001b[1m308/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8664 - auc: 0.6331 - loss: 0.4787\n","Epoch 17: val_loss improved from 0.59473 to 0.59400, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8662 - auc: 0.6332 - loss: 0.4788 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5940\n","Epoch 18/100\n","\u001b[1m289/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8607 - auc: 0.6626 - loss: 0.4696\n","Epoch 18: val_loss improved from 0.59400 to 0.59344, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8603 - auc: 0.6606 - loss: 0.4702 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5934\n","Epoch 19/100\n","\u001b[1m289/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8478 - auc: 0.6539 - loss: 0.4795\n","Epoch 19: val_loss improved from 0.59344 to 0.59330, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8483 - auc: 0.6536 - loss: 0.4787 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5933\n","Epoch 20/100\n","\u001b[1m309/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8526 - auc: 0.6662 - loss: 0.4586\n","Epoch 20: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8527 - auc: 0.6659 - loss: 0.4586 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5934\n","Epoch 21/100\n","\u001b[1m312/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8581 - auc: 0.6742 - loss: 0.4508\n","Epoch 21: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8580 - auc: 0.6740 - loss: 0.4508 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5939\n","Epoch 22/100\n","\u001b[1m289/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8778 - auc: 0.6781 - loss: 0.4305\n","Epoch 22: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8761 - auc: 0.6752 - loss: 0.4322 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5944\n","Epoch 23/100\n","\u001b[1m310/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8681 - auc: 0.6685 - loss: 0.4328\n","Epoch 23: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8679 - auc: 0.6682 - loss: 0.4330 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5952\n","Epoch 24/100\n","\u001b[1m308/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8522 - auc: 0.6423 - loss: 0.4493\n","Epoch 24: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8523 - auc: 0.6424 - loss: 0.4491 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5960\n","Epoch 25/100\n","\u001b[1m311/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8553 - auc: 0.6551 - loss: 0.4398\n","Epoch 25: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8553 - auc: 0.6550 - loss: 0.4398 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5969\n","Epoch 26/100\n","\u001b[1m308/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8541 - auc: 0.6271 - loss: 0.4392\n","Epoch 26: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8541 - auc: 0.6275 - loss: 0.4391 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5979\n","Epoch 27/100\n","\u001b[1m312/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8710 - auc: 0.6780 - loss: 0.4141\n","Epoch 27: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8709 - auc: 0.6777 - loss: 0.4142 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5988\n","Epoch 28/100\n","\u001b[1m311/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8508 - auc: 0.6143 - loss: 0.4400\n","Epoch 28: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8509 - auc: 0.6147 - loss: 0.4398 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5996\n","Epoch 29/100\n","\u001b[1m304/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8653 - auc: 0.6666 - loss: 0.4166\n","Epoch 29: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8649 - auc: 0.6660 - loss: 0.4170 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6006\n","Epoch 30/100\n","\u001b[1m304/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8483 - auc: 0.5961 - loss: 0.4421\n","Epoch 30: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8486 - auc: 0.5977 - loss: 0.4415 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6017\n","Epoch 31/100\n","\u001b[1m297/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8707 - auc: 0.6890 - loss: 0.4000\n","Epoch 31: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8701 - auc: 0.6871 - loss: 0.4010 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6027\n","Epoch 32/100\n","\u001b[1m308/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8747 - auc: 0.6820 - loss: 0.3929\n","Epoch 32: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8743 - auc: 0.6812 - loss: 0.3934 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6037\n","Epoch 33/100\n","\u001b[1m309/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8538 - auc: 0.6422 - loss: 0.4243\n","Epoch 33: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8538 - auc: 0.6423 - loss: 0.4241 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6046\n","Epoch 34/100\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8530 - auc: 0.6050 - loss: 0.4244\n","Epoch 34: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8530 - auc: 0.6051 - loss: 0.4243 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6057\n","Epoch 35/100\n","\u001b[1m288/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8654 - auc: 0.6571 - loss: 0.4053\n","Epoch 35: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8646 - auc: 0.6566 - loss: 0.4062 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6067\n","Epoch 36/100\n","\u001b[1m313/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8635 - auc: 0.6624 - loss: 0.4037\n","Epoch 36: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8635 - auc: 0.6624 - loss: 0.4037 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6077\n","Epoch 37/100\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8500 - auc: 0.6452 - loss: 0.4204\n","Epoch 37: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8500 - auc: 0.6453 - loss: 0.4204 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6086\n","Epoch 38/100\n","\u001b[1m310/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8381 - auc: 0.6257 - loss: 0.4351\n","Epoch 38: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8384 - auc: 0.6261 - loss: 0.4347 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6095\n","Epoch 39/100\n","\u001b[1m311/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8646 - auc: 0.6798 - loss: 0.3948\n","Epoch 39: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8645 - auc: 0.6794 - loss: 0.3950 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6108\n","Epoch 40/100\n","\u001b[1m289/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8598 - auc: 0.6259 - loss: 0.4088\n","Epoch 40: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8595 - auc: 0.6275 - loss: 0.4088 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6121\n","Epoch 41/100\n","\u001b[1m290/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8435 - auc: 0.6183 - loss: 0.4251\n","Epoch 41: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8448 - auc: 0.6210 - loss: 0.4232 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6136\n","Epoch 42/100\n","\u001b[1m313/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8502 - auc: 0.6350 - loss: 0.4149\n","Epoch 42: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8503 - auc: 0.6351 - loss: 0.4148 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6147\n","Epoch 43/100\n","\u001b[1m305/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8690 - auc: 0.6530 - loss: 0.3914\n","Epoch 43: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8686 - auc: 0.6531 - loss: 0.3918 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6164\n","Epoch 44/100\n","\u001b[1m313/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8638 - auc: 0.6564 - loss: 0.3960\n","Epoch 44: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8637 - auc: 0.6564 - loss: 0.3960 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6181\n","Epoch 45/100\n","\u001b[1m308/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8324 - auc: 0.6289 - loss: 0.4324\n","Epoch 45: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8329 - auc: 0.6293 - loss: 0.4317 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6196\n","Epoch 46/100\n","\u001b[1m313/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8389 - auc: 0.6378 - loss: 0.4250\n","Epoch 46: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8390 - auc: 0.6379 - loss: 0.4248 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6211\n","Epoch 47/100\n","\u001b[1m292/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8527 - auc: 0.6318 - loss: 0.4075\n","Epoch 47: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8527 - auc: 0.6331 - loss: 0.4073 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6228\n","Epoch 48/100\n","\u001b[1m292/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8557 - auc: 0.6453 - loss: 0.4019\n","Epoch 48: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8557 - auc: 0.6464 - loss: 0.4017 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6245\n","Epoch 49/100\n","\u001b[1m309/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8537 - auc: 0.6328 - loss: 0.4058\n","Epoch 49: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8538 - auc: 0.6333 - loss: 0.4057 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6260\n","Epoch 50/100\n","\u001b[1m289/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8464 - auc: 0.6418 - loss: 0.4110\n","Epoch 50: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8470 - auc: 0.6425 - loss: 0.4101 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6278\n","Epoch 51/100\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8506 - auc: 0.6468 - loss: 0.4055\n","Epoch 51: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8506 - auc: 0.6468 - loss: 0.4054 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6296\n","Epoch 52/100\n","\u001b[1m291/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8427 - auc: 0.6469 - loss: 0.4129\n","Epoch 52: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8435 - auc: 0.6475 - loss: 0.4118 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6316\n","Epoch 53/100\n","\u001b[1m313/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8611 - auc: 0.6411 - loss: 0.3884\n","Epoch 53: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8610 - auc: 0.6411 - loss: 0.3884 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6336\n","Epoch 54/100\n","\u001b[1m290/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8611 - auc: 0.6766 - loss: 0.3837\n","Epoch 54: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8606 - auc: 0.6740 - loss: 0.3846 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6353\n","Epoch 55/100\n","\u001b[1m311/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8498 - auc: 0.6568 - loss: 0.4019\n","Epoch 55: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8499 - auc: 0.6568 - loss: 0.4018 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6374\n","Epoch 56/100\n","\u001b[1m290/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8838 - auc: 0.7090 - loss: 0.3520\n","Epoch 56: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8817 - auc: 0.7048 - loss: 0.3550 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6394\n","Epoch 57/100\n","\u001b[1m290/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8805 - auc: 0.7193 - loss: 0.3494\n","Epoch 57: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8787 - auc: 0.7144 - loss: 0.3526 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6413\n","Epoch 58/100\n","\u001b[1m299/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8743 - auc: 0.7123 - loss: 0.3577\n","Epoch 58: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8734 - auc: 0.7101 - loss: 0.3593 - val_acc: 0.6709 - val_auc: 0.8758 - val_loss: 0.6434\n","Epoch 59/100\n","\u001b[1m300/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8502 - auc: 0.6530 - loss: 0.3986\n","Epoch 59: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8504 - auc: 0.6541 - loss: 0.3982 - val_acc: 0.6709 - val_auc: 0.8758 - val_loss: 0.6455\n","Epoch 60/100\n","\u001b[1m296/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8588 - auc: 0.6621 - loss: 0.3853\n","Epoch 60: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8587 - auc: 0.6624 - loss: 0.3852 - val_acc: 0.6709 - val_auc: 0.8758 - val_loss: 0.6479\n","Epoch 61/100\n","\u001b[1m288/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8759 - auc: 0.7034 - loss: 0.3614\n","Epoch 61: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8746 - auc: 0.7016 - loss: 0.3629 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6502\n","Epoch 62/100\n","\u001b[1m289/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8735 - auc: 0.7339 - loss: 0.3569\n","Epoch 62: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8722 - auc: 0.7297 - loss: 0.3589 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6523\n","Epoch 63/100\n","\u001b[1m309/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8335 - auc: 0.6696 - loss: 0.4115\n","Epoch 63: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8339 - auc: 0.6700 - loss: 0.4109 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6547\n","Epoch 64/100\n","\u001b[1m310/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8347 - auc: 0.6438 - loss: 0.4191\n","Epoch 64: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8351 - auc: 0.6448 - loss: 0.4186 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6571\n","Epoch 65/100\n","\u001b[1m311/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8631 - auc: 0.6956 - loss: 0.3764\n","Epoch 65: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8630 - auc: 0.6957 - loss: 0.3765 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6595\n","Epoch 66/100\n","\u001b[1m308/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8592 - auc: 0.7698 - loss: 0.3757\n","Epoch 66: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8591 - auc: 0.7699 - loss: 0.3758 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6623\n","Epoch 67/100\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8544 - auc: 0.7940 - loss: 0.3819\n","Epoch 67: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8544 - auc: 0.7940 - loss: 0.3819 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6647\n","Epoch 68/100\n","\u001b[1m311/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8671 - auc: 0.8268 - loss: 0.3664\n","Epoch 68: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8670 - auc: 0.8267 - loss: 0.3665 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6674\n","Epoch 69/100\n","\u001b[1m290/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8516 - auc: 0.8402 - loss: 0.3798\n","Epoch 69: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8521 - auc: 0.8397 - loss: 0.3793 - val_acc: 0.6709 - val_auc: 0.6624 - val_loss: 0.6703\n","Epoch 70/100\n","\u001b[1m313/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8643 - auc: 0.8618 - loss: 0.3666\n","Epoch 70: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8643 - auc: 0.8618 - loss: 0.3666 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6728\n","Epoch 71/100\n","\u001b[1m313/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8524 - auc: 0.8457 - loss: 0.3830\n","Epoch 71: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8524 - auc: 0.8459 - loss: 0.3830 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6756\n","Epoch 72/100\n","\u001b[1m310/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8567 - auc: 0.8623 - loss: 0.3694\n","Epoch 72: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8567 - auc: 0.8624 - loss: 0.3695 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6785\n","Epoch 73/100\n","\u001b[1m303/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8532 - auc: 0.8553 - loss: 0.3790\n","Epoch 73: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8533 - auc: 0.8565 - loss: 0.3787 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6815\n","Epoch 74/100\n","\u001b[1m304/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8442 - auc: 0.8995 - loss: 0.3863\n","Epoch 74: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8446 - auc: 0.8997 - loss: 0.3858 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6844\n","Epoch 75/100\n","\u001b[1m310/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8462 - auc: 0.9192 - loss: 0.3890\n","Epoch 75: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8464 - auc: 0.9192 - loss: 0.3887 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6874\n","Epoch 76/100\n","\u001b[1m311/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8722 - auc: 0.9253 - loss: 0.3466\n","Epoch 76: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8720 - auc: 0.9252 - loss: 0.3469 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6907\n","Epoch 77/100\n","\u001b[1m313/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8623 - auc: 0.9329 - loss: 0.3608\n","Epoch 77: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8622 - auc: 0.9329 - loss: 0.3609 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6936\n","Epoch 78/100\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8358 - auc: 0.9200 - loss: 0.3914\n","Epoch 78: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8359 - auc: 0.9201 - loss: 0.3913 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6970\n","Epoch 79/100\n","\u001b[1m311/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8640 - auc: 0.9387 - loss: 0.3544\n","Epoch 79: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8639 - auc: 0.9386 - loss: 0.3545 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.7004\n","Epoch 80/100\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8369 - auc: 0.9182 - loss: 0.3907\n","Epoch 80: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8369 - auc: 0.9183 - loss: 0.3906 - val_acc: 0.6709 - val_auc: 0.2866 - val_loss: 0.7039\n","Epoch 81/100\n","\u001b[1m293/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8521 - auc: 0.9267 - loss: 0.3665\n","Epoch 81: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8524 - auc: 0.9270 - loss: 0.3662 - val_acc: 0.6709 - val_auc: 0.2866 - val_loss: 0.7075\n","Epoch 82/100\n","\u001b[1m301/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8486 - auc: 0.9337 - loss: 0.3679\n","Epoch 82: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8489 - auc: 0.9339 - loss: 0.3676 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7112\n","Epoch 83/100\n","\u001b[1m291/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8404 - auc: 0.9345 - loss: 0.3776\n","Epoch 83: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8417 - auc: 0.9347 - loss: 0.3760 - val_acc: 0.6709 - val_auc: 0.2866 - val_loss: 0.7153\n","Epoch 84/100\n","\u001b[1m310/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8656 - auc: 0.9241 - loss: 0.3489\n","Epoch 84: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8655 - auc: 0.9243 - loss: 0.3490 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7192\n","Epoch 85/100\n","\u001b[1m312/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8514 - auc: 0.9455 - loss: 0.3608\n","Epoch 85: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8515 - auc: 0.9454 - loss: 0.3608 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7234\n","Epoch 86/100\n","\u001b[1m291/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8654 - auc: 0.9364 - loss: 0.3446\n","Epoch 86: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8647 - auc: 0.9363 - loss: 0.3453 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7274\n","Epoch 87/100\n","\u001b[1m304/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8677 - auc: 0.9432 - loss: 0.3398\n","Epoch 87: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8673 - auc: 0.9428 - loss: 0.3403 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7314\n","Epoch 88/100\n","\u001b[1m310/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8729 - auc: 0.9336 - loss: 0.3322\n","Epoch 88: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8726 - auc: 0.9336 - loss: 0.3325 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7355\n","Epoch 89/100\n","\u001b[1m307/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8696 - auc: 0.9523 - loss: 0.3275\n","Epoch 89: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8693 - auc: 0.9518 - loss: 0.3281 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7398\n","Epoch 90/100\n","\u001b[1m313/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8480 - auc: 0.9306 - loss: 0.3642\n","Epoch 90: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8480 - auc: 0.9306 - loss: 0.3641 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7447\n","Epoch 91/100\n","\u001b[1m290/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8631 - auc: 0.9430 - loss: 0.3353\n","Epoch 91: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8626 - auc: 0.9419 - loss: 0.3362 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7495\n","Epoch 92/100\n","\u001b[1m298/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8666 - auc: 0.9443 - loss: 0.3234\n","Epoch 92: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8659 - auc: 0.9437 - loss: 0.3248 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7543\n","Epoch 93/100\n","\u001b[1m288/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8698 - auc: 0.9533 - loss: 0.3184\n","Epoch 93: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8688 - auc: 0.9512 - loss: 0.3203 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7599\n","Epoch 94/100\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8783 - auc: 0.9323 - loss: 0.3134\n","Epoch 94: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8782 - auc: 0.9322 - loss: 0.3135 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7649\n","Epoch 95/100\n","\u001b[1m294/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8529 - auc: 0.9360 - loss: 0.3448\n","Epoch 95: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8530 - auc: 0.9359 - loss: 0.3446 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7702\n","Epoch 96/100\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8514 - auc: 0.9426 - loss: 0.3377\n","Epoch 96: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8514 - auc: 0.9426 - loss: 0.3377 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7759\n","Epoch 97/100\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8675 - auc: 0.9346 - loss: 0.3191\n","Epoch 97: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8674 - auc: 0.9346 - loss: 0.3192 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7816\n","Epoch 98/100\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8634 - auc: 0.9175 - loss: 0.3310\n","Epoch 98: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8633 - auc: 0.9176 - loss: 0.3310 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7874\n","Epoch 99/100\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8359 - auc: 0.9324 - loss: 0.3553\n","Epoch 99: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8360 - auc: 0.9324 - loss: 0.3552 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7930\n","Epoch 100/100\n","\u001b[1m310/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8701 - auc: 0.9450 - loss: 0.3132\n","Epoch 100: val_loss did not improve from 0.59330\n","\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8699 - auc: 0.9449 - loss: 0.3135 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7999\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 7 | VAL  | AUC=1.0000 | ACC=0.6709 | n=234\n","Fold 7 | TEST | AUC=0.0000 | ACC=0.9375 | n=16\n","\n","--- Fold 8/14 ---\n"," train | ids:   36 | files:  930 | pos:  299 | neg:  631\n","   val | ids:    4 | files:  207 | pos:   77 | neg:  130\n","  test | ids:    3 | files:   53 | pos:   29 | neg:   24\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6972 - auc: 0.6087 - loss: 0.6753\n","Epoch 1: val_loss improved from inf to 0.64270, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - acc: 0.7001 - auc: 0.6108 - loss: 0.6745 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6427\n","Epoch 2/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8395 - auc: 0.6073 - loss: 0.6380\n","Epoch 2: val_loss improved from 0.64270 to 0.62306, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8405 - auc: 0.6085 - loss: 0.6372 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6231\n","Epoch 3/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8398 - auc: 0.5907 - loss: 0.6167\n","Epoch 3: val_loss improved from 0.62306 to 0.61579, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8406 - auc: 0.5923 - loss: 0.6154 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6158\n","Epoch 4/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8350 - auc: 0.6130 - loss: 0.6048\n","Epoch 4: val_loss improved from 0.61579 to 0.61376, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8363 - auc: 0.6132 - loss: 0.6036 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6138\n","Epoch 5/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8595 - auc: 0.6124 - loss: 0.5765\n","Epoch 5: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8591 - auc: 0.6124 - loss: 0.5765 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6139\n","Epoch 6/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8582 - auc: 0.6080 - loss: 0.5690\n","Epoch 6: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8579 - auc: 0.6082 - loss: 0.5687 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6138\n","Epoch 7/100\n","\u001b[1m294/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8565 - auc: 0.6399 - loss: 0.5521\n","Epoch 7: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8563 - auc: 0.6386 - loss: 0.5522 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6165\n","Epoch 8/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8728 - auc: 0.6325 - loss: 0.5190\n","Epoch 8: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8718 - auc: 0.6321 - loss: 0.5203 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6190\n","Epoch 9/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8553 - auc: 0.6009 - loss: 0.5349\n","Epoch 9: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8552 - auc: 0.6023 - loss: 0.5349 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6207\n","Epoch 10/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8488 - auc: 0.6213 - loss: 0.5368\n","Epoch 10: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8491 - auc: 0.6213 - loss: 0.5364 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6223\n","Epoch 11/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8555 - auc: 0.6590 - loss: 0.5339\n","Epoch 11: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8555 - auc: 0.6569 - loss: 0.5330 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6244\n","Epoch 12/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8465 - auc: 0.6252 - loss: 0.5214\n","Epoch 12: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8466 - auc: 0.6252 - loss: 0.5213 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6255\n","Epoch 13/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8424 - auc: 0.5926 - loss: 0.5300\n","Epoch 13: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8425 - auc: 0.5928 - loss: 0.5299 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6265\n","Epoch 14/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8399 - auc: 0.5786 - loss: 0.5224\n","Epoch 14: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8399 - auc: 0.5788 - loss: 0.5224 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6283\n","Epoch 15/100\n","\u001b[1m291/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8620 - auc: 0.6341 - loss: 0.4912\n","Epoch 15: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8615 - auc: 0.6334 - loss: 0.4917 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6293\n","Epoch 16/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8715 - auc: 0.6474 - loss: 0.4763\n","Epoch 16: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8703 - auc: 0.6462 - loss: 0.4776 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6301\n","Epoch 17/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8655 - auc: 0.6723 - loss: 0.4745\n","Epoch 17: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8647 - auc: 0.6689 - loss: 0.4757 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6309\n","Epoch 18/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8604 - auc: 0.6532 - loss: 0.4728\n","Epoch 18: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8597 - auc: 0.6518 - loss: 0.4739 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6319\n","Epoch 19/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8568 - auc: 0.6842 - loss: 0.4748\n","Epoch 19: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8566 - auc: 0.6822 - loss: 0.4751 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6336\n","Epoch 20/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8637 - auc: 0.7068 - loss: 0.4584\n","Epoch 20: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8632 - auc: 0.7052 - loss: 0.4593 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6344\n","Epoch 21/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8433 - auc: 0.6665 - loss: 0.4870\n","Epoch 21: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8440 - auc: 0.6689 - loss: 0.4858 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6355\n","Epoch 22/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8537 - auc: 0.7059 - loss: 0.4616\n","Epoch 22: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8537 - auc: 0.7067 - loss: 0.4618 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6370\n","Epoch 23/100\n","\u001b[1m289/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8558 - auc: 0.7207 - loss: 0.4574\n","Epoch 23: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8556 - auc: 0.7205 - loss: 0.4575 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6383\n","Epoch 24/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8625 - auc: 0.7199 - loss: 0.4475\n","Epoch 24: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8619 - auc: 0.7203 - loss: 0.4478 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6397\n","Epoch 25/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8531 - auc: 0.7426 - loss: 0.4495\n","Epoch 25: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8530 - auc: 0.7415 - loss: 0.4495 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6412\n","Epoch 26/100\n","\u001b[1m291/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8597 - auc: 0.7342 - loss: 0.4356\n","Epoch 26: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8594 - auc: 0.7341 - loss: 0.4359 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6426\n","Epoch 27/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8781 - auc: 0.7771 - loss: 0.4052\n","Epoch 27: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8761 - auc: 0.7735 - loss: 0.4077 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6439\n","Epoch 28/100\n","\u001b[1m306/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8524 - auc: 0.7378 - loss: 0.4319\n","Epoch 28: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8524 - auc: 0.7379 - loss: 0.4319 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6474\n","Epoch 29/100\n","\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8296 - auc: 0.7186 - loss: 0.4571\n","Epoch 29: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8301 - auc: 0.7193 - loss: 0.4565 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6485\n","Epoch 30/100\n","\u001b[1m291/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8497 - auc: 0.7482 - loss: 0.4286\n","Epoch 30: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8498 - auc: 0.7503 - loss: 0.4283 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6510\n","Epoch 31/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8536 - auc: 0.8146 - loss: 0.4133\n","Epoch 31: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8536 - auc: 0.8146 - loss: 0.4133 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6537\n","Epoch 32/100\n","\u001b[1m291/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8464 - auc: 0.8058 - loss: 0.4198\n","Epoch 32: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8470 - auc: 0.8071 - loss: 0.4190 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6573\n","Epoch 33/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8540 - auc: 0.8472 - loss: 0.4028\n","Epoch 33: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8537 - auc: 0.8471 - loss: 0.4032 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6596\n","Epoch 34/100\n","\u001b[1m306/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8415 - auc: 0.8801 - loss: 0.4153\n","Epoch 34: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8417 - auc: 0.8800 - loss: 0.4151 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6624\n","Epoch 35/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8338 - auc: 0.8954 - loss: 0.4177\n","Epoch 35: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8339 - auc: 0.8954 - loss: 0.4177 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6654\n","Epoch 36/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8302 - auc: 0.8763 - loss: 0.4194\n","Epoch 36: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8320 - auc: 0.8774 - loss: 0.4170 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6685\n","Epoch 37/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8413 - auc: 0.8998 - loss: 0.3979\n","Epoch 37: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8423 - auc: 0.8998 - loss: 0.3967 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6720\n","Epoch 38/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8530 - auc: 0.9207 - loss: 0.3764\n","Epoch 38: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8531 - auc: 0.9194 - loss: 0.3765 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6741\n","Epoch 39/100\n","\u001b[1m291/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8566 - auc: 0.9334 - loss: 0.3634\n","Epoch 39: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8564 - auc: 0.9317 - loss: 0.3641 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6772\n","Epoch 40/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8364 - auc: 0.9216 - loss: 0.3839\n","Epoch 40: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8365 - auc: 0.9215 - loss: 0.3838 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6812\n","Epoch 41/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8650 - auc: 0.8960 - loss: 0.3552\n","Epoch 41: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8642 - auc: 0.8968 - loss: 0.3559 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6850\n","Epoch 42/100\n","\u001b[1m304/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8507 - auc: 0.8778 - loss: 0.3737\n","Epoch 42: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8507 - auc: 0.8785 - loss: 0.3734 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6874\n","Epoch 43/100\n","\u001b[1m300/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8578 - auc: 0.9163 - loss: 0.3494\n","Epoch 43: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8576 - auc: 0.9160 - loss: 0.3496 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6938\n","Epoch 44/100\n","\u001b[1m303/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8475 - auc: 0.9088 - loss: 0.3574\n","Epoch 44: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8477 - auc: 0.9089 - loss: 0.3572 - val_acc: 0.6280 - val_auc: 1.0000 - val_loss: 0.6965\n","Epoch 45/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8463 - auc: 0.9063 - loss: 0.3598\n","Epoch 45: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8469 - auc: 0.9069 - loss: 0.3587 - val_acc: 0.6280 - val_auc: 0.6538 - val_loss: 0.7002\n","Epoch 46/100\n","\u001b[1m293/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8415 - auc: 0.9015 - loss: 0.3621\n","Epoch 46: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8421 - auc: 0.9024 - loss: 0.3610 - val_acc: 0.6280 - val_auc: 0.6538 - val_loss: 0.7071\n","Epoch 47/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8473 - auc: 0.9059 - loss: 0.3493\n","Epoch 47: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8478 - auc: 0.9066 - loss: 0.3484 - val_acc: 0.6280 - val_auc: 0.6538 - val_loss: 0.7105\n","Epoch 48/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8269 - auc: 0.9041 - loss: 0.3644\n","Epoch 48: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8271 - auc: 0.9042 - loss: 0.3642 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.7168\n","Epoch 49/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8594 - auc: 0.9157 - loss: 0.3225\n","Epoch 49: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8590 - auc: 0.9158 - loss: 0.3229 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.7214\n","Epoch 50/100\n","\u001b[1m302/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8791 - auc: 0.9211 - loss: 0.2970\n","Epoch 50: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8783 - auc: 0.9209 - loss: 0.2978 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.7237\n","Epoch 51/100\n","\u001b[1m306/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8561 - auc: 0.9060 - loss: 0.3227\n","Epoch 51: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8560 - auc: 0.9061 - loss: 0.3226 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.7300\n","Epoch 52/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8529 - auc: 0.9200 - loss: 0.3142\n","Epoch 52: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8527 - auc: 0.9194 - loss: 0.3146 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.7397\n","Epoch 53/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8478 - auc: 0.9174 - loss: 0.3165\n","Epoch 53: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8486 - auc: 0.9173 - loss: 0.3159 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.7435\n","Epoch 54/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8576 - auc: 0.9018 - loss: 0.3130\n","Epoch 54: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8574 - auc: 0.9026 - loss: 0.3128 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.7503\n","Epoch 55/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8659 - auc: 0.9272 - loss: 0.2886\n","Epoch 55: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8652 - auc: 0.9265 - loss: 0.2896 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.7564\n","Epoch 56/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8633 - auc: 0.9207 - loss: 0.2922\n","Epoch 56: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8632 - auc: 0.9206 - loss: 0.2923 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.7652\n","Epoch 57/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8502 - auc: 0.9100 - loss: 0.3033\n","Epoch 57: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8502 - auc: 0.9100 - loss: 0.3033 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.7737\n","Epoch 58/100\n","\u001b[1m299/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8552 - auc: 0.9079 - loss: 0.3005\n","Epoch 58: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8552 - auc: 0.9081 - loss: 0.3005 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.7780\n","Epoch 59/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8562 - auc: 0.8972 - loss: 0.3028\n","Epoch 59: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8561 - auc: 0.8975 - loss: 0.3027 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.7844\n","Epoch 60/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8712 - auc: 0.9195 - loss: 0.2762\n","Epoch 60: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8698 - auc: 0.9193 - loss: 0.2775 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.7901\n","Epoch 61/100\n","\u001b[1m294/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8491 - auc: 0.9178 - loss: 0.2911\n","Epoch 61: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8493 - auc: 0.9178 - loss: 0.2911 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.7986\n","Epoch 62/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8680 - auc: 0.9248 - loss: 0.2763\n","Epoch 62: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8669 - auc: 0.9244 - loss: 0.2774 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.8041\n","Epoch 63/100\n","\u001b[1m291/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8632 - auc: 0.9375 - loss: 0.2689\n","Epoch 63: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8628 - auc: 0.9369 - loss: 0.2697 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.8105\n","Epoch 64/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8438 - auc: 0.9287 - loss: 0.3022\n","Epoch 64: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8444 - auc: 0.9287 - loss: 0.3012 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.8174\n","Epoch 65/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8542 - auc: 0.9140 - loss: 0.2967\n","Epoch 65: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8541 - auc: 0.9151 - loss: 0.2960 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.8265\n","Epoch 66/100\n","\u001b[1m289/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8559 - auc: 0.9277 - loss: 0.2826\n","Epoch 66: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8559 - auc: 0.9281 - loss: 0.2826 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.8337\n","Epoch 67/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8577 - auc: 0.9243 - loss: 0.2883\n","Epoch 67: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8577 - auc: 0.9244 - loss: 0.2883 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.8351\n","Epoch 68/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8502 - auc: 0.9298 - loss: 0.2963\n","Epoch 68: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8502 - auc: 0.9299 - loss: 0.2961 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.8450\n","Epoch 69/100\n","\u001b[1m300/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8527 - auc: 0.9300 - loss: 0.2799\n","Epoch 69: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8527 - auc: 0.9303 - loss: 0.2799 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.8502\n","Epoch 70/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8472 - auc: 0.9429 - loss: 0.2787\n","Epoch 70: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8473 - auc: 0.9428 - loss: 0.2787 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.8617\n","Epoch 71/100\n","\u001b[1m289/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8660 - auc: 0.9381 - loss: 0.2669\n","Epoch 71: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8652 - auc: 0.9383 - loss: 0.2675 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.8652\n","Epoch 72/100\n","\u001b[1m303/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8491 - auc: 0.9367 - loss: 0.2830\n","Epoch 72: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8492 - auc: 0.9367 - loss: 0.2828 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.8698\n","Epoch 73/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8778 - auc: 0.9346 - loss: 0.2601\n","Epoch 73: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8777 - auc: 0.9346 - loss: 0.2601 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.8780\n","Epoch 74/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8521 - auc: 0.9386 - loss: 0.2724\n","Epoch 74: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8521 - auc: 0.9386 - loss: 0.2724 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.8810\n","Epoch 75/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8397 - auc: 0.9366 - loss: 0.2879\n","Epoch 75: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8406 - auc: 0.9368 - loss: 0.2871 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.8898\n","Epoch 76/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8616 - auc: 0.9159 - loss: 0.2827\n","Epoch 76: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8611 - auc: 0.9178 - loss: 0.2819 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.8943\n","Epoch 77/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8660 - auc: 0.9427 - loss: 0.2661\n","Epoch 77: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8650 - auc: 0.9424 - loss: 0.2668 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.9000\n","Epoch 78/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8597 - auc: 0.9279 - loss: 0.2703\n","Epoch 78: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8593 - auc: 0.9290 - loss: 0.2703 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.9020\n","Epoch 79/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8513 - auc: 0.9413 - loss: 0.2747\n","Epoch 79: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8513 - auc: 0.9413 - loss: 0.2747 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.9084\n","Epoch 80/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8584 - auc: 0.9511 - loss: 0.2671\n","Epoch 80: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8584 - auc: 0.9511 - loss: 0.2671 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.9132\n","Epoch 81/100\n","\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8654 - auc: 0.9178 - loss: 0.2781\n","Epoch 81: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8651 - auc: 0.9183 - loss: 0.2780 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.9102\n","Epoch 82/100\n","\u001b[1m306/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8669 - auc: 0.9497 - loss: 0.2518\n","Epoch 82: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8667 - auc: 0.9496 - loss: 0.2521 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.9202\n","Epoch 83/100\n","\u001b[1m302/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8371 - auc: 0.9053 - loss: 0.3152\n","Epoch 83: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8375 - auc: 0.9063 - loss: 0.3139 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.9249\n","Epoch 84/100\n","\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8636 - auc: 0.9573 - loss: 0.2398\n","Epoch 84: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8634 - auc: 0.9570 - loss: 0.2404 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.9215\n","Epoch 85/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8539 - auc: 0.9553 - loss: 0.2455\n","Epoch 85: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8538 - auc: 0.9539 - loss: 0.2478 - val_acc: 0.6280 - val_auc: 0.2000 - val_loss: 0.9210\n","Epoch 86/100\n","\u001b[1m297/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8612 - auc: 0.9443 - loss: 0.2571\n","Epoch 86: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8608 - auc: 0.9441 - loss: 0.2577 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.9361\n","Epoch 87/100\n","\u001b[1m300/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8370 - auc: 0.9327 - loss: 0.2866\n","Epoch 87: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8376 - auc: 0.9330 - loss: 0.2859 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.9389\n","Epoch 88/100\n","\u001b[1m298/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8557 - auc: 0.9472 - loss: 0.2599\n","Epoch 88: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8560 - auc: 0.9468 - loss: 0.2603 - val_acc: 0.6280 - val_auc: 0.3077 - val_loss: 0.9401\n","Epoch 89/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9054 - auc: 0.9446 - loss: 0.2655\n","Epoch 89: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9055 - auc: 0.9445 - loss: 0.2656 - val_acc: 0.6280 - val_auc: 0.2000 - val_loss: 0.9438\n","Epoch 90/100\n","\u001b[1m302/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9319 - auc: 0.9450 - loss: 0.2588\n","Epoch 90: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9318 - auc: 0.9448 - loss: 0.2590 - val_acc: 0.6280 - val_auc: 0.2000 - val_loss: 0.9446\n","Epoch 91/100\n","\u001b[1m303/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9229 - auc: 0.9541 - loss: 0.2641\n","Epoch 91: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9230 - auc: 0.9538 - loss: 0.2641 - val_acc: 0.6280 - val_auc: 0.2000 - val_loss: 0.9483\n","Epoch 92/100\n","\u001b[1m296/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9376 - auc: 0.9294 - loss: 0.2804\n","Epoch 92: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9377 - auc: 0.9298 - loss: 0.2798 - val_acc: 0.6280 - val_auc: 0.2000 - val_loss: 0.9541\n","Epoch 93/100\n","\u001b[1m301/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9063 - auc: 0.9142 - loss: 0.2993\n","Epoch 93: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9072 - auc: 0.9150 - loss: 0.2982 - val_acc: 0.6280 - val_auc: 0.2000 - val_loss: 0.9536\n","Epoch 94/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9320 - auc: 0.9470 - loss: 0.2642\n","Epoch 94: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9315 - auc: 0.9467 - loss: 0.2644 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.9534\n","Epoch 95/100\n","\u001b[1m295/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9435 - auc: 0.9442 - loss: 0.2592\n","Epoch 95: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9434 - auc: 0.9439 - loss: 0.2596 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.9606\n","Epoch 96/100\n","\u001b[1m293/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9373 - auc: 0.9463 - loss: 0.2551\n","Epoch 96: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9375 - auc: 0.9459 - loss: 0.2558 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.9631\n","Epoch 97/100\n","\u001b[1m291/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9433 - auc: 0.9420 - loss: 0.2578\n","Epoch 97: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9433 - auc: 0.9420 - loss: 0.2580 - val_acc: 0.6280 - val_auc: 0.2000 - val_loss: 0.9686\n","Epoch 98/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9319 - auc: 0.9414 - loss: 0.2755\n","Epoch 98: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9322 - auc: 0.9412 - loss: 0.2750 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.9669\n","Epoch 99/100\n","\u001b[1m291/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9378 - auc: 0.9333 - loss: 0.2756\n","Epoch 99: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9377 - auc: 0.9338 - loss: 0.2749 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.9654\n","Epoch 100/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9443 - auc: 0.9464 - loss: 0.2539\n","Epoch 100: val_loss did not improve from 0.61376\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9441 - auc: 0.9460 - loss: 0.2546 - val_acc: 0.6280 - val_auc: 0.0923 - val_loss: 0.9736\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 8 | VAL  | AUC=1.0000 | ACC=0.6280 | n=207\n","Fold 8 | TEST | AUC=1.0000 | ACC=1.0000 | n=53\n","\n","--- Fold 9/14 ---\n"," train | ids:   36 | files:  867 | pos:  309 | neg:  558\n","   val | ids:    4 | files:  234 | pos:   77 | neg:  157\n","  test | ids:    3 | files:   89 | pos:   19 | neg:   70\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m268/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4581 - auc: 0.2796 - loss: 0.7030\n","Epoch 1: val_loss improved from inf to 0.59331, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - acc: 0.4658 - auc: 0.2836 - loss: 0.7021 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5933\n","Epoch 2/100\n","\u001b[1m271/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6650 - auc: 0.4911 - loss: 0.6550\n","Epoch 2: val_loss improved from 0.59331 to 0.56974, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6638 - auc: 0.4959 - loss: 0.6546 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5697\n","Epoch 3/100\n","\u001b[1m274/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6643 - auc: 0.6402 - loss: 0.6189\n","Epoch 3: val_loss improved from 0.56974 to 0.56083, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6633 - auc: 0.6409 - loss: 0.6191 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5608\n","Epoch 4/100\n","\u001b[1m278/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7253 - auc: 0.6386 - loss: 0.6077\n","Epoch 4: val_loss improved from 0.56083 to 0.55778, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7268 - auc: 0.6389 - loss: 0.6077 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5578\n","Epoch 5/100\n","\u001b[1m283/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8448 - auc: 0.6505 - loss: 0.5899\n","Epoch 5: val_loss improved from 0.55778 to 0.55635, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8447 - auc: 0.6503 - loss: 0.5900 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5563\n","Epoch 6/100\n","\u001b[1m276/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8370 - auc: 0.6308 - loss: 0.5869\n","Epoch 6: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8372 - auc: 0.6314 - loss: 0.5868 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5576\n","Epoch 7/100\n","\u001b[1m279/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8703 - auc: 0.6819 - loss: 0.5476\n","Epoch 7: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8693 - auc: 0.6804 - loss: 0.5485 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5602\n","Epoch 8/100\n","\u001b[1m281/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8389 - auc: 0.6220 - loss: 0.5733\n","Epoch 8: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8390 - auc: 0.6227 - loss: 0.5729 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5629\n","Epoch 9/100\n","\u001b[1m270/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8502 - auc: 0.6513 - loss: 0.5547\n","Epoch 9: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8497 - auc: 0.6504 - loss: 0.5547 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5661\n","Epoch 10/100\n","\u001b[1m277/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8407 - auc: 0.6251 - loss: 0.5513\n","Epoch 10: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8408 - auc: 0.6259 - loss: 0.5510 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5696\n","Epoch 11/100\n","\u001b[1m265/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8354 - auc: 0.6112 - loss: 0.5455\n","Epoch 11: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8363 - auc: 0.6141 - loss: 0.5445 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5729\n","Epoch 12/100\n","\u001b[1m273/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8315 - auc: 0.6285 - loss: 0.5451\n","Epoch 12: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8321 - auc: 0.6293 - loss: 0.5442 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5772\n","Epoch 13/100\n","\u001b[1m274/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8569 - auc: 0.6413 - loss: 0.5075\n","Epoch 13: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8561 - auc: 0.6412 - loss: 0.5084 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.5819\n","Epoch 14/100\n","\u001b[1m277/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8456 - auc: 0.6210 - loss: 0.5161\n","Epoch 14: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8454 - auc: 0.6218 - loss: 0.5160 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5865\n","Epoch 15/100\n","\u001b[1m278/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8514 - auc: 0.6292 - loss: 0.4999\n","Epoch 15: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8510 - auc: 0.6296 - loss: 0.5002 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5907\n","Epoch 16/100\n","\u001b[1m279/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8398 - auc: 0.6383 - loss: 0.5067\n","Epoch 16: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8399 - auc: 0.6383 - loss: 0.5064 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5938\n","Epoch 17/100\n","\u001b[1m286/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8533 - auc: 0.6653 - loss: 0.4867\n","Epoch 17: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8532 - auc: 0.6649 - loss: 0.4868 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5972\n","Epoch 18/100\n","\u001b[1m282/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8329 - auc: 0.6261 - loss: 0.5033\n","Epoch 18: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8332 - auc: 0.6266 - loss: 0.5029 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5998\n","Epoch 19/100\n","\u001b[1m278/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8399 - auc: 0.6318 - loss: 0.4927\n","Epoch 19: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8400 - auc: 0.6319 - loss: 0.4925 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6026\n","Epoch 20/100\n","\u001b[1m286/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8419 - auc: 0.6357 - loss: 0.4880\n","Epoch 20: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8419 - auc: 0.6358 - loss: 0.4879 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6051\n","Epoch 21/100\n","\u001b[1m282/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8465 - auc: 0.6406 - loss: 0.4716\n","Epoch 21: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8464 - auc: 0.6406 - loss: 0.4718 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6069\n","Epoch 22/100\n","\u001b[1m282/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8540 - auc: 0.6531 - loss: 0.4662\n","Epoch 22: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8537 - auc: 0.6526 - loss: 0.4664 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6092\n","Epoch 23/100\n","\u001b[1m280/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8419 - auc: 0.6548 - loss: 0.4725\n","Epoch 23: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8420 - auc: 0.6541 - loss: 0.4724 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6107\n","Epoch 24/100\n","\u001b[1m272/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8603 - auc: 0.6654 - loss: 0.4497\n","Epoch 24: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8592 - auc: 0.6635 - loss: 0.4509 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6126\n","Epoch 25/100\n","\u001b[1m277/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8270 - auc: 0.6292 - loss: 0.4802\n","Epoch 25: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8277 - auc: 0.6294 - loss: 0.4795 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6138\n","Epoch 26/100\n","\u001b[1m266/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8263 - auc: 0.6198 - loss: 0.4830\n","Epoch 26: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8275 - auc: 0.6207 - loss: 0.4815 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6163\n","Epoch 27/100\n","\u001b[1m284/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8595 - auc: 0.6694 - loss: 0.4395\n","Epoch 27: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8592 - auc: 0.6688 - loss: 0.4399 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6184\n","Epoch 28/100\n","\u001b[1m277/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8544 - auc: 0.6304 - loss: 0.4446\n","Epoch 28: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8540 - auc: 0.6307 - loss: 0.4451 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6203\n","Epoch 29/100\n","\u001b[1m280/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8352 - auc: 0.6054 - loss: 0.4675\n","Epoch 29: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8354 - auc: 0.6063 - loss: 0.4671 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6223\n","Epoch 30/100\n","\u001b[1m283/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8648 - auc: 0.6399 - loss: 0.4278\n","Epoch 30: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8643 - auc: 0.6400 - loss: 0.4282 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6243\n","Epoch 31/100\n","\u001b[1m281/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8432 - auc: 0.6507 - loss: 0.4462\n","Epoch 31: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8432 - auc: 0.6503 - loss: 0.4462 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6250\n","Epoch 32/100\n","\u001b[1m283/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8452 - auc: 0.6420 - loss: 0.4415\n","Epoch 32: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8452 - auc: 0.6419 - loss: 0.4415 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6267\n","Epoch 33/100\n","\u001b[1m278/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8224 - auc: 0.6101 - loss: 0.4663\n","Epoch 33: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8233 - auc: 0.6112 - loss: 0.4653 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6283\n","Epoch 34/100\n","\u001b[1m271/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8403 - auc: 0.6475 - loss: 0.4399\n","Epoch 34: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8405 - auc: 0.6469 - loss: 0.4398 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6296\n","Epoch 35/100\n","\u001b[1m276/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8172 - auc: 0.6210 - loss: 0.4655\n","Epoch 35: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8184 - auc: 0.6216 - loss: 0.4642 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6303\n","Epoch 36/100\n","\u001b[1m273/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8161 - auc: 0.5981 - loss: 0.4679\n","Epoch 36: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8176 - auc: 0.6003 - loss: 0.4660 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6314\n","Epoch 37/100\n","\u001b[1m274/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8410 - auc: 0.6212 - loss: 0.4342\n","Epoch 37: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8412 - auc: 0.6220 - loss: 0.4340 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6323\n","Epoch 38/100\n","\u001b[1m284/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8295 - auc: 0.5826 - loss: 0.4514\n","Epoch 38: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8298 - auc: 0.5839 - loss: 0.4510 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6337\n","Epoch 39/100\n","\u001b[1m267/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8344 - auc: 0.6395 - loss: 0.4323\n","Epoch 39: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8352 - auc: 0.6392 - loss: 0.4317 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6280\n","Epoch 40/100\n","\u001b[1m270/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8304 - auc: 0.6323 - loss: 0.4390\n","Epoch 40: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8313 - auc: 0.6371 - loss: 0.4376 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6192\n","Epoch 41/100\n","\u001b[1m265/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8579 - auc: 0.7498 - loss: 0.4001\n","Epoch 41: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8566 - auc: 0.7492 - loss: 0.4015 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6190\n","Epoch 42/100\n","\u001b[1m275/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8272 - auc: 0.7285 - loss: 0.4325\n","Epoch 42: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8280 - auc: 0.7297 - loss: 0.4315 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6198\n","Epoch 43/100\n","\u001b[1m279/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8522 - auc: 0.7708 - loss: 0.3974\n","Epoch 43: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8519 - auc: 0.7701 - loss: 0.3978 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6210\n","Epoch 44/100\n","\u001b[1m275/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8304 - auc: 0.7523 - loss: 0.4238\n","Epoch 44: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8311 - auc: 0.7541 - loss: 0.4230 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6228\n","Epoch 45/100\n","\u001b[1m286/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8613 - auc: 0.8150 - loss: 0.3802\n","Epoch 45: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8610 - auc: 0.8147 - loss: 0.3806 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6250\n","Epoch 46/100\n","\u001b[1m280/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8344 - auc: 0.8591 - loss: 0.4165\n","Epoch 46: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8346 - auc: 0.8599 - loss: 0.4160 - val_acc: 0.6709 - val_auc: 0.7134 - val_loss: 0.6269\n","Epoch 47/100\n","\u001b[1m286/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8683 - auc: 0.8899 - loss: 0.3701\n","Epoch 47: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8680 - auc: 0.8897 - loss: 0.3705 - val_acc: 0.6709 - val_auc: 0.7134 - val_loss: 0.6292\n","Epoch 48/100\n","\u001b[1m280/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8520 - auc: 0.9012 - loss: 0.3885\n","Epoch 48: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8518 - auc: 0.9010 - loss: 0.3888 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6333\n","Epoch 49/100\n","\u001b[1m280/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8447 - auc: 0.8871 - loss: 0.3984\n","Epoch 49: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8446 - auc: 0.8874 - loss: 0.3984 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6356\n","Epoch 50/100\n","\u001b[1m280/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8402 - auc: 0.8856 - loss: 0.3934\n","Epoch 50: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8403 - auc: 0.8862 - loss: 0.3934 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6384\n","Epoch 51/100\n","\u001b[1m278/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8281 - auc: 0.8921 - loss: 0.4125\n","Epoch 51: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8287 - auc: 0.8926 - loss: 0.4116 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6421\n","Epoch 52/100\n","\u001b[1m264/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8250 - auc: 0.8969 - loss: 0.4111\n","Epoch 52: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8264 - auc: 0.8983 - loss: 0.4093 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6458\n","Epoch 53/100\n","\u001b[1m284/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8382 - auc: 0.8986 - loss: 0.3979\n","Epoch 53: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8383 - auc: 0.8989 - loss: 0.3976 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6481\n","Epoch 54/100\n","\u001b[1m275/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8281 - auc: 0.9300 - loss: 0.3979\n","Epoch 54: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8288 - auc: 0.9300 - loss: 0.3973 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6517\n","Epoch 55/100\n","\u001b[1m282/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8512 - auc: 0.9385 - loss: 0.3700\n","Epoch 55: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8510 - auc: 0.9387 - loss: 0.3703 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6549\n","Epoch 56/100\n","\u001b[1m270/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8398 - auc: 0.9442 - loss: 0.3826\n","Epoch 56: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8401 - auc: 0.9447 - loss: 0.3822 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6578\n","Epoch 57/100\n","\u001b[1m273/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8425 - auc: 0.9468 - loss: 0.3756\n","Epoch 57: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8425 - auc: 0.9469 - loss: 0.3757 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6619\n","Epoch 58/100\n","\u001b[1m277/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8382 - auc: 0.9319 - loss: 0.3814\n","Epoch 58: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8383 - auc: 0.9327 - loss: 0.3811 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6652\n","Epoch 59/100\n","\u001b[1m284/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8245 - auc: 0.9555 - loss: 0.3888\n","Epoch 59: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8249 - auc: 0.9554 - loss: 0.3884 - val_acc: 0.6709 - val_auc: 0.3376 - val_loss: 0.6692\n","Epoch 60/100\n","\u001b[1m285/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8251 - auc: 0.9471 - loss: 0.3900\n","Epoch 60: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8254 - auc: 0.9471 - loss: 0.3896 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.6719\n","Epoch 61/100\n","\u001b[1m286/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8337 - auc: 0.9458 - loss: 0.3786\n","Epoch 61: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8338 - auc: 0.9459 - loss: 0.3784 - val_acc: 0.6709 - val_auc: 0.3376 - val_loss: 0.6761\n","Epoch 62/100\n","\u001b[1m286/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8339 - auc: 0.9647 - loss: 0.3725\n","Epoch 62: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8341 - auc: 0.9645 - loss: 0.3724 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.6806\n","Epoch 63/100\n","\u001b[1m286/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8355 - auc: 0.9343 - loss: 0.3733\n","Epoch 63: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8356 - auc: 0.9345 - loss: 0.3732 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.6831\n","Epoch 64/100\n","\u001b[1m284/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8490 - auc: 0.9568 - loss: 0.3488\n","Epoch 64: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8489 - auc: 0.9567 - loss: 0.3490 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.6874\n","Epoch 65/100\n","\u001b[1m283/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8333 - auc: 0.9347 - loss: 0.3803\n","Epoch 65: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8336 - auc: 0.9351 - loss: 0.3798 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.6915\n","Epoch 66/100\n","\u001b[1m279/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8378 - auc: 0.9587 - loss: 0.3565\n","Epoch 66: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8380 - auc: 0.9584 - loss: 0.3565 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.6957\n","Epoch 67/100\n","\u001b[1m285/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8449 - auc: 0.9492 - loss: 0.3557\n","Epoch 67: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8449 - auc: 0.9493 - loss: 0.3557 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.6995\n","Epoch 68/100\n","\u001b[1m285/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8267 - auc: 0.9408 - loss: 0.3695\n","Epoch 68: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8270 - auc: 0.9410 - loss: 0.3692 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7033\n","Epoch 69/100\n","\u001b[1m278/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8637 - auc: 0.9573 - loss: 0.3273\n","Epoch 69: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8630 - auc: 0.9571 - loss: 0.3281 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7077\n","Epoch 70/100\n","\u001b[1m271/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8312 - auc: 0.9514 - loss: 0.3592\n","Epoch 70: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8319 - auc: 0.9513 - loss: 0.3584 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7116\n","Epoch 71/100\n","\u001b[1m267/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8461 - auc: 0.9266 - loss: 0.3516\n","Epoch 71: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8460 - auc: 0.9283 - loss: 0.3510 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7147\n","Epoch 72/100\n","\u001b[1m276/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8387 - auc: 0.9458 - loss: 0.3480\n","Epoch 72: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8389 - auc: 0.9461 - loss: 0.3477 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7203\n","Epoch 73/100\n","\u001b[1m278/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8702 - auc: 0.9601 - loss: 0.3129\n","Epoch 73: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8692 - auc: 0.9595 - loss: 0.3139 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7244\n","Epoch 74/100\n","\u001b[1m274/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8413 - auc: 0.9484 - loss: 0.3386\n","Epoch 74: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8413 - auc: 0.9484 - loss: 0.3386 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7298\n","Epoch 75/100\n","\u001b[1m283/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8355 - auc: 0.9466 - loss: 0.3415\n","Epoch 75: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8356 - auc: 0.9467 - loss: 0.3414 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7337\n","Epoch 76/100\n","\u001b[1m282/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8490 - auc: 0.9533 - loss: 0.3236\n","Epoch 76: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8488 - auc: 0.9532 - loss: 0.3239 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7392\n","Epoch 77/100\n","\u001b[1m284/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8445 - auc: 0.9512 - loss: 0.3280\n","Epoch 77: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8445 - auc: 0.9511 - loss: 0.3280 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7424\n","Epoch 78/100\n","\u001b[1m284/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8551 - auc: 0.9489 - loss: 0.3172\n","Epoch 78: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8548 - auc: 0.9489 - loss: 0.3175 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7473\n","Epoch 79/100\n","\u001b[1m282/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8453 - auc: 0.9494 - loss: 0.3248\n","Epoch 79: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8452 - auc: 0.9494 - loss: 0.3248 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7525\n","Epoch 80/100\n","\u001b[1m278/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8478 - auc: 0.9488 - loss: 0.3215\n","Epoch 80: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8476 - auc: 0.9488 - loss: 0.3217 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7572\n","Epoch 81/100\n","\u001b[1m287/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8526 - auc: 0.9497 - loss: 0.3129\n","Epoch 81: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8525 - auc: 0.9497 - loss: 0.3130 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7619\n","Epoch 82/100\n","\u001b[1m283/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8301 - auc: 0.9434 - loss: 0.3346\n","Epoch 82: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8304 - auc: 0.9436 - loss: 0.3342 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7673\n","Epoch 83/100\n","\u001b[1m277/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8541 - auc: 0.9569 - loss: 0.3040\n","Epoch 83: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8536 - auc: 0.9565 - loss: 0.3046 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7722\n","Epoch 84/100\n","\u001b[1m279/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8317 - auc: 0.9463 - loss: 0.3349\n","Epoch 84: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8322 - auc: 0.9465 - loss: 0.3342 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7768\n","Epoch 85/100\n","\u001b[1m282/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8444 - auc: 0.9324 - loss: 0.3252\n","Epoch 85: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8444 - auc: 0.9328 - loss: 0.3249 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7805\n","Epoch 86/100\n","\u001b[1m266/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8216 - auc: 0.9436 - loss: 0.3348\n","Epoch 86: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8235 - auc: 0.9439 - loss: 0.3331 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7874\n","Epoch 87/100\n","\u001b[1m281/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8699 - auc: 0.9472 - loss: 0.2956\n","Epoch 87: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8691 - auc: 0.9474 - loss: 0.2961 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7891\n","Epoch 88/100\n","\u001b[1m275/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8329 - auc: 0.9531 - loss: 0.3114\n","Epoch 88: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8334 - auc: 0.9529 - loss: 0.3114 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.7946\n","Epoch 89/100\n","\u001b[1m281/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8509 - auc: 0.9535 - loss: 0.2889\n","Epoch 89: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8506 - auc: 0.9534 - loss: 0.2896 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8012\n","Epoch 90/100\n","\u001b[1m283/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8537 - auc: 0.9510 - loss: 0.2990\n","Epoch 90: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8535 - auc: 0.9510 - loss: 0.2991 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8061\n","Epoch 91/100\n","\u001b[1m283/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8364 - auc: 0.9550 - loss: 0.3026\n","Epoch 91: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8366 - auc: 0.9548 - loss: 0.3026 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8117\n","Epoch 92/100\n","\u001b[1m282/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8577 - auc: 0.9388 - loss: 0.2955\n","Epoch 92: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8573 - auc: 0.9390 - loss: 0.2957 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8154\n","Epoch 93/100\n","\u001b[1m283/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8403 - auc: 0.9636 - loss: 0.2935\n","Epoch 93: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8403 - auc: 0.9632 - loss: 0.2938 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8204\n","Epoch 94/100\n","\u001b[1m285/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8610 - auc: 0.9519 - loss: 0.2867\n","Epoch 94: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8606 - auc: 0.9518 - loss: 0.2870 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8237\n","Epoch 95/100\n","\u001b[1m281/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8562 - auc: 0.9411 - loss: 0.3004\n","Epoch 95: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8559 - auc: 0.9413 - loss: 0.3003 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8274\n","Epoch 96/100\n","\u001b[1m281/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8394 - auc: 0.9496 - loss: 0.3003\n","Epoch 96: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8396 - auc: 0.9496 - loss: 0.3002 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8333\n","Epoch 97/100\n","\u001b[1m279/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8579 - auc: 0.9376 - loss: 0.3165\n","Epoch 97: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8582 - auc: 0.9381 - loss: 0.3157 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8379\n","Epoch 98/100\n","\u001b[1m283/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8471 - auc: 0.9549 - loss: 0.2895\n","Epoch 98: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8474 - auc: 0.9548 - loss: 0.2896 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8430\n","Epoch 99/100\n","\u001b[1m276/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8484 - auc: 0.9458 - loss: 0.2912\n","Epoch 99: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8483 - auc: 0.9459 - loss: 0.2914 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8461\n","Epoch 100/100\n","\u001b[1m279/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9268 - auc: 0.9404 - loss: 0.3155\n","Epoch 100: val_loss did not improve from 0.55635\n","\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9272 - auc: 0.9407 - loss: 0.3147 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.8529\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 9 | VAL  | AUC=1.0000 | ACC=0.6709 | n=234\n","Fold 9 | TEST | AUC=1.0000 | ACC=1.0000 | n=89\n","\n","--- Fold 10/14 ---\n"," train | ids:   36 | files:  935 | pos:  327 | neg:  608\n","   val | ids:    4 | files:  234 | pos:   77 | neg:  157\n","  test | ids:    3 | files:   21 | pos:    1 | neg:   20\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m296/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.7883 - auc: 0.6690 - loss: 0.6552\n","Epoch 1: val_loss improved from inf to 0.63164, saving model to best_tab_only_fold10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - acc: 0.7883 - auc: 0.6685 - loss: 0.6549 - val_acc: 0.6709 - val_auc: 0.8758 - val_loss: 0.6316\n","Epoch 2/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7781 - auc: 0.6502 - loss: 0.6368\n","Epoch 2: val_loss improved from 0.63164 to 0.62002, saving model to best_tab_only_fold10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7783 - auc: 0.6500 - loss: 0.6367 - val_acc: 0.6709 - val_auc: 0.8758 - val_loss: 0.6200\n","Epoch 3/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8062 - auc: 0.6694 - loss: 0.6174\n","Epoch 3: val_loss improved from 0.62002 to 0.61277, saving model to best_tab_only_fold10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8060 - auc: 0.6691 - loss: 0.6175 - val_acc: 0.6709 - val_auc: 0.8758 - val_loss: 0.6128\n","Epoch 4/100\n","\u001b[1m302/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7773 - auc: 0.6544 - loss: 0.6221\n","Epoch 4: val_loss improved from 0.61277 to 0.60728, saving model to best_tab_only_fold10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7777 - auc: 0.6542 - loss: 0.6218 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6073\n","Epoch 5/100\n","\u001b[1m287/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7970 - auc: 0.6817 - loss: 0.6019\n","Epoch 5: val_loss improved from 0.60728 to 0.60287, saving model to best_tab_only_fold10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7964 - auc: 0.6786 - loss: 0.6023 - val_acc: 0.6709 - val_auc: 0.8758 - val_loss: 0.6029\n","Epoch 6/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7497 - auc: 0.6500 - loss: 0.6161\n","Epoch 6: val_loss improved from 0.60287 to 0.59880, saving model to best_tab_only_fold10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7499 - auc: 0.6500 - loss: 0.6160 - val_acc: 0.6709 - val_auc: 0.8758 - val_loss: 0.5988\n","Epoch 7/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7936 - auc: 0.6838 - loss: 0.5888\n","Epoch 7: val_loss improved from 0.59880 to 0.59747, saving model to best_tab_only_fold10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7936 - auc: 0.6834 - loss: 0.5889 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5975\n","Epoch 8/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7570 - auc: 0.6193 - loss: 0.6032\n","Epoch 8: val_loss improved from 0.59747 to 0.59406, saving model to best_tab_only_fold10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7574 - auc: 0.6197 - loss: 0.6030 - val_acc: 0.6709 - val_auc: 0.8758 - val_loss: 0.5941\n","Epoch 9/100\n","\u001b[1m304/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8012 - auc: 0.6506 - loss: 0.5745\n","Epoch 9: val_loss did not improve from 0.59406\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8008 - auc: 0.6504 - loss: 0.5748 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5944\n","Epoch 10/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7970 - auc: 0.6264 - loss: 0.5870\n","Epoch 10: val_loss improved from 0.59406 to 0.59062, saving model to best_tab_only_fold10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7980 - auc: 0.6269 - loss: 0.5867 - val_acc: 0.6709 - val_auc: 0.8758 - val_loss: 0.5906\n","Epoch 11/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8479 - auc: 0.6198 - loss: 0.5787\n","Epoch 11: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8480 - auc: 0.6203 - loss: 0.5786 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5919\n","Epoch 12/100\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8524 - auc: 0.6231 - loss: 0.5702\n","Epoch 12: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8524 - auc: 0.6232 - loss: 0.5702 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5912\n","Epoch 13/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8526 - auc: 0.6419 - loss: 0.5629\n","Epoch 13: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8527 - auc: 0.6420 - loss: 0.5629 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5915\n","Epoch 14/100\n","\u001b[1m288/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8534 - auc: 0.6618 - loss: 0.5547\n","Epoch 14: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8538 - auc: 0.6607 - loss: 0.5547 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5912\n","Epoch 15/100\n","\u001b[1m287/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8601 - auc: 0.6733 - loss: 0.5513\n","Epoch 15: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8598 - auc: 0.6710 - loss: 0.5514 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5915\n","Epoch 16/100\n","\u001b[1m286/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8831 - auc: 0.6912 - loss: 0.5203\n","Epoch 16: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8809 - auc: 0.6876 - loss: 0.5226 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5919\n","Epoch 17/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8629 - auc: 0.6441 - loss: 0.5383\n","Epoch 17: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8628 - auc: 0.6441 - loss: 0.5384 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5923\n","Epoch 18/100\n","\u001b[1m287/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8785 - auc: 0.6965 - loss: 0.5198\n","Epoch 18: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8768 - auc: 0.6926 - loss: 0.5214 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5926\n","Epoch 19/100\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8614 - auc: 0.6699 - loss: 0.5289\n","Epoch 19: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8613 - auc: 0.6698 - loss: 0.5290 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5930\n","Epoch 20/100\n","\u001b[1m292/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8474 - auc: 0.5995 - loss: 0.5415\n","Epoch 20: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8480 - auc: 0.6025 - loss: 0.5409 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5935\n","Epoch 21/100\n","\u001b[1m290/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8589 - auc: 0.6559 - loss: 0.5236\n","Epoch 21: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8587 - auc: 0.6550 - loss: 0.5240 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5936\n","Epoch 22/100\n","\u001b[1m304/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8357 - auc: 0.6246 - loss: 0.5414\n","Epoch 22: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8363 - auc: 0.6249 - loss: 0.5410 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5936\n","Epoch 23/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8488 - auc: 0.6492 - loss: 0.5316\n","Epoch 23: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8488 - auc: 0.6492 - loss: 0.5315 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5947\n","Epoch 24/100\n","\u001b[1m299/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8593 - auc: 0.6576 - loss: 0.5151\n","Epoch 24: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8592 - auc: 0.6570 - loss: 0.5152 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5952\n","Epoch 25/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8467 - auc: 0.6148 - loss: 0.5261\n","Epoch 25: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8468 - auc: 0.6150 - loss: 0.5260 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5957\n","Epoch 26/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8710 - auc: 0.6829 - loss: 0.4924\n","Epoch 26: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8708 - auc: 0.6823 - loss: 0.4927 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5968\n","Epoch 27/100\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8441 - auc: 0.6402 - loss: 0.5149\n","Epoch 27: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8442 - auc: 0.6403 - loss: 0.5149 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5976\n","Epoch 28/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8558 - auc: 0.6283 - loss: 0.5075\n","Epoch 28: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8558 - auc: 0.6286 - loss: 0.5074 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5983\n","Epoch 29/100\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8509 - auc: 0.6244 - loss: 0.5058\n","Epoch 29: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8509 - auc: 0.6245 - loss: 0.5058 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.5994\n","Epoch 30/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8631 - auc: 0.6260 - loss: 0.4906\n","Epoch 30: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8631 - auc: 0.6261 - loss: 0.4907 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6004\n","Epoch 31/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8348 - auc: 0.6006 - loss: 0.5190\n","Epoch 31: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8351 - auc: 0.6012 - loss: 0.5187 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6014\n","Epoch 32/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8552 - auc: 0.6146 - loss: 0.4921\n","Epoch 32: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8552 - auc: 0.6148 - loss: 0.4920 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6026\n","Epoch 33/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8591 - auc: 0.6470 - loss: 0.4870\n","Epoch 33: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8591 - auc: 0.6469 - loss: 0.4870 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6038\n","Epoch 34/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8551 - auc: 0.6289 - loss: 0.4787\n","Epoch 34: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8551 - auc: 0.6290 - loss: 0.4787 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6049\n","Epoch 35/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8532 - auc: 0.6734 - loss: 0.4758\n","Epoch 35: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8532 - auc: 0.6729 - loss: 0.4758 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6059\n","Epoch 36/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8626 - auc: 0.6571 - loss: 0.4643\n","Epoch 36: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8625 - auc: 0.6570 - loss: 0.4644 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6074\n","Epoch 37/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8585 - auc: 0.6449 - loss: 0.4673\n","Epoch 37: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8585 - auc: 0.6449 - loss: 0.4673 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6087\n","Epoch 38/100\n","\u001b[1m298/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8553 - auc: 0.6604 - loss: 0.4639\n","Epoch 38: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8554 - auc: 0.6599 - loss: 0.4640 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6100\n","Epoch 39/100\n","\u001b[1m303/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8616 - auc: 0.6534 - loss: 0.4541\n","Epoch 39: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8614 - auc: 0.6532 - loss: 0.4545 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6115\n","Epoch 40/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8544 - auc: 0.6406 - loss: 0.4634\n","Epoch 40: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8544 - auc: 0.6406 - loss: 0.4633 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6130\n","Epoch 41/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8504 - auc: 0.6091 - loss: 0.4694\n","Epoch 41: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8505 - auc: 0.6096 - loss: 0.4692 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6146\n","Epoch 42/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8679 - auc: 0.6731 - loss: 0.4398\n","Epoch 42: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8677 - auc: 0.6728 - loss: 0.4399 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6161\n","Epoch 43/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8451 - auc: 0.6005 - loss: 0.4672\n","Epoch 43: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8453 - auc: 0.6012 - loss: 0.4670 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6177\n","Epoch 44/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8572 - auc: 0.6203 - loss: 0.4529\n","Epoch 44: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8571 - auc: 0.6207 - loss: 0.4528 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6194\n","Epoch 45/100\n","\u001b[1m302/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8419 - auc: 0.6455 - loss: 0.4557\n","Epoch 45: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8424 - auc: 0.6454 - loss: 0.4553 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6211\n","Epoch 46/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8571 - auc: 0.6011 - loss: 0.4468\n","Epoch 46: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8571 - auc: 0.6020 - loss: 0.4467 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6228\n","Epoch 47/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8615 - auc: 0.6401 - loss: 0.4347\n","Epoch 47: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8613 - auc: 0.6401 - loss: 0.4348 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6247\n","Epoch 48/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8476 - auc: 0.6169 - loss: 0.4485\n","Epoch 48: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8476 - auc: 0.6171 - loss: 0.4484 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6266\n","Epoch 49/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8333 - auc: 0.5997 - loss: 0.4637\n","Epoch 49: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8335 - auc: 0.5999 - loss: 0.4635 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6283\n","Epoch 50/100\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8614 - auc: 0.6449 - loss: 0.4258\n","Epoch 50: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8614 - auc: 0.6449 - loss: 0.4258 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6303\n","Epoch 51/100\n","\u001b[1m300/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8621 - auc: 0.6240 - loss: 0.4295\n","Epoch 51: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8618 - auc: 0.6248 - loss: 0.4296 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6323\n","Epoch 52/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8605 - auc: 0.6759 - loss: 0.4123\n","Epoch 52: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8605 - auc: 0.6755 - loss: 0.4125 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6343\n","Epoch 53/100\n","\u001b[1m303/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8718 - auc: 0.6576 - loss: 0.4075\n","Epoch 53: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8712 - auc: 0.6572 - loss: 0.4080 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6362\n","Epoch 54/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8499 - auc: 0.6260 - loss: 0.4294\n","Epoch 54: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8500 - auc: 0.6261 - loss: 0.4293 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6384\n","Epoch 55/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8443 - auc: 0.5759 - loss: 0.4405\n","Epoch 55: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8444 - auc: 0.5765 - loss: 0.4403 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6407\n","Epoch 56/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8577 - auc: 0.6410 - loss: 0.4157\n","Epoch 56: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8577 - auc: 0.6411 - loss: 0.4157 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6429\n","Epoch 57/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8669 - auc: 0.6686 - loss: 0.4001\n","Epoch 57: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8666 - auc: 0.6681 - loss: 0.4004 - val_acc: 0.6709 - val_auc: 0.7516 - val_loss: 0.6450\n","Epoch 58/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8672 - auc: 0.6918 - loss: 0.3936\n","Epoch 58: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8671 - auc: 0.6916 - loss: 0.3937 - val_acc: 0.6709 - val_auc: 0.6624 - val_loss: 0.6474\n","Epoch 59/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8491 - auc: 0.6667 - loss: 0.4147\n","Epoch 59: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8491 - auc: 0.6667 - loss: 0.4147 - val_acc: 0.6709 - val_auc: 0.6624 - val_loss: 0.6500\n","Epoch 60/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8417 - auc: 0.6534 - loss: 0.4242\n","Epoch 60: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8418 - auc: 0.6538 - loss: 0.4240 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6524\n","Epoch 61/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8701 - auc: 0.7382 - loss: 0.3797\n","Epoch 61: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8699 - auc: 0.7375 - loss: 0.3801 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6544\n","Epoch 62/100\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8413 - auc: 0.7615 - loss: 0.4201\n","Epoch 62: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8413 - auc: 0.7616 - loss: 0.4200 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6570\n","Epoch 63/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8539 - auc: 0.7938 - loss: 0.4038\n","Epoch 63: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8539 - auc: 0.7940 - loss: 0.4037 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6597\n","Epoch 64/100\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8451 - auc: 0.8189 - loss: 0.4069\n","Epoch 64: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8452 - auc: 0.8189 - loss: 0.4069 - val_acc: 0.6709 - val_auc: 0.5732 - val_loss: 0.6624\n","Epoch 65/100\n","\u001b[1m302/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8859 - auc: 0.8438 - loss: 0.3582\n","Epoch 65: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8849 - auc: 0.8434 - loss: 0.3594 - val_acc: 0.6709 - val_auc: 0.2866 - val_loss: 0.6641\n","Epoch 66/100\n","\u001b[1m302/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8562 - auc: 0.8518 - loss: 0.3922\n","Epoch 66: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8562 - auc: 0.8521 - loss: 0.3921 - val_acc: 0.6709 - val_auc: 0.2866 - val_loss: 0.6671\n","Epoch 67/100\n","\u001b[1m299/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8559 - auc: 0.8786 - loss: 0.3808\n","Epoch 67: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8559 - auc: 0.8791 - loss: 0.3810 - val_acc: 0.6709 - val_auc: 0.2866 - val_loss: 0.6699\n","Epoch 68/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8557 - auc: 0.8902 - loss: 0.3853\n","Epoch 68: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8557 - auc: 0.8905 - loss: 0.3853 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.6729\n","Epoch 69/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8448 - auc: 0.9139 - loss: 0.3962\n","Epoch 69: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8449 - auc: 0.9140 - loss: 0.3960 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.6756\n","Epoch 70/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8469 - auc: 0.9333 - loss: 0.3943\n","Epoch 70: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8470 - auc: 0.9333 - loss: 0.3942 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.6786\n","Epoch 71/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8711 - auc: 0.9356 - loss: 0.3598\n","Epoch 71: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8710 - auc: 0.9356 - loss: 0.3599 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.6815\n","Epoch 72/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8482 - auc: 0.9294 - loss: 0.3911\n","Epoch 72: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8483 - auc: 0.9294 - loss: 0.3909 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.6842\n","Epoch 73/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8434 - auc: 0.9056 - loss: 0.3880\n","Epoch 73: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8435 - auc: 0.9057 - loss: 0.3879 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.6873\n","Epoch 74/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8403 - auc: 0.9116 - loss: 0.3913\n","Epoch 74: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8406 - auc: 0.9121 - loss: 0.3908 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.6902\n","Epoch 75/100\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8551 - auc: 0.9292 - loss: 0.3744\n","Epoch 75: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8551 - auc: 0.9293 - loss: 0.3744 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.6932\n","Epoch 76/100\n","\u001b[1m304/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8519 - auc: 0.9253 - loss: 0.3778\n","Epoch 76: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8520 - auc: 0.9256 - loss: 0.3775 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.6961\n","Epoch 77/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8649 - auc: 0.9375 - loss: 0.3488\n","Epoch 77: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8648 - auc: 0.9375 - loss: 0.3489 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.6991\n","Epoch 78/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8380 - auc: 0.9261 - loss: 0.3882\n","Epoch 78: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8383 - auc: 0.9263 - loss: 0.3877 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7021\n","Epoch 79/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8400 - auc: 0.9227 - loss: 0.3808\n","Epoch 79: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8402 - auc: 0.9229 - loss: 0.3805 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7055\n","Epoch 80/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8562 - auc: 0.9461 - loss: 0.3528\n","Epoch 80: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8562 - auc: 0.9458 - loss: 0.3530 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7086\n","Epoch 81/100\n","\u001b[1m303/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8587 - auc: 0.9387 - loss: 0.3524\n","Epoch 81: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8587 - auc: 0.9386 - loss: 0.3525 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7118\n","Epoch 82/100\n","\u001b[1m302/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8493 - auc: 0.9272 - loss: 0.3636\n","Epoch 82: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8496 - auc: 0.9274 - loss: 0.3632 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7150\n","Epoch 83/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8688 - auc: 0.9349 - loss: 0.3426\n","Epoch 83: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8685 - auc: 0.9349 - loss: 0.3428 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7176\n","Epoch 84/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8715 - auc: 0.9288 - loss: 0.3332\n","Epoch 84: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8713 - auc: 0.9289 - loss: 0.3335 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7207\n","Epoch 85/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8499 - auc: 0.9392 - loss: 0.3556\n","Epoch 85: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8500 - auc: 0.9392 - loss: 0.3556 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7241\n","Epoch 86/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8647 - auc: 0.9521 - loss: 0.3375\n","Epoch 86: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8646 - auc: 0.9520 - loss: 0.3375 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7275\n","Epoch 87/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8591 - auc: 0.9377 - loss: 0.3428\n","Epoch 87: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8590 - auc: 0.9377 - loss: 0.3429 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7309\n","Epoch 88/100\n","\u001b[1m289/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8697 - auc: 0.9413 - loss: 0.3301\n","Epoch 88: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8687 - auc: 0.9411 - loss: 0.3311 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7337\n","Epoch 89/100\n","\u001b[1m304/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8521 - auc: 0.9433 - loss: 0.3470\n","Epoch 89: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8522 - auc: 0.9432 - loss: 0.3468 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7374\n","Epoch 90/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8512 - auc: 0.9388 - loss: 0.3420\n","Epoch 90: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8513 - auc: 0.9388 - loss: 0.3420 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7410\n","Epoch 91/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8414 - auc: 0.9395 - loss: 0.3540\n","Epoch 91: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8415 - auc: 0.9395 - loss: 0.3539 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7445\n","Epoch 92/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8695 - auc: 0.9343 - loss: 0.3234\n","Epoch 92: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8692 - auc: 0.9344 - loss: 0.3236 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7476\n","Epoch 93/100\n","\u001b[1m304/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8579 - auc: 0.9324 - loss: 0.3367\n","Epoch 93: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8578 - auc: 0.9324 - loss: 0.3367 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7511\n","Epoch 94/100\n","\u001b[1m300/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8696 - auc: 0.9315 - loss: 0.3254\n","Epoch 94: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8689 - auc: 0.9320 - loss: 0.3258 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7541\n","Epoch 95/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8175 - auc: 0.9291 - loss: 0.3685\n","Epoch 95: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8185 - auc: 0.9294 - loss: 0.3675 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7585\n","Epoch 96/100\n","\u001b[1m294/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8594 - auc: 0.9350 - loss: 0.3304\n","Epoch 96: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8591 - auc: 0.9354 - loss: 0.3305 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7614\n","Epoch 97/100\n","\u001b[1m287/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8585 - auc: 0.9372 - loss: 0.3267\n","Epoch 97: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8581 - auc: 0.9371 - loss: 0.3270 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7648\n","Epoch 98/100\n","\u001b[1m304/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8689 - auc: 0.9393 - loss: 0.3143\n","Epoch 98: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8685 - auc: 0.9394 - loss: 0.3146 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7681\n","Epoch 99/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8456 - auc: 0.9304 - loss: 0.3382\n","Epoch 99: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8458 - auc: 0.9305 - loss: 0.3379 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7717\n","Epoch 100/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8602 - auc: 0.9470 - loss: 0.3174\n","Epoch 100: val_loss did not improve from 0.59062\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8602 - auc: 0.9470 - loss: 0.3174 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7755\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 10 | VAL  | AUC=0.7516 | ACC=0.6709 | n=234\n","Fold 10 | TEST | AUC=0.8500 | ACC=0.9524 | n=21\n","\n","--- Fold 11/14 ---\n"," train | ids:   36 | files:  903 | pos:  290 | neg:  613\n","   val | ids:    4 | files:  202 | pos:   77 | neg:  125\n","  test | ids:    3 | files:   85 | pos:   38 | neg:   47\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m279/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8329 - auc: 0.7038 - loss: 0.5767\n","Epoch 1: val_loss improved from inf to 0.63047, saving model to best_tab_only_fold11.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - acc: 0.8315 - auc: 0.7020 - loss: 0.5767 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6305\n","Epoch 2/100\n","\u001b[1m282/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8244 - auc: 0.6736 - loss: 0.5538\n","Epoch 2: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8244 - auc: 0.6750 - loss: 0.5539 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6337\n","Epoch 3/100\n","\u001b[1m279/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8894 - auc: 0.6946 - loss: 0.5470\n","Epoch 3: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8896 - auc: 0.6952 - loss: 0.5467 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6395\n","Epoch 4/100\n","\u001b[1m279/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8879 - auc: 0.6744 - loss: 0.5396\n","Epoch 4: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8881 - auc: 0.6761 - loss: 0.5396 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6452\n","Epoch 5/100\n","\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8933 - auc: 0.7567 - loss: 0.5108\n","Epoch 5: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8928 - auc: 0.7556 - loss: 0.5113 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6506\n","Epoch 6/100\n","\u001b[1m296/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8932 - auc: 0.7064 - loss: 0.5207\n","Epoch 6: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8932 - auc: 0.7063 - loss: 0.5209 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6542\n","Epoch 7/100\n","\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8798 - auc: 0.6732 - loss: 0.5483\n","Epoch 7: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8804 - auc: 0.6746 - loss: 0.5472 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6587\n","Epoch 8/100\n","\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8935 - auc: 0.7164 - loss: 0.5279\n","Epoch 8: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8934 - auc: 0.7153 - loss: 0.5277 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6626\n","Epoch 9/100\n","\u001b[1m280/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8943 - auc: 0.7045 - loss: 0.5120\n","Epoch 9: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8941 - auc: 0.7040 - loss: 0.5127 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6664\n","Epoch 10/100\n","\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8936 - auc: 0.6765 - loss: 0.5111\n","Epoch 10: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8935 - auc: 0.6778 - loss: 0.5112 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6700\n","Epoch 11/100\n","\u001b[1m282/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9092 - auc: 0.7174 - loss: 0.4896\n","Epoch 11: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9080 - auc: 0.7162 - loss: 0.4909 - val_acc: 0.6188 - val_auc: 0.7200 - val_loss: 0.6726\n","Epoch 12/100\n","\u001b[1m280/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8854 - auc: 0.6801 - loss: 0.5113\n","Epoch 12: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8858 - auc: 0.6811 - loss: 0.5111 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6752\n","Epoch 13/100\n","\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8673 - auc: 0.6193 - loss: 0.5384\n","Epoch 13: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8686 - auc: 0.6239 - loss: 0.5364 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6788\n","Epoch 14/100\n","\u001b[1m279/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8958 - auc: 0.7055 - loss: 0.4949\n","Epoch 14: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8955 - auc: 0.7050 - loss: 0.4952 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6822\n","Epoch 15/100\n","\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8932 - auc: 0.7046 - loss: 0.4957\n","Epoch 15: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8931 - auc: 0.7044 - loss: 0.4956 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6857\n","Epoch 16/100\n","\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8964 - auc: 0.7124 - loss: 0.4853\n","Epoch 16: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8962 - auc: 0.7119 - loss: 0.4855 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6887\n","Epoch 17/100\n","\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9007 - auc: 0.7157 - loss: 0.4762\n","Epoch 17: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9002 - auc: 0.7147 - loss: 0.4770 - val_acc: 0.6188 - val_auc: 0.7200 - val_loss: 0.6904\n","Epoch 18/100\n","\u001b[1m280/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8801 - auc: 0.6859 - loss: 0.5073\n","Epoch 18: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8808 - auc: 0.6867 - loss: 0.5059 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6941\n","Epoch 19/100\n","\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9090 - auc: 0.7445 - loss: 0.4508\n","Epoch 19: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9078 - auc: 0.7414 - loss: 0.4529 - val_acc: 0.6188 - val_auc: 0.7200 - val_loss: 0.6968\n","Epoch 20/100\n","\u001b[1m278/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9074 - auc: 0.7263 - loss: 0.4489\n","Epoch 20: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9061 - auc: 0.7241 - loss: 0.4511 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.7007\n","Epoch 21/100\n","\u001b[1m278/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8802 - auc: 0.6842 - loss: 0.4850\n","Epoch 21: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8810 - auc: 0.6852 - loss: 0.4841 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.7047\n","Epoch 22/100\n","\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8905 - auc: 0.7174 - loss: 0.4598\n","Epoch 22: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8904 - auc: 0.7162 - loss: 0.4602 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.7087\n","Epoch 23/100\n","\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8892 - auc: 0.6638 - loss: 0.4725\n","Epoch 23: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8893 - auc: 0.6659 - loss: 0.4719 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.7124\n","Epoch 24/100\n","\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8874 - auc: 0.7141 - loss: 0.4595\n","Epoch 24: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8876 - auc: 0.7133 - loss: 0.4593 - val_acc: 0.6188 - val_auc: 0.7200 - val_loss: 0.7170\n","Epoch 25/100\n","\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9067 - auc: 0.6964 - loss: 0.4259\n","Epoch 25: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9059 - auc: 0.6967 - loss: 0.4273 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.7200\n","Epoch 26/100\n","\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8912 - auc: 0.6942 - loss: 0.4499\n","Epoch 26: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8912 - auc: 0.6943 - loss: 0.4499 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.7231\n","Epoch 27/100\n","\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8960 - auc: 0.7314 - loss: 0.4350\n","Epoch 27: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8957 - auc: 0.7296 - loss: 0.4355 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.7280\n","Epoch 28/100\n","\u001b[1m281/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8992 - auc: 0.7296 - loss: 0.4213\n","Epoch 28: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8987 - auc: 0.7277 - loss: 0.4224 - val_acc: 0.6188 - val_auc: 0.7200 - val_loss: 0.7324\n","Epoch 29/100\n","\u001b[1m278/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9051 - auc: 0.7558 - loss: 0.4015\n","Epoch 29: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9041 - auc: 0.7519 - loss: 0.4037 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.7362\n","Epoch 30/100\n","\u001b[1m277/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8860 - auc: 0.6656 - loss: 0.4395\n","Epoch 30: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8866 - auc: 0.6691 - loss: 0.4384 - val_acc: 0.6188 - val_auc: 0.7200 - val_loss: 0.7411\n","Epoch 31/100\n","\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8940 - auc: 0.6884 - loss: 0.4217\n","Epoch 31: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8939 - auc: 0.6885 - loss: 0.4218 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.7455\n","Epoch 32/100\n","\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8656 - auc: 0.6663 - loss: 0.4603\n","Epoch 32: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8670 - auc: 0.6682 - loss: 0.4582 - val_acc: 0.6188 - val_auc: 0.7200 - val_loss: 0.7507\n","Epoch 33/100\n","\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8792 - auc: 0.6711 - loss: 0.4402\n","Epoch 33: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8798 - auc: 0.6725 - loss: 0.4389 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.7560\n","Epoch 34/100\n","\u001b[1m299/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9064 - auc: 0.7344 - loss: 0.3873\n","Epoch 34: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9062 - auc: 0.7341 - loss: 0.3875 - val_acc: 0.6188 - val_auc: 0.7200 - val_loss: 0.7603\n","Epoch 35/100\n","\u001b[1m298/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8905 - auc: 0.7010 - loss: 0.4041\n","Epoch 35: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8905 - auc: 0.7011 - loss: 0.4041 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.7641\n","Epoch 36/100\n","\u001b[1m276/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9025 - auc: 0.7396 - loss: 0.3835\n","Epoch 36: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9016 - auc: 0.7372 - loss: 0.3847 - val_acc: 0.6188 - val_auc: 0.7200 - val_loss: 0.7699\n","Epoch 37/100\n","\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8831 - auc: 0.6861 - loss: 0.4094\n","Epoch 37: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8835 - auc: 0.6876 - loss: 0.4087 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.7742\n","Epoch 38/100\n","\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9039 - auc: 0.7374 - loss: 0.3634\n","Epoch 38: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9034 - auc: 0.7368 - loss: 0.3643 - val_acc: 0.6188 - val_auc: 0.7200 - val_loss: 0.7952\n","Epoch 39/100\n","\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8960 - auc: 0.7919 - loss: 0.3591\n","Epoch 39: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8957 - auc: 0.7918 - loss: 0.3600 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.8023\n","Epoch 40/100\n","\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8923 - auc: 0.8194 - loss: 0.3657\n","Epoch 40: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8922 - auc: 0.8200 - loss: 0.3658 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.8096\n","Epoch 41/100\n","\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8875 - auc: 0.8707 - loss: 0.3664\n","Epoch 41: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8876 - auc: 0.8714 - loss: 0.3661 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.8153\n","Epoch 42/100\n","\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8783 - auc: 0.9015 - loss: 0.3703\n","Epoch 42: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8790 - auc: 0.9012 - loss: 0.3694 - val_acc: 0.6188 - val_auc: 0.4520 - val_loss: 0.8237\n","Epoch 43/100\n","\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9002 - auc: 0.8938 - loss: 0.3341\n","Epoch 43: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8998 - auc: 0.8939 - loss: 0.3348 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 0.8290\n","Epoch 44/100\n","\u001b[1m283/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8946 - auc: 0.8997 - loss: 0.3374\n","Epoch 44: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8946 - auc: 0.8995 - loss: 0.3374 - val_acc: 0.6188 - val_auc: 0.0920 - val_loss: 0.8376\n","Epoch 45/100\n","\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8875 - auc: 0.9026 - loss: 0.3364\n","Epoch 45: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8877 - auc: 0.9027 - loss: 0.3363 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 0.8453\n","Epoch 46/100\n","\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9113 - auc: 0.9310 - loss: 0.3021\n","Epoch 46: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9102 - auc: 0.9306 - loss: 0.3036 - val_acc: 0.6188 - val_auc: 0.0920 - val_loss: 0.8509\n","Epoch 47/100\n","\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8945 - auc: 0.9540 - loss: 0.3177\n","Epoch 47: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8944 - auc: 0.9543 - loss: 0.3180 - val_acc: 0.6188 - val_auc: 0.0920 - val_loss: 0.8604\n","Epoch 48/100\n","\u001b[1m279/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8868 - auc: 0.9572 - loss: 0.3247\n","Epoch 48: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8871 - auc: 0.9574 - loss: 0.3242 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 0.8674\n","Epoch 49/100\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8993 - auc: 0.9649 - loss: 0.3002\n","Epoch 49: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8993 - auc: 0.9648 - loss: 0.3002 - val_acc: 0.6188 - val_auc: 0.0920 - val_loss: 0.8746\n","Epoch 50/100\n","\u001b[1m279/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8750 - auc: 0.9543 - loss: 0.3270\n","Epoch 50: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8763 - auc: 0.9548 - loss: 0.3252 - val_acc: 0.6188 - val_auc: 0.0920 - val_loss: 0.8868\n","Epoch 51/100\n","\u001b[1m297/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9149 - auc: 0.9771 - loss: 0.2660\n","Epoch 51: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9145 - auc: 0.9768 - loss: 0.2665 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 0.8935\n","Epoch 52/100\n","\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9034 - auc: 0.9511 - loss: 0.2799\n","Epoch 52: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9029 - auc: 0.9517 - loss: 0.2805 - val_acc: 0.6188 - val_auc: 0.0920 - val_loss: 0.9030\n","Epoch 53/100\n","\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8990 - auc: 0.9673 - loss: 0.2764\n","Epoch 53: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8985 - auc: 0.9671 - loss: 0.2771 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 0.9111\n","Epoch 54/100\n","\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8858 - auc: 0.9290 - loss: 0.3000\n","Epoch 54: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8861 - auc: 0.9308 - loss: 0.2992 - val_acc: 0.6188 - val_auc: 0.0920 - val_loss: 0.9214\n","Epoch 55/100\n","\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8946 - auc: 0.9633 - loss: 0.2755\n","Epoch 55: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8945 - auc: 0.9635 - loss: 0.2754 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 0.9312\n","Epoch 56/100\n","\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9062 - auc: 0.9591 - loss: 0.2611\n","Epoch 56: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9058 - auc: 0.9592 - loss: 0.2614 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 0.9407\n","Epoch 57/100\n","\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8982 - auc: 0.9688 - loss: 0.2571\n","Epoch 57: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8979 - auc: 0.9686 - loss: 0.2576 - val_acc: 0.6188 - val_auc: 0.0920 - val_loss: 0.9509\n","Epoch 58/100\n","\u001b[1m282/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9021 - auc: 0.9615 - loss: 0.2524\n","Epoch 58: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9013 - auc: 0.9615 - loss: 0.2532 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 0.9610\n","Epoch 59/100\n","\u001b[1m281/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9051 - auc: 0.9645 - loss: 0.2368\n","Epoch 59: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9042 - auc: 0.9643 - loss: 0.2382 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 0.9729\n","Epoch 60/100\n","\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8749 - auc: 0.9704 - loss: 0.2674\n","Epoch 60: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8755 - auc: 0.9702 - loss: 0.2668 - val_acc: 0.6188 - val_auc: 0.0920 - val_loss: 0.9865\n","Epoch 61/100\n","\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8926 - auc: 0.9569 - loss: 0.2514\n","Epoch 61: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8925 - auc: 0.9571 - loss: 0.2513 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 0.9935\n","Epoch 62/100\n","\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8950 - auc: 0.9437 - loss: 0.2527\n","Epoch 62: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8948 - auc: 0.9444 - loss: 0.2523 - val_acc: 0.6188 - val_auc: 0.0920 - val_loss: 1.0045\n","Epoch 63/100\n","\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8857 - auc: 0.9578 - loss: 0.2508\n","Epoch 63: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8861 - auc: 0.9580 - loss: 0.2503 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 1.0179\n","Epoch 64/100\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8969 - auc: 0.9613 - loss: 0.2321\n","Epoch 64: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8969 - auc: 0.9613 - loss: 0.2321 - val_acc: 0.6188 - val_auc: 0.0920 - val_loss: 1.0265\n","Epoch 65/100\n","\u001b[1m281/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8849 - auc: 0.9682 - loss: 0.2332\n","Epoch 65: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8852 - auc: 0.9678 - loss: 0.2331 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 1.0374\n","Epoch 66/100\n","\u001b[1m278/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8930 - auc: 0.9714 - loss: 0.2220\n","Epoch 66: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8927 - auc: 0.9706 - loss: 0.2227 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 1.0503\n","Epoch 67/100\n","\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8895 - auc: 0.9562 - loss: 0.2326\n","Epoch 67: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8896 - auc: 0.9566 - loss: 0.2321 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 1.0624\n","Epoch 68/100\n","\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9003 - auc: 0.9643 - loss: 0.2126\n","Epoch 68: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8998 - auc: 0.9642 - loss: 0.2130 - val_acc: 0.6188 - val_auc: 0.0920 - val_loss: 1.0716\n","Epoch 69/100\n","\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8794 - auc: 0.9649 - loss: 0.2207\n","Epoch 69: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8802 - auc: 0.9647 - loss: 0.2204 - val_acc: 0.6188 - val_auc: 0.0920 - val_loss: 1.0875\n","Epoch 70/100\n","\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8919 - auc: 0.9711 - loss: 0.2076\n","Epoch 70: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8918 - auc: 0.9706 - loss: 0.2080 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 1.0969\n","Epoch 71/100\n","\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8862 - auc: 0.9644 - loss: 0.2116\n","Epoch 71: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8864 - auc: 0.9643 - loss: 0.2116 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 1.1074\n","Epoch 72/100\n","\u001b[1m282/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8925 - auc: 0.9687 - loss: 0.2048\n","Epoch 72: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8924 - auc: 0.9685 - loss: 0.2048 - val_acc: 0.6188 - val_auc: 0.0920 - val_loss: 1.1182\n","Epoch 73/100\n","\u001b[1m287/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9027 - auc: 0.9641 - loss: 0.1918\n","Epoch 73: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9022 - auc: 0.9641 - loss: 0.1924 - val_acc: 0.6188 - val_auc: 0.0000e+00 - val_loss: 1.1261\n","Epoch 74/100\n","\u001b[1m283/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9018 - auc: 0.9655 - loss: 0.1873\n","Epoch 74: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9011 - auc: 0.9653 - loss: 0.1882 - val_acc: 0.6188 - val_auc: 0.0480 - val_loss: 1.1336\n","Epoch 75/100\n","\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8936 - auc: 0.9612 - loss: 0.1926\n","Epoch 75: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8935 - auc: 0.9613 - loss: 0.1928 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 1.1508\n","Epoch 76/100\n","\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8840 - auc: 0.9506 - loss: 0.2086\n","Epoch 76: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8844 - auc: 0.9513 - loss: 0.2079 - val_acc: 0.6188 - val_auc: 0.0480 - val_loss: 1.1596\n","Epoch 77/100\n","\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9067 - auc: 0.9781 - loss: 0.1706\n","Epoch 77: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9062 - auc: 0.9773 - loss: 0.1717 - val_acc: 0.6188 - val_auc: 0.0960 - val_loss: 1.1654\n","Epoch 78/100\n","\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9755 - auc: 0.9565 - loss: 0.2004\n","Epoch 78: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9753 - auc: 0.9568 - loss: 0.1999 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 1.1754\n","Epoch 79/100\n","\u001b[1m280/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9423 - auc: 0.9630 - loss: 0.1783\n","Epoch 79: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9429 - auc: 0.9631 - loss: 0.1790 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 1.1842\n","Epoch 80/100\n","\u001b[1m280/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9796 - auc: 0.9568 - loss: 0.1879\n","Epoch 80: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9797 - auc: 0.9573 - loss: 0.1876 - val_acc: 0.6188 - val_auc: 0.0960 - val_loss: 1.1943\n","Epoch 81/100\n","\u001b[1m278/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9875 - auc: 0.9759 - loss: 0.1673\n","Epoch 81: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9869 - auc: 0.9748 - loss: 0.1686 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 1.2034\n","Epoch 82/100\n","\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9895 - auc: 0.9796 - loss: 0.1682\n","Epoch 82: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9890 - auc: 0.9788 - loss: 0.1688 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 1.2125\n","Epoch 83/100\n","\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9865 - auc: 0.9748 - loss: 0.1668\n","Epoch 83: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9863 - auc: 0.9745 - loss: 0.1672 - val_acc: 0.6188 - val_auc: 0.0960 - val_loss: 1.2213\n","Epoch 84/100\n","\u001b[1m290/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9789 - auc: 0.9707 - loss: 0.1788\n","Epoch 84: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9789 - auc: 0.9705 - loss: 0.1787 - val_acc: 0.6188 - val_auc: 0.0960 - val_loss: 1.2319\n","Epoch 85/100\n","\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9796 - auc: 0.9648 - loss: 0.1817\n","Epoch 85: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9798 - auc: 0.9650 - loss: 0.1812 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 1.2388\n","Epoch 86/100\n","\u001b[1m281/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9851 - auc: 0.9660 - loss: 0.1498\n","Epoch 86: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9848 - auc: 0.9661 - loss: 0.1516 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 1.2401\n","Epoch 87/100\n","\u001b[1m280/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9850 - auc: 0.9753 - loss: 0.1480\n","Epoch 87: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9848 - auc: 0.9747 - loss: 0.1495 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 1.2481\n","Epoch 88/100\n","\u001b[1m282/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9821 - auc: 0.9697 - loss: 0.1628\n","Epoch 88: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9820 - auc: 0.9696 - loss: 0.1633 - val_acc: 0.6188 - val_auc: 0.0960 - val_loss: 1.2597\n","Epoch 89/100\n","\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9735 - auc: 0.9412 - loss: 0.1879\n","Epoch 89: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9739 - auc: 0.9427 - loss: 0.1868 - val_acc: 0.6188 - val_auc: 0.0960 - val_loss: 1.2650\n","Epoch 90/100\n","\u001b[1m291/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9800 - auc: 0.9694 - loss: 0.1696\n","Epoch 90: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9800 - auc: 0.9694 - loss: 0.1695 - val_acc: 0.6188 - val_auc: 0.0960 - val_loss: 1.2757\n","Epoch 91/100\n","\u001b[1m286/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9675 - auc: 0.9348 - loss: 0.1996\n","Epoch 91: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9682 - auc: 0.9367 - loss: 0.1979 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 1.2806\n","Epoch 92/100\n","\u001b[1m282/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9895 - auc: 0.9854 - loss: 0.1361\n","Epoch 92: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9890 - auc: 0.9845 - loss: 0.1378 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 1.2864\n","Epoch 93/100\n","\u001b[1m289/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9840 - auc: 0.9745 - loss: 0.1569\n","Epoch 93: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9839 - auc: 0.9744 - loss: 0.1571 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 1.2899\n","Epoch 94/100\n","\u001b[1m300/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9770 - auc: 0.9603 - loss: 0.1860\n","Epoch 94: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9770 - auc: 0.9604 - loss: 0.1858 - val_acc: 0.6188 - val_auc: 0.0960 - val_loss: 1.3056\n","Epoch 95/100\n","\u001b[1m277/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9894 - auc: 0.9848 - loss: 0.1404\n","Epoch 95: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9887 - auc: 0.9836 - loss: 0.1422 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 1.2989\n","Epoch 96/100\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9823 - auc: 0.9725 - loss: 0.1530\n","Epoch 96: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9823 - auc: 0.9725 - loss: 0.1530 - val_acc: 0.6188 - val_auc: 0.0960 - val_loss: 1.3123\n","Epoch 97/100\n","\u001b[1m280/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9767 - auc: 0.9600 - loss: 0.1767\n","Epoch 97: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9769 - auc: 0.9608 - loss: 0.1754 - val_acc: 0.6188 - val_auc: 0.0960 - val_loss: 1.3211\n","Epoch 98/100\n","\u001b[1m285/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9773 - auc: 0.9686 - loss: 0.1573\n","Epoch 98: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9773 - auc: 0.9688 - loss: 0.1573 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 1.3267\n","Epoch 99/100\n","\u001b[1m280/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9801 - auc: 0.9706 - loss: 0.1604\n","Epoch 99: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9802 - auc: 0.9708 - loss: 0.1601 - val_acc: 0.6188 - val_auc: 0.0960 - val_loss: 1.3218\n","Epoch 100/100\n","\u001b[1m288/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9888 - auc: 0.9819 - loss: 0.1284\n","Epoch 100: val_loss did not improve from 0.63047\n","\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.9881 - auc: 0.9814 - loss: 0.1297 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 1.3282\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 11 | VAL  | AUC=0.7200 | ACC=0.6188 | n=202\n","Fold 11 | TEST | AUC=0.0000 | ACC=0.5529 | n=85\n","\n","--- Fold 12/14 ---\n"," train | ids:   36 | files:  830 | pos:  269 | neg:  561\n","   val | ids:    4 | files:  202 | pos:   77 | neg:  125\n","  test | ids:    3 | files:  158 | pos:   59 | neg:   99\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m274/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2915 - auc: 0.4319 - loss: 1.0308\n","Epoch 1: val_loss improved from inf to 0.85904, saving model to best_tab_only_fold12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - acc: 0.2920 - auc: 0.4317 - loss: 1.0297 - val_acc: 0.3812 - val_auc: 0.0920 - val_loss: 0.8590\n","Epoch 2/100\n","\u001b[1m262/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3006 - auc: 0.5388 - loss: 0.8267\n","Epoch 2: val_loss improved from 0.85904 to 0.76294, saving model to best_tab_only_fold12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.2989 - auc: 0.5345 - loss: 0.8257 - val_acc: 0.3812 - val_auc: 0.0920 - val_loss: 0.7629\n","Epoch 3/100\n","\u001b[1m254/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3205 - auc: 0.5215 - loss: 0.7304\n","Epoch 3: val_loss improved from 0.76294 to 0.70301, saving model to best_tab_only_fold12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.3240 - auc: 0.5246 - loss: 0.7291 - val_acc: 0.5594 - val_auc: 0.0920 - val_loss: 0.7030\n","Epoch 4/100\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7199 - auc: 0.7107 - loss: 0.6681\n","Epoch 4: val_loss improved from 0.70301 to 0.67114, saving model to best_tab_only_fold12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7200 - auc: 0.7108 - loss: 0.6681 - val_acc: 0.6188 - val_auc: 0.4520 - val_loss: 0.6711\n","Epoch 5/100\n","\u001b[1m272/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7468 - auc: 0.6174 - loss: 0.6298\n","Epoch 5: val_loss improved from 0.67114 to 0.65594, saving model to best_tab_only_fold12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7471 - auc: 0.6182 - loss: 0.6296 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6559\n","Epoch 6/100\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7552 - auc: 0.5749 - loss: 0.6115\n","Epoch 6: val_loss improved from 0.65594 to 0.64900, saving model to best_tab_only_fold12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7552 - auc: 0.5749 - loss: 0.6115 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6490\n","Epoch 7/100\n","\u001b[1m263/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7683 - auc: 0.6105 - loss: 0.5775\n","Epoch 7: val_loss improved from 0.64900 to 0.64665, saving model to best_tab_only_fold12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7679 - auc: 0.6090 - loss: 0.5781 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6467\n","Epoch 8/100\n","\u001b[1m262/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7516 - auc: 0.5896 - loss: 0.5906\n","Epoch 8: val_loss improved from 0.64665 to 0.64593, saving model to best_tab_only_fold12.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7522 - auc: 0.5894 - loss: 0.5900 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6459\n","Epoch 9/100\n","\u001b[1m255/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7516 - auc: 0.5759 - loss: 0.5891\n","Epoch 9: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7525 - auc: 0.5764 - loss: 0.5878 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6462\n","Epoch 10/100\n","\u001b[1m257/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7584 - auc: 0.6102 - loss: 0.5763\n","Epoch 10: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7603 - auc: 0.6086 - loss: 0.5758 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6467\n","Epoch 11/100\n","\u001b[1m258/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8111 - auc: 0.6159 - loss: 0.5428\n","Epoch 11: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8105 - auc: 0.6149 - loss: 0.5442 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6474\n","Epoch 12/100\n","\u001b[1m257/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8256 - auc: 0.5766 - loss: 0.5714\n","Epoch 12: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8263 - auc: 0.5780 - loss: 0.5705 - val_acc: 0.6188 - val_auc: 0.8120 - val_loss: 0.6480\n","Epoch 13/100\n","\u001b[1m255/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8171 - auc: 0.5899 - loss: 0.5798\n","Epoch 13: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8188 - auc: 0.5901 - loss: 0.5775 - val_acc: 0.6188 - val_auc: 0.8600 - val_loss: 0.6487\n","Epoch 14/100\n","\u001b[1m262/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8433 - auc: 0.5952 - loss: 0.5465\n","Epoch 14: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8430 - auc: 0.5950 - loss: 0.5467 - val_acc: 0.6188 - val_auc: 0.8600 - val_loss: 0.6491\n","Epoch 15/100\n","\u001b[1m260/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8190 - auc: 0.5778 - loss: 0.5560\n","Epoch 15: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8201 - auc: 0.5790 - loss: 0.5552 - val_acc: 0.6188 - val_auc: 0.8600 - val_loss: 0.6498\n","Epoch 16/100\n","\u001b[1m262/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8478 - auc: 0.6150 - loss: 0.5286\n","Epoch 16: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8470 - auc: 0.6133 - loss: 0.5294 - val_acc: 0.6188 - val_auc: 0.8600 - val_loss: 0.6503\n","Epoch 17/100\n","\u001b[1m260/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8638 - auc: 0.6112 - loss: 0.5038\n","Epoch 17: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8623 - auc: 0.6104 - loss: 0.5056 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6510\n","Epoch 18/100\n","\u001b[1m259/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8017 - auc: 0.5411 - loss: 0.5764\n","Epoch 18: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8039 - auc: 0.5445 - loss: 0.5736 - val_acc: 0.6188 - val_auc: 1.0000 - val_loss: 0.6517\n","Epoch 19/100\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8401 - auc: 0.6058 - loss: 0.5257\n","Epoch 19: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8401 - auc: 0.6058 - loss: 0.5257 - val_acc: 0.6188 - val_auc: 0.8600 - val_loss: 0.6524\n","Epoch 20/100\n","\u001b[1m254/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8579 - auc: 0.5852 - loss: 0.5038\n","Epoch 20: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8560 - auc: 0.5865 - loss: 0.5056 - val_acc: 0.6188 - val_auc: 0.8600 - val_loss: 0.6531\n","Epoch 21/100\n","\u001b[1m273/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8121 - auc: 0.5593 - loss: 0.5503\n","Epoch 21: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8125 - auc: 0.5600 - loss: 0.5497 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6541\n","Epoch 22/100\n","\u001b[1m259/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8387 - auc: 0.6361 - loss: 0.5127\n","Epoch 22: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8384 - auc: 0.6337 - loss: 0.5130 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6550\n","Epoch 23/100\n","\u001b[1m262/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8344 - auc: 0.5447 - loss: 0.5144\n","Epoch 23: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8347 - auc: 0.5476 - loss: 0.5141 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6561\n","Epoch 24/100\n","\u001b[1m261/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8430 - auc: 0.5996 - loss: 0.4974\n","Epoch 24: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8427 - auc: 0.5997 - loss: 0.4979 - val_acc: 0.6188 - val_auc: 0.8600 - val_loss: 0.6568\n","Epoch 25/100\n","\u001b[1m259/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8463 - auc: 0.6122 - loss: 0.4940\n","Epoch 25: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8458 - auc: 0.6121 - loss: 0.4944 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6578\n","Epoch 26/100\n","\u001b[1m264/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8229 - auc: 0.5584 - loss: 0.5188\n","Epoch 26: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8237 - auc: 0.5612 - loss: 0.5177 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6588\n","Epoch 27/100\n","\u001b[1m262/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8270 - auc: 0.5904 - loss: 0.5072\n","Epoch 27: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8275 - auc: 0.5909 - loss: 0.5066 - val_acc: 0.6188 - val_auc: 1.0000 - val_loss: 0.6598\n","Epoch 28/100\n","\u001b[1m261/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8544 - auc: 0.6470 - loss: 0.4714\n","Epoch 28: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8533 - auc: 0.6448 - loss: 0.4727 - val_acc: 0.6188 - val_auc: 1.0000 - val_loss: 0.6605\n","Epoch 29/100\n","\u001b[1m260/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8523 - auc: 0.6318 - loss: 0.4679\n","Epoch 29: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8512 - auc: 0.6307 - loss: 0.4692 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6616\n","Epoch 30/100\n","\u001b[1m262/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8225 - auc: 0.5634 - loss: 0.5037\n","Epoch 30: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8231 - auc: 0.5659 - loss: 0.5027 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6628\n","Epoch 31/100\n","\u001b[1m257/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8402 - auc: 0.6162 - loss: 0.4789\n","Epoch 31: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8399 - auc: 0.6163 - loss: 0.4790 - val_acc: 0.6188 - val_auc: 1.0000 - val_loss: 0.6639\n","Epoch 32/100\n","\u001b[1m258/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8335 - auc: 0.5853 - loss: 0.4815\n","Epoch 32: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8335 - auc: 0.5873 - loss: 0.4814 - val_acc: 0.6188 - val_auc: 1.0000 - val_loss: 0.6648\n","Epoch 33/100\n","\u001b[1m256/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8307 - auc: 0.6214 - loss: 0.4769\n","Epoch 33: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8312 - auc: 0.6217 - loss: 0.4765 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6659\n","Epoch 34/100\n","\u001b[1m258/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8483 - auc: 0.6252 - loss: 0.4566\n","Epoch 34: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8473 - auc: 0.6248 - loss: 0.4577 - val_acc: 0.6188 - val_auc: 1.0000 - val_loss: 0.6661\n","Epoch 35/100\n","\u001b[1m276/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8159 - auc: 0.6257 - loss: 0.4858\n","Epoch 35: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8160 - auc: 0.6258 - loss: 0.4857 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6675\n","Epoch 36/100\n","\u001b[1m257/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8175 - auc: 0.6248 - loss: 0.4823\n","Epoch 36: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8188 - auc: 0.6261 - loss: 0.4809 - val_acc: 0.6188 - val_auc: 1.0000 - val_loss: 0.6686\n","Epoch 37/100\n","\u001b[1m274/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8304 - auc: 0.6195 - loss: 0.4710\n","Epoch 37: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8305 - auc: 0.6198 - loss: 0.4708 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6697\n","Epoch 38/100\n","\u001b[1m256/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8392 - auc: 0.6152 - loss: 0.4570\n","Epoch 38: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8391 - auc: 0.6181 - loss: 0.4568 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6707\n","Epoch 39/100\n","\u001b[1m261/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8433 - auc: 0.6958 - loss: 0.4405\n","Epoch 39: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8427 - auc: 0.6939 - loss: 0.4414 - val_acc: 0.6188 - val_auc: 1.0000 - val_loss: 0.6710\n","Epoch 40/100\n","\u001b[1m261/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8294 - auc: 0.6669 - loss: 0.4568\n","Epoch 40: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8298 - auc: 0.6674 - loss: 0.4564 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6725\n","Epoch 41/100\n","\u001b[1m264/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8337 - auc: 0.6804 - loss: 0.4488\n","Epoch 41: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8338 - auc: 0.6810 - loss: 0.4488 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6737\n","Epoch 42/100\n","\u001b[1m265/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8391 - auc: 0.7001 - loss: 0.4413\n","Epoch 42: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8390 - auc: 0.7002 - loss: 0.4413 - val_acc: 0.6188 - val_auc: 1.0000 - val_loss: 0.6750\n","Epoch 43/100\n","\u001b[1m262/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8141 - auc: 0.6934 - loss: 0.4683\n","Epoch 43: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8153 - auc: 0.6956 - loss: 0.4668 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6760\n","Epoch 44/100\n","\u001b[1m260/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8423 - auc: 0.7467 - loss: 0.4308\n","Epoch 44: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8420 - auc: 0.7462 - loss: 0.4313 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6771\n","Epoch 45/100\n","\u001b[1m254/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8442 - auc: 0.7727 - loss: 0.4231\n","Epoch 45: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8437 - auc: 0.7732 - loss: 0.4239 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6785\n","Epoch 46/100\n","\u001b[1m258/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8286 - auc: 0.7968 - loss: 0.4416\n","Epoch 46: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8291 - auc: 0.7979 - loss: 0.4411 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6796\n","Epoch 47/100\n","\u001b[1m256/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8349 - auc: 0.8271 - loss: 0.4334\n","Epoch 47: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8352 - auc: 0.8268 - loss: 0.4330 - val_acc: 0.6188 - val_auc: 1.0000 - val_loss: 0.6814\n","Epoch 48/100\n","\u001b[1m256/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8381 - auc: 0.8217 - loss: 0.4298\n","Epoch 48: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8377 - auc: 0.8218 - loss: 0.4299 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6821\n","Epoch 49/100\n","\u001b[1m261/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8281 - auc: 0.8171 - loss: 0.4365\n","Epoch 49: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8285 - auc: 0.8174 - loss: 0.4359 - val_acc: 0.6188 - val_auc: 1.0000 - val_loss: 0.6837\n","Epoch 50/100\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8455 - auc: 0.8479 - loss: 0.4129\n","Epoch 50: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8455 - auc: 0.8479 - loss: 0.4129 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6853\n","Epoch 51/100\n","\u001b[1m271/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8452 - auc: 0.8607 - loss: 0.4051\n","Epoch 51: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8450 - auc: 0.8601 - loss: 0.4055 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6869\n","Epoch 52/100\n","\u001b[1m273/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8133 - auc: 0.8324 - loss: 0.4463\n","Epoch 52: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8137 - auc: 0.8328 - loss: 0.4458 - val_acc: 0.6188 - val_auc: 1.0000 - val_loss: 0.6884\n","Epoch 53/100\n","\u001b[1m266/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8108 - auc: 0.8528 - loss: 0.4429\n","Epoch 53: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8119 - auc: 0.8540 - loss: 0.4417 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6907\n","Epoch 54/100\n","\u001b[1m258/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8492 - auc: 0.8537 - loss: 0.4000\n","Epoch 54: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8483 - auc: 0.8547 - loss: 0.4009 - val_acc: 0.6188 - val_auc: 0.9080 - val_loss: 0.6919\n","Epoch 55/100\n","\u001b[1m254/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8296 - auc: 0.8930 - loss: 0.4167\n","Epoch 55: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8301 - auc: 0.8928 - loss: 0.4163 - val_acc: 0.6188 - val_auc: 1.0000 - val_loss: 0.6935\n","Epoch 56/100\n","\u001b[1m256/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8587 - auc: 0.9176 - loss: 0.3831\n","Epoch 56: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8569 - auc: 0.9164 - loss: 0.3852 - val_acc: 0.6188 - val_auc: 0.5480 - val_loss: 0.6947\n","Epoch 57/100\n","\u001b[1m255/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8465 - auc: 0.9198 - loss: 0.4011\n","Epoch 57: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8456 - auc: 0.9191 - loss: 0.4017 - val_acc: 0.6188 - val_auc: 0.6400 - val_loss: 0.6967\n","Epoch 58/100\n","\u001b[1m276/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8725 - auc: 0.9085 - loss: 0.3687\n","Epoch 58: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8722 - auc: 0.9086 - loss: 0.3690 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.6980\n","Epoch 59/100\n","\u001b[1m258/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8597 - auc: 0.9189 - loss: 0.3799\n","Epoch 59: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8580 - auc: 0.9187 - loss: 0.3816 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.6999\n","Epoch 60/100\n","\u001b[1m256/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8540 - auc: 0.9215 - loss: 0.3848\n","Epoch 60: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8527 - auc: 0.9214 - loss: 0.3860 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7018\n","Epoch 61/100\n","\u001b[1m257/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8531 - auc: 0.9085 - loss: 0.3866\n","Epoch 61: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8518 - auc: 0.9090 - loss: 0.3876 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7034\n","Epoch 62/100\n","\u001b[1m262/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8476 - auc: 0.8996 - loss: 0.3925\n","Epoch 62: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8468 - auc: 0.9005 - loss: 0.3929 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7052\n","Epoch 63/100\n","\u001b[1m254/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8530 - auc: 0.9234 - loss: 0.3791\n","Epoch 63: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8516 - auc: 0.9233 - loss: 0.3805 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7073\n","Epoch 64/100\n","\u001b[1m258/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8290 - auc: 0.9298 - loss: 0.4033\n","Epoch 64: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8293 - auc: 0.9298 - loss: 0.4029 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7092\n","Epoch 65/100\n","\u001b[1m257/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8330 - auc: 0.9298 - loss: 0.3990\n","Epoch 65: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8333 - auc: 0.9295 - loss: 0.3984 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7114\n","Epoch 66/100\n","\u001b[1m260/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8478 - auc: 0.9183 - loss: 0.3806\n","Epoch 66: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8471 - auc: 0.9189 - loss: 0.3813 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7132\n","Epoch 67/100\n","\u001b[1m253/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8307 - auc: 0.9275 - loss: 0.4008\n","Epoch 67: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8311 - auc: 0.9282 - loss: 0.3999 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7150\n","Epoch 68/100\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8424 - auc: 0.9277 - loss: 0.3822\n","Epoch 68: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8423 - auc: 0.9278 - loss: 0.3823 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7171\n","Epoch 69/100\n","\u001b[1m274/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8418 - auc: 0.9394 - loss: 0.3779\n","Epoch 69: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8418 - auc: 0.9394 - loss: 0.3781 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7192\n","Epoch 70/100\n","\u001b[1m260/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8116 - auc: 0.9325 - loss: 0.4069\n","Epoch 70: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8133 - auc: 0.9327 - loss: 0.4053 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7225\n","Epoch 71/100\n","\u001b[1m259/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8290 - auc: 0.9381 - loss: 0.3914\n","Epoch 71: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8297 - auc: 0.9386 - loss: 0.3906 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7243\n","Epoch 72/100\n","\u001b[1m261/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8290 - auc: 0.9314 - loss: 0.3904\n","Epoch 72: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8295 - auc: 0.9319 - loss: 0.3898 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7258\n","Epoch 73/100\n","\u001b[1m260/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8266 - auc: 0.9331 - loss: 0.3831\n","Epoch 73: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8273 - auc: 0.9331 - loss: 0.3827 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7280\n","Epoch 74/100\n","\u001b[1m259/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8373 - auc: 0.9414 - loss: 0.3741\n","Epoch 74: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8371 - auc: 0.9416 - loss: 0.3744 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7296\n","Epoch 75/100\n","\u001b[1m264/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8257 - auc: 0.9196 - loss: 0.3922\n","Epoch 75: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8261 - auc: 0.9203 - loss: 0.3916 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7322\n","Epoch 76/100\n","\u001b[1m258/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8371 - auc: 0.9558 - loss: 0.3721\n","Epoch 76: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8369 - auc: 0.9548 - loss: 0.3725 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7344\n","Epoch 77/100\n","\u001b[1m255/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8337 - auc: 0.9430 - loss: 0.3712\n","Epoch 77: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8340 - auc: 0.9426 - loss: 0.3713 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7372\n","Epoch 78/100\n","\u001b[1m260/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8414 - auc: 0.9317 - loss: 0.3694\n","Epoch 78: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8411 - auc: 0.9322 - loss: 0.3695 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7381\n","Epoch 79/100\n","\u001b[1m261/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8303 - auc: 0.9438 - loss: 0.3738\n","Epoch 79: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8306 - auc: 0.9436 - loss: 0.3736 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7405\n","Epoch 80/100\n","\u001b[1m261/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8178 - auc: 0.9319 - loss: 0.3866\n","Epoch 80: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8190 - auc: 0.9325 - loss: 0.3854 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7437\n","Epoch 81/100\n","\u001b[1m262/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8309 - auc: 0.9392 - loss: 0.3701\n","Epoch 81: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8311 - auc: 0.9393 - loss: 0.3700 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7457\n","Epoch 82/100\n","\u001b[1m260/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8289 - auc: 0.9383 - loss: 0.3701\n","Epoch 82: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8294 - auc: 0.9384 - loss: 0.3699 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7479\n","Epoch 83/100\n","\u001b[1m254/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8353 - auc: 0.9509 - loss: 0.3595\n","Epoch 83: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8353 - auc: 0.9500 - loss: 0.3600 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7501\n","Epoch 84/100\n","\u001b[1m253/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8272 - auc: 0.9553 - loss: 0.3649\n","Epoch 84: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8279 - auc: 0.9542 - loss: 0.3647 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7521\n","Epoch 85/100\n","\u001b[1m256/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8285 - auc: 0.9328 - loss: 0.3711\n","Epoch 85: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8288 - auc: 0.9333 - loss: 0.3706 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7545\n","Epoch 86/100\n","\u001b[1m255/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8444 - auc: 0.9197 - loss: 0.3576\n","Epoch 86: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8436 - auc: 0.9213 - loss: 0.3579 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7558\n","Epoch 87/100\n","\u001b[1m260/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8464 - auc: 0.9392 - loss: 0.3455\n","Epoch 87: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8457 - auc: 0.9392 - loss: 0.3464 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7582\n","Epoch 88/100\n","\u001b[1m252/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8509 - auc: 0.9396 - loss: 0.3413\n","Epoch 88: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8493 - auc: 0.9395 - loss: 0.3429 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7609\n","Epoch 89/100\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8318 - auc: 0.9379 - loss: 0.3642\n","Epoch 89: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8319 - auc: 0.9379 - loss: 0.3642 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7638\n","Epoch 90/100\n","\u001b[1m261/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8343 - auc: 0.9552 - loss: 0.3533\n","Epoch 90: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8343 - auc: 0.9543 - loss: 0.3535 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7653\n","Epoch 91/100\n","\u001b[1m257/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8241 - auc: 0.9497 - loss: 0.3532\n","Epoch 91: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8250 - auc: 0.9492 - loss: 0.3531 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7690\n","Epoch 92/100\n","\u001b[1m257/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8539 - auc: 0.9255 - loss: 0.3358\n","Epoch 92: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8525 - auc: 0.9262 - loss: 0.3370 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7700\n","Epoch 93/100\n","\u001b[1m258/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7983 - auc: 0.9474 - loss: 0.3803\n","Epoch 93: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8009 - auc: 0.9468 - loss: 0.3782 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7742\n","Epoch 94/100\n","\u001b[1m257/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8165 - auc: 0.8991 - loss: 0.3852\n","Epoch 94: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8181 - auc: 0.9025 - loss: 0.3824 - val_acc: 0.6188 - val_auc: 0.1880 - val_loss: 0.7761\n","Epoch 95/100\n","\u001b[1m261/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8105 - auc: 0.9452 - loss: 0.3667\n","Epoch 95: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8120 - auc: 0.9449 - loss: 0.3655 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7792\n","Epoch 96/100\n","\u001b[1m253/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8154 - auc: 0.9211 - loss: 0.3663\n","Epoch 96: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8173 - auc: 0.9224 - loss: 0.3645 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7829\n","Epoch 97/100\n","\u001b[1m260/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8623 - auc: 0.9565 - loss: 0.3129\n","Epoch 97: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8607 - auc: 0.9556 - loss: 0.3148 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7831\n","Epoch 98/100\n","\u001b[1m259/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8200 - auc: 0.9303 - loss: 0.3581\n","Epoch 98: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8211 - auc: 0.9310 - loss: 0.3571 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7866\n","Epoch 99/100\n","\u001b[1m254/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8304 - auc: 0.9423 - loss: 0.3468\n","Epoch 99: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8308 - auc: 0.9422 - loss: 0.3464 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7888\n","Epoch 100/100\n","\u001b[1m256/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8328 - auc: 0.9435 - loss: 0.3437\n","Epoch 100: val_loss did not improve from 0.64593\n","\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8328 - auc: 0.9432 - loss: 0.3437 - val_acc: 0.6188 - val_auc: 0.2800 - val_loss: 0.7903\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 12 | VAL  | AUC=0.9040 | ACC=0.6188 | n=202\n","Fold 12 | TEST | AUC=1.0000 | ACC=1.0000 | n=158\n","\n","--- Fold 13/14 ---\n"," train | ids:   36 | files:  991 | pos:  286 | neg:  705\n","   val | ids:    4 | files:  118 | pos:   77 | neg:   41\n","  test | ids:    3 | files:   81 | pos:   42 | neg:   39\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.3163 - auc: 0.3855 - loss: 0.9584\n","Epoch 1: val_loss improved from inf to 0.61243, saving model to best_tab_only_fold13.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - acc: 0.3159 - auc: 0.3855 - loss: 0.9582 - val_acc: 0.6525 - val_auc: 1.0000 - val_loss: 0.6124\n","Epoch 2/100\n","\u001b[1m312/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.2379 - auc: 0.3942 - loss: 0.8617\n","Epoch 2: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.2377 - auc: 0.3926 - loss: 0.8600 - val_acc: 0.6525 - val_auc: 1.0000 - val_loss: 0.6244\n","Epoch 3/100\n","\u001b[1m310/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.2207 - auc: 0.3744 - loss: 0.7758\n","Epoch 3: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.2216 - auc: 0.3743 - loss: 0.7744 - val_acc: 0.7542 - val_auc: 1.0000 - val_loss: 0.6468\n","Epoch 4/100\n","\u001b[1m311/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3180 - auc: 0.4003 - loss: 0.7155\n","Epoch 4: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.3242 - auc: 0.4048 - loss: 0.7147 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.6743\n","Epoch 5/100\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6986 - auc: 0.5257 - loss: 0.6707\n","Epoch 5: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6986 - auc: 0.5258 - loss: 0.6706 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.7020\n","Epoch 6/100\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7956 - auc: 0.5338 - loss: 0.6358\n","Epoch 6: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7956 - auc: 0.5339 - loss: 0.6358 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.7313\n","Epoch 7/100\n","\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7810 - auc: 0.5419 - loss: 0.6179\n","Epoch 7: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7815 - auc: 0.5430 - loss: 0.6176 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.7594\n","Epoch 8/100\n","\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7985 - auc: 0.5954 - loss: 0.5895\n","Epoch 8: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7985 - auc: 0.5953 - loss: 0.5895 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.7872\n","Epoch 9/100\n","\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8077 - auc: 0.5958 - loss: 0.5704\n","Epoch 9: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8076 - auc: 0.5957 - loss: 0.5704 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8120\n","Epoch 10/100\n","\u001b[1m312/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7832 - auc: 0.5785 - loss: 0.5774\n","Epoch 10: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7841 - auc: 0.5795 - loss: 0.5764 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8360\n","Epoch 11/100\n","\u001b[1m313/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8167 - auc: 0.5921 - loss: 0.5428\n","Epoch 11: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8157 - auc: 0.5920 - loss: 0.5434 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8570\n","Epoch 12/100\n","\u001b[1m309/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8080 - auc: 0.5747 - loss: 0.5413\n","Epoch 12: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8074 - auc: 0.5756 - loss: 0.5416 - val_acc: 0.3475 - val_auc: 0.6829 - val_loss: 0.8921\n","Epoch 13/100\n","\u001b[1m308/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8095 - auc: 0.6502 - loss: 0.5261\n","Epoch 13: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8089 - auc: 0.6465 - loss: 0.5266 - val_acc: 0.3475 - val_auc: 0.6829 - val_loss: 0.9215\n","Epoch 14/100\n","\u001b[1m311/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8208 - auc: 0.5883 - loss: 0.5091\n","Epoch 14: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8207 - auc: 0.5882 - loss: 0.5103 - val_acc: 0.3475 - val_auc: 0.6829 - val_loss: 0.9432\n","Epoch 15/100\n","\u001b[1m311/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8429 - auc: 0.6137 - loss: 0.5124\n","Epoch 15: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8429 - auc: 0.6120 - loss: 0.5130 - val_acc: 0.3475 - val_auc: 0.6829 - val_loss: 0.9649\n","Epoch 16/100\n","\u001b[1m313/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8633 - auc: 0.5817 - loss: 0.5167\n","Epoch 16: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8632 - auc: 0.5819 - loss: 0.5167 - val_acc: 0.3475 - val_auc: 0.6829 - val_loss: 0.9864\n","Epoch 17/100\n","\u001b[1m317/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8562 - auc: 0.5847 - loss: 0.5158\n","Epoch 17: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8565 - auc: 0.5856 - loss: 0.5153 - val_acc: 0.3475 - val_auc: 0.6829 - val_loss: 1.0096\n","Epoch 18/100\n","\u001b[1m313/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8680 - auc: 0.6093 - loss: 0.4941\n","Epoch 18: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8677 - auc: 0.6087 - loss: 0.4945 - val_acc: 0.3475 - val_auc: 0.6829 - val_loss: 1.0293\n","Epoch 19/100\n","\u001b[1m308/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8565 - auc: 0.6170 - loss: 0.5077\n","Epoch 19: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8568 - auc: 0.6157 - loss: 0.5068 - val_acc: 0.3475 - val_auc: 0.6829 - val_loss: 1.0504\n","Epoch 20/100\n","\u001b[1m309/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8564 - auc: 0.5912 - loss: 0.4985\n","Epoch 20: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8568 - auc: 0.5933 - loss: 0.4976 - val_acc: 0.3475 - val_auc: 0.6829 - val_loss: 1.0709\n","Epoch 21/100\n","\u001b[1m311/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8781 - auc: 0.6703 - loss: 0.4579\n","Epoch 21: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8772 - auc: 0.6673 - loss: 0.4592 - val_acc: 0.3475 - val_auc: 0.3415 - val_loss: 1.0903\n","Epoch 22/100\n","\u001b[1m307/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8636 - auc: 0.6023 - loss: 0.4692\n","Epoch 22: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8637 - auc: 0.6053 - loss: 0.4691 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.1101\n","Epoch 23/100\n","\u001b[1m311/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8656 - auc: 0.6580 - loss: 0.4582\n","Epoch 23: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8654 - auc: 0.6567 - loss: 0.4586 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.1282\n","Epoch 24/100\n","\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8482 - auc: 0.6348 - loss: 0.4789\n","Epoch 24: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8484 - auc: 0.6348 - loss: 0.4786 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.1466\n","Epoch 25/100\n","\u001b[1m310/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8805 - auc: 0.6626 - loss: 0.4299\n","Epoch 25: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8794 - auc: 0.6618 - loss: 0.4313 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.1627\n","Epoch 26/100\n","\u001b[1m313/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8764 - auc: 0.6863 - loss: 0.4254\n","Epoch 26: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8756 - auc: 0.6847 - loss: 0.4266 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.1821\n","Epoch 27/100\n","\u001b[1m310/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8895 - auc: 0.7282 - loss: 0.4069\n","Epoch 27: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8879 - auc: 0.7257 - loss: 0.4090 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.2039\n","Epoch 28/100\n","\u001b[1m311/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8757 - auc: 0.7111 - loss: 0.4174\n","Epoch 28: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8748 - auc: 0.7118 - loss: 0.4185 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.2254\n","Epoch 29/100\n","\u001b[1m311/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8628 - auc: 0.7644 - loss: 0.4285\n","Epoch 29: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8627 - auc: 0.7632 - loss: 0.4285 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.2439\n","Epoch 30/100\n","\u001b[1m316/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8762 - auc: 0.7254 - loss: 0.4090\n","Epoch 30: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8756 - auc: 0.7271 - loss: 0.4095 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.2647\n","Epoch 31/100\n","\u001b[1m314/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8827 - auc: 0.7506 - loss: 0.3973\n","Epoch 31: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8817 - auc: 0.7520 - loss: 0.3983 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.2840\n","Epoch 32/100\n","\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8714 - auc: 0.7917 - loss: 0.4000\n","Epoch 32: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8710 - auc: 0.7914 - loss: 0.4005 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.3063\n","Epoch 33/100\n","\u001b[1m313/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8597 - auc: 0.7804 - loss: 0.4103\n","Epoch 33: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8599 - auc: 0.7808 - loss: 0.4101 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.3266\n","Epoch 34/100\n","\u001b[1m312/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8698 - auc: 0.7718 - loss: 0.3947\n","Epoch 34: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8694 - auc: 0.7726 - loss: 0.3950 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.3496\n","Epoch 35/100\n","\u001b[1m308/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8624 - auc: 0.7858 - loss: 0.3997\n","Epoch 35: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8626 - auc: 0.7862 - loss: 0.3993 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.3712\n","Epoch 36/100\n","\u001b[1m313/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8659 - auc: 0.7773 - loss: 0.3926\n","Epoch 36: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8657 - auc: 0.7777 - loss: 0.3925 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.3963\n","Epoch 37/100\n","\u001b[1m309/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8561 - auc: 0.7684 - loss: 0.3994\n","Epoch 37: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8565 - auc: 0.7701 - loss: 0.3987 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.4185\n","Epoch 38/100\n","\u001b[1m307/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8719 - auc: 0.8023 - loss: 0.3729\n","Epoch 38: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8714 - auc: 0.8019 - loss: 0.3736 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.4433\n","Epoch 39/100\n","\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8438 - auc: 0.8009 - loss: 0.4040\n","Epoch 39: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8441 - auc: 0.8010 - loss: 0.4035 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.4676\n","Epoch 40/100\n","\u001b[1m309/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8618 - auc: 0.7887 - loss: 0.3809\n","Epoch 40: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8619 - auc: 0.7902 - loss: 0.3805 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.4919\n","Epoch 41/100\n","\u001b[1m313/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8532 - auc: 0.8274 - loss: 0.3820\n","Epoch 41: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8536 - auc: 0.8269 - loss: 0.3816 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.5144\n","Epoch 42/100\n","\u001b[1m317/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8679 - auc: 0.8209 - loss: 0.3642\n","Epoch 42: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8677 - auc: 0.8217 - loss: 0.3644 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.5411\n","Epoch 43/100\n","\u001b[1m309/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8657 - auc: 0.8393 - loss: 0.3626\n","Epoch 43: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8656 - auc: 0.8405 - loss: 0.3627 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.5639\n","Epoch 44/100\n","\u001b[1m311/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8515 - auc: 0.8552 - loss: 0.3791\n","Epoch 44: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8520 - auc: 0.8563 - loss: 0.3782 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.5912\n","Epoch 45/100\n","\u001b[1m309/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8743 - auc: 0.8590 - loss: 0.3504\n","Epoch 45: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8734 - auc: 0.8608 - loss: 0.3511 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.6137\n","Epoch 46/100\n","\u001b[1m313/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8508 - auc: 0.8751 - loss: 0.3734\n","Epoch 46: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8515 - auc: 0.8757 - loss: 0.3724 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.6381\n","Epoch 47/100\n","\u001b[1m310/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8782 - auc: 0.9002 - loss: 0.3355\n","Epoch 47: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8771 - auc: 0.8993 - loss: 0.3368 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.6618\n","Epoch 48/100\n","\u001b[1m310/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8601 - auc: 0.8948 - loss: 0.3511\n","Epoch 48: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8602 - auc: 0.8949 - loss: 0.3511 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.6869\n","Epoch 49/100\n","\u001b[1m306/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8707 - auc: 0.8762 - loss: 0.3480\n","Epoch 49: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8701 - auc: 0.8773 - loss: 0.3481 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.7090\n","Epoch 50/100\n","\u001b[1m308/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8636 - auc: 0.9065 - loss: 0.3387\n","Epoch 50: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8635 - auc: 0.9062 - loss: 0.3394 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.7312\n","Epoch 51/100\n","\u001b[1m308/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8534 - auc: 0.9246 - loss: 0.3591\n","Epoch 51: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8539 - auc: 0.9245 - loss: 0.3583 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.7570\n","Epoch 52/100\n","\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8523 - auc: 0.9211 - loss: 0.3551\n","Epoch 52: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8524 - auc: 0.9212 - loss: 0.3550 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.7805\n","Epoch 53/100\n","\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8625 - auc: 0.9511 - loss: 0.3387\n","Epoch 53: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8625 - auc: 0.9508 - loss: 0.3387 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.8038\n","Epoch 54/100\n","\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8570 - auc: 0.9324 - loss: 0.3457\n","Epoch 54: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8572 - auc: 0.9326 - loss: 0.3455 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.8250\n","Epoch 55/100\n","\u001b[1m309/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8610 - auc: 0.9459 - loss: 0.3370\n","Epoch 55: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8610 - auc: 0.9456 - loss: 0.3370 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.8464\n","Epoch 56/100\n","\u001b[1m310/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8710 - auc: 0.9376 - loss: 0.3271\n","Epoch 56: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8704 - auc: 0.9380 - loss: 0.3278 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.8663\n","Epoch 57/100\n","\u001b[1m313/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8448 - auc: 0.9285 - loss: 0.3599\n","Epoch 57: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8456 - auc: 0.9295 - loss: 0.3585 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.8890\n","Epoch 58/100\n","\u001b[1m310/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8620 - auc: 0.9522 - loss: 0.3272\n","Epoch 58: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8619 - auc: 0.9516 - loss: 0.3276 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.9096\n","Epoch 59/100\n","\u001b[1m314/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8514 - auc: 0.9452 - loss: 0.3421\n","Epoch 59: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8520 - auc: 0.9452 - loss: 0.3415 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.9305\n","Epoch 60/100\n","\u001b[1m314/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8537 - auc: 0.9392 - loss: 0.3374\n","Epoch 60: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8542 - auc: 0.9395 - loss: 0.3369 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.9518\n","Epoch 61/100\n","\u001b[1m307/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8651 - auc: 0.9609 - loss: 0.3206\n","Epoch 61: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8650 - auc: 0.9596 - loss: 0.3211 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.9691\n","Epoch 62/100\n","\u001b[1m311/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8485 - auc: 0.9274 - loss: 0.3536\n","Epoch 62: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8495 - auc: 0.9285 - loss: 0.3517 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 1.9883\n","Epoch 63/100\n","\u001b[1m309/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8800 - auc: 0.9248 - loss: 0.3073\n","Epoch 63: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8787 - auc: 0.9262 - loss: 0.3084 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.0020\n","Epoch 64/100\n","\u001b[1m312/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8653 - auc: 0.9417 - loss: 0.3205\n","Epoch 64: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8651 - auc: 0.9418 - loss: 0.3206 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.0211\n","Epoch 65/100\n","\u001b[1m306/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8542 - auc: 0.9182 - loss: 0.3371\n","Epoch 65: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8548 - auc: 0.9202 - loss: 0.3358 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.0384\n","Epoch 66/100\n","\u001b[1m310/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8580 - auc: 0.9574 - loss: 0.3143\n","Epoch 66: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8584 - auc: 0.9568 - loss: 0.3145 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.0575\n","Epoch 67/100\n","\u001b[1m309/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8820 - auc: 0.9583 - loss: 0.2879\n","Epoch 67: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8807 - auc: 0.9575 - loss: 0.2898 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.0772\n","Epoch 68/100\n","\u001b[1m308/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8456 - auc: 0.9468 - loss: 0.3311\n","Epoch 68: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8467 - auc: 0.9466 - loss: 0.3302 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.0954\n","Epoch 69/100\n","\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8521 - auc: 0.9588 - loss: 0.3168\n","Epoch 69: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8522 - auc: 0.9587 - loss: 0.3167 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.1173\n","Epoch 70/100\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8624 - auc: 0.9446 - loss: 0.3133\n","Epoch 70: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8624 - auc: 0.9446 - loss: 0.3133 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.1263\n","Epoch 71/100\n","\u001b[1m310/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8808 - auc: 0.9546 - loss: 0.2864\n","Epoch 71: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8796 - auc: 0.9542 - loss: 0.2880 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.1365\n","Epoch 72/100\n","\u001b[1m314/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8434 - auc: 0.9467 - loss: 0.3268\n","Epoch 72: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8444 - auc: 0.9466 - loss: 0.3259 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.1569\n","Epoch 73/100\n","\u001b[1m312/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8770 - auc: 0.9511 - loss: 0.2904\n","Epoch 73: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8760 - auc: 0.9508 - loss: 0.2916 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.1717\n","Epoch 74/100\n","\u001b[1m309/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8658 - auc: 0.9490 - loss: 0.3029\n","Epoch 74: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8657 - auc: 0.9489 - loss: 0.3032 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.1819\n","Epoch 75/100\n","\u001b[1m308/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8799 - auc: 0.9643 - loss: 0.2768\n","Epoch 75: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8789 - auc: 0.9633 - loss: 0.2786 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.1955\n","Epoch 76/100\n","\u001b[1m313/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8498 - auc: 0.9433 - loss: 0.3197\n","Epoch 76: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8505 - auc: 0.9436 - loss: 0.3189 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.2131\n","Epoch 77/100\n","\u001b[1m310/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8738 - auc: 0.9662 - loss: 0.2783\n","Epoch 77: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8732 - auc: 0.9650 - loss: 0.2798 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.2295\n","Epoch 78/100\n","\u001b[1m316/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8606 - auc: 0.9541 - loss: 0.2993\n","Epoch 78: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8608 - auc: 0.9538 - loss: 0.2995 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.2428\n","Epoch 79/100\n","\u001b[1m316/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8610 - auc: 0.9479 - loss: 0.3006\n","Epoch 79: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8610 - auc: 0.9478 - loss: 0.3009 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.2525\n","Epoch 80/100\n","\u001b[1m313/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8618 - auc: 0.9426 - loss: 0.3002\n","Epoch 80: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8618 - auc: 0.9429 - loss: 0.3003 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.2709\n","Epoch 81/100\n","\u001b[1m311/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8567 - auc: 0.9477 - loss: 0.3019\n","Epoch 81: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8571 - auc: 0.9478 - loss: 0.3016 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.2875\n","Epoch 82/100\n","\u001b[1m315/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8765 - auc: 0.9591 - loss: 0.2744\n","Epoch 82: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8758 - auc: 0.9584 - loss: 0.2757 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.2978\n","Epoch 83/100\n","\u001b[1m311/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8784 - auc: 0.9431 - loss: 0.2906\n","Epoch 83: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8774 - auc: 0.9434 - loss: 0.2909 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.3062\n","Epoch 84/100\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8643 - auc: 0.9327 - loss: 0.3076\n","Epoch 84: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8643 - auc: 0.9328 - loss: 0.3075 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.3194\n","Epoch 85/100\n","\u001b[1m308/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8671 - auc: 0.9241 - loss: 0.3016\n","Epoch 85: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8669 - auc: 0.9256 - loss: 0.3011 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.3343\n","Epoch 86/100\n","\u001b[1m313/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8500 - auc: 0.9358 - loss: 0.3149\n","Epoch 86: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8506 - auc: 0.9364 - loss: 0.3138 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.3445\n","Epoch 87/100\n","\u001b[1m313/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8547 - auc: 0.9461 - loss: 0.3084\n","Epoch 87: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8552 - auc: 0.9460 - loss: 0.3076 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.3571\n","Epoch 88/100\n","\u001b[1m312/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8684 - auc: 0.9529 - loss: 0.2871\n","Epoch 88: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8680 - auc: 0.9523 - loss: 0.2875 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.3653\n","Epoch 89/100\n","\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8590 - auc: 0.9454 - loss: 0.2988\n","Epoch 89: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8591 - auc: 0.9454 - loss: 0.2988 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.3763\n","Epoch 90/100\n","\u001b[1m308/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8745 - auc: 0.9713 - loss: 0.2561\n","Epoch 90: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8737 - auc: 0.9696 - loss: 0.2583 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.3889\n","Epoch 91/100\n","\u001b[1m311/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8797 - auc: 0.9549 - loss: 0.2697\n","Epoch 91: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8787 - auc: 0.9543 - loss: 0.2710 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.3916\n","Epoch 92/100\n","\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8527 - auc: 0.9306 - loss: 0.3098\n","Epoch 92: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8528 - auc: 0.9306 - loss: 0.3097 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.4084\n","Epoch 93/100\n","\u001b[1m306/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8584 - auc: 0.9463 - loss: 0.2903\n","Epoch 93: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8588 - auc: 0.9460 - loss: 0.2902 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.4176\n","Epoch 94/100\n","\u001b[1m313/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8694 - auc: 0.9631 - loss: 0.2666\n","Epoch 94: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8690 - auc: 0.9620 - loss: 0.2677 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.4277\n","Epoch 95/100\n","\u001b[1m310/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8582 - auc: 0.9229 - loss: 0.3082\n","Epoch 95: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8585 - auc: 0.9242 - loss: 0.3068 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.4376\n","Epoch 96/100\n","\u001b[1m311/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8776 - auc: 0.9654 - loss: 0.2568\n","Epoch 96: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8767 - auc: 0.9642 - loss: 0.2585 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.4389\n","Epoch 97/100\n","\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8389 - auc: 0.9529 - loss: 0.3019\n","Epoch 97: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8392 - auc: 0.9528 - loss: 0.3017 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.4556\n","Epoch 98/100\n","\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8543 - auc: 0.9360 - loss: 0.2969\n","Epoch 98: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8546 - auc: 0.9363 - loss: 0.2964 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.4627\n","Epoch 99/100\n","\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8678 - auc: 0.9393 - loss: 0.2855\n","Epoch 99: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8676 - auc: 0.9394 - loss: 0.2854 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.4713\n","Epoch 100/100\n","\u001b[1m307/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8559 - auc: 0.9347 - loss: 0.2957\n","Epoch 100: val_loss did not improve from 0.61243\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8563 - auc: 0.9353 - loss: 0.2949 - val_acc: 0.3475 - val_auc: 0.0000e+00 - val_loss: 2.4827\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 13 | VAL  | AUC=1.0000 | ACC=0.6525 | n=118\n","Fold 13 | TEST | AUC=0.0000 | ACC=0.5185 | n=81\n","\n","--- Fold 14/14 ---\n"," train | ids:   36 | files:  929 | pos:  319 | neg:  610\n","   val | ids:    4 | files:  118 | pos:   77 | neg:   41\n","  test | ids:    3 | files:  143 | pos:    9 | neg:  134\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 4))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.6469 - auc: 0.4874 - loss: 0.6717\n","Epoch 1: val_loss improved from inf to 0.65379, saving model to best_tab_only_fold14.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - acc: 0.6470 - auc: 0.4880 - loss: 0.6716 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.6538\n","Epoch 2/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6303 - auc: 0.5905 - loss: 0.6636\n","Epoch 2: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6304 - auc: 0.5906 - loss: 0.6636 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.6636\n","Epoch 3/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6596 - auc: 0.5982 - loss: 0.6374\n","Epoch 3: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6597 - auc: 0.5984 - loss: 0.6373 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.6741\n","Epoch 4/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7041 - auc: 0.7303 - loss: 0.6233\n","Epoch 4: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7060 - auc: 0.7312 - loss: 0.6224 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.6867\n","Epoch 5/100\n","\u001b[1m289/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7167 - auc: 0.7183 - loss: 0.6068\n","Epoch 5: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7174 - auc: 0.7198 - loss: 0.6064 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.6985\n","Epoch 6/100\n","\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8121 - auc: 0.7669 - loss: 0.5746\n","Epoch 6: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8121 - auc: 0.7664 - loss: 0.5749 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.7104\n","Epoch 7/100\n","\u001b[1m302/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8522 - auc: 0.7310 - loss: 0.5798\n","Epoch 7: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.8522 - auc: 0.7312 - loss: 0.5796 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.7225\n","Epoch 8/100\n","\u001b[1m296/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8657 - auc: 0.7335 - loss: 0.5546\n","Epoch 8: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8652 - auc: 0.7339 - loss: 0.5548 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.7346\n","Epoch 9/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8536 - auc: 0.7263 - loss: 0.5503\n","Epoch 9: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8535 - auc: 0.7276 - loss: 0.5501 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.7459\n","Epoch 10/100\n","\u001b[1m304/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8739 - auc: 0.7782 - loss: 0.5181\n","Epoch 10: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8734 - auc: 0.7774 - loss: 0.5185 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.7570\n","Epoch 11/100\n","\u001b[1m306/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8483 - auc: 0.7262 - loss: 0.5282\n","Epoch 11: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8483 - auc: 0.7264 - loss: 0.5281 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.7668\n","Epoch 12/100\n","\u001b[1m303/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8676 - auc: 0.7528 - loss: 0.5062\n","Epoch 12: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8672 - auc: 0.7524 - loss: 0.5065 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.7757\n","Epoch 13/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8478 - auc: 0.7224 - loss: 0.5100\n","Epoch 13: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8478 - auc: 0.7225 - loss: 0.5099 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.7855\n","Epoch 14/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8733 - auc: 0.7444 - loss: 0.4784\n","Epoch 14: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8732 - auc: 0.7444 - loss: 0.4785 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.7937\n","Epoch 15/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8667 - auc: 0.7611 - loss: 0.4752\n","Epoch 15: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8656 - auc: 0.7593 - loss: 0.4767 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8002\n","Epoch 16/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8553 - auc: 0.7456 - loss: 0.4901\n","Epoch 16: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8550 - auc: 0.7452 - loss: 0.4900 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8069\n","Epoch 17/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8548 - auc: 0.7484 - loss: 0.4777\n","Epoch 17: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8548 - auc: 0.7482 - loss: 0.4778 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8135\n","Epoch 18/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8492 - auc: 0.7367 - loss: 0.4831\n","Epoch 18: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8494 - auc: 0.7372 - loss: 0.4826 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8188\n","Epoch 19/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8695 - auc: 0.7668 - loss: 0.4505\n","Epoch 19: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8694 - auc: 0.7666 - loss: 0.4507 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8239\n","Epoch 20/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8464 - auc: 0.7474 - loss: 0.4743\n","Epoch 20: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8465 - auc: 0.7473 - loss: 0.4742 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8293\n","Epoch 21/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8373 - auc: 0.7146 - loss: 0.4849\n","Epoch 21: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8384 - auc: 0.7170 - loss: 0.4832 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8334\n","Epoch 22/100\n","\u001b[1m304/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8620 - auc: 0.7464 - loss: 0.4460\n","Epoch 22: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8618 - auc: 0.7464 - loss: 0.4463 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8377\n","Epoch 23/100\n","\u001b[1m306/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8498 - auc: 0.7383 - loss: 0.4571\n","Epoch 23: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8498 - auc: 0.7385 - loss: 0.4570 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8408\n","Epoch 24/100\n","\u001b[1m296/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8515 - auc: 0.7162 - loss: 0.4519\n","Epoch 24: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8515 - auc: 0.7175 - loss: 0.4519 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8438\n","Epoch 25/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8754 - auc: 0.7691 - loss: 0.4171\n","Epoch 25: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8740 - auc: 0.7683 - loss: 0.4188 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8474\n","Epoch 26/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8428 - auc: 0.7532 - loss: 0.4551\n","Epoch 26: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8435 - auc: 0.7545 - loss: 0.4540 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8494\n","Epoch 27/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8653 - auc: 0.7916 - loss: 0.4216\n","Epoch 27: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8643 - auc: 0.7912 - loss: 0.4227 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8523\n","Epoch 28/100\n","\u001b[1m289/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8439 - auc: 0.7784 - loss: 0.4461\n","Epoch 28: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8446 - auc: 0.7794 - loss: 0.4450 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8551\n","Epoch 29/100\n","\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8649 - auc: 0.8118 - loss: 0.4140\n","Epoch 29: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8647 - auc: 0.8115 - loss: 0.4142 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8570\n","Epoch 30/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8478 - auc: 0.7936 - loss: 0.4333\n","Epoch 30: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8479 - auc: 0.7936 - loss: 0.4332 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8590\n","Epoch 31/100\n","\u001b[1m289/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8677 - auc: 0.8236 - loss: 0.3943\n","Epoch 31: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8669 - auc: 0.8219 - loss: 0.3959 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8600\n","Epoch 32/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8711 - auc: 0.7980 - loss: 0.3962\n","Epoch 32: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8699 - auc: 0.7979 - loss: 0.3977 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8611\n","Epoch 33/100\n","\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8666 - auc: 0.8172 - loss: 0.3927\n","Epoch 33: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8663 - auc: 0.8168 - loss: 0.3931 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8617\n","Epoch 34/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8539 - auc: 0.8049 - loss: 0.4093\n","Epoch 34: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8540 - auc: 0.8042 - loss: 0.4092 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8632\n","Epoch 35/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8225 - auc: 0.7840 - loss: 0.4452\n","Epoch 35: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8248 - auc: 0.7847 - loss: 0.4425 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8639\n","Epoch 36/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8383 - auc: 0.7910 - loss: 0.4214\n","Epoch 36: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8394 - auc: 0.7917 - loss: 0.4200 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8654\n","Epoch 37/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8505 - auc: 0.8112 - loss: 0.3979\n","Epoch 37: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8505 - auc: 0.8111 - loss: 0.3979 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8668\n","Epoch 38/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8339 - auc: 0.7806 - loss: 0.4289\n","Epoch 38: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8357 - auc: 0.7822 - loss: 0.4262 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8685\n","Epoch 39/100\n","\u001b[1m303/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8511 - auc: 0.7791 - loss: 0.4046\n","Epoch 39: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8512 - auc: 0.7796 - loss: 0.4044 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8682\n","Epoch 40/100\n","\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8459 - auc: 0.8004 - loss: 0.4007\n","Epoch 40: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8460 - auc: 0.8003 - loss: 0.4006 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8689\n","Epoch 41/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8538 - auc: 0.7949 - loss: 0.3923\n","Epoch 41: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8538 - auc: 0.7949 - loss: 0.3923 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8688\n","Epoch 42/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8590 - auc: 0.8165 - loss: 0.3767\n","Epoch 42: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8584 - auc: 0.8150 - loss: 0.3779 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8687\n","Epoch 43/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8485 - auc: 0.7874 - loss: 0.3946\n","Epoch 43: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8485 - auc: 0.7875 - loss: 0.3945 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8689\n","Epoch 44/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8435 - auc: 0.7815 - loss: 0.4017\n","Epoch 44: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8435 - auc: 0.7816 - loss: 0.4017 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8695\n","Epoch 45/100\n","\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8586 - auc: 0.8168 - loss: 0.3722\n","Epoch 45: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8586 - auc: 0.8165 - loss: 0.3724 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8709\n","Epoch 46/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8629 - auc: 0.8090 - loss: 0.3660\n","Epoch 46: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8629 - auc: 0.8090 - loss: 0.3661 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8685\n","Epoch 47/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8639 - auc: 0.8229 - loss: 0.3647\n","Epoch 47: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8639 - auc: 0.8229 - loss: 0.3647 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8712\n","Epoch 48/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8416 - auc: 0.7993 - loss: 0.3948\n","Epoch 48: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8418 - auc: 0.7994 - loss: 0.3945 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8709\n","Epoch 49/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8626 - auc: 0.8344 - loss: 0.3555\n","Epoch 49: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8625 - auc: 0.8342 - loss: 0.3556 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8713\n","Epoch 50/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8658 - auc: 0.8203 - loss: 0.3602\n","Epoch 50: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8647 - auc: 0.8194 - loss: 0.3614 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8714\n","Epoch 51/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8359 - auc: 0.8021 - loss: 0.3977\n","Epoch 51: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8374 - auc: 0.8027 - loss: 0.3956 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8729\n","Epoch 52/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8565 - auc: 0.8322 - loss: 0.3621\n","Epoch 52: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8565 - auc: 0.8319 - loss: 0.3622 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8729\n","Epoch 53/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8451 - auc: 0.8000 - loss: 0.3815\n","Epoch 53: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8457 - auc: 0.8007 - loss: 0.3807 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8734\n","Epoch 54/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8571 - auc: 0.8311 - loss: 0.3546\n","Epoch 54: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8570 - auc: 0.8309 - loss: 0.3547 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8738\n","Epoch 55/100\n","\u001b[1m301/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8447 - auc: 0.7913 - loss: 0.3823\n","Epoch 55: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8450 - auc: 0.7920 - loss: 0.3817 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8752\n","Epoch 56/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8668 - auc: 0.8293 - loss: 0.3440\n","Epoch 56: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8667 - auc: 0.8292 - loss: 0.3442 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8752\n","Epoch 57/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8272 - auc: 0.7931 - loss: 0.3960\n","Epoch 57: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8287 - auc: 0.7941 - loss: 0.3942 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8756\n","Epoch 58/100\n","\u001b[1m289/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8688 - auc: 0.8275 - loss: 0.3390\n","Epoch 58: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8676 - auc: 0.8263 - loss: 0.3408 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8757\n","Epoch 59/100\n","\u001b[1m289/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8577 - auc: 0.8184 - loss: 0.3533\n","Epoch 59: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8573 - auc: 0.8181 - loss: 0.3538 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8761\n","Epoch 60/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8577 - auc: 0.8078 - loss: 0.3601\n","Epoch 60: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8574 - auc: 0.8084 - loss: 0.3599 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8773\n","Epoch 61/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8569 - auc: 0.8237 - loss: 0.3513\n","Epoch 61: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8567 - auc: 0.8232 - loss: 0.3518 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8782\n","Epoch 62/100\n","\u001b[1m291/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8389 - auc: 0.7831 - loss: 0.3814\n","Epoch 62: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8399 - auc: 0.7851 - loss: 0.3798 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8803\n","Epoch 63/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8399 - auc: 0.8131 - loss: 0.3728\n","Epoch 63: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8410 - auc: 0.8141 - loss: 0.3714 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8828\n","Epoch 64/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8482 - auc: 0.8358 - loss: 0.3636\n","Epoch 64: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8486 - auc: 0.8359 - loss: 0.3629 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8834\n","Epoch 65/100\n","\u001b[1m302/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8601 - auc: 0.8543 - loss: 0.3520\n","Epoch 65: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8599 - auc: 0.8549 - loss: 0.3520 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8848\n","Epoch 66/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8532 - auc: 0.8902 - loss: 0.3437\n","Epoch 66: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8531 - auc: 0.8897 - loss: 0.3444 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8861\n","Epoch 67/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8309 - auc: 0.9064 - loss: 0.3720\n","Epoch 67: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8328 - auc: 0.9065 - loss: 0.3700 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8894\n","Epoch 68/100\n","\u001b[1m300/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8648 - auc: 0.9265 - loss: 0.3334\n","Epoch 68: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8644 - auc: 0.9262 - loss: 0.3340 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8913\n","Epoch 69/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8639 - auc: 0.9259 - loss: 0.3302\n","Epoch 69: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8638 - auc: 0.9259 - loss: 0.3303 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8875\n","Epoch 70/100\n","\u001b[1m306/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8487 - auc: 0.9111 - loss: 0.3444\n","Epoch 70: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8488 - auc: 0.9112 - loss: 0.3444 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8892\n","Epoch 71/100\n","\u001b[1m302/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8515 - auc: 0.9342 - loss: 0.3331\n","Epoch 71: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8515 - auc: 0.9337 - loss: 0.3333 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.8963\n","Epoch 72/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8575 - auc: 0.9257 - loss: 0.3286\n","Epoch 72: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8575 - auc: 0.9256 - loss: 0.3287 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.9055\n","Epoch 73/100\n","\u001b[1m289/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8688 - auc: 0.9356 - loss: 0.3197\n","Epoch 73: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8680 - auc: 0.9347 - loss: 0.3206 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.9141\n","Epoch 74/100\n","\u001b[1m289/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8432 - auc: 0.9393 - loss: 0.3426\n","Epoch 74: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8440 - auc: 0.9381 - loss: 0.3420 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.9214\n","Epoch 75/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8721 - auc: 0.9312 - loss: 0.3100\n","Epoch 75: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8709 - auc: 0.9305 - loss: 0.3116 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.9282\n","Epoch 76/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8511 - auc: 0.9275 - loss: 0.3307\n","Epoch 76: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8512 - auc: 0.9275 - loss: 0.3307 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.9352\n","Epoch 77/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8465 - auc: 0.9130 - loss: 0.3410\n","Epoch 77: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8465 - auc: 0.9130 - loss: 0.3410 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.9436\n","Epoch 78/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8588 - auc: 0.9348 - loss: 0.3201\n","Epoch 78: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8583 - auc: 0.9336 - loss: 0.3211 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.9496\n","Epoch 79/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8652 - auc: 0.9303 - loss: 0.3092\n","Epoch 79: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8652 - auc: 0.9303 - loss: 0.3092 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.9560\n","Epoch 80/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8519 - auc: 0.9122 - loss: 0.3322\n","Epoch 80: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8519 - auc: 0.9122 - loss: 0.3322 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.9624\n","Epoch 81/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8696 - auc: 0.9235 - loss: 0.3052\n","Epoch 81: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8694 - auc: 0.9235 - loss: 0.3054 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.9688\n","Epoch 82/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8629 - auc: 0.9162 - loss: 0.3186\n","Epoch 82: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8628 - auc: 0.9162 - loss: 0.3186 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.9747\n","Epoch 83/100\n","\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8521 - auc: 0.9124 - loss: 0.3338\n","Epoch 83: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8522 - auc: 0.9125 - loss: 0.3336 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.9800\n","Epoch 84/100\n","\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8641 - auc: 0.9321 - loss: 0.3023\n","Epoch 84: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8639 - auc: 0.9318 - loss: 0.3028 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.9874\n","Epoch 85/100\n","\u001b[1m303/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8526 - auc: 0.9148 - loss: 0.3261\n","Epoch 85: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8526 - auc: 0.9149 - loss: 0.3261 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 0.9933\n","Epoch 86/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8657 - auc: 0.9325 - loss: 0.3044\n","Epoch 86: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8656 - auc: 0.9323 - loss: 0.3046 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0014\n","Epoch 87/100\n","\u001b[1m296/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8507 - auc: 0.9154 - loss: 0.3252\n","Epoch 87: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8509 - auc: 0.9156 - loss: 0.3248 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0060\n","Epoch 88/100\n","\u001b[1m299/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8301 - auc: 0.9135 - loss: 0.3455\n","Epoch 88: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8309 - auc: 0.9135 - loss: 0.3445 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0157\n","Epoch 89/100\n","\u001b[1m284/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8679 - auc: 0.9075 - loss: 0.3005\n","Epoch 89: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8668 - auc: 0.9083 - loss: 0.3018 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0222\n","Epoch 90/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8576 - auc: 0.9153 - loss: 0.3129\n","Epoch 90: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8576 - auc: 0.9153 - loss: 0.3129 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0286\n","Epoch 91/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8531 - auc: 0.9252 - loss: 0.3104\n","Epoch 91: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8531 - auc: 0.9252 - loss: 0.3104 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0359\n","Epoch 92/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8550 - auc: 0.9204 - loss: 0.3108\n","Epoch 92: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8549 - auc: 0.9199 - loss: 0.3110 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0427\n","Epoch 93/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8477 - auc: 0.9066 - loss: 0.3225\n","Epoch 93: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8481 - auc: 0.9075 - loss: 0.3216 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0486\n","Epoch 94/100\n","\u001b[1m284/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8232 - auc: 0.8981 - loss: 0.3530\n","Epoch 94: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8258 - auc: 0.8999 - loss: 0.3492 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0552\n","Epoch 95/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8482 - auc: 0.9224 - loss: 0.3123\n","Epoch 95: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8485 - auc: 0.9218 - loss: 0.3121 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0663\n","Epoch 96/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8615 - auc: 0.9183 - loss: 0.2974\n","Epoch 96: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8611 - auc: 0.9183 - loss: 0.2979 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0704\n","Epoch 97/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8558 - auc: 0.9079 - loss: 0.3055\n","Epoch 97: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8558 - auc: 0.9080 - loss: 0.3055 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0779\n","Epoch 98/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8598 - auc: 0.9138 - loss: 0.2985\n","Epoch 98: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8594 - auc: 0.9142 - loss: 0.2987 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0877\n","Epoch 99/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8690 - auc: 0.9226 - loss: 0.2857\n","Epoch 99: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8677 - auc: 0.9221 - loss: 0.2871 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.0936\n","Epoch 100/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8551 - auc: 0.9066 - loss: 0.2998\n","Epoch 100: val_loss did not improve from 0.65379\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8551 - auc: 0.9078 - loss: 0.2997 - val_acc: 0.3475 - val_auc: 1.0000 - val_loss: 1.1015\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 14 | VAL  | AUC=1.0000 | ACC=0.3475 | n=118\n","Fold 14 | TEST | AUC=0.0000 | ACC=0.9371 | n=143\n","\n","Per-fold VAL  AUCs: [np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(0.4615), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.7516), np.float64(0.72), np.float64(0.904), np.float64(1.0), np.float64(1.0)]\n","Per-fold VAL  ACCs: [0.3186, 0.6525, 0.6468, 0.4031, 0.6709, 1.0, 0.6709, 0.628, 0.6709, 0.6709, 0.6188, 0.6188, 0.6525, 0.3475]\n","Per-fold TEST AUCs: [np.float64(0.0805), np.float64(1.0), np.float64(0.8), np.float64(0.2449), np.float64(1.0), np.float64(0.0385), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(0.85), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0)]\n","Per-fold TEST ACCs: [0.9721, 0.7105, 0.8537, 0.5904, 0.8333, 0.2524, 0.9375, 1.0, 1.0, 0.9524, 0.5529, 1.0, 0.5185, 0.9371]\n","\n","VAL  AUC: 0.8455 ± 0.2810 | ACC: 0.6122 ± 0.1623\n","TEST AUC: 0.5010 ± 0.4564 | ACC: 0.7936 ± 0.2246\n","\n","Saved metrics to cv_tabonly_fold_metrics.csv and ROC plots to roc_val_fold_XX.png / roc_test_fold_XX.png\n"]}]},{"cell_type":"code","source":["rows"],"metadata":{"id":"KUgcBvQhpHVE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760666880042,"user_tz":300,"elapsed":1189,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"outputId":"1fec9e76-67a5-4169-d7cd-c383b4dfb7e9"},"id":"KUgcBvQhpHVE","execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'fold': 1,\n","  'train_files': 898,\n","  'val_files': 113,\n","  'test_files': 179,\n","  'val_auc': np.float64(0.0),\n","  'val_acc': 0.3185840707964602,\n","  'test_auc': np.float64(0.08045977011494254),\n","  'test_acc': 0.9720670391061452},\n"," {'fold': 2,\n","  'train_files': 958,\n","  'val_files': 118,\n","  'test_files': 114,\n","  'val_auc': np.float64(1.0),\n","  'val_acc': 0.652542372881356,\n","  'test_auc': np.float64(1.0),\n","  'test_acc': 0.7105263157894737},\n"," {'fold': 3,\n","  'train_files': 931,\n","  'val_files': 218,\n","  'test_files': 41,\n","  'val_auc': np.float64(1.0),\n","  'val_acc': 0.6467889908256881,\n","  'test_auc': np.float64(0.8),\n","  'test_acc': 0.8536585365853658},\n"," {'fold': 4,\n","  'train_files': 978,\n","  'val_files': 129,\n","  'test_files': 83,\n","  'val_auc': np.float64(0.46153846153846156),\n","  'val_acc': 0.40310077519379844,\n","  'test_auc': np.float64(0.24489795918367352),\n","  'test_acc': 0.5903614457831325},\n"," {'fold': 5,\n","  'train_files': 932,\n","  'val_files': 234,\n","  'test_files': 24,\n","  'val_auc': np.float64(1.0),\n","  'val_acc': 0.6709401709401709,\n","  'test_auc': np.float64(1.0),\n","  'test_acc': 0.8333333333333334},\n"," {'fold': 6,\n","  'train_files': 987,\n","  'val_files': 100,\n","  'test_files': 103,\n","  'val_auc': np.float64(1.0),\n","  'val_acc': 1.0,\n","  'test_auc': np.float64(0.038461538461538436),\n","  'test_acc': 0.2524271844660194},\n"," {'fold': 7,\n","  'train_files': 940,\n","  'val_files': 234,\n","  'test_files': 16,\n","  'val_auc': np.float64(1.0),\n","  'val_acc': 0.6709401709401709,\n","  'test_auc': np.float64(0.0),\n","  'test_acc': 0.9375},\n"," {'fold': 8,\n","  'train_files': 930,\n","  'val_files': 207,\n","  'test_files': 53,\n","  'val_auc': np.float64(1.0),\n","  'val_acc': 0.6280193236714976,\n","  'test_auc': np.float64(1.0),\n","  'test_acc': 1.0},\n"," {'fold': 9,\n","  'train_files': 867,\n","  'val_files': 234,\n","  'test_files': 89,\n","  'val_auc': np.float64(1.0),\n","  'val_acc': 0.6709401709401709,\n","  'test_auc': np.float64(1.0),\n","  'test_acc': 1.0},\n"," {'fold': 10,\n","  'train_files': 935,\n","  'val_files': 234,\n","  'test_files': 21,\n","  'val_auc': np.float64(0.7515923566878981),\n","  'val_acc': 0.6709401709401709,\n","  'test_auc': np.float64(0.85),\n","  'test_acc': 0.9523809523809523},\n"," {'fold': 11,\n","  'train_files': 903,\n","  'val_files': 202,\n","  'test_files': 85,\n","  'val_auc': np.float64(0.72),\n","  'val_acc': 0.6188118811881188,\n","  'test_auc': np.float64(0.0),\n","  'test_acc': 0.5529411764705883},\n"," {'fold': 12,\n","  'train_files': 830,\n","  'val_files': 202,\n","  'test_files': 158,\n","  'val_auc': np.float64(0.904),\n","  'val_acc': 0.6188118811881188,\n","  'test_auc': np.float64(1.0),\n","  'test_acc': 1.0},\n"," {'fold': 13,\n","  'train_files': 991,\n","  'val_files': 118,\n","  'test_files': 81,\n","  'val_auc': np.float64(1.0),\n","  'val_acc': 0.652542372881356,\n","  'test_auc': np.float64(0.0),\n","  'test_acc': 0.5185185185185185},\n"," {'fold': 14,\n","  'train_files': 929,\n","  'val_files': 118,\n","  'test_files': 143,\n","  'val_auc': np.float64(1.0),\n","  'val_acc': 0.3474576271186441,\n","  'test_auc': np.float64(0.0),\n","  'test_acc': 0.9370629370629371}]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["test_auc = np.array([r[\"test_auc\"] for r in rows], dtype=float)\n","test_acc = np.array([r[\"test_acc\"] for r in rows], dtype=float)\n","\n","print(f\"Mean TEST AUC: {np.nanmean(test_auc):.4f}\")\n","print(f\"Mean TEST ACC: {np.nanmean(test_acc):.4f}\")"],"metadata":{"id":"sPOzCNAug4NW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760666880054,"user_tz":300,"elapsed":10,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"outputId":"8cfcc473-8796-494a-b926-5cd9a7d224d9"},"id":"sPOzCNAug4NW","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean TEST AUC: 0.5010\n","Mean TEST ACC: 0.7936\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xxOkMiS4g4SL","executionInfo":{"status":"ok","timestamp":1760666880058,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"xxOkMiS4g4SL","execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":8,"id":"ksQMstdc-o-3","metadata":{"id":"ksQMstdc-o-3","executionInfo":{"status":"ok","timestamp":1760666880062,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"JSdB6j-a-pDF","metadata":{"id":"JSdB6j-a-pDF","executionInfo":{"status":"ok","timestamp":1760666880068,"user_tz":300,"elapsed":4,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"U7ouQnxD-pF_","metadata":{"id":"U7ouQnxD-pF_","executionInfo":{"status":"ok","timestamp":1760666880071,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"WnjxgEPK-pIJ","metadata":{"id":"WnjxgEPK-pIJ","executionInfo":{"status":"ok","timestamp":1760666880075,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"j28g8Lqp-pKy","metadata":{"id":"j28g8Lqp-pKy","executionInfo":{"status":"ok","timestamp":1760666880080,"user_tz":300,"elapsed":4,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"DJbv-4-G-pMn","metadata":{"id":"DJbv-4-G-pMn","executionInfo":{"status":"ok","timestamp":1760666880086,"user_tz":300,"elapsed":8,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"Cxtz-1Fo-pPP","metadata":{"id":"Cxtz-1Fo-pPP","executionInfo":{"status":"ok","timestamp":1760666880088,"user_tz":300,"elapsed":4,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"JinSNJgh-pRf","metadata":{"id":"JinSNJgh-pRf","executionInfo":{"status":"ok","timestamp":1760666880091,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"ywg21ljv-pcL","metadata":{"id":"ywg21ljv-pcL","executionInfo":{"status":"ok","timestamp":1760666880092,"user_tz":300,"elapsed":0,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"Jl01Xhpa-pfL","metadata":{"id":"Jl01Xhpa-pfL","executionInfo":{"status":"ok","timestamp":1760666880094,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"ErNrKHRm-pg_","metadata":{"id":"ErNrKHRm-pg_","executionInfo":{"status":"ok","timestamp":1760666880099,"user_tz":300,"elapsed":3,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"IElgvqQj-pit","metadata":{"id":"IElgvqQj-pit","executionInfo":{"status":"ok","timestamp":1760666880104,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"-TADzyG9-pnO","metadata":{"id":"-TADzyG9-pnO","executionInfo":{"status":"ok","timestamp":1760666880107,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"miiDblbz-ppC","metadata":{"id":"miiDblbz-ppC","executionInfo":{"status":"ok","timestamp":1760666880111,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"Bnp7fHxm-pqu","metadata":{"id":"Bnp7fHxm-pqu","executionInfo":{"status":"ok","timestamp":1760666880114,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"UiQbsLv47Xu-","metadata":{"id":"UiQbsLv47Xu-","executionInfo":{"status":"ok","timestamp":1760666880119,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"hhAiYZZVGIsM","metadata":{"id":"hhAiYZZVGIsM","executionInfo":{"status":"ok","timestamp":1760666880122,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"EWQ7UG7zGIuj","metadata":{"id":"EWQ7UG7zGIuj","executionInfo":{"status":"ok","timestamp":1760666880126,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"hUObArfBGIw5","metadata":{"id":"hUObArfBGIw5","executionInfo":{"status":"ok","timestamp":1760666880129,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"ln5ftwRAGI0C","metadata":{"id":"ln5ftwRAGI0C","executionInfo":{"status":"ok","timestamp":1760666880135,"user_tz":300,"elapsed":4,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"jgczkpH8GI2s","metadata":{"id":"jgczkpH8GI2s","executionInfo":{"status":"ok","timestamp":1760666880138,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"CFxtsYm4DJxo","metadata":{"id":"CFxtsYm4DJxo","executionInfo":{"status":"ok","timestamp":1760666880167,"user_tz":300,"elapsed":27,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"zIo_rXgnDJzw","metadata":{"id":"zIo_rXgnDJzw","executionInfo":{"status":"ok","timestamp":1760666880172,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"N4iBf4B0DJ14","metadata":{"id":"N4iBf4B0DJ14","executionInfo":{"status":"ok","timestamp":1760666880175,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"mGuWgjhCDJ5y","metadata":{"id":"mGuWgjhCDJ5y","executionInfo":{"status":"ok","timestamp":1760666880183,"user_tz":300,"elapsed":6,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"mtPQw2LIDJ8A","metadata":{"id":"mtPQw2LIDJ8A","executionInfo":{"status":"ok","timestamp":1760666880187,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"VRIqcx7HDJ9m","metadata":{"id":"VRIqcx7HDJ9m","executionInfo":{"status":"ok","timestamp":1760666880191,"user_tz":300,"elapsed":2,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"id":"HfhdGuLEDJ_u","metadata":{"id":"HfhdGuLEDJ_u","executionInfo":{"status":"ok","timestamp":1760666880194,"user_tz":300,"elapsed":1,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"virtual ENV","language":"python","name":"environment_instance"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":5}