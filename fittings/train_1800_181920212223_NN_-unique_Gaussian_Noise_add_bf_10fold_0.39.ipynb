{"cells":[{"cell_type":"code","execution_count":null,"id":"8f5a4f5b-bad9-49e3-8dd6-7304666df443","metadata":{"id":"8f5a4f5b-bad9-49e3-8dd6-7304666df443"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","import torchvision\n","import torchvision.transforms as transforms\n","import os\n","import argparse\n","from pathlib import Path\n","import re\n","import random\n","import math\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"dr2Fm7p5mAAN","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15673,"status":"ok","timestamp":1760498689044,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"},"user_tz":300},"id":"dr2Fm7p5mAAN","outputId":"517e4d19-dab2-448f-b094-01d58584accd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":[],"metadata":{"id":"gUHWAH8qdC05"},"id":"gUHWAH8qdC05","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L2wH-XagdC3h"},"id":"L2wH-XagdC3h","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Reading the BF data"],"metadata":{"id":"51Qe0XC1X2Ju"},"id":"51Qe0XC1X2Ju"},{"cell_type":"code","source":["bf_path = '/content/drive/MyDrive/ALL_CLEAN_DEIDEN_NAME AND ECMO DATA(Sheet1) (1) (version 2).csv'\n","cols = ['ID','weight', 'study_height', 'age_days', 'bsa', 'Reason for ECMO']\n","df = pd.read_csv(bf_path, usecols=cols)\n","\n","for col in ['weight', 'study_height', 'age_days', 'bsa']:\n","    s = pd.to_numeric(df[col], errors='coerce')\n","    mx = s.max(skipna=True)\n","    if pd.notna(mx) and mx != 0:\n","        df[col] = s / mx\n","    else:\n","        df[col] = s\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eI4st7P3X51D","executionInfo":{"status":"ok","timestamp":1760498690797,"user_tz":300,"elapsed":1746,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"outputId":"c9180a34-3459-4d61-b5c3-385d8af583f2"},"id":"eI4st7P3X51D","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   ID  age_days    weight  study_height       bsa Reason for ECMO\n","0   1  0.018213  0.042214      0.344538  0.128389        cardiac \n","1   2  0.072852  0.070000      0.431373  0.184992        cardiac \n","2   3  0.793776  0.403571      0.896359  0.640295         cardiac\n","3   4  0.000287  0.022786      0.268908  0.083332         cardiac\n","4   5  0.000287  0.023571      0.285714  0.087365     respiratory\n"]}]},{"cell_type":"code","source":["diag_clean = (\n","    df['Reason for ECMO']\n","      .astype('string')\n","      .str.strip()\n","      .str.replace(r'\\s+', ' ', regex=True)\n","      .fillna('Unknown')\n",")\n","\n","codes, uniques = pd.factorize(diag_clean, sort=True)\n","df['Reason for ECMO'] = codes.astype('int64')\n","diagnosis_mapping = {cat: int(i) for i, cat in enumerate(uniques)}\n","\n","# Peek\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6KRSpwpSX53j","executionInfo":{"status":"ok","timestamp":1760498690814,"user_tz":300,"elapsed":15,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"outputId":"6d70d604-7076-4c22-adbc-6d67706ad4bf"},"id":"6KRSpwpSX53j","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   ID  age_days    weight  study_height       bsa  Reason for ECMO\n","0   1  0.018213  0.042214      0.344538  0.128389                2\n","1   2  0.072852  0.070000      0.431373  0.184992                2\n","2   3  0.793776  0.403571      0.896359  0.640295                2\n","3   4  0.000287  0.022786      0.268908  0.083332                2\n","4   5  0.000287  0.023571      0.285714  0.087365                3\n"]}]},{"cell_type":"code","source":["df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5Jnj3X_X5_P","executionInfo":{"status":"ok","timestamp":1760498690829,"user_tz":300,"elapsed":13,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"outputId":"ccf17fae-da01-4948-ae8a-3d0b36b2b36e"},"id":"Z5Jnj3X_X5_P","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(73, 6)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":[],"metadata":{"id":"Z-Q3ZaH-X6EY"},"id":"Z-Q3ZaH-X6EY","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"REn1fKi1pHMT"},"id":"REn1fKi1pHMT","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### No normalization!"],"metadata":{"id":"vCi0eO54p2NW"},"id":"vCi0eO54p2NW"},{"cell_type":"code","source":["from pathlib import Path\n","import re, random, math, os\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.metrics import roc_auc_score\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# =========================\n","# Config\n","# =========================\n","SPLIT_DIR = r\"/content/drive/MyDrive/CD/patient_data_clean_nozero_181920212223_1800\"\n","POS_PATIENTS = {1, 2, 16, 19, 21, 22, 25, 37, 39, 43, 44, 47, 50, 56, 58, 62, 65, 66, 73, 78}\n","\n","BATCH_SIZE       = 3\n","EPOCHS           = 100\n","LR               = 1e-4\n","SEED             = 1\n","\n","# =========================\n","# Repro\n","# =========================\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n","for g in tf.config.list_physical_devices('GPU'):\n","    try: tf.config.experimental.set_memory_growth(g, True)\n","    except Exception: pass\n","\n","# =========================\n","# Helpers\n","# =========================\n","PATIENT_NUM_RX = re.compile(r'^ID(\\d+)')  # e.g., \"ID76-2_...\" -> 76\n","\n","def patient_num_from_path(pathlike):\n","    stem = Path(pathlike).stem\n","    m = PATIENT_NUM_RX.match(stem)\n","    return int(m.group(1)) if m else None\n","\n","def label_for_file(p: Path) -> int:\n","    pnum = patient_num_from_path(p)\n","    return 1 if (pnum is not None and pnum in POS_PATIENTS) else 0\n","\n","# =========================\n","# Load pre-existing 4-feature DataFrame: df (must be in memory)\n","# Must contain column 'ID' + exactly 4 feature columns.\n","# =========================\n","feats_df = df.copy()  # <-- uses your in-memory DataFrame\n","if \"ID\" not in feats_df.columns:\n","    raise RuntimeError(\"Your features DataFrame must contain column 'ID'.\")\n","\n","FEAT_COLS = [c for c in feats_df.columns if c != \"ID\"]\n","#if len(FEAT_COLS) != 4:\n","#    raise RuntimeError(f\"Expected exactly 4 feature columns besides 'ID', found {len(FEAT_COLS)}: {FEAT_COLS}\")\n","\n","# Clean and index by ID; drop rows with missing any of the 4 features\n","feats_df[\"ID\"] = pd.to_numeric(feats_df[\"ID\"], errors=\"coerce\").astype(\"Int64\")\n","feats_df = feats_df.dropna(subset=[\"ID\"] + FEAT_COLS).copy()\n","feats_df[\"ID\"] = feats_df[\"ID\"].astype(int)\n","\n","ID_TO_FEAT = {\n","    int(row[\"ID\"]): row[FEAT_COLS].astype(\"float32\").to_numpy()\n","    for _, row in feats_df.iterrows()\n","}\n","FEAT_DIM = len(FEAT_COLS)\n","print('FEAT_DIM =', FEAT_DIM)\n","\n","# =========================\n","# List EEG files ONLY to define splits by patient ID (no EEG is loaded)\n","# =========================\n","split_dir = Path(SPLIT_DIR)\n","all_csvs = sorted(split_dir.glob(\"*.csv\"))\n","if not all_csvs:\n","    raise FileNotFoundError(f\"No CSV found in {SPLIT_DIR}\")\n","\n","# Map: id -> list of files for that patient\n","id_to_files = {}\n","for f in all_csvs:\n","    pid = patient_num_from_path(f)\n","    if pid is None:\n","        continue\n","    id_to_files.setdefault(pid, []).append(f)\n","\n","all_ids = sorted(id_to_files.keys())\n","\n","# Use only IDs that have the required 4 features\n","valid_ids = [pid for pid in all_ids if pid in ID_TO_FEAT]\n","if not valid_ids:\n","    raise RuntimeError(\"No overlapping patient IDs between files and the 4-feature table.\")\n","if len(valid_ids) < len(all_ids):\n","    print(f\"Dropping {len(all_ids)-len(valid_ids)} patient IDs without 4-feature rows.\")\n","\n","labels_all = np.array([1 if pid in POS_PATIENTS else 0 for pid in valid_ids], dtype=int)\n","\n","print(\"Total valid IDs:\", len(valid_ids),\n","      \"| Pos IDs:\", labels_all.sum(),\n","      \"| Neg IDs:\", (1 - labels_all).sum())\n","\n","# =========================\n","# Data Sequence (tab-only)\n","# Each file becomes one sample with that patient's 4 features.\n","# =========================\n","class TabSequence(keras.utils.Sequence):\n","    def __init__(self, files, batch_size=BATCH_SIZE, shuffle=True):\n","        super().__init__()\n","        # Keep only files whose patient ID has 4 features\n","        self.files = [f for f in files if patient_num_from_path(f) in ID_TO_FEAT]\n","        self.batch_size = int(batch_size)\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        return math.ceil(len(self.files) / self.batch_size)\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.files))\n","        if self.shuffle:\n","            np.random.shuffle(self.indexes)\n","\n","    def __getitem__(self, idx):\n","        idxs = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n","        batch_files = [self.files[i] for i in idxs]\n","        B = len(batch_files)\n","\n","        X_tab = np.empty((B, FEAT_DIM), dtype=np.float32)\n","        y     = np.empty((B,), dtype=np.int32)\n","\n","        for i, f in enumerate(batch_files):\n","            pid = patient_num_from_path(f)\n","            X_tab[i] = ID_TO_FEAT[pid]      # (4,)\n","            y[i] = label_for_file(f)\n","\n","        return {\"tab_input\": X_tab}, y\n","\n","# =========================\n","# Tab-only Model: 4 -> 8 -> 8 -> 1\n","# =========================\n","def build_model(tab_dim=FEAT_DIM, lr=LR, dropout=0.2):\n","    tab_in = keras.Input(shape=(tab_dim,), name=\"tab_input\")\n","    t = layers.Dense(8, activation=\"relu\")(tab_in)\n","    t = layers.Dense(8, activation=\"relu\")(t)\n","    t = layers.Dropout(dropout)(t)\n","    out = layers.Dense(1, activation=\"sigmoid\")(t)\n","\n","    model = keras.Model(inputs=tab_in, outputs=out)\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(learning_rate=lr),\n","        loss=\"binary_crossentropy\",\n","        metrics=[keras.metrics.BinaryAccuracy(name=\"acc\"),\n","                 keras.metrics.AUC(name=\"auc\")],\n","    )\n","    return model\n","\n","# =========================\n","# 10-fold Cross-Validation by patient ID (stratified)\n","# =========================\n","skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n","\n","fold_aucs = []\n","for fold_idx, (train_index, test_index) in enumerate(skf.split(valid_ids, labels_all), start=1):\n","    ids_train_full = [valid_ids[i] for i in train_index]\n","    ids_test       = [valid_ids[i] for i in test_index]\n","\n","    # small validation split from training IDs (stratified, by ID)\n","    train_labels_full = np.array([1 if pid in POS_PATIENTS else 0 for pid in ids_train_full], dtype=int)\n","    ids_tr, ids_val = train_test_split(\n","        ids_train_full, test_size=0.10, random_state=SEED,\n","        stratify=train_labels_full\n","    )\n","\n","    # Build file lists for this fold\n","    train_files = [f for pid in ids_tr  for f in id_to_files[pid]]\n","    val_files   = [f for pid in ids_val for f in id_to_files[pid]]\n","    test_files  = [f for pid in ids_test for f in id_to_files[pid]]\n","\n","    print(f\"\\n--- Fold {fold_idx}/10 ---\")\n","    def split_summary_by_ids(name, ids, files):\n","        ys = np.array([label_for_file(f) for f in files], dtype=int)\n","        print(f\"{name:>6} | ids: {len(ids):4d} | files: {len(files):4d} | pos: {(ys==1).sum():4d} | neg: {(ys==0).sum():4d}\")\n","    split_summary_by_ids(\"train\", ids_tr,  train_files)\n","    split_summary_by_ids(\"val\",   ids_val, val_files)\n","    split_summary_by_ids(\"test\",  ids_test, test_files)\n","\n","    # Generators\n","    train_gen = TabSequence(train_files, batch_size=BATCH_SIZE, shuffle=True)\n","    val_gen   = TabSequence(val_files,   batch_size=BATCH_SIZE, shuffle=False)\n","\n","    # Model + training\n","    model = build_model()\n","    best_path = f\"best_tab_only_fold{fold_idx}.h5\"\n","    ckpt = keras.callbacks.ModelCheckpoint(\n","        best_path, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1\n","    )\n","\n","    history = model.fit(\n","        train_gen,\n","        validation_data=val_gen,\n","        epochs=EPOCHS,\n","        callbacks=[ckpt],\n","        verbose=1,\n","    )\n","\n","    # Evaluate on this fold's test set\n","    best_model = keras.models.load_model(best_path)\n","\n","    test_files2 = [f for f in test_files if patient_num_from_path(f) in ID_TO_FEAT]\n","    X_tab_test = np.empty((len(test_files2), FEAT_DIM), dtype=np.float32)\n","    for i, f in enumerate(test_files2):\n","        X_tab_test[i] = ID_TO_FEAT[patient_num_from_path(f)]\n","    y_true = np.array([label_for_file(f) for f in test_files2], dtype=int)\n","\n","    probs1 = best_model.predict({\"tab_input\": X_tab_test}, verbose=0).ravel().astype(float)\n","    try:\n","        auc = roc_auc_score(y_true, probs1)\n","    except ValueError:\n","        auc = float('nan')\n","\n","    fold_aucs.append(float(auc))\n","    print(f\"Fold {fold_idx} AUC: {auc:.4f}\")\n","\n","# =========================\n","# Results across folds\n","# =========================\n","print(\"\\nAUCs per fold:\", fold_aucs)\n","if len([a for a in fold_aucs if not np.isnan(a)]) > 0:\n","    print(f\"Mean AUC: {np.nanmean(fold_aucs):.4f} ± {np.nanstd(fold_aucs):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lD7pVdaPpHPi","outputId":"f96de1e1-6fae-4f82-f34e-48f2d9a41cfe","executionInfo":{"status":"ok","timestamp":1760499681301,"user_tz":300,"elapsed":869174,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"lD7pVdaPpHPi","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FEAT_DIM = 5\n","Total valid IDs: 44 | Pos IDs: 14 | Neg IDs: 30\n","\n","--- Fold 1/10 ---\n"," train | ids:   35 | files:  904 | pos:  318 | neg:  586\n","   val | ids:    4 | files:   42 | pos:    1 | neg:   41\n","  test | ids:    5 | files:  254 | pos:   86 | neg:  168\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 5))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m287/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.4206 - auc: 0.4503 - loss: 0.7065\n","Epoch 1: val_loss improved from inf to 0.65956, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - acc: 0.4188 - auc: 0.4488 - loss: 0.7066 - val_acc: 0.6905 - val_auc: 1.0000 - val_loss: 0.6596\n","Epoch 2/100\n","\u001b[1m289/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4586 - auc: 0.4124 - loss: 0.7008\n","Epoch 2: val_loss improved from 0.65956 to 0.64397, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.4621 - auc: 0.4140 - loss: 0.7005 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.6440\n","Epoch 3/100\n","\u001b[1m289/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5967 - auc: 0.4540 - loss: 0.6867\n","Epoch 3: val_loss improved from 0.64397 to 0.62979, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.5964 - auc: 0.4544 - loss: 0.6866 - val_acc: 0.9762 - val_auc: 1.0000 - val_loss: 0.6298\n","Epoch 4/100\n","\u001b[1m283/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6167 - auc: 0.5482 - loss: 0.6706\n","Epoch 4: val_loss improved from 0.62979 to 0.60841, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6170 - auc: 0.5475 - loss: 0.6706 - val_acc: 0.9762 - val_auc: 0.6585 - val_loss: 0.6084\n","Epoch 5/100\n","\u001b[1m282/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6074 - auc: 0.5246 - loss: 0.6669\n","Epoch 5: val_loss improved from 0.60841 to 0.58584, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6080 - auc: 0.5279 - loss: 0.6666 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.5858\n","Epoch 6/100\n","\u001b[1m286/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6539 - auc: 0.6443 - loss: 0.6436\n","Epoch 6: val_loss improved from 0.58584 to 0.56592, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6526 - auc: 0.6416 - loss: 0.6442 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.5659\n","Epoch 7/100\n","\u001b[1m289/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6248 - auc: 0.5897 - loss: 0.6570\n","Epoch 7: val_loss improved from 0.56592 to 0.54851, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6256 - auc: 0.5904 - loss: 0.6568 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.5485\n","Epoch 8/100\n","\u001b[1m290/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6398 - auc: 0.5830 - loss: 0.6573\n","Epoch 8: val_loss improved from 0.54851 to 0.53370, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6403 - auc: 0.5840 - loss: 0.6568 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.5337\n","Epoch 9/100\n","\u001b[1m284/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6569 - auc: 0.6351 - loss: 0.6410\n","Epoch 9: val_loss improved from 0.53370 to 0.52045, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6576 - auc: 0.6342 - loss: 0.6409 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.5204\n","Epoch 10/100\n","\u001b[1m284/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6557 - auc: 0.6031 - loss: 0.6503\n","Epoch 10: val_loss improved from 0.52045 to 0.50825, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6567 - auc: 0.6045 - loss: 0.6494 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.5082\n","Epoch 11/100\n","\u001b[1m281/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6560 - auc: 0.6276 - loss: 0.6429\n","Epoch 11: val_loss improved from 0.50825 to 0.49796, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6578 - auc: 0.6280 - loss: 0.6420 - val_acc: 0.9762 - val_auc: 0.0244 - val_loss: 0.4980\n","Epoch 12/100\n","\u001b[1m297/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6894 - auc: 0.6899 - loss: 0.6130\n","Epoch 12: val_loss improved from 0.49796 to 0.48469, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6893 - auc: 0.6893 - loss: 0.6131 - val_acc: 0.9762 - val_auc: 0.0244 - val_loss: 0.4847\n","Epoch 13/100\n","\u001b[1m279/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6627 - auc: 0.6519 - loss: 0.6322\n","Epoch 13: val_loss improved from 0.48469 to 0.47476, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6645 - auc: 0.6515 - loss: 0.6313 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.4748\n","Epoch 14/100\n","\u001b[1m281/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6928 - auc: 0.6047 - loss: 0.6215\n","Epoch 14: val_loss improved from 0.47476 to 0.46765, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6928 - auc: 0.6055 - loss: 0.6214 - val_acc: 0.9762 - val_auc: 0.0244 - val_loss: 0.4677\n","Epoch 15/100\n","\u001b[1m281/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6969 - auc: 0.5593 - loss: 0.6271\n","Epoch 15: val_loss improved from 0.46765 to 0.46576, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6961 - auc: 0.5633 - loss: 0.6270 - val_acc: 0.9762 - val_auc: 0.0244 - val_loss: 0.4658\n","Epoch 16/100\n","\u001b[1m284/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7050 - auc: 0.6649 - loss: 0.6052\n","Epoch 16: val_loss improved from 0.46576 to 0.45894, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7042 - auc: 0.6639 - loss: 0.6058 - val_acc: 0.9762 - val_auc: 0.0244 - val_loss: 0.4589\n","Epoch 17/100\n","\u001b[1m291/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6568 - auc: 0.6163 - loss: 0.6360\n","Epoch 17: val_loss improved from 0.45894 to 0.45414, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6579 - auc: 0.6169 - loss: 0.6352 - val_acc: 0.9762 - val_auc: 0.0244 - val_loss: 0.4541\n","Epoch 18/100\n","\u001b[1m284/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7009 - auc: 0.6252 - loss: 0.6071\n","Epoch 18: val_loss improved from 0.45414 to 0.44972, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7005 - auc: 0.6245 - loss: 0.6076 - val_acc: 0.9762 - val_auc: 0.0244 - val_loss: 0.4497\n","Epoch 19/100\n","\u001b[1m288/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7165 - auc: 0.5985 - loss: 0.6007\n","Epoch 19: val_loss improved from 0.44972 to 0.44908, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7152 - auc: 0.5995 - loss: 0.6014 - val_acc: 0.9762 - val_auc: 0.0244 - val_loss: 0.4491\n","Epoch 20/100\n","\u001b[1m286/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7062 - auc: 0.6435 - loss: 0.6027\n","Epoch 20: val_loss improved from 0.44908 to 0.44437, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7056 - auc: 0.6425 - loss: 0.6031 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.4444\n","Epoch 21/100\n","\u001b[1m284/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7019 - auc: 0.5976 - loss: 0.6101\n","Epoch 21: val_loss improved from 0.44437 to 0.44429, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7018 - auc: 0.5987 - loss: 0.6102 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.4443\n","Epoch 22/100\n","\u001b[1m284/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6998 - auc: 0.6459 - loss: 0.6073\n","Epoch 22: val_loss improved from 0.44429 to 0.44220, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6996 - auc: 0.6449 - loss: 0.6075 - val_acc: 0.9762 - val_auc: 0.0244 - val_loss: 0.4422\n","Epoch 23/100\n","\u001b[1m281/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7043 - auc: 0.6644 - loss: 0.6014\n","Epoch 23: val_loss improved from 0.44220 to 0.43896, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7044 - auc: 0.6617 - loss: 0.6020 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.4390\n","Epoch 24/100\n","\u001b[1m285/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7054 - auc: 0.6096 - loss: 0.6094\n","Epoch 24: val_loss improved from 0.43896 to 0.43539, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7054 - auc: 0.6112 - loss: 0.6092 - val_acc: 0.9762 - val_auc: 0.0244 - val_loss: 0.4354\n","Epoch 25/100\n","\u001b[1m288/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7066 - auc: 0.6266 - loss: 0.6031\n","Epoch 25: val_loss improved from 0.43539 to 0.43290, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7066 - auc: 0.6273 - loss: 0.6031 - val_acc: 0.9762 - val_auc: 0.0244 - val_loss: 0.4329\n","Epoch 26/100\n","\u001b[1m296/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6906 - auc: 0.6425 - loss: 0.6105\n","Epoch 26: val_loss improved from 0.43290 to 0.42876, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6910 - auc: 0.6425 - loss: 0.6103 - val_acc: 0.9762 - val_auc: 0.0244 - val_loss: 0.4288\n","Epoch 27/100\n","\u001b[1m283/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6907 - auc: 0.6642 - loss: 0.6047\n","Epoch 27: val_loss improved from 0.42876 to 0.42666, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6913 - auc: 0.6622 - loss: 0.6046 - val_acc: 0.9762 - val_auc: 0.0244 - val_loss: 0.4267\n","Epoch 28/100\n","\u001b[1m294/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6863 - auc: 0.6262 - loss: 0.6127\n","Epoch 28: val_loss did not improve from 0.42666\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6868 - auc: 0.6265 - loss: 0.6124 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.4291\n","Epoch 29/100\n","\u001b[1m278/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6987 - auc: 0.6110 - loss: 0.5997\n","Epoch 29: val_loss improved from 0.42666 to 0.42522, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6987 - auc: 0.6144 - loss: 0.5995 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.4252\n","Epoch 30/100\n","\u001b[1m284/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7233 - auc: 0.6502 - loss: 0.5812\n","Epoch 30: val_loss did not improve from 0.42522\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7217 - auc: 0.6504 - loss: 0.5824 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.4272\n","Epoch 31/100\n","\u001b[1m282/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7039 - auc: 0.6539 - loss: 0.5960\n","Epoch 31: val_loss improved from 0.42522 to 0.42339, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7039 - auc: 0.6519 - loss: 0.5966 - val_acc: 0.9762 - val_auc: 0.0244 - val_loss: 0.4234\n","Epoch 32/100\n","\u001b[1m286/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7133 - auc: 0.6802 - loss: 0.5815\n","Epoch 32: val_loss did not improve from 0.42339\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7125 - auc: 0.6781 - loss: 0.5824 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.4242\n","Epoch 33/100\n","\u001b[1m284/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7190 - auc: 0.6231 - loss: 0.5911\n","Epoch 33: val_loss improved from 0.42339 to 0.42180, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7182 - auc: 0.6245 - loss: 0.5914 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.4218\n","Epoch 34/100\n","\u001b[1m284/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7293 - auc: 0.6678 - loss: 0.5756\n","Epoch 34: val_loss did not improve from 0.42180\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7276 - auc: 0.6665 - loss: 0.5768 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.4242\n","Epoch 35/100\n","\u001b[1m285/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6795 - auc: 0.6861 - loss: 0.6005\n","Epoch 35: val_loss improved from 0.42180 to 0.41785, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6806 - auc: 0.6851 - loss: 0.6000 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.4179\n","Epoch 36/100\n","\u001b[1m279/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7080 - auc: 0.5954 - loss: 0.6014\n","Epoch 36: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7075 - auc: 0.5984 - loss: 0.6011 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.4186\n","Epoch 37/100\n","\u001b[1m284/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6762 - auc: 0.6234 - loss: 0.6237\n","Epoch 37: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6780 - auc: 0.6254 - loss: 0.6218 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.4198\n","Epoch 38/100\n","\u001b[1m285/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7157 - auc: 0.6315 - loss: 0.5851\n","Epoch 38: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7151 - auc: 0.6328 - loss: 0.5852 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.4198\n","Epoch 39/100\n","\u001b[1m284/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7027 - auc: 0.6377 - loss: 0.5948\n","Epoch 39: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7028 - auc: 0.6389 - loss: 0.5946 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.4192\n","Epoch 40/100\n","\u001b[1m289/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7135 - auc: 0.6785 - loss: 0.5798\n","Epoch 40: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7131 - auc: 0.6774 - loss: 0.5803 - val_acc: 0.9762 - val_auc: 0.1707 - val_loss: 0.4193\n","Epoch 41/100\n","\u001b[1m281/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7249 - auc: 0.6686 - loss: 0.5692\n","Epoch 41: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7234 - auc: 0.6692 - loss: 0.5701 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4205\n","Epoch 42/100\n","\u001b[1m286/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6960 - auc: 0.6475 - loss: 0.5943\n","Epoch 42: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6960 - auc: 0.6493 - loss: 0.5940 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4193\n","Epoch 43/100\n","\u001b[1m282/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7043 - auc: 0.6298 - loss: 0.5940\n","Epoch 43: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7040 - auc: 0.6312 - loss: 0.5939 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4220\n","Epoch 44/100\n","\u001b[1m301/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6954 - auc: 0.6588 - loss: 0.5904\n","Epoch 44: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6954 - auc: 0.6587 - loss: 0.5904 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4214\n","Epoch 45/100\n","\u001b[1m291/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7162 - auc: 0.6443 - loss: 0.5836\n","Epoch 45: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7158 - auc: 0.6456 - loss: 0.5837 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4236\n","Epoch 46/100\n","\u001b[1m283/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7002 - auc: 0.6432 - loss: 0.5909\n","Epoch 46: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7003 - auc: 0.6448 - loss: 0.5906 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4211\n","Epoch 47/100\n","\u001b[1m287/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7034 - auc: 0.6581 - loss: 0.5888\n","Epoch 47: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7034 - auc: 0.6585 - loss: 0.5887 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4224\n","Epoch 48/100\n","\u001b[1m283/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6921 - auc: 0.6710 - loss: 0.5921\n","Epoch 48: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6929 - auc: 0.6695 - loss: 0.5920 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4205\n","Epoch 49/100\n","\u001b[1m287/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6928 - auc: 0.7150 - loss: 0.5818\n","Epoch 49: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6933 - auc: 0.7141 - loss: 0.5817 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4194\n","Epoch 50/100\n","\u001b[1m285/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6981 - auc: 0.6305 - loss: 0.5960\n","Epoch 50: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6985 - auc: 0.6328 - loss: 0.5952 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4197\n","Epoch 51/100\n","\u001b[1m277/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6893 - auc: 0.7099 - loss: 0.5817\n","Epoch 51: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6901 - auc: 0.7109 - loss: 0.5811 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4187\n","Epoch 52/100\n","\u001b[1m279/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7004 - auc: 0.6926 - loss: 0.5779\n","Epoch 52: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7005 - auc: 0.6927 - loss: 0.5780 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4184\n","Epoch 53/100\n","\u001b[1m282/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7205 - auc: 0.6819 - loss: 0.5662\n","Epoch 53: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7194 - auc: 0.6825 - loss: 0.5670 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4220\n","Epoch 54/100\n","\u001b[1m283/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7197 - auc: 0.6959 - loss: 0.5653\n","Epoch 54: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7186 - auc: 0.6952 - loss: 0.5662 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4226\n","Epoch 55/100\n","\u001b[1m284/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6884 - auc: 0.7038 - loss: 0.5846\n","Epoch 55: val_loss did not improve from 0.41785\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6895 - auc: 0.7050 - loss: 0.5837 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4180\n","Epoch 56/100\n","\u001b[1m286/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6875 - auc: 0.7236 - loss: 0.5817\n","Epoch 56: val_loss improved from 0.41785 to 0.41536, saving model to best_tab_only_fold1.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6883 - auc: 0.7217 - loss: 0.5815 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4154\n","Epoch 57/100\n","\u001b[1m286/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7183 - auc: 0.7373 - loss: 0.5598\n","Epoch 57: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7173 - auc: 0.7359 - loss: 0.5609 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4169\n","Epoch 58/100\n","\u001b[1m283/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6932 - auc: 0.6676 - loss: 0.5866\n","Epoch 58: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6939 - auc: 0.6711 - loss: 0.5854 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4177\n","Epoch 59/100\n","\u001b[1m285/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6912 - auc: 0.6772 - loss: 0.5905\n","Epoch 59: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6921 - auc: 0.6784 - loss: 0.5897 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4188\n","Epoch 60/100\n","\u001b[1m281/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7265 - auc: 0.7214 - loss: 0.5537\n","Epoch 60: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7249 - auc: 0.7208 - loss: 0.5550 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4190\n","Epoch 61/100\n","\u001b[1m282/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6950 - auc: 0.6953 - loss: 0.5803\n","Epoch 61: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6957 - auc: 0.6965 - loss: 0.5795 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4168\n","Epoch 62/100\n","\u001b[1m295/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6994 - auc: 0.7133 - loss: 0.5720\n","Epoch 62: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6995 - auc: 0.7137 - loss: 0.5717 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4182\n","Epoch 63/100\n","\u001b[1m301/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7016 - auc: 0.6962 - loss: 0.5710\n","Epoch 63: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7016 - auc: 0.6962 - loss: 0.5710 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4194\n","Epoch 64/100\n","\u001b[1m287/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7109 - auc: 0.7250 - loss: 0.5601\n","Epoch 64: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7105 - auc: 0.7244 - loss: 0.5604 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4197\n","Epoch 65/100\n","\u001b[1m282/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7096 - auc: 0.7341 - loss: 0.5558\n","Epoch 65: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7089 - auc: 0.7346 - loss: 0.5561 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4176\n","Epoch 66/100\n","\u001b[1m282/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7189 - auc: 0.7438 - loss: 0.5498\n","Epoch 66: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7180 - auc: 0.7425 - loss: 0.5508 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4182\n","Epoch 67/100\n","\u001b[1m284/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6878 - auc: 0.7280 - loss: 0.5737\n","Epoch 67: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6884 - auc: 0.7274 - loss: 0.5734 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4186\n","Epoch 68/100\n","\u001b[1m279/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6888 - auc: 0.7481 - loss: 0.5717\n","Epoch 68: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6900 - auc: 0.7459 - loss: 0.5712 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4164\n","Epoch 69/100\n","\u001b[1m282/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7163 - auc: 0.7329 - loss: 0.5510\n","Epoch 69: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7155 - auc: 0.7333 - loss: 0.5515 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4204\n","Epoch 70/100\n","\u001b[1m286/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7160 - auc: 0.7225 - loss: 0.5559\n","Epoch 70: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7152 - auc: 0.7230 - loss: 0.5562 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4217\n","Epoch 71/100\n","\u001b[1m284/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7015 - auc: 0.7385 - loss: 0.5626\n","Epoch 71: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7015 - auc: 0.7382 - loss: 0.5625 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4195\n","Epoch 72/100\n","\u001b[1m286/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6975 - auc: 0.7028 - loss: 0.5713\n","Epoch 72: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6979 - auc: 0.7035 - loss: 0.5708 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4217\n","Epoch 73/100\n","\u001b[1m286/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7018 - auc: 0.7537 - loss: 0.5546\n","Epoch 73: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7016 - auc: 0.7537 - loss: 0.5546 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4237\n","Epoch 74/100\n","\u001b[1m282/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7181 - auc: 0.7262 - loss: 0.5451\n","Epoch 74: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7169 - auc: 0.7266 - loss: 0.5461 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4251\n","Epoch 75/100\n","\u001b[1m287/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7071 - auc: 0.7105 - loss: 0.5572\n","Epoch 75: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7067 - auc: 0.7115 - loss: 0.5574 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4262\n","Epoch 76/100\n","\u001b[1m285/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7169 - auc: 0.6963 - loss: 0.5573\n","Epoch 76: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7162 - auc: 0.6973 - loss: 0.5576 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4304\n","Epoch 77/100\n","\u001b[1m278/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6956 - auc: 0.7292 - loss: 0.5680\n","Epoch 77: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6966 - auc: 0.7303 - loss: 0.5671 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4281\n","Epoch 78/100\n","\u001b[1m301/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7000 - auc: 0.7483 - loss: 0.5572\n","Epoch 78: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7000 - auc: 0.7482 - loss: 0.5572 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4269\n","Epoch 79/100\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7184 - auc: 0.6794 - loss: 0.5655\n","Epoch 79: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7184 - auc: 0.6795 - loss: 0.5654 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4284\n","Epoch 80/100\n","\u001b[1m291/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7084 - auc: 0.7548 - loss: 0.5497\n","Epoch 80: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7084 - auc: 0.7552 - loss: 0.5496 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4280\n","Epoch 81/100\n","\u001b[1m287/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7135 - auc: 0.7555 - loss: 0.5491\n","Epoch 81: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7133 - auc: 0.7554 - loss: 0.5492 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4294\n","Epoch 82/100\n","\u001b[1m287/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7256 - auc: 0.7120 - loss: 0.5430\n","Epoch 82: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7246 - auc: 0.7119 - loss: 0.5438 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4341\n","Epoch 83/100\n","\u001b[1m291/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7158 - auc: 0.7517 - loss: 0.5388\n","Epoch 83: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7154 - auc: 0.7515 - loss: 0.5392 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4328\n","Epoch 84/100\n","\u001b[1m289/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7121 - auc: 0.6921 - loss: 0.5611\n","Epoch 84: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7118 - auc: 0.6937 - loss: 0.5609 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4332\n","Epoch 85/100\n","\u001b[1m292/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6768 - auc: 0.7358 - loss: 0.5694\n","Epoch 85: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6778 - auc: 0.7358 - loss: 0.5688 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4279\n","Epoch 86/100\n","\u001b[1m291/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7416 - auc: 0.7343 - loss: 0.5232\n","Epoch 86: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7399 - auc: 0.7349 - loss: 0.5242 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4342\n","Epoch 87/100\n","\u001b[1m286/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7008 - auc: 0.7415 - loss: 0.5642\n","Epoch 87: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7015 - auc: 0.7420 - loss: 0.5633 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4301\n","Epoch 88/100\n","\u001b[1m283/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7121 - auc: 0.7173 - loss: 0.5563\n","Epoch 88: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7122 - auc: 0.7191 - loss: 0.5557 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4324\n","Epoch 89/100\n","\u001b[1m290/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7074 - auc: 0.7634 - loss: 0.5446\n","Epoch 89: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7076 - auc: 0.7634 - loss: 0.5445 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4336\n","Epoch 90/100\n","\u001b[1m282/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7268 - auc: 0.7546 - loss: 0.5335\n","Epoch 90: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7259 - auc: 0.7548 - loss: 0.5341 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4384\n","Epoch 91/100\n","\u001b[1m288/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6997 - auc: 0.7714 - loss: 0.5579\n","Epoch 91: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7007 - auc: 0.7716 - loss: 0.5571 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4264\n","Epoch 92/100\n","\u001b[1m288/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7040 - auc: 0.7512 - loss: 0.5517\n","Epoch 92: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7048 - auc: 0.7513 - loss: 0.5512 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4340\n","Epoch 93/100\n","\u001b[1m286/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7030 - auc: 0.7285 - loss: 0.5624\n","Epoch 93: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7039 - auc: 0.7289 - loss: 0.5617 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4336\n","Epoch 94/100\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6762 - auc: 0.7471 - loss: 0.5645\n","Epoch 94: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6763 - auc: 0.7472 - loss: 0.5644 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4289\n","Epoch 95/100\n","\u001b[1m290/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6938 - auc: 0.7229 - loss: 0.5684\n","Epoch 95: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6948 - auc: 0.7245 - loss: 0.5672 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4326\n","Epoch 96/100\n","\u001b[1m278/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6992 - auc: 0.7351 - loss: 0.5569\n","Epoch 96: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7001 - auc: 0.7348 - loss: 0.5561 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4356\n","Epoch 97/100\n","\u001b[1m281/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7290 - auc: 0.7647 - loss: 0.5302\n","Epoch 97: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7286 - auc: 0.7634 - loss: 0.5310 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4352\n","Epoch 98/100\n","\u001b[1m280/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7154 - auc: 0.7400 - loss: 0.5410\n","Epoch 98: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7152 - auc: 0.7422 - loss: 0.5405 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4380\n","Epoch 99/100\n","\u001b[1m284/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7243 - auc: 0.7442 - loss: 0.5408\n","Epoch 99: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7239 - auc: 0.7450 - loss: 0.5409 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4381\n","Epoch 100/100\n","\u001b[1m288/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7233 - auc: 0.7155 - loss: 0.5362\n","Epoch 100: val_loss did not improve from 0.41536\n","\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7228 - auc: 0.7173 - loss: 0.5364 - val_acc: 0.9762 - val_auc: 0.3171 - val_loss: 0.4429\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 1 AUC: 0.2857\n","\n","--- Fold 2/10 ---\n"," train | ids:   35 | files: 1014 | pos:  327 | neg:  687\n","   val | ids:    4 | files:  106 | pos:   38 | neg:   68\n","  test | ids:    5 | files:   80 | pos:   40 | neg:   40\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 5))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m313/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4885 - auc: 0.5221 - loss: 0.7127\n","Epoch 1: val_loss improved from inf to 0.73120, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - acc: 0.4881 - auc: 0.5224 - loss: 0.7125 - val_acc: 0.3679 - val_auc: 0.4265 - val_loss: 0.7312\n","Epoch 2/100\n","\u001b[1m333/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4506 - auc: 0.5096 - loss: 0.7022\n","Epoch 2: val_loss improved from 0.73120 to 0.71378, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.4511 - auc: 0.5102 - loss: 0.7019 - val_acc: 0.3679 - val_auc: 0.4265 - val_loss: 0.7138\n","Epoch 3/100\n","\u001b[1m333/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5687 - auc: 0.5721 - loss: 0.6739\n","Epoch 3: val_loss improved from 0.71378 to 0.70222, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.5689 - auc: 0.5721 - loss: 0.6738 - val_acc: 0.2736 - val_auc: 0.4265 - val_loss: 0.7022\n","Epoch 4/100\n","\u001b[1m322/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6327 - auc: 0.5831 - loss: 0.6566\n","Epoch 4: val_loss improved from 0.70222 to 0.69234, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6329 - auc: 0.5826 - loss: 0.6567 - val_acc: 0.2736 - val_auc: 0.4265 - val_loss: 0.6923\n","Epoch 5/100\n","\u001b[1m325/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6596 - auc: 0.5771 - loss: 0.6558\n","Epoch 5: val_loss improved from 0.69234 to 0.68923, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6603 - auc: 0.5768 - loss: 0.6556 - val_acc: 0.6415 - val_auc: 0.0147 - val_loss: 0.6892\n","Epoch 6/100\n","\u001b[1m316/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6896 - auc: 0.6207 - loss: 0.6381\n","Epoch 6: val_loss improved from 0.68923 to 0.68176, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6898 - auc: 0.6189 - loss: 0.6384 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6818\n","Epoch 7/100\n","\u001b[1m327/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6893 - auc: 0.6002 - loss: 0.6392\n","Epoch 7: val_loss improved from 0.68176 to 0.67582, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6898 - auc: 0.6003 - loss: 0.6391 - val_acc: 0.6415 - val_auc: 0.0147 - val_loss: 0.6758\n","Epoch 8/100\n","\u001b[1m328/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7147 - auc: 0.5710 - loss: 0.6339\n","Epoch 8: val_loss improved from 0.67582 to 0.67162, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7144 - auc: 0.5714 - loss: 0.6340 - val_acc: 0.6415 - val_auc: 0.0147 - val_loss: 0.6716\n","Epoch 9/100\n","\u001b[1m332/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7244 - auc: 0.6114 - loss: 0.6307\n","Epoch 9: val_loss improved from 0.67162 to 0.66855, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7242 - auc: 0.6112 - loss: 0.6306 - val_acc: 0.6415 - val_auc: 0.0147 - val_loss: 0.6685\n","Epoch 10/100\n","\u001b[1m333/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7016 - auc: 0.5728 - loss: 0.6354\n","Epoch 10: val_loss improved from 0.66855 to 0.66573, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7017 - auc: 0.5736 - loss: 0.6352 - val_acc: 0.6415 - val_auc: 0.0147 - val_loss: 0.6657\n","Epoch 11/100\n","\u001b[1m316/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7153 - auc: 0.6028 - loss: 0.6255\n","Epoch 11: val_loss improved from 0.66573 to 0.66334, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7152 - auc: 0.6027 - loss: 0.6254 - val_acc: 0.6415 - val_auc: 0.0147 - val_loss: 0.6633\n","Epoch 12/100\n","\u001b[1m332/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7286 - auc: 0.6528 - loss: 0.6062\n","Epoch 12: val_loss improved from 0.66334 to 0.66119, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7283 - auc: 0.6524 - loss: 0.6064 - val_acc: 0.6415 - val_auc: 0.0147 - val_loss: 0.6612\n","Epoch 13/100\n","\u001b[1m327/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7083 - auc: 0.6225 - loss: 0.6147\n","Epoch 13: val_loss improved from 0.66119 to 0.65901, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7083 - auc: 0.6217 - loss: 0.6150 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6590\n","Epoch 14/100\n","\u001b[1m330/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7072 - auc: 0.6505 - loss: 0.6119\n","Epoch 14: val_loss improved from 0.65901 to 0.65681, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7072 - auc: 0.6497 - loss: 0.6120 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6568\n","Epoch 15/100\n","\u001b[1m331/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7254 - auc: 0.6177 - loss: 0.6081\n","Epoch 15: val_loss improved from 0.65681 to 0.65545, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7250 - auc: 0.6177 - loss: 0.6083 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6555\n","Epoch 16/100\n","\u001b[1m328/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6937 - auc: 0.6250 - loss: 0.6233\n","Epoch 16: val_loss did not improve from 0.65545\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6942 - auc: 0.6252 - loss: 0.6230 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6555\n","Epoch 17/100\n","\u001b[1m330/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7161 - auc: 0.6241 - loss: 0.6083\n","Epoch 17: val_loss improved from 0.65545 to 0.65376, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7161 - auc: 0.6238 - loss: 0.6085 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6538\n","Epoch 18/100\n","\u001b[1m327/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6834 - auc: 0.6178 - loss: 0.6335\n","Epoch 18: val_loss did not improve from 0.65376\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6844 - auc: 0.6182 - loss: 0.6328 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6540\n","Epoch 19/100\n","\u001b[1m329/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7256 - auc: 0.6595 - loss: 0.5975\n","Epoch 19: val_loss improved from 0.65376 to 0.65339, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7253 - auc: 0.6586 - loss: 0.5978 - val_acc: 0.6415 - val_auc: 0.0147 - val_loss: 0.6534\n","Epoch 20/100\n","\u001b[1m319/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7362 - auc: 0.6477 - loss: 0.5876\n","Epoch 20: val_loss improved from 0.65339 to 0.65137, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7350 - auc: 0.6461 - loss: 0.5888 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6514\n","Epoch 21/100\n","\u001b[1m326/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7400 - auc: 0.6251 - loss: 0.5990\n","Epoch 21: val_loss improved from 0.65137 to 0.65127, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7395 - auc: 0.6250 - loss: 0.5992 - val_acc: 0.6415 - val_auc: 0.7132 - val_loss: 0.6513\n","Epoch 22/100\n","\u001b[1m326/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7248 - auc: 0.6627 - loss: 0.5889\n","Epoch 22: val_loss did not improve from 0.65127\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7246 - auc: 0.6623 - loss: 0.5894 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6514\n","Epoch 23/100\n","\u001b[1m327/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7385 - auc: 0.6096 - loss: 0.5958\n","Epoch 23: val_loss improved from 0.65127 to 0.65093, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7378 - auc: 0.6100 - loss: 0.5963 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6509\n","Epoch 24/100\n","\u001b[1m332/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7142 - auc: 0.6016 - loss: 0.6128\n","Epoch 24: val_loss improved from 0.65093 to 0.65084, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7144 - auc: 0.6018 - loss: 0.6127 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6508\n","Epoch 25/100\n","\u001b[1m336/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7173 - auc: 0.6431 - loss: 0.5982\n","Epoch 25: val_loss did not improve from 0.65084\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7173 - auc: 0.6430 - loss: 0.5983 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6513\n","Epoch 26/100\n","\u001b[1m333/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7211 - auc: 0.6245 - loss: 0.6043\n","Epoch 26: val_loss did not improve from 0.65084\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7210 - auc: 0.6246 - loss: 0.6043 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6511\n","Epoch 27/100\n","\u001b[1m326/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7138 - auc: 0.6283 - loss: 0.6114\n","Epoch 27: val_loss did not improve from 0.65084\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7140 - auc: 0.6272 - loss: 0.6113 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6517\n","Epoch 28/100\n","\u001b[1m325/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7248 - auc: 0.6018 - loss: 0.6029\n","Epoch 28: val_loss did not improve from 0.65084\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7245 - auc: 0.6021 - loss: 0.6030 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6519\n","Epoch 29/100\n","\u001b[1m329/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7217 - auc: 0.6504 - loss: 0.5918\n","Epoch 29: val_loss did not improve from 0.65084\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7217 - auc: 0.6501 - loss: 0.5919 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6511\n","Epoch 30/100\n","\u001b[1m329/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7218 - auc: 0.6566 - loss: 0.5967\n","Epoch 30: val_loss improved from 0.65084 to 0.65078, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7217 - auc: 0.6556 - loss: 0.5968 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6508\n","Epoch 31/100\n","\u001b[1m323/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7072 - auc: 0.6538 - loss: 0.6045\n","Epoch 31: val_loss did not improve from 0.65078\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7077 - auc: 0.6522 - loss: 0.6043 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6516\n","Epoch 32/100\n","\u001b[1m326/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7432 - auc: 0.6068 - loss: 0.5847\n","Epoch 32: val_loss improved from 0.65078 to 0.65062, saving model to best_tab_only_fold2.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7423 - auc: 0.6070 - loss: 0.5852 - val_acc: 0.6415 - val_auc: 1.0000 - val_loss: 0.6506\n","Epoch 33/100\n","\u001b[1m332/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7364 - auc: 0.6215 - loss: 0.5900\n","Epoch 33: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7362 - auc: 0.6212 - loss: 0.5903 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6512\n","Epoch 34/100\n","\u001b[1m318/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7348 - auc: 0.6248 - loss: 0.5822\n","Epoch 34: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7336 - auc: 0.6258 - loss: 0.5829 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6514\n","Epoch 35/100\n","\u001b[1m323/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7271 - auc: 0.6417 - loss: 0.5837\n","Epoch 35: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7266 - auc: 0.6412 - loss: 0.5842 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6515\n","Epoch 36/100\n","\u001b[1m324/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7148 - auc: 0.6101 - loss: 0.5995\n","Epoch 36: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7151 - auc: 0.6113 - loss: 0.5990 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6518\n","Epoch 37/100\n","\u001b[1m322/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7020 - auc: 0.5999 - loss: 0.6127\n","Epoch 37: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7029 - auc: 0.6011 - loss: 0.6117 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6533\n","Epoch 38/100\n","\u001b[1m327/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7131 - auc: 0.6264 - loss: 0.6019\n","Epoch 38: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7132 - auc: 0.6257 - loss: 0.6018 - val_acc: 0.6415 - val_auc: 0.5074 - val_loss: 0.6532\n","Epoch 39/100\n","\u001b[1m331/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7152 - auc: 0.6204 - loss: 0.6020\n","Epoch 39: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7154 - auc: 0.6200 - loss: 0.6019 - val_acc: 0.6415 - val_auc: 0.7132 - val_loss: 0.6521\n","Epoch 40/100\n","\u001b[1m331/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7271 - auc: 0.6046 - loss: 0.5910\n","Epoch 40: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7269 - auc: 0.6048 - loss: 0.5910 - val_acc: 0.6415 - val_auc: 0.7132 - val_loss: 0.6526\n","Epoch 41/100\n","\u001b[1m328/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7343 - auc: 0.6025 - loss: 0.5842\n","Epoch 41: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7339 - auc: 0.6024 - loss: 0.5847 - val_acc: 0.6415 - val_auc: 0.7132 - val_loss: 0.6525\n","Epoch 42/100\n","\u001b[1m332/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7089 - auc: 0.6002 - loss: 0.6042\n","Epoch 42: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7091 - auc: 0.6010 - loss: 0.6039 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6537\n","Epoch 43/100\n","\u001b[1m330/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7287 - auc: 0.6333 - loss: 0.5819\n","Epoch 43: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7286 - auc: 0.6333 - loss: 0.5820 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6540\n","Epoch 44/100\n","\u001b[1m327/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7256 - auc: 0.6318 - loss: 0.5867\n","Epoch 44: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7252 - auc: 0.6311 - loss: 0.5870 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6542\n","Epoch 45/100\n","\u001b[1m319/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7389 - auc: 0.5968 - loss: 0.5781\n","Epoch 45: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7378 - auc: 0.5976 - loss: 0.5789 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6542\n","Epoch 46/100\n","\u001b[1m315/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7170 - auc: 0.6247 - loss: 0.5869\n","Epoch 46: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7169 - auc: 0.6243 - loss: 0.5872 - val_acc: 0.6415 - val_auc: 0.7132 - val_loss: 0.6544\n","Epoch 47/100\n","\u001b[1m327/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7422 - auc: 0.6201 - loss: 0.5699\n","Epoch 47: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7412 - auc: 0.6197 - loss: 0.5707 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6544\n","Epoch 48/100\n","\u001b[1m316/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7266 - auc: 0.5890 - loss: 0.5890\n","Epoch 48: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7262 - auc: 0.5907 - loss: 0.5890 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6546\n","Epoch 49/100\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7121 - auc: 0.6372 - loss: 0.5916\n","Epoch 49: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7121 - auc: 0.6371 - loss: 0.5916 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6552\n","Epoch 50/100\n","\u001b[1m317/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7201 - auc: 0.5891 - loss: 0.5949\n","Epoch 50: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7199 - auc: 0.5903 - loss: 0.5946 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6554\n","Epoch 51/100\n","\u001b[1m332/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7077 - auc: 0.6255 - loss: 0.5921\n","Epoch 51: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7079 - auc: 0.6249 - loss: 0.5920 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6565\n","Epoch 52/100\n","\u001b[1m313/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7026 - auc: 0.5992 - loss: 0.6020\n","Epoch 52: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7036 - auc: 0.5995 - loss: 0.6013 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6562\n","Epoch 53/100\n","\u001b[1m312/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7044 - auc: 0.6255 - loss: 0.5945\n","Epoch 53: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7051 - auc: 0.6240 - loss: 0.5944 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6559\n","Epoch 54/100\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7334 - auc: 0.5777 - loss: 0.5823\n","Epoch 54: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7334 - auc: 0.5779 - loss: 0.5824 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6571\n","Epoch 55/100\n","\u001b[1m332/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7225 - auc: 0.6366 - loss: 0.5823\n","Epoch 55: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7222 - auc: 0.6367 - loss: 0.5824 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6565\n","Epoch 56/100\n","\u001b[1m324/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7573 - auc: 0.6306 - loss: 0.5531\n","Epoch 56: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7556 - auc: 0.6306 - loss: 0.5544 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6573\n","Epoch 57/100\n","\u001b[1m320/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6971 - auc: 0.6311 - loss: 0.6004\n","Epoch 57: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6983 - auc: 0.6306 - loss: 0.5995 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6575\n","Epoch 58/100\n","\u001b[1m323/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7208 - auc: 0.6254 - loss: 0.5808\n","Epoch 58: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7207 - auc: 0.6261 - loss: 0.5808 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6578\n","Epoch 59/100\n","\u001b[1m321/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7210 - auc: 0.6576 - loss: 0.5722\n","Epoch 59: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7207 - auc: 0.6565 - loss: 0.5728 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6576\n","Epoch 60/100\n","\u001b[1m326/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6903 - auc: 0.6030 - loss: 0.6111\n","Epoch 60: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6911 - auc: 0.6030 - loss: 0.6104 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6580\n","Epoch 61/100\n","\u001b[1m319/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7076 - auc: 0.6345 - loss: 0.5888\n","Epoch 61: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7081 - auc: 0.6342 - loss: 0.5885 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6589\n","Epoch 62/100\n","\u001b[1m319/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7211 - auc: 0.6142 - loss: 0.5838\n","Epoch 62: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7212 - auc: 0.6149 - loss: 0.5836 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6582\n","Epoch 63/100\n","\u001b[1m319/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7126 - auc: 0.6329 - loss: 0.5849\n","Epoch 63: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7125 - auc: 0.6337 - loss: 0.5847 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6591\n","Epoch 64/100\n","\u001b[1m330/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7254 - auc: 0.5917 - loss: 0.5863\n","Epoch 64: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7252 - auc: 0.5923 - loss: 0.5862 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6594\n","Epoch 65/100\n","\u001b[1m333/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7237 - auc: 0.6100 - loss: 0.5779\n","Epoch 65: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7236 - auc: 0.6102 - loss: 0.5779 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6600\n","Epoch 66/100\n","\u001b[1m326/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6915 - auc: 0.5997 - loss: 0.6065\n","Epoch 66: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6927 - auc: 0.6006 - loss: 0.6055 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6605\n","Epoch 67/100\n","\u001b[1m332/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7127 - auc: 0.6394 - loss: 0.5819\n","Epoch 67: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7129 - auc: 0.6391 - loss: 0.5818 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6595\n","Epoch 68/100\n","\u001b[1m336/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7151 - auc: 0.6528 - loss: 0.5797\n","Epoch 68: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7152 - auc: 0.6527 - loss: 0.5797 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6597\n","Epoch 69/100\n","\u001b[1m328/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7084 - auc: 0.6036 - loss: 0.5901\n","Epoch 69: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7085 - auc: 0.6043 - loss: 0.5899 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6602\n","Epoch 70/100\n","\u001b[1m331/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7012 - auc: 0.5743 - loss: 0.6055\n","Epoch 70: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7015 - auc: 0.5752 - loss: 0.6051 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6608\n","Epoch 71/100\n","\u001b[1m336/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7405 - auc: 0.6143 - loss: 0.5657\n","Epoch 71: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7403 - auc: 0.6144 - loss: 0.5658 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6608\n","Epoch 72/100\n","\u001b[1m334/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7129 - auc: 0.6295 - loss: 0.5863\n","Epoch 72: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7130 - auc: 0.6295 - loss: 0.5862 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6613\n","Epoch 73/100\n","\u001b[1m315/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7305 - auc: 0.6232 - loss: 0.5683\n","Epoch 73: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7297 - auc: 0.6221 - loss: 0.5692 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6620\n","Epoch 74/100\n","\u001b[1m329/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7178 - auc: 0.5825 - loss: 0.5902\n","Epoch 74: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7177 - auc: 0.5839 - loss: 0.5899 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6616\n","Epoch 75/100\n","\u001b[1m333/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7005 - auc: 0.6382 - loss: 0.5897\n","Epoch 75: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7007 - auc: 0.6381 - loss: 0.5896 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6618\n","Epoch 76/100\n","\u001b[1m320/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7221 - auc: 0.6125 - loss: 0.5827\n","Epoch 76: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7222 - auc: 0.6125 - loss: 0.5826 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6622\n","Epoch 77/100\n","\u001b[1m318/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7116 - auc: 0.6331 - loss: 0.5813\n","Epoch 77: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7122 - auc: 0.6340 - loss: 0.5807 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6632\n","Epoch 78/100\n","\u001b[1m326/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7028 - auc: 0.6626 - loss: 0.5815\n","Epoch 78: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7032 - auc: 0.6614 - loss: 0.5815 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6628\n","Epoch 79/100\n","\u001b[1m335/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7202 - auc: 0.6099 - loss: 0.5793\n","Epoch 79: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7202 - auc: 0.6101 - loss: 0.5793 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6637\n","Epoch 80/100\n","\u001b[1m334/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6917 - auc: 0.6736 - loss: 0.5902\n","Epoch 80: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6921 - auc: 0.6734 - loss: 0.5899 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6638\n","Epoch 81/100\n","\u001b[1m336/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7081 - auc: 0.6653 - loss: 0.5791\n","Epoch 81: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7082 - auc: 0.6651 - loss: 0.5790 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6637\n","Epoch 82/100\n","\u001b[1m332/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7134 - auc: 0.7122 - loss: 0.5651\n","Epoch 82: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7136 - auc: 0.7114 - loss: 0.5651 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6638\n","Epoch 83/100\n","\u001b[1m336/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7248 - auc: 0.6198 - loss: 0.5735\n","Epoch 83: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7247 - auc: 0.6198 - loss: 0.5736 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6640\n","Epoch 84/100\n","\u001b[1m327/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7014 - auc: 0.6443 - loss: 0.5898\n","Epoch 84: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7021 - auc: 0.6443 - loss: 0.5892 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6646\n","Epoch 85/100\n","\u001b[1m331/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7287 - auc: 0.6310 - loss: 0.5686\n","Epoch 85: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7285 - auc: 0.6314 - loss: 0.5688 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6657\n","Epoch 86/100\n","\u001b[1m336/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7197 - auc: 0.6267 - loss: 0.5762\n","Epoch 86: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7197 - auc: 0.6266 - loss: 0.5762 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6646\n","Epoch 87/100\n","\u001b[1m335/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7151 - auc: 0.6175 - loss: 0.5802\n","Epoch 87: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7152 - auc: 0.6176 - loss: 0.5802 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6648\n","Epoch 88/100\n","\u001b[1m335/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7233 - auc: 0.6596 - loss: 0.5683\n","Epoch 88: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7232 - auc: 0.6595 - loss: 0.5683 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6654\n","Epoch 89/100\n","\u001b[1m335/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7212 - auc: 0.6161 - loss: 0.5798\n","Epoch 89: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7211 - auc: 0.6162 - loss: 0.5798 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6657\n","Epoch 90/100\n","\u001b[1m326/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6952 - auc: 0.6138 - loss: 0.5982\n","Epoch 90: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6958 - auc: 0.6141 - loss: 0.5976 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6659\n","Epoch 91/100\n","\u001b[1m326/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7286 - auc: 0.6775 - loss: 0.5580\n","Epoch 91: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7281 - auc: 0.6765 - loss: 0.5586 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6652\n","Epoch 92/100\n","\u001b[1m336/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7208 - auc: 0.6052 - loss: 0.5813\n","Epoch 92: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7208 - auc: 0.6053 - loss: 0.5813 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6667\n","Epoch 93/100\n","\u001b[1m318/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7222 - auc: 0.6275 - loss: 0.5741\n","Epoch 93: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7218 - auc: 0.6286 - loss: 0.5741 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6658\n","Epoch 94/100\n","\u001b[1m325/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7206 - auc: 0.6546 - loss: 0.5683\n","Epoch 94: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7204 - auc: 0.6543 - loss: 0.5686 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6665\n","Epoch 95/100\n","\u001b[1m326/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6938 - auc: 0.6420 - loss: 0.5931\n","Epoch 95: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6949 - auc: 0.6411 - loss: 0.5925 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6670\n","Epoch 96/100\n","\u001b[1m324/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7163 - auc: 0.6210 - loss: 0.5803\n","Epoch 96: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7165 - auc: 0.6204 - loss: 0.5803 - val_acc: 0.6415 - val_auc: 0.2206 - val_loss: 0.6669\n","Epoch 97/100\n","\u001b[1m319/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7130 - auc: 0.5938 - loss: 0.5851\n","Epoch 97: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7131 - auc: 0.5940 - loss: 0.5852 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6669\n","Epoch 98/100\n","\u001b[1m323/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7246 - auc: 0.6136 - loss: 0.5751\n","Epoch 98: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7244 - auc: 0.6139 - loss: 0.5752 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6676\n","Epoch 99/100\n","\u001b[1m317/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7345 - auc: 0.6603 - loss: 0.5566\n","Epoch 99: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7334 - auc: 0.6583 - loss: 0.5579 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6670\n","Epoch 100/100\n","\u001b[1m323/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7325 - auc: 0.6456 - loss: 0.5623\n","Epoch 100: val_loss did not improve from 0.65062\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7318 - auc: 0.6446 - loss: 0.5632 - val_acc: 0.6415 - val_auc: 0.4265 - val_loss: 0.6682\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 2 AUC: 0.2388\n","\n","--- Fold 3/10 ---\n"," train | ids:   35 | files:  978 | pos:  323 | neg:  655\n","   val | ids:    4 | files:   53 | pos:    1 | neg:   52\n","  test | ids:    5 | files:  169 | pos:   81 | neg:   88\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 5))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4180 - auc: 0.4245 - loss: 0.7175\n","Epoch 1: val_loss improved from inf to 0.67293, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - acc: 0.4184 - auc: 0.4247 - loss: 0.7173 - val_acc: 0.5472 - val_auc: 0.9904 - val_loss: 0.6729\n","Epoch 2/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5386 - auc: 0.4494 - loss: 0.6916\n","Epoch 2: val_loss improved from 0.67293 to 0.62468, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.5396 - auc: 0.4484 - loss: 0.6916 - val_acc: 0.9811 - val_auc: 1.0000 - val_loss: 0.6247\n","Epoch 3/100\n","\u001b[1m318/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5982 - auc: 0.4670 - loss: 0.6763\n","Epoch 3: val_loss improved from 0.62468 to 0.59094, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.5984 - auc: 0.4674 - loss: 0.6761 - val_acc: 0.9811 - val_auc: 0.7788 - val_loss: 0.5909\n","Epoch 4/100\n","\u001b[1m322/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6213 - auc: 0.4975 - loss: 0.6582\n","Epoch 4: val_loss improved from 0.59094 to 0.56430, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6213 - auc: 0.4977 - loss: 0.6582 - val_acc: 0.9811 - val_auc: 0.5577 - val_loss: 0.5643\n","Epoch 5/100\n","\u001b[1m305/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6207 - auc: 0.4698 - loss: 0.6519\n","Epoch 5: val_loss improved from 0.56430 to 0.53922, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6217 - auc: 0.4718 - loss: 0.6520 - val_acc: 0.9811 - val_auc: 0.5577 - val_loss: 0.5392\n","Epoch 6/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6510 - auc: 0.4988 - loss: 0.6570\n","Epoch 6: val_loss improved from 0.53922 to 0.52713, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6524 - auc: 0.5008 - loss: 0.6564 - val_acc: 0.9811 - val_auc: 0.5577 - val_loss: 0.5271\n","Epoch 7/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6853 - auc: 0.5368 - loss: 0.6398\n","Epoch 7: val_loss improved from 0.52713 to 0.51679, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6849 - auc: 0.5376 - loss: 0.6398 - val_acc: 0.9811 - val_auc: 0.5577 - val_loss: 0.5168\n","Epoch 8/100\n","\u001b[1m305/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6690 - auc: 0.5684 - loss: 0.6436\n","Epoch 8: val_loss improved from 0.51679 to 0.50563, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6696 - auc: 0.5685 - loss: 0.6432 - val_acc: 0.9811 - val_auc: 0.5577 - val_loss: 0.5056\n","Epoch 9/100\n","\u001b[1m306/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6914 - auc: 0.5642 - loss: 0.6270\n","Epoch 9: val_loss improved from 0.50563 to 0.49503, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6905 - auc: 0.5651 - loss: 0.6273 - val_acc: 0.9811 - val_auc: 0.5577 - val_loss: 0.4950\n","Epoch 10/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6845 - auc: 0.5553 - loss: 0.6313\n","Epoch 10: val_loss improved from 0.49503 to 0.48577, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6843 - auc: 0.5559 - loss: 0.6314 - val_acc: 0.9811 - val_auc: 0.5577 - val_loss: 0.4858\n","Epoch 11/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6994 - auc: 0.5959 - loss: 0.6184\n","Epoch 11: val_loss improved from 0.48577 to 0.47875, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6985 - auc: 0.5949 - loss: 0.6191 - val_acc: 0.9811 - val_auc: 0.5577 - val_loss: 0.4787\n","Epoch 12/100\n","\u001b[1m303/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6634 - auc: 0.6243 - loss: 0.6279\n","Epoch 12: val_loss improved from 0.47875 to 0.47345, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6638 - auc: 0.6214 - loss: 0.6281 - val_acc: 0.9811 - val_auc: 0.5577 - val_loss: 0.4734\n","Epoch 13/100\n","\u001b[1m303/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6572 - auc: 0.5766 - loss: 0.6405\n","Epoch 13: val_loss improved from 0.47345 to 0.46616, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6581 - auc: 0.5804 - loss: 0.6393 - val_acc: 0.9811 - val_auc: 0.5577 - val_loss: 0.4662\n","Epoch 14/100\n","\u001b[1m302/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6801 - auc: 0.6538 - loss: 0.6157\n","Epoch 14: val_loss improved from 0.46616 to 0.45863, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6797 - auc: 0.6536 - loss: 0.6158 - val_acc: 0.9811 - val_auc: 0.5577 - val_loss: 0.4586\n","Epoch 15/100\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6894 - auc: 0.6230 - loss: 0.6156\n","Epoch 15: val_loss improved from 0.45863 to 0.45531, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6894 - auc: 0.6230 - loss: 0.6156 - val_acc: 0.9811 - val_auc: 0.5577 - val_loss: 0.4553\n","Epoch 16/100\n","\u001b[1m303/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6957 - auc: 0.6733 - loss: 0.6111\n","Epoch 16: val_loss improved from 0.45531 to 0.45009, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6956 - auc: 0.6715 - loss: 0.6115 - val_acc: 0.9811 - val_auc: 0.5577 - val_loss: 0.4501\n","Epoch 17/100\n","\u001b[1m301/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6918 - auc: 0.6583 - loss: 0.6166\n","Epoch 17: val_loss improved from 0.45009 to 0.44685, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6921 - auc: 0.6591 - loss: 0.6165 - val_acc: 0.9811 - val_auc: 0.2885 - val_loss: 0.4468\n","Epoch 18/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6896 - auc: 0.6820 - loss: 0.6198\n","Epoch 18: val_loss improved from 0.44685 to 0.44397, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6905 - auc: 0.6813 - loss: 0.6194 - val_acc: 0.9811 - val_auc: 0.2885 - val_loss: 0.4440\n","Epoch 19/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7121 - auc: 0.7091 - loss: 0.6056\n","Epoch 19: val_loss improved from 0.44397 to 0.44142, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7117 - auc: 0.7072 - loss: 0.6060 - val_acc: 0.9811 - val_auc: 0.2885 - val_loss: 0.4414\n","Epoch 20/100\n","\u001b[1m314/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7241 - auc: 0.6528 - loss: 0.6123\n","Epoch 20: val_loss improved from 0.44142 to 0.43877, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7237 - auc: 0.6539 - loss: 0.6123 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4388\n","Epoch 21/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6925 - auc: 0.6900 - loss: 0.6219\n","Epoch 21: val_loss improved from 0.43877 to 0.43793, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6936 - auc: 0.6892 - loss: 0.6215 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4379\n","Epoch 22/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6947 - auc: 0.7227 - loss: 0.6195\n","Epoch 22: val_loss improved from 0.43793 to 0.43415, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6958 - auc: 0.7223 - loss: 0.6188 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4342\n","Epoch 23/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7002 - auc: 0.7074 - loss: 0.6186\n","Epoch 23: val_loss improved from 0.43415 to 0.43088, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7009 - auc: 0.7073 - loss: 0.6180 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4309\n","Epoch 24/100\n","\u001b[1m314/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7204 - auc: 0.7162 - loss: 0.5990\n","Epoch 24: val_loss improved from 0.43088 to 0.42765, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7202 - auc: 0.7166 - loss: 0.5991 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4276\n","Epoch 25/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7138 - auc: 0.6799 - loss: 0.6123\n","Epoch 25: val_loss improved from 0.42765 to 0.42653, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7138 - auc: 0.6804 - loss: 0.6122 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4265\n","Epoch 26/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6969 - auc: 0.7395 - loss: 0.6051\n","Epoch 26: val_loss improved from 0.42653 to 0.42557, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6976 - auc: 0.7392 - loss: 0.6048 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4256\n","Epoch 27/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7225 - auc: 0.7448 - loss: 0.5908\n","Epoch 27: val_loss improved from 0.42557 to 0.42342, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7221 - auc: 0.7444 - loss: 0.5912 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4234\n","Epoch 28/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7093 - auc: 0.7178 - loss: 0.6051\n","Epoch 28: val_loss did not improve from 0.42342\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7095 - auc: 0.7171 - loss: 0.6052 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4240\n","Epoch 29/100\n","\u001b[1m310/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7260 - auc: 0.7412 - loss: 0.5870\n","Epoch 29: val_loss improved from 0.42342 to 0.42251, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7257 - auc: 0.7408 - loss: 0.5874 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4225\n","Epoch 30/100\n","\u001b[1m304/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7082 - auc: 0.7223 - loss: 0.6012\n","Epoch 30: val_loss improved from 0.42251 to 0.41892, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7095 - auc: 0.7218 - loss: 0.6007 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4189\n","Epoch 31/100\n","\u001b[1m324/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7274 - auc: 0.7268 - loss: 0.5919\n","Epoch 31: val_loss did not improve from 0.41892\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7273 - auc: 0.7267 - loss: 0.5919 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4196\n","Epoch 32/100\n","\u001b[1m316/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7065 - auc: 0.7202 - loss: 0.6040\n","Epoch 32: val_loss improved from 0.41892 to 0.41887, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7068 - auc: 0.7198 - loss: 0.6039 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4189\n","Epoch 33/100\n","\u001b[1m303/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6995 - auc: 0.7034 - loss: 0.6033\n","Epoch 33: val_loss improved from 0.41887 to 0.41845, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7004 - auc: 0.7035 - loss: 0.6029 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4184\n","Epoch 34/100\n","\u001b[1m302/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6890 - auc: 0.7321 - loss: 0.5984\n","Epoch 34: val_loss improved from 0.41845 to 0.41541, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6905 - auc: 0.7317 - loss: 0.5977 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4154\n","Epoch 35/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7079 - auc: 0.7287 - loss: 0.5939\n","Epoch 35: val_loss improved from 0.41541 to 0.41181, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7083 - auc: 0.7285 - loss: 0.5936 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4118\n","Epoch 36/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7265 - auc: 0.6947 - loss: 0.5870\n","Epoch 36: val_loss did not improve from 0.41181\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7257 - auc: 0.6951 - loss: 0.5874 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4119\n","Epoch 37/100\n","\u001b[1m314/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7185 - auc: 0.6892 - loss: 0.5952\n","Epoch 37: val_loss did not improve from 0.41181\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7183 - auc: 0.6884 - loss: 0.5956 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4147\n","Epoch 38/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7483 - auc: 0.6999 - loss: 0.5713\n","Epoch 38: val_loss did not improve from 0.41181\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7468 - auc: 0.7010 - loss: 0.5718 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4153\n","Epoch 39/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7085 - auc: 0.6908 - loss: 0.5975\n","Epoch 39: val_loss did not improve from 0.41181\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7089 - auc: 0.6909 - loss: 0.5973 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4136\n","Epoch 40/100\n","\u001b[1m302/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7238 - auc: 0.7200 - loss: 0.5752\n","Epoch 40: val_loss improved from 0.41181 to 0.41002, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7229 - auc: 0.7198 - loss: 0.5756 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4100\n","Epoch 41/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7178 - auc: 0.7400 - loss: 0.5759\n","Epoch 41: val_loss improved from 0.41002 to 0.40698, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7179 - auc: 0.7396 - loss: 0.5760 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4070\n","Epoch 42/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7097 - auc: 0.7177 - loss: 0.5831\n","Epoch 42: val_loss improved from 0.40698 to 0.40688, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7099 - auc: 0.7177 - loss: 0.5830 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4069\n","Epoch 43/100\n","\u001b[1m305/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7254 - auc: 0.7565 - loss: 0.5639\n","Epoch 43: val_loss improved from 0.40688 to 0.40525, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7250 - auc: 0.7541 - loss: 0.5648 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4053\n","Epoch 44/100\n","\u001b[1m310/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7149 - auc: 0.7198 - loss: 0.5785\n","Epoch 44: val_loss improved from 0.40525 to 0.40471, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7148 - auc: 0.7197 - loss: 0.5787 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4047\n","Epoch 45/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7086 - auc: 0.7325 - loss: 0.5812\n","Epoch 45: val_loss improved from 0.40471 to 0.40200, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7090 - auc: 0.7325 - loss: 0.5809 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4020\n","Epoch 46/100\n","\u001b[1m305/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7279 - auc: 0.6753 - loss: 0.5809\n","Epoch 46: val_loss did not improve from 0.40200\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7269 - auc: 0.6760 - loss: 0.5815 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4041\n","Epoch 47/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7166 - auc: 0.6813 - loss: 0.5896\n","Epoch 47: val_loss did not improve from 0.40200\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7166 - auc: 0.6818 - loss: 0.5895 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4027\n","Epoch 48/100\n","\u001b[1m314/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7026 - auc: 0.6781 - loss: 0.5980\n","Epoch 48: val_loss improved from 0.40200 to 0.40103, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7032 - auc: 0.6792 - loss: 0.5973 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4010\n","Epoch 49/100\n","\u001b[1m302/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7368 - auc: 0.7204 - loss: 0.5686\n","Epoch 49: val_loss did not improve from 0.40103\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7355 - auc: 0.7200 - loss: 0.5692 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4016\n","Epoch 50/100\n","\u001b[1m305/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7268 - auc: 0.6786 - loss: 0.5839\n","Epoch 50: val_loss did not improve from 0.40103\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7260 - auc: 0.6802 - loss: 0.5836 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4013\n","Epoch 51/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7202 - auc: 0.7030 - loss: 0.5772\n","Epoch 51: val_loss improved from 0.40103 to 0.40051, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7202 - auc: 0.7032 - loss: 0.5772 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4005\n","Epoch 52/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7138 - auc: 0.7088 - loss: 0.5810\n","Epoch 52: val_loss improved from 0.40051 to 0.39997, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7143 - auc: 0.7088 - loss: 0.5807 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4000\n","Epoch 53/100\n","\u001b[1m314/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7218 - auc: 0.6703 - loss: 0.5852\n","Epoch 53: val_loss did not improve from 0.39997\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7217 - auc: 0.6710 - loss: 0.5851 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4022\n","Epoch 54/100\n","\u001b[1m304/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6924 - auc: 0.7158 - loss: 0.5860\n","Epoch 54: val_loss did not improve from 0.39997\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6939 - auc: 0.7158 - loss: 0.5851 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4010\n","Epoch 55/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7303 - auc: 0.7180 - loss: 0.5679\n","Epoch 55: val_loss improved from 0.39997 to 0.39924, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7298 - auc: 0.7180 - loss: 0.5678 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3992\n","Epoch 56/100\n","\u001b[1m310/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7153 - auc: 0.6974 - loss: 0.5729\n","Epoch 56: val_loss did not improve from 0.39924\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7153 - auc: 0.6972 - loss: 0.5733 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4006\n","Epoch 57/100\n","\u001b[1m305/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7298 - auc: 0.7063 - loss: 0.5628\n","Epoch 57: val_loss did not improve from 0.39924\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7288 - auc: 0.7060 - loss: 0.5635 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.4009\n","Epoch 58/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7297 - auc: 0.6922 - loss: 0.5681\n","Epoch 58: val_loss improved from 0.39924 to 0.39918, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7290 - auc: 0.6925 - loss: 0.5684 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3992\n","Epoch 59/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7034 - auc: 0.6845 - loss: 0.5906\n","Epoch 59: val_loss did not improve from 0.39918\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7042 - auc: 0.6849 - loss: 0.5897 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3999\n","Epoch 60/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7337 - auc: 0.6765 - loss: 0.5645\n","Epoch 60: val_loss improved from 0.39918 to 0.39808, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7327 - auc: 0.6782 - loss: 0.5649 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3981\n","Epoch 61/100\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6986 - auc: 0.6978 - loss: 0.5843\n","Epoch 61: val_loss improved from 0.39808 to 0.39440, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6986 - auc: 0.6978 - loss: 0.5842 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3944\n","Epoch 62/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7174 - auc: 0.6691 - loss: 0.5788\n","Epoch 62: val_loss did not improve from 0.39440\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7173 - auc: 0.6696 - loss: 0.5788 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3973\n","Epoch 63/100\n","\u001b[1m317/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7262 - auc: 0.6630 - loss: 0.5804\n","Epoch 63: val_loss did not improve from 0.39440\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7259 - auc: 0.6639 - loss: 0.5803 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3977\n","Epoch 64/100\n","\u001b[1m324/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6989 - auc: 0.6780 - loss: 0.5913\n","Epoch 64: val_loss did not improve from 0.39440\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6990 - auc: 0.6782 - loss: 0.5912 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3974\n","Epoch 65/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7078 - auc: 0.7225 - loss: 0.5671\n","Epoch 65: val_loss did not improve from 0.39440\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7083 - auc: 0.7215 - loss: 0.5672 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3981\n","Epoch 66/100\n","\u001b[1m305/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7024 - auc: 0.6974 - loss: 0.5756\n","Epoch 66: val_loss did not improve from 0.39440\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7025 - auc: 0.6968 - loss: 0.5755 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3990\n","Epoch 67/100\n","\u001b[1m315/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7410 - auc: 0.7257 - loss: 0.5408\n","Epoch 67: val_loss did not improve from 0.39440\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7400 - auc: 0.7249 - loss: 0.5417 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3969\n","Epoch 68/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7345 - auc: 0.6938 - loss: 0.5618\n","Epoch 68: val_loss did not improve from 0.39440\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7339 - auc: 0.6944 - loss: 0.5620 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3951\n","Epoch 69/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7154 - auc: 0.6650 - loss: 0.5915\n","Epoch 69: val_loss did not improve from 0.39440\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7160 - auc: 0.6658 - loss: 0.5907 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3971\n","Epoch 70/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7102 - auc: 0.6921 - loss: 0.5742\n","Epoch 70: val_loss did not improve from 0.39440\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7104 - auc: 0.6907 - loss: 0.5745 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3984\n","Epoch 71/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7206 - auc: 0.6716 - loss: 0.5731\n","Epoch 71: val_loss did not improve from 0.39440\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7207 - auc: 0.6718 - loss: 0.5732 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3962\n","Epoch 72/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7171 - auc: 0.7215 - loss: 0.5645\n","Epoch 72: val_loss did not improve from 0.39440\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7170 - auc: 0.7199 - loss: 0.5649 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3961\n","Epoch 73/100\n","\u001b[1m312/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7072 - auc: 0.6607 - loss: 0.5809\n","Epoch 73: val_loss did not improve from 0.39440\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7077 - auc: 0.6619 - loss: 0.5804 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3946\n","Epoch 74/100\n","\u001b[1m306/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6909 - auc: 0.6676 - loss: 0.5941\n","Epoch 74: val_loss did not improve from 0.39440\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6921 - auc: 0.6693 - loss: 0.5925 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3968\n","Epoch 75/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7402 - auc: 0.6995 - loss: 0.5536\n","Epoch 75: val_loss did not improve from 0.39440\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7388 - auc: 0.6996 - loss: 0.5543 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3977\n","Epoch 76/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7052 - auc: 0.7249 - loss: 0.5621\n","Epoch 76: val_loss improved from 0.39440 to 0.39170, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7059 - auc: 0.7240 - loss: 0.5620 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3917\n","Epoch 77/100\n","\u001b[1m323/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7327 - auc: 0.7278 - loss: 0.5414\n","Epoch 77: val_loss did not improve from 0.39170\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7326 - auc: 0.7277 - loss: 0.5416 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3918\n","Epoch 78/100\n","\u001b[1m320/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7054 - auc: 0.6920 - loss: 0.5761\n","Epoch 78: val_loss improved from 0.39170 to 0.39150, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7057 - auc: 0.6921 - loss: 0.5759 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3915\n","Epoch 79/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7174 - auc: 0.6705 - loss: 0.5678\n","Epoch 79: val_loss did not improve from 0.39150\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7176 - auc: 0.6716 - loss: 0.5676 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3920\n","Epoch 80/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7280 - auc: 0.7059 - loss: 0.5577\n","Epoch 80: val_loss did not improve from 0.39150\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7280 - auc: 0.7059 - loss: 0.5577 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3927\n","Epoch 81/100\n","\u001b[1m306/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6793 - auc: 0.6850 - loss: 0.5862\n","Epoch 81: val_loss improved from 0.39150 to 0.39043, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6813 - auc: 0.6850 - loss: 0.5848 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3904\n","Epoch 82/100\n","\u001b[1m302/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6897 - auc: 0.6906 - loss: 0.5849\n","Epoch 82: val_loss did not improve from 0.39043\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6921 - auc: 0.6893 - loss: 0.5838 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3922\n","Epoch 83/100\n","\u001b[1m301/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7069 - auc: 0.7096 - loss: 0.5602\n","Epoch 83: val_loss did not improve from 0.39043\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7080 - auc: 0.7088 - loss: 0.5599 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3916\n","Epoch 84/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7165 - auc: 0.6888 - loss: 0.5625\n","Epoch 84: val_loss did not improve from 0.39043\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7165 - auc: 0.6887 - loss: 0.5625 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3922\n","Epoch 85/100\n","\u001b[1m305/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7049 - auc: 0.6741 - loss: 0.5750\n","Epoch 85: val_loss did not improve from 0.39043\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7056 - auc: 0.6750 - loss: 0.5744 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3933\n","Epoch 86/100\n","\u001b[1m307/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7122 - auc: 0.6622 - loss: 0.5746\n","Epoch 86: val_loss did not improve from 0.39043\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7125 - auc: 0.6624 - loss: 0.5744 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3950\n","Epoch 87/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7132 - auc: 0.6638 - loss: 0.5723\n","Epoch 87: val_loss did not improve from 0.39043\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7135 - auc: 0.6648 - loss: 0.5718 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3929\n","Epoch 88/100\n","\u001b[1m309/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7173 - auc: 0.6897 - loss: 0.5557\n","Epoch 88: val_loss did not improve from 0.39043\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7173 - auc: 0.6898 - loss: 0.5559 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3926\n","Epoch 89/100\n","\u001b[1m306/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7320 - auc: 0.6633 - loss: 0.5602\n","Epoch 89: val_loss did not improve from 0.39043\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7306 - auc: 0.6634 - loss: 0.5609 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3952\n","Epoch 90/100\n","\u001b[1m304/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7288 - auc: 0.6657 - loss: 0.5600\n","Epoch 90: val_loss did not improve from 0.39043\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7280 - auc: 0.6657 - loss: 0.5605 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3942\n","Epoch 91/100\n","\u001b[1m303/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6927 - auc: 0.6546 - loss: 0.5928\n","Epoch 91: val_loss did not improve from 0.39043\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6946 - auc: 0.6563 - loss: 0.5905 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3940\n","Epoch 92/100\n","\u001b[1m302/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7410 - auc: 0.7177 - loss: 0.5398\n","Epoch 92: val_loss improved from 0.39043 to 0.38983, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7401 - auc: 0.7164 - loss: 0.5406 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3898\n","Epoch 93/100\n","\u001b[1m302/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6865 - auc: 0.6580 - loss: 0.5923\n","Epoch 93: val_loss improved from 0.38983 to 0.38888, saving model to best_tab_only_fold3.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6885 - auc: 0.6602 - loss: 0.5902 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3889\n","Epoch 94/100\n","\u001b[1m319/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7259 - auc: 0.6942 - loss: 0.5513\n","Epoch 94: val_loss did not improve from 0.38888\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7257 - auc: 0.6941 - loss: 0.5516 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3903\n","Epoch 95/100\n","\u001b[1m325/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7193 - auc: 0.6827 - loss: 0.5643\n","Epoch 95: val_loss did not improve from 0.38888\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7193 - auc: 0.6827 - loss: 0.5643 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3919\n","Epoch 96/100\n","\u001b[1m305/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7262 - auc: 0.6833 - loss: 0.5538\n","Epoch 96: val_loss did not improve from 0.38888\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7257 - auc: 0.6837 - loss: 0.5541 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3910\n","Epoch 97/100\n","\u001b[1m311/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7195 - auc: 0.6683 - loss: 0.5651\n","Epoch 97: val_loss did not improve from 0.38888\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7193 - auc: 0.6684 - loss: 0.5651 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3918\n","Epoch 98/100\n","\u001b[1m308/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6992 - auc: 0.6832 - loss: 0.5684\n","Epoch 98: val_loss did not improve from 0.38888\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6999 - auc: 0.6835 - loss: 0.5682 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3914\n","Epoch 99/100\n","\u001b[1m310/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7165 - auc: 0.6777 - loss: 0.5636\n","Epoch 99: val_loss did not improve from 0.38888\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7167 - auc: 0.6781 - loss: 0.5635 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3913\n","Epoch 100/100\n","\u001b[1m306/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7223 - auc: 0.6504 - loss: 0.5642\n","Epoch 100: val_loss did not improve from 0.38888\n","\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7221 - auc: 0.6522 - loss: 0.5640 - val_acc: 0.9811 - val_auc: 0.0192 - val_loss: 0.3897\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a85bd27e660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a85bd27e660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 3 AUC: 0.0275\n","\n","--- Fold 4/10 ---\n"," train | ids:   35 | files:  968 | pos:  337 | neg:  631\n","   val | ids:    4 | files:  181 | pos:   38 | neg:  143\n","  test | ids:    5 | files:   51 | pos:   30 | neg:   21\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 5))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m318/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.7098 - auc: 0.5831 - loss: 0.6271\n","Epoch 1: val_loss improved from inf to 0.55786, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - acc: 0.7095 - auc: 0.5831 - loss: 0.6273 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5579\n","Epoch 2/100\n","\u001b[1m319/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6837 - auc: 0.5908 - loss: 0.6346\n","Epoch 2: val_loss improved from 0.55786 to 0.55286, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6838 - auc: 0.5909 - loss: 0.6346 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5529\n","Epoch 3/100\n","\u001b[1m313/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6917 - auc: 0.6120 - loss: 0.6313\n","Epoch 3: val_loss improved from 0.55286 to 0.54797, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6917 - auc: 0.6115 - loss: 0.6313 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5480\n","Epoch 4/100\n","\u001b[1m304/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6607 - auc: 0.5762 - loss: 0.6503\n","Epoch 4: val_loss improved from 0.54797 to 0.54561, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6627 - auc: 0.5773 - loss: 0.6492 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5456\n","Epoch 5/100\n","\u001b[1m302/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6942 - auc: 0.5951 - loss: 0.6307\n","Epoch 5: val_loss improved from 0.54561 to 0.54294, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6939 - auc: 0.5959 - loss: 0.6305 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5429\n","Epoch 6/100\n","\u001b[1m302/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6803 - auc: 0.6149 - loss: 0.6325\n","Epoch 6: val_loss improved from 0.54294 to 0.54006, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6812 - auc: 0.6147 - loss: 0.6320 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5401\n","Epoch 7/100\n","\u001b[1m300/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6757 - auc: 0.5445 - loss: 0.6467\n","Epoch 7: val_loss improved from 0.54006 to 0.53903, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6770 - auc: 0.5475 - loss: 0.6456 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5390\n","Epoch 8/100\n","\u001b[1m304/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6793 - auc: 0.5864 - loss: 0.6372\n","Epoch 8: val_loss improved from 0.53903 to 0.53840, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6805 - auc: 0.5861 - loss: 0.6368 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5384\n","Epoch 9/100\n","\u001b[1m303/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6799 - auc: 0.5864 - loss: 0.6374\n","Epoch 9: val_loss improved from 0.53840 to 0.53791, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6806 - auc: 0.5861 - loss: 0.6371 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5379\n","Epoch 10/100\n","\u001b[1m304/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7302 - auc: 0.6099 - loss: 0.6028\n","Epoch 10: val_loss improved from 0.53791 to 0.53514, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7284 - auc: 0.6101 - loss: 0.6039 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5351\n","Epoch 11/100\n","\u001b[1m300/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6975 - auc: 0.5826 - loss: 0.6257\n","Epoch 11: val_loss improved from 0.53514 to 0.53458, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6975 - auc: 0.5832 - loss: 0.6258 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5346\n","Epoch 12/100\n","\u001b[1m303/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6933 - auc: 0.5559 - loss: 0.6369\n","Epoch 12: val_loss improved from 0.53458 to 0.53448, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6932 - auc: 0.5572 - loss: 0.6366 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5345\n","Epoch 13/100\n","\u001b[1m302/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6834 - auc: 0.5921 - loss: 0.6310\n","Epoch 13: val_loss improved from 0.53448 to 0.53385, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6840 - auc: 0.5922 - loss: 0.6308 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5339\n","Epoch 14/100\n","\u001b[1m299/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6773 - auc: 0.5531 - loss: 0.6472\n","Epoch 14: val_loss did not improve from 0.53385\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6787 - auc: 0.5540 - loss: 0.6462 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5353\n","Epoch 15/100\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6606 - auc: 0.5514 - loss: 0.6573\n","Epoch 15: val_loss did not improve from 0.53385\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6607 - auc: 0.5515 - loss: 0.6572 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5347\n","Epoch 16/100\n","\u001b[1m320/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6966 - auc: 0.6059 - loss: 0.6260\n","Epoch 16: val_loss did not improve from 0.53385\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6966 - auc: 0.6057 - loss: 0.6260 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5342\n","Epoch 17/100\n","\u001b[1m318/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7002 - auc: 0.6046 - loss: 0.6181\n","Epoch 17: val_loss improved from 0.53385 to 0.53153, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7001 - auc: 0.6051 - loss: 0.6181 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5315\n","Epoch 18/100\n","\u001b[1m305/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6863 - auc: 0.6235 - loss: 0.6268\n","Epoch 18: val_loss improved from 0.53153 to 0.53141, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6867 - auc: 0.6217 - loss: 0.6267 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5314\n","Epoch 19/100\n","\u001b[1m307/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7025 - auc: 0.6276 - loss: 0.6138\n","Epoch 19: val_loss improved from 0.53141 to 0.53039, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7022 - auc: 0.6276 - loss: 0.6141 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5304\n","Epoch 20/100\n","\u001b[1m321/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6965 - auc: 0.6378 - loss: 0.6157\n","Epoch 20: val_loss improved from 0.53039 to 0.52878, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6965 - auc: 0.6377 - loss: 0.6157 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5288\n","Epoch 21/100\n","\u001b[1m305/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6861 - auc: 0.6599 - loss: 0.6159\n","Epoch 21: val_loss did not improve from 0.52878\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6866 - auc: 0.6577 - loss: 0.6160 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5289\n","Epoch 22/100\n","\u001b[1m321/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7032 - auc: 0.6333 - loss: 0.6146\n","Epoch 22: val_loss improved from 0.52878 to 0.52873, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7031 - auc: 0.6330 - loss: 0.6147 - val_acc: 0.7901 - val_auc: 0.5874 - val_loss: 0.5287\n","Epoch 23/100\n","\u001b[1m309/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6711 - auc: 0.6092 - loss: 0.6340\n","Epoch 23: val_loss improved from 0.52873 to 0.52841, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6721 - auc: 0.6095 - loss: 0.6335 - val_acc: 0.7901 - val_auc: 0.5874 - val_loss: 0.5284\n","Epoch 24/100\n","\u001b[1m305/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7139 - auc: 0.6022 - loss: 0.6100\n","Epoch 24: val_loss improved from 0.52841 to 0.52813, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7128 - auc: 0.6034 - loss: 0.6105 - val_acc: 0.7901 - val_auc: 0.5874 - val_loss: 0.5281\n","Epoch 25/100\n","\u001b[1m305/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7046 - auc: 0.6283 - loss: 0.6103\n","Epoch 25: val_loss improved from 0.52813 to 0.52724, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7041 - auc: 0.6288 - loss: 0.6107 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5272\n","Epoch 26/100\n","\u001b[1m309/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6882 - auc: 0.5872 - loss: 0.6288\n","Epoch 26: val_loss did not improve from 0.52724\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6885 - auc: 0.5887 - loss: 0.6285 - val_acc: 0.7901 - val_auc: 0.5874 - val_loss: 0.5275\n","Epoch 27/100\n","\u001b[1m305/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6944 - auc: 0.5936 - loss: 0.6231\n","Epoch 27: val_loss did not improve from 0.52724\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6942 - auc: 0.5943 - loss: 0.6231 - val_acc: 0.7901 - val_auc: 0.5874 - val_loss: 0.5279\n","Epoch 28/100\n","\u001b[1m301/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6795 - auc: 0.6335 - loss: 0.6299\n","Epoch 28: val_loss improved from 0.52724 to 0.52659, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6802 - auc: 0.6339 - loss: 0.6290 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5266\n","Epoch 29/100\n","\u001b[1m315/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6993 - auc: 0.6231 - loss: 0.6151\n","Epoch 29: val_loss improved from 0.52659 to 0.52568, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6992 - auc: 0.6230 - loss: 0.6152 - val_acc: 0.7901 - val_auc: 0.5874 - val_loss: 0.5257\n","Epoch 30/100\n","\u001b[1m313/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7000 - auc: 0.6003 - loss: 0.6223\n","Epoch 30: val_loss did not improve from 0.52568\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6999 - auc: 0.6007 - loss: 0.6223 - val_acc: 0.7901 - val_auc: 0.2727 - val_loss: 0.5263\n","Epoch 31/100\n","\u001b[1m317/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7113 - auc: 0.5903 - loss: 0.6197\n","Epoch 31: val_loss did not improve from 0.52568\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7110 - auc: 0.5905 - loss: 0.6197 - val_acc: 0.7901 - val_auc: 0.5874 - val_loss: 0.5272\n","Epoch 32/100\n","\u001b[1m300/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6895 - auc: 0.6142 - loss: 0.6257\n","Epoch 32: val_loss did not improve from 0.52568\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6897 - auc: 0.6123 - loss: 0.6257 - val_acc: 0.7901 - val_auc: 0.5874 - val_loss: 0.5280\n","Epoch 33/100\n","\u001b[1m299/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6941 - auc: 0.6482 - loss: 0.6122\n","Epoch 33: val_loss did not improve from 0.52568\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6939 - auc: 0.6475 - loss: 0.6124 - val_acc: 0.7901 - val_auc: 0.5874 - val_loss: 0.5264\n","Epoch 34/100\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6997 - auc: 0.6196 - loss: 0.6162\n","Epoch 34: val_loss improved from 0.52568 to 0.52556, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6996 - auc: 0.6196 - loss: 0.6162 - val_acc: 0.7901 - val_auc: 0.5874 - val_loss: 0.5256\n","Epoch 35/100\n","\u001b[1m300/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6983 - auc: 0.6085 - loss: 0.6157\n","Epoch 35: val_loss did not improve from 0.52556\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6977 - auc: 0.6092 - loss: 0.6160 - val_acc: 0.7901 - val_auc: 0.5874 - val_loss: 0.5261\n","Epoch 36/100\n","\u001b[1m306/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6710 - auc: 0.6332 - loss: 0.6261\n","Epoch 36: val_loss did not improve from 0.52556\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6723 - auc: 0.6316 - loss: 0.6259 - val_acc: 0.7901 - val_auc: 0.5874 - val_loss: 0.5268\n","Epoch 37/100\n","\u001b[1m298/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6828 - auc: 0.6407 - loss: 0.6208\n","Epoch 37: val_loss improved from 0.52556 to 0.52449, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6835 - auc: 0.6414 - loss: 0.6202 - val_acc: 0.7901 - val_auc: 0.5874 - val_loss: 0.5245\n","Epoch 38/100\n","\u001b[1m309/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6782 - auc: 0.6334 - loss: 0.6261\n","Epoch 38: val_loss improved from 0.52449 to 0.52414, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6789 - auc: 0.6330 - loss: 0.6257 - val_acc: 0.7901 - val_auc: 0.5874 - val_loss: 0.5241\n","Epoch 39/100\n","\u001b[1m307/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6741 - auc: 0.6226 - loss: 0.6316\n","Epoch 39: val_loss did not improve from 0.52414\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6752 - auc: 0.6226 - loss: 0.6309 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5247\n","Epoch 40/100\n","\u001b[1m303/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6952 - auc: 0.6135 - loss: 0.6202\n","Epoch 40: val_loss improved from 0.52414 to 0.52353, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6951 - auc: 0.6142 - loss: 0.6200 - val_acc: 0.7901 - val_auc: 0.5874 - val_loss: 0.5235\n","Epoch 41/100\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6718 - auc: 0.6839 - loss: 0.6153\n","Epoch 41: val_loss improved from 0.52353 to 0.52301, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6719 - auc: 0.6838 - loss: 0.6153 - val_acc: 0.7901 - val_auc: 0.5874 - val_loss: 0.5230\n","Epoch 42/100\n","\u001b[1m305/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6524 - auc: 0.5601 - loss: 0.6538\n","Epoch 42: val_loss did not improve from 0.52301\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6547 - auc: 0.5620 - loss: 0.6520 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5240\n","Epoch 43/100\n","\u001b[1m315/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6995 - auc: 0.5562 - loss: 0.6210\n","Epoch 43: val_loss did not improve from 0.52301\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6994 - auc: 0.5574 - loss: 0.6209 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5243\n","Epoch 44/100\n","\u001b[1m321/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6913 - auc: 0.6455 - loss: 0.6139\n","Epoch 44: val_loss did not improve from 0.52301\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6913 - auc: 0.6452 - loss: 0.6139 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5238\n","Epoch 45/100\n","\u001b[1m317/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7152 - auc: 0.6634 - loss: 0.5935\n","Epoch 45: val_loss did not improve from 0.52301\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7146 - auc: 0.6627 - loss: 0.5940 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5240\n","Epoch 46/100\n","\u001b[1m301/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7167 - auc: 0.6195 - loss: 0.5983\n","Epoch 46: val_loss did not improve from 0.52301\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7151 - auc: 0.6194 - loss: 0.5995 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5233\n","Epoch 47/100\n","\u001b[1m307/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7109 - auc: 0.6350 - loss: 0.6005\n","Epoch 47: val_loss did not improve from 0.52301\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7102 - auc: 0.6329 - loss: 0.6014 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5253\n","Epoch 48/100\n","\u001b[1m304/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6938 - auc: 0.6504 - loss: 0.6087\n","Epoch 48: val_loss did not improve from 0.52301\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6942 - auc: 0.6499 - loss: 0.6086 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5236\n","Epoch 49/100\n","\u001b[1m301/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7244 - auc: 0.6388 - loss: 0.5944\n","Epoch 49: val_loss did not improve from 0.52301\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7223 - auc: 0.6371 - loss: 0.5958 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5242\n","Epoch 50/100\n","\u001b[1m303/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6685 - auc: 0.6119 - loss: 0.6341\n","Epoch 50: val_loss did not improve from 0.52301\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6700 - auc: 0.6116 - loss: 0.6331 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5234\n","Epoch 51/100\n","\u001b[1m301/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7355 - auc: 0.6508 - loss: 0.5830\n","Epoch 51: val_loss did not improve from 0.52301\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7328 - auc: 0.6488 - loss: 0.5850 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5238\n","Epoch 52/100\n","\u001b[1m301/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7019 - auc: 0.6416 - loss: 0.6044\n","Epoch 52: val_loss improved from 0.52301 to 0.52282, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7017 - auc: 0.6406 - loss: 0.6048 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5228\n","Epoch 53/100\n","\u001b[1m303/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6887 - auc: 0.6145 - loss: 0.6193\n","Epoch 53: val_loss improved from 0.52282 to 0.52208, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6892 - auc: 0.6157 - loss: 0.6187 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5221\n","Epoch 54/100\n","\u001b[1m307/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6891 - auc: 0.6644 - loss: 0.6067\n","Epoch 54: val_loss improved from 0.52208 to 0.52095, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6892 - auc: 0.6635 - loss: 0.6067 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5210\n","Epoch 55/100\n","\u001b[1m305/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6985 - auc: 0.6229 - loss: 0.6118\n","Epoch 55: val_loss did not improve from 0.52095\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6986 - auc: 0.6230 - loss: 0.6117 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5222\n","Epoch 56/100\n","\u001b[1m320/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6952 - auc: 0.5949 - loss: 0.6119\n","Epoch 56: val_loss improved from 0.52095 to 0.52024, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6952 - auc: 0.5955 - loss: 0.6118 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5202\n","Epoch 57/100\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7135 - auc: 0.6777 - loss: 0.5850\n","Epoch 57: val_loss did not improve from 0.52024\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7134 - auc: 0.6775 - loss: 0.5851 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5213\n","Epoch 58/100\n","\u001b[1m317/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6977 - auc: 0.6050 - loss: 0.6130\n","Epoch 58: val_loss did not improve from 0.52024\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6976 - auc: 0.6049 - loss: 0.6130 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5215\n","Epoch 59/100\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6793 - auc: 0.6677 - loss: 0.6090\n","Epoch 59: val_loss improved from 0.52024 to 0.52002, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6794 - auc: 0.6676 - loss: 0.6090 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5200\n","Epoch 60/100\n","\u001b[1m307/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6996 - auc: 0.6344 - loss: 0.6024\n","Epoch 60: val_loss did not improve from 0.52002\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6992 - auc: 0.6338 - loss: 0.6028 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5206\n","Epoch 61/100\n","\u001b[1m309/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6839 - auc: 0.6461 - loss: 0.6088\n","Epoch 61: val_loss improved from 0.52002 to 0.51937, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6844 - auc: 0.6458 - loss: 0.6086 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5194\n","Epoch 62/100\n","\u001b[1m311/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6900 - auc: 0.6526 - loss: 0.6054\n","Epoch 62: val_loss did not improve from 0.51937\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6903 - auc: 0.6519 - loss: 0.6054 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5198\n","Epoch 63/100\n","\u001b[1m311/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6957 - auc: 0.6653 - loss: 0.5990\n","Epoch 63: val_loss improved from 0.51937 to 0.51837, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6958 - auc: 0.6643 - loss: 0.5992 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5184\n","Epoch 64/100\n","\u001b[1m307/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6909 - auc: 0.6096 - loss: 0.6142\n","Epoch 64: val_loss did not improve from 0.51837\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6911 - auc: 0.6100 - loss: 0.6139 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5202\n","Epoch 65/100\n","\u001b[1m308/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6978 - auc: 0.6456 - loss: 0.6035\n","Epoch 65: val_loss did not improve from 0.51837\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6978 - auc: 0.6452 - loss: 0.6036 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5194\n","Epoch 66/100\n","\u001b[1m305/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6931 - auc: 0.6475 - loss: 0.6035\n","Epoch 66: val_loss did not improve from 0.51837\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6932 - auc: 0.6467 - loss: 0.6036 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5192\n","Epoch 67/100\n","\u001b[1m304/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6883 - auc: 0.5986 - loss: 0.6152\n","Epoch 67: val_loss did not improve from 0.51837\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6885 - auc: 0.5994 - loss: 0.6149 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5206\n","Epoch 68/100\n","\u001b[1m308/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6811 - auc: 0.6366 - loss: 0.6144\n","Epoch 68: val_loss did not improve from 0.51837\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6815 - auc: 0.6364 - loss: 0.6141 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5200\n","Epoch 69/100\n","\u001b[1m312/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6833 - auc: 0.6303 - loss: 0.6112\n","Epoch 69: val_loss did not improve from 0.51837\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6837 - auc: 0.6301 - loss: 0.6109 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5191\n","Epoch 70/100\n","\u001b[1m310/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6987 - auc: 0.6437 - loss: 0.5991\n","Epoch 70: val_loss improved from 0.51837 to 0.51796, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6986 - auc: 0.6428 - loss: 0.5994 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5180\n","Epoch 71/100\n","\u001b[1m305/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6824 - auc: 0.6622 - loss: 0.6045\n","Epoch 71: val_loss improved from 0.51796 to 0.51624, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6832 - auc: 0.6610 - loss: 0.6043 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5162\n","Epoch 72/100\n","\u001b[1m320/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6867 - auc: 0.6090 - loss: 0.6141\n","Epoch 72: val_loss did not improve from 0.51624\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6869 - auc: 0.6088 - loss: 0.6140 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5189\n","Epoch 73/100\n","\u001b[1m318/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6480 - auc: 0.6109 - loss: 0.6330\n","Epoch 73: val_loss did not improve from 0.51624\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6488 - auc: 0.6112 - loss: 0.6325 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5178\n","Epoch 74/100\n","\u001b[1m309/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6879 - auc: 0.6553 - loss: 0.6025\n","Epoch 74: val_loss did not improve from 0.51624\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6879 - auc: 0.6544 - loss: 0.6027 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5177\n","Epoch 75/100\n","\u001b[1m302/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7234 - auc: 0.5863 - loss: 0.5892\n","Epoch 75: val_loss did not improve from 0.51624\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7211 - auc: 0.5882 - loss: 0.5904 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5185\n","Epoch 76/100\n","\u001b[1m309/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6869 - auc: 0.6130 - loss: 0.6106\n","Epoch 76: val_loss did not improve from 0.51624\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6871 - auc: 0.6135 - loss: 0.6103 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5181\n","Epoch 77/100\n","\u001b[1m304/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7136 - auc: 0.6019 - loss: 0.5951\n","Epoch 77: val_loss did not improve from 0.51624\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7123 - auc: 0.6036 - loss: 0.5957 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5184\n","Epoch 78/100\n","\u001b[1m302/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6831 - auc: 0.6332 - loss: 0.6092\n","Epoch 78: val_loss did not improve from 0.51624\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6837 - auc: 0.6334 - loss: 0.6087 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5174\n","Epoch 79/100\n","\u001b[1m303/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6956 - auc: 0.6225 - loss: 0.6028\n","Epoch 79: val_loss did not improve from 0.51624\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6956 - auc: 0.6213 - loss: 0.6031 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5187\n","Epoch 80/100\n","\u001b[1m301/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6896 - auc: 0.6653 - loss: 0.5989\n","Epoch 80: val_loss improved from 0.51624 to 0.51565, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6903 - auc: 0.6650 - loss: 0.5984 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5156\n","Epoch 81/100\n","\u001b[1m303/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7041 - auc: 0.5847 - loss: 0.6037\n","Epoch 81: val_loss did not improve from 0.51565\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7036 - auc: 0.5861 - loss: 0.6038 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5191\n","Epoch 82/100\n","\u001b[1m311/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6843 - auc: 0.6545 - loss: 0.6044\n","Epoch 82: val_loss did not improve from 0.51565\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6844 - auc: 0.6537 - loss: 0.6044 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5186\n","Epoch 83/100\n","\u001b[1m310/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7136 - auc: 0.6472 - loss: 0.5836\n","Epoch 83: val_loss did not improve from 0.51565\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7127 - auc: 0.6468 - loss: 0.5842 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5173\n","Epoch 84/100\n","\u001b[1m309/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6905 - auc: 0.6341 - loss: 0.6025\n","Epoch 84: val_loss did not improve from 0.51565\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6908 - auc: 0.6335 - loss: 0.6025 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5184\n","Epoch 85/100\n","\u001b[1m305/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7075 - auc: 0.6153 - loss: 0.5938\n","Epoch 85: val_loss did not improve from 0.51565\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7071 - auc: 0.6157 - loss: 0.5940 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5183\n","Epoch 86/100\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7121 - auc: 0.6728 - loss: 0.5797\n","Epoch 86: val_loss did not improve from 0.51565\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7121 - auc: 0.6728 - loss: 0.5797 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5166\n","Epoch 87/100\n","\u001b[1m302/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6974 - auc: 0.6021 - loss: 0.6046\n","Epoch 87: val_loss did not improve from 0.51565\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6974 - auc: 0.6031 - loss: 0.6044 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5168\n","Epoch 88/100\n","\u001b[1m320/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6733 - auc: 0.6444 - loss: 0.6118\n","Epoch 88: val_loss did not improve from 0.51565\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6736 - auc: 0.6445 - loss: 0.6116 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5163\n","Epoch 89/100\n","\u001b[1m304/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6791 - auc: 0.6503 - loss: 0.6035\n","Epoch 89: val_loss improved from 0.51565 to 0.51483, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6799 - auc: 0.6502 - loss: 0.6031 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5148\n","Epoch 90/100\n","\u001b[1m304/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6983 - auc: 0.6068 - loss: 0.6020\n","Epoch 90: val_loss did not improve from 0.51483\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6982 - auc: 0.6082 - loss: 0.6019 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5159\n","Epoch 91/100\n","\u001b[1m303/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6917 - auc: 0.6439 - loss: 0.5950\n","Epoch 91: val_loss improved from 0.51483 to 0.51454, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6919 - auc: 0.6437 - loss: 0.5951 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5145\n","Epoch 92/100\n","\u001b[1m307/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6781 - auc: 0.6126 - loss: 0.6116\n","Epoch 92: val_loss did not improve from 0.51454\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6788 - auc: 0.6135 - loss: 0.6111 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5149\n","Epoch 93/100\n","\u001b[1m311/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7034 - auc: 0.5809 - loss: 0.6017\n","Epoch 93: val_loss did not improve from 0.51454\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7031 - auc: 0.5823 - loss: 0.6017 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5152\n","Epoch 94/100\n","\u001b[1m306/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7084 - auc: 0.6550 - loss: 0.5835\n","Epoch 94: val_loss did not improve from 0.51454\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7078 - auc: 0.6539 - loss: 0.5841 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5151\n","Epoch 95/100\n","\u001b[1m303/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6915 - auc: 0.6432 - loss: 0.5966\n","Epoch 95: val_loss did not improve from 0.51454\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6918 - auc: 0.6420 - loss: 0.5967 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5147\n","Epoch 96/100\n","\u001b[1m302/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6766 - auc: 0.6076 - loss: 0.6116\n","Epoch 96: val_loss improved from 0.51454 to 0.51352, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6776 - auc: 0.6097 - loss: 0.6107 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5135\n","Epoch 97/100\n","\u001b[1m304/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7189 - auc: 0.6361 - loss: 0.5822\n","Epoch 97: val_loss did not improve from 0.51352\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7176 - auc: 0.6346 - loss: 0.5833 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5151\n","Epoch 98/100\n","\u001b[1m312/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6968 - auc: 0.6202 - loss: 0.5972\n","Epoch 98: val_loss did not improve from 0.51352\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6969 - auc: 0.6207 - loss: 0.5971 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5151\n","Epoch 99/100\n","\u001b[1m307/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6991 - auc: 0.6383 - loss: 0.5934\n","Epoch 99: val_loss did not improve from 0.51352\n","\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6987 - auc: 0.6375 - loss: 0.5937 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5145\n","Epoch 100/100\n","\u001b[1m321/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6856 - auc: 0.6377 - loss: 0.6011\n","Epoch 100: val_loss improved from 0.51352 to 0.51253, saving model to best_tab_only_fold4.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6857 - auc: 0.6378 - loss: 0.6010 - val_acc: 0.7901 - val_auc: 0.9021 - val_loss: 0.5125\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 4 AUC: 0.9524\n","\n","--- Fold 5/10 ---\n"," train | ids:   36 | files:  996 | pos:  309 | neg:  687\n","   val | ids:    4 | files:  145 | pos:   77 | neg:   68\n","  test | ids:    4 | files:   59 | pos:   19 | neg:   40\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 5))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m308/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6597 - auc: 0.6383 - loss: 0.6380\n","Epoch 1: val_loss improved from inf to 0.82786, saving model to best_tab_only_fold5.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - acc: 0.6625 - auc: 0.6388 - loss: 0.6372 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8279\n","Epoch 2/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7243 - auc: 0.6573 - loss: 0.6008\n","Epoch 2: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7242 - auc: 0.6574 - loss: 0.6009 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8730\n","Epoch 3/100\n","\u001b[1m323/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7109 - auc: 0.6484 - loss: 0.6043\n","Epoch 3: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7113 - auc: 0.6489 - loss: 0.6040 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9129\n","Epoch 4/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7041 - auc: 0.6295 - loss: 0.6111\n","Epoch 4: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7046 - auc: 0.6307 - loss: 0.6104 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9525\n","Epoch 5/100\n","\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7367 - auc: 0.7059 - loss: 0.5710\n","Epoch 5: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7366 - auc: 0.7057 - loss: 0.5711 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9838\n","Epoch 6/100\n","\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7428 - auc: 0.6821 - loss: 0.5675\n","Epoch 6: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7426 - auc: 0.6819 - loss: 0.5676 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0081\n","Epoch 7/100\n","\u001b[1m308/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7399 - auc: 0.6826 - loss: 0.5755\n","Epoch 7: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7390 - auc: 0.6825 - loss: 0.5758 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0361\n","Epoch 8/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7561 - auc: 0.6735 - loss: 0.5574\n","Epoch 8: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7557 - auc: 0.6735 - loss: 0.5578 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0612\n","Epoch 9/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7274 - auc: 0.6802 - loss: 0.5817\n","Epoch 9: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7278 - auc: 0.6804 - loss: 0.5814 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0854\n","Epoch 10/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7353 - auc: 0.6875 - loss: 0.5732\n","Epoch 10: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7354 - auc: 0.6879 - loss: 0.5730 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1066\n","Epoch 11/100\n","\u001b[1m314/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7435 - auc: 0.6616 - loss: 0.5723\n","Epoch 11: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7433 - auc: 0.6637 - loss: 0.5719 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1233\n","Epoch 12/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7131 - auc: 0.6758 - loss: 0.5972\n","Epoch 12: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7135 - auc: 0.6758 - loss: 0.5968 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1373\n","Epoch 13/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7426 - auc: 0.6869 - loss: 0.5586\n","Epoch 13: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7425 - auc: 0.6870 - loss: 0.5588 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1507\n","Epoch 14/100\n","\u001b[1m307/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7617 - auc: 0.7262 - loss: 0.5440\n","Epoch 14: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7601 - auc: 0.7238 - loss: 0.5455 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1644\n","Epoch 15/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7418 - auc: 0.6818 - loss: 0.5608\n","Epoch 15: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7417 - auc: 0.6821 - loss: 0.5609 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1781\n","Epoch 16/100\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7352 - auc: 0.6666 - loss: 0.5795\n","Epoch 16: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7352 - auc: 0.6666 - loss: 0.5795 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1917\n","Epoch 17/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7518 - auc: 0.7086 - loss: 0.5563\n","Epoch 17: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7515 - auc: 0.7082 - loss: 0.5565 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2009\n","Epoch 18/100\n","\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7460 - auc: 0.7115 - loss: 0.5534\n","Epoch 18: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7459 - auc: 0.7114 - loss: 0.5535 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2141\n","Epoch 19/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7568 - auc: 0.6851 - loss: 0.5526\n","Epoch 19: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7565 - auc: 0.6851 - loss: 0.5528 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2194\n","Epoch 20/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7164 - auc: 0.6869 - loss: 0.5745\n","Epoch 20: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7167 - auc: 0.6869 - loss: 0.5744 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2301\n","Epoch 21/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7663 - auc: 0.7087 - loss: 0.5384\n","Epoch 21: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7658 - auc: 0.7085 - loss: 0.5389 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2411\n","Epoch 22/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7219 - auc: 0.7011 - loss: 0.5661\n","Epoch 22: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7220 - auc: 0.7011 - loss: 0.5660 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2527\n","Epoch 23/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7259 - auc: 0.7120 - loss: 0.5666\n","Epoch 23: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7262 - auc: 0.7112 - loss: 0.5665 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2605\n","Epoch 24/100\n","\u001b[1m322/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7488 - auc: 0.6726 - loss: 0.5534\n","Epoch 24: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7485 - auc: 0.6732 - loss: 0.5535 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2658\n","Epoch 25/100\n","\u001b[1m313/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7233 - auc: 0.7105 - loss: 0.5524\n","Epoch 25: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7240 - auc: 0.7096 - loss: 0.5526 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2753\n","Epoch 26/100\n","\u001b[1m309/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7260 - auc: 0.6962 - loss: 0.5674\n","Epoch 26: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7269 - auc: 0.6955 - loss: 0.5670 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2816\n","Epoch 27/100\n","\u001b[1m311/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7597 - auc: 0.7112 - loss: 0.5497\n","Epoch 27: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7586 - auc: 0.7102 - loss: 0.5500 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2904\n","Epoch 28/100\n","\u001b[1m309/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7332 - auc: 0.7458 - loss: 0.5471\n","Epoch 28: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7336 - auc: 0.7424 - loss: 0.5477 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2955\n","Epoch 29/100\n","\u001b[1m310/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7717 - auc: 0.6679 - loss: 0.5423\n","Epoch 29: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7697 - auc: 0.6697 - loss: 0.5431 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3006\n","Epoch 30/100\n","\u001b[1m313/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7192 - auc: 0.6563 - loss: 0.5845\n","Epoch 30: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7203 - auc: 0.6587 - loss: 0.5827 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3093\n","Epoch 31/100\n","\u001b[1m309/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7378 - auc: 0.6918 - loss: 0.5582\n","Epoch 31: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7378 - auc: 0.6919 - loss: 0.5580 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3106\n","Epoch 32/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7282 - auc: 0.6958 - loss: 0.5667\n","Epoch 32: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7283 - auc: 0.6957 - loss: 0.5665 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3141\n","Epoch 33/100\n","\u001b[1m307/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7417 - auc: 0.6797 - loss: 0.5638\n","Epoch 33: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7408 - auc: 0.6818 - loss: 0.5632 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3211\n","Epoch 34/100\n","\u001b[1m311/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7437 - auc: 0.6595 - loss: 0.5607\n","Epoch 34: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7433 - auc: 0.6618 - loss: 0.5602 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3257\n","Epoch 35/100\n","\u001b[1m310/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7525 - auc: 0.7404 - loss: 0.5244\n","Epoch 35: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7518 - auc: 0.7385 - loss: 0.5258 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3331\n","Epoch 36/100\n","\u001b[1m309/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7378 - auc: 0.6748 - loss: 0.5631\n","Epoch 36: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7381 - auc: 0.6762 - loss: 0.5625 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3355\n","Epoch 37/100\n","\u001b[1m312/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7267 - auc: 0.7150 - loss: 0.5503\n","Epoch 37: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7276 - auc: 0.7142 - loss: 0.5503 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3391\n","Epoch 38/100\n","\u001b[1m326/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7107 - auc: 0.6877 - loss: 0.5821\n","Epoch 38: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7113 - auc: 0.6881 - loss: 0.5814 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3466\n","Epoch 39/100\n","\u001b[1m324/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7483 - auc: 0.7486 - loss: 0.5248\n","Epoch 39: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7481 - auc: 0.7480 - loss: 0.5252 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3567\n","Epoch 40/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7200 - auc: 0.7165 - loss: 0.5545\n","Epoch 40: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7207 - auc: 0.7161 - loss: 0.5542 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3566\n","Epoch 41/100\n","\u001b[1m310/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7220 - auc: 0.7261 - loss: 0.5481\n","Epoch 41: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7230 - auc: 0.7253 - loss: 0.5478 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3589\n","Epoch 42/100\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7343 - auc: 0.6652 - loss: 0.5699\n","Epoch 42: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7343 - auc: 0.6654 - loss: 0.5698 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3619\n","Epoch 43/100\n","\u001b[1m309/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7228 - auc: 0.6830 - loss: 0.5626\n","Epoch 43: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7243 - auc: 0.6847 - loss: 0.5612 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3697\n","Epoch 44/100\n","\u001b[1m308/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7061 - auc: 0.7052 - loss: 0.5754\n","Epoch 44: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7085 - auc: 0.7057 - loss: 0.5731 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3724\n","Epoch 45/100\n","\u001b[1m308/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7385 - auc: 0.7360 - loss: 0.5361\n","Epoch 45: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7387 - auc: 0.7342 - loss: 0.5367 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3730\n","Epoch 46/100\n","\u001b[1m308/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7353 - auc: 0.7121 - loss: 0.5471\n","Epoch 46: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7356 - auc: 0.7123 - loss: 0.5467 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3792\n","Epoch 47/100\n","\u001b[1m309/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7600 - auc: 0.7429 - loss: 0.5180\n","Epoch 47: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7588 - auc: 0.7410 - loss: 0.5194 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3806\n","Epoch 48/100\n","\u001b[1m310/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7240 - auc: 0.6657 - loss: 0.5668\n","Epoch 48: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7249 - auc: 0.6689 - loss: 0.5650 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3830\n","Epoch 49/100\n","\u001b[1m307/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7309 - auc: 0.7243 - loss: 0.5398\n","Epoch 49: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7319 - auc: 0.7228 - loss: 0.5401 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3860\n","Epoch 50/100\n","\u001b[1m309/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7655 - auc: 0.7341 - loss: 0.5165\n","Epoch 50: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7636 - auc: 0.7333 - loss: 0.5179 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3864\n","Epoch 51/100\n","\u001b[1m312/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7519 - auc: 0.7072 - loss: 0.5324\n","Epoch 51: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7511 - auc: 0.7068 - loss: 0.5332 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3838\n","Epoch 52/100\n","\u001b[1m309/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7197 - auc: 0.7027 - loss: 0.5541\n","Epoch 52: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7210 - auc: 0.7029 - loss: 0.5531 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3871\n","Epoch 53/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7438 - auc: 0.7273 - loss: 0.5276\n","Epoch 53: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7437 - auc: 0.7273 - loss: 0.5277 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3972\n","Epoch 54/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7700 - auc: 0.6979 - loss: 0.5176\n","Epoch 54: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7689 - auc: 0.6983 - loss: 0.5185 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3920\n","Epoch 55/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7360 - auc: 0.6958 - loss: 0.5443\n","Epoch 55: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7360 - auc: 0.6960 - loss: 0.5442 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3908\n","Epoch 56/100\n","\u001b[1m308/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7401 - auc: 0.6794 - loss: 0.5525\n","Epoch 56: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7401 - auc: 0.6820 - loss: 0.5513 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3971\n","Epoch 57/100\n","\u001b[1m313/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7335 - auc: 0.7087 - loss: 0.5402\n","Epoch 57: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7337 - auc: 0.7090 - loss: 0.5400 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3943\n","Epoch 58/100\n","\u001b[1m311/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7173 - auc: 0.6705 - loss: 0.5670\n","Epoch 58: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7190 - auc: 0.6723 - loss: 0.5651 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3983\n","Epoch 59/100\n","\u001b[1m311/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7196 - auc: 0.7199 - loss: 0.5404\n","Epoch 59: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7208 - auc: 0.7201 - loss: 0.5398 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4030\n","Epoch 60/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7396 - auc: 0.7090 - loss: 0.5379\n","Epoch 60: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7396 - auc: 0.7090 - loss: 0.5379 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4026\n","Epoch 61/100\n","\u001b[1m311/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7599 - auc: 0.7099 - loss: 0.5271\n","Epoch 61: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7586 - auc: 0.7103 - loss: 0.5276 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4035\n","Epoch 62/100\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7316 - auc: 0.7010 - loss: 0.5365\n","Epoch 62: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7316 - auc: 0.7011 - loss: 0.5365 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4093\n","Epoch 63/100\n","\u001b[1m309/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7577 - auc: 0.7195 - loss: 0.5183\n","Epoch 63: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7566 - auc: 0.7190 - loss: 0.5193 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4148\n","Epoch 64/100\n","\u001b[1m308/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7373 - auc: 0.7101 - loss: 0.5372\n","Epoch 64: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7375 - auc: 0.7106 - loss: 0.5368 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4142\n","Epoch 65/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7502 - auc: 0.7161 - loss: 0.5202\n","Epoch 65: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7500 - auc: 0.7160 - loss: 0.5204 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4146\n","Epoch 66/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7460 - auc: 0.7060 - loss: 0.5301\n","Epoch 66: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7460 - auc: 0.7060 - loss: 0.5301 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4139\n","Epoch 67/100\n","\u001b[1m330/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7372 - auc: 0.7039 - loss: 0.5374\n","Epoch 67: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7372 - auc: 0.7040 - loss: 0.5373 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4162\n","Epoch 68/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7572 - auc: 0.7292 - loss: 0.5161\n","Epoch 68: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7566 - auc: 0.7285 - loss: 0.5169 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4178\n","Epoch 69/100\n","\u001b[1m320/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7275 - auc: 0.7230 - loss: 0.5355\n","Epoch 69: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7279 - auc: 0.7224 - loss: 0.5355 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4182\n","Epoch 70/100\n","\u001b[1m309/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7410 - auc: 0.6967 - loss: 0.5406\n","Epoch 70: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7408 - auc: 0.6976 - loss: 0.5402 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4176\n","Epoch 71/100\n","\u001b[1m312/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7454 - auc: 0.7171 - loss: 0.5233\n","Epoch 71: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7450 - auc: 0.7165 - loss: 0.5240 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4196\n","Epoch 72/100\n","\u001b[1m329/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7260 - auc: 0.6951 - loss: 0.5557\n","Epoch 72: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7262 - auc: 0.6953 - loss: 0.5554 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4216\n","Epoch 73/100\n","\u001b[1m309/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7517 - auc: 0.7083 - loss: 0.5276\n","Epoch 73: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7509 - auc: 0.7087 - loss: 0.5278 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4217\n","Epoch 74/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7356 - auc: 0.6967 - loss: 0.5460\n","Epoch 74: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7356 - auc: 0.6967 - loss: 0.5460 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4192\n","Epoch 75/100\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7377 - auc: 0.7217 - loss: 0.5310\n","Epoch 75: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7377 - auc: 0.7217 - loss: 0.5310 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4236\n","Epoch 76/100\n","\u001b[1m306/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7334 - auc: 0.7368 - loss: 0.5251\n","Epoch 76: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7337 - auc: 0.7356 - loss: 0.5255 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4282\n","Epoch 77/100\n","\u001b[1m309/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7368 - auc: 0.7010 - loss: 0.5445\n","Epoch 77: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7371 - auc: 0.7019 - loss: 0.5435 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4301\n","Epoch 78/100\n","\u001b[1m308/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7189 - auc: 0.7359 - loss: 0.5357\n","Epoch 78: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7203 - auc: 0.7350 - loss: 0.5350 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4316\n","Epoch 79/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7297 - auc: 0.7335 - loss: 0.5211\n","Epoch 79: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7299 - auc: 0.7333 - loss: 0.5211 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4337\n","Epoch 80/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7282 - auc: 0.7143 - loss: 0.5364\n","Epoch 80: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7283 - auc: 0.7143 - loss: 0.5363 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4287\n","Epoch 81/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7436 - auc: 0.7245 - loss: 0.5189\n","Epoch 81: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7434 - auc: 0.7240 - loss: 0.5194 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4346\n","Epoch 82/100\n","\u001b[1m319/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7464 - auc: 0.7060 - loss: 0.5263\n","Epoch 82: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7461 - auc: 0.7064 - loss: 0.5264 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4350\n","Epoch 83/100\n","\u001b[1m317/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7411 - auc: 0.7145 - loss: 0.5320\n","Epoch 83: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7409 - auc: 0.7146 - loss: 0.5319 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4367\n","Epoch 84/100\n","\u001b[1m308/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7419 - auc: 0.7032 - loss: 0.5305\n","Epoch 84: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7418 - auc: 0.7040 - loss: 0.5302 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4354\n","Epoch 85/100\n","\u001b[1m308/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7415 - auc: 0.6944 - loss: 0.5348\n","Epoch 85: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7414 - auc: 0.6961 - loss: 0.5342 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4369\n","Epoch 86/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7259 - auc: 0.7178 - loss: 0.5335\n","Epoch 86: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7262 - auc: 0.7178 - loss: 0.5333 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4368\n","Epoch 87/100\n","\u001b[1m307/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7030 - auc: 0.6915 - loss: 0.5667\n","Epoch 87: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7058 - auc: 0.6933 - loss: 0.5637 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4350\n","Epoch 88/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7265 - auc: 0.7028 - loss: 0.5402\n","Epoch 88: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7268 - auc: 0.7030 - loss: 0.5400 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4368\n","Epoch 89/100\n","\u001b[1m311/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7460 - auc: 0.6992 - loss: 0.5266\n","Epoch 89: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7455 - auc: 0.6999 - loss: 0.5267 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4337\n","Epoch 90/100\n","\u001b[1m310/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7611 - auc: 0.7166 - loss: 0.5097\n","Epoch 90: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7595 - auc: 0.7168 - loss: 0.5109 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4276\n","Epoch 91/100\n","\u001b[1m309/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7406 - auc: 0.7184 - loss: 0.5219\n","Epoch 91: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7403 - auc: 0.7180 - loss: 0.5224 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4326\n","Epoch 92/100\n","\u001b[1m308/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7306 - auc: 0.6985 - loss: 0.5373\n","Epoch 92: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7313 - auc: 0.6996 - loss: 0.5367 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4339\n","Epoch 93/100\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7625 - auc: 0.7356 - loss: 0.4977\n","Epoch 93: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7624 - auc: 0.7356 - loss: 0.4978 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4291\n","Epoch 94/100\n","\u001b[1m328/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7249 - auc: 0.6937 - loss: 0.5479\n","Epoch 94: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7251 - auc: 0.6938 - loss: 0.5477 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4280\n","Epoch 95/100\n","\u001b[1m325/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7344 - auc: 0.7042 - loss: 0.5311\n","Epoch 95: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7344 - auc: 0.7043 - loss: 0.5310 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4299\n","Epoch 96/100\n","\u001b[1m318/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7584 - auc: 0.7055 - loss: 0.5214\n","Epoch 96: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7577 - auc: 0.7055 - loss: 0.5217 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4294\n","Epoch 97/100\n","\u001b[1m317/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7429 - auc: 0.7072 - loss: 0.5196\n","Epoch 97: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7426 - auc: 0.7076 - loss: 0.5199 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4280\n","Epoch 98/100\n","\u001b[1m327/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7405 - auc: 0.7431 - loss: 0.5126\n","Epoch 98: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7405 - auc: 0.7426 - loss: 0.5128 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4347\n","Epoch 99/100\n","\u001b[1m311/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7173 - auc: 0.7411 - loss: 0.5250\n","Epoch 99: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7186 - auc: 0.7395 - loss: 0.5250 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4365\n","Epoch 100/100\n","\u001b[1m331/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7626 - auc: 0.7287 - loss: 0.4962\n","Epoch 100: val_loss did not improve from 0.82786\n","\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7624 - auc: 0.7286 - loss: 0.4964 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.4371\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 5 AUC: 0.3750\n","\n","--- Fold 6/10 ---\n"," train | ids:   36 | files:  927 | pos:  327 | neg:  600\n","   val | ids:    4 | files:  234 | pos:   77 | neg:  157\n","  test | ids:    4 | files:   39 | pos:    1 | neg:   38\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 5))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m303/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4537 - auc: 0.3946 - loss: 0.7218\n","Epoch 1: val_loss improved from inf to 0.64119, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - acc: 0.4542 - auc: 0.3949 - loss: 0.7215 - val_acc: 1.0000 - val_auc: 1.0000 - val_loss: 0.6412\n","Epoch 2/100\n","\u001b[1m302/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5472 - auc: 0.4249 - loss: 0.6879\n","Epoch 2: val_loss improved from 0.64119 to 0.62372, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.5475 - auc: 0.4258 - loss: 0.6878 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6237\n","Epoch 3/100\n","\u001b[1m305/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5950 - auc: 0.4775 - loss: 0.6682\n","Epoch 3: val_loss improved from 0.62372 to 0.61956, saving model to best_tab_only_fold6.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.5950 - auc: 0.4775 - loss: 0.6682 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6196\n","Epoch 4/100\n","\u001b[1m308/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6333 - auc: 0.5206 - loss: 0.6525\n","Epoch 4: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6333 - auc: 0.5206 - loss: 0.6525 - val_acc: 0.6709 - val_auc: 1.0000 - val_loss: 0.6212\n","Epoch 5/100\n","\u001b[1m301/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6516 - auc: 0.5344 - loss: 0.6495\n","Epoch 5: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6516 - auc: 0.5346 - loss: 0.6495 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6259\n","Epoch 6/100\n","\u001b[1m297/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6543 - auc: 0.5860 - loss: 0.6426\n","Epoch 6: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6547 - auc: 0.5875 - loss: 0.6422 - val_acc: 0.6709 - val_auc: 0.4268 - val_loss: 0.6316\n","Epoch 7/100\n","\u001b[1m305/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6666 - auc: 0.6327 - loss: 0.6308\n","Epoch 7: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6665 - auc: 0.6329 - loss: 0.6308 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.6385\n","Epoch 8/100\n","\u001b[1m299/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6473 - auc: 0.6464 - loss: 0.6348\n","Epoch 8: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6478 - auc: 0.6463 - loss: 0.6345 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.6476\n","Epoch 9/100\n","\u001b[1m305/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6565 - auc: 0.6172 - loss: 0.6351\n","Epoch 9: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6566 - auc: 0.6176 - loss: 0.6349 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.6575\n","Epoch 10/100\n","\u001b[1m306/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6650 - auc: 0.5939 - loss: 0.6310\n","Epoch 10: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6651 - auc: 0.5942 - loss: 0.6310 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.6668\n","Epoch 11/100\n","\u001b[1m303/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6688 - auc: 0.6592 - loss: 0.6337\n","Epoch 11: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6692 - auc: 0.6587 - loss: 0.6334 - val_acc: 0.6709 - val_auc: 0.2484 - val_loss: 0.6724\n","Epoch 12/100\n","\u001b[1m300/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6789 - auc: 0.6429 - loss: 0.6265\n","Epoch 12: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6791 - auc: 0.6433 - loss: 0.6262 - val_acc: 0.6709 - val_auc: 0.1242 - val_loss: 0.6771\n","Epoch 13/100\n","\u001b[1m304/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6611 - auc: 0.6543 - loss: 0.6284\n","Epoch 13: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6615 - auc: 0.6541 - loss: 0.6282 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.6823\n","Epoch 14/100\n","\u001b[1m305/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6844 - auc: 0.6245 - loss: 0.6231\n","Epoch 14: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6846 - auc: 0.6246 - loss: 0.6230 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.6875\n","Epoch 15/100\n","\u001b[1m298/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6814 - auc: 0.6628 - loss: 0.6148\n","Epoch 15: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6819 - auc: 0.6626 - loss: 0.6146 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.6930\n","Epoch 16/100\n","\u001b[1m303/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6789 - auc: 0.6640 - loss: 0.6109\n","Epoch 16: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6791 - auc: 0.6639 - loss: 0.6108 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.6981\n","Epoch 17/100\n","\u001b[1m304/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6717 - auc: 0.6257 - loss: 0.6266\n","Epoch 17: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6722 - auc: 0.6259 - loss: 0.6263 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7029\n","Epoch 18/100\n","\u001b[1m307/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6816 - auc: 0.6519 - loss: 0.6122\n","Epoch 18: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6818 - auc: 0.6519 - loss: 0.6121 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7085\n","Epoch 19/100\n","\u001b[1m306/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6834 - auc: 0.6551 - loss: 0.6103\n","Epoch 19: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6836 - auc: 0.6550 - loss: 0.6102 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7133\n","Epoch 20/100\n","\u001b[1m297/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7061 - auc: 0.6573 - loss: 0.5959\n","Epoch 20: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7058 - auc: 0.6572 - loss: 0.5960 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7181\n","Epoch 21/100\n","\u001b[1m294/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6993 - auc: 0.6348 - loss: 0.6021\n","Epoch 21: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6994 - auc: 0.6345 - loss: 0.6021 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7222\n","Epoch 22/100\n","\u001b[1m292/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7158 - auc: 0.6388 - loss: 0.5886\n","Epoch 22: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7152 - auc: 0.6393 - loss: 0.5889 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7257\n","Epoch 23/100\n","\u001b[1m307/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6868 - auc: 0.6229 - loss: 0.6117\n","Epoch 23: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6870 - auc: 0.6231 - loss: 0.6115 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7289\n","Epoch 24/100\n","\u001b[1m302/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6986 - auc: 0.6662 - loss: 0.5962\n","Epoch 24: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6987 - auc: 0.6659 - loss: 0.5961 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7329\n","Epoch 25/100\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7226 - auc: 0.6744 - loss: 0.5735\n","Epoch 25: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7226 - auc: 0.6743 - loss: 0.5736 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7364\n","Epoch 26/100\n","\u001b[1m306/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7001 - auc: 0.6716 - loss: 0.5880\n","Epoch 26: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7002 - auc: 0.6716 - loss: 0.5880 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7401\n","Epoch 27/100\n","\u001b[1m306/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6905 - auc: 0.6701 - loss: 0.5949\n","Epoch 27: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6907 - auc: 0.6700 - loss: 0.5948 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7435\n","Epoch 28/100\n","\u001b[1m304/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6813 - auc: 0.6472 - loss: 0.6090\n","Epoch 28: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6816 - auc: 0.6476 - loss: 0.6087 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7466\n","Epoch 29/100\n","\u001b[1m305/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6655 - auc: 0.6664 - loss: 0.6158\n","Epoch 29: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6660 - auc: 0.6664 - loss: 0.6154 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7495\n","Epoch 30/100\n","\u001b[1m304/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6985 - auc: 0.6336 - loss: 0.6015\n","Epoch 30: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6985 - auc: 0.6338 - loss: 0.6014 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7523\n","Epoch 31/100\n","\u001b[1m306/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6954 - auc: 0.6835 - loss: 0.5851\n","Epoch 31: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6955 - auc: 0.6834 - loss: 0.5851 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7553\n","Epoch 32/100\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7029 - auc: 0.6681 - loss: 0.5808\n","Epoch 32: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7029 - auc: 0.6681 - loss: 0.5808 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7580\n","Epoch 33/100\n","\u001b[1m302/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6615 - auc: 0.6411 - loss: 0.6138\n","Epoch 33: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6624 - auc: 0.6416 - loss: 0.6132 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7610\n","Epoch 34/100\n","\u001b[1m292/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6953 - auc: 0.6957 - loss: 0.5835\n","Epoch 34: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6956 - auc: 0.6945 - loss: 0.5836 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7641\n","Epoch 35/100\n","\u001b[1m297/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7021 - auc: 0.6511 - loss: 0.5848\n","Epoch 35: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7020 - auc: 0.6517 - loss: 0.5848 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7667\n","Epoch 36/100\n","\u001b[1m291/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7104 - auc: 0.6730 - loss: 0.5702\n","Epoch 36: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7098 - auc: 0.6723 - loss: 0.5710 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7692\n","Epoch 37/100\n","\u001b[1m303/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7104 - auc: 0.6810 - loss: 0.5654\n","Epoch 37: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7101 - auc: 0.6811 - loss: 0.5657 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7726\n","Epoch 38/100\n","\u001b[1m300/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7171 - auc: 0.6924 - loss: 0.5602\n","Epoch 38: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7166 - auc: 0.6918 - loss: 0.5607 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7749\n","Epoch 39/100\n","\u001b[1m299/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6987 - auc: 0.6717 - loss: 0.5790\n","Epoch 39: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6987 - auc: 0.6724 - loss: 0.5789 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7769\n","Epoch 40/100\n","\u001b[1m300/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7159 - auc: 0.6828 - loss: 0.5619\n","Epoch 40: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7154 - auc: 0.6825 - loss: 0.5623 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7796\n","Epoch 41/100\n","\u001b[1m296/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6943 - auc: 0.6564 - loss: 0.5833\n","Epoch 41: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6944 - auc: 0.6570 - loss: 0.5831 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7814\n","Epoch 42/100\n","\u001b[1m298/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6855 - auc: 0.6428 - loss: 0.5958\n","Epoch 42: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6860 - auc: 0.6439 - loss: 0.5952 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7835\n","Epoch 43/100\n","\u001b[1m299/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6806 - auc: 0.6763 - loss: 0.5924\n","Epoch 43: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6813 - auc: 0.6767 - loss: 0.5918 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7858\n","Epoch 44/100\n","\u001b[1m301/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6950 - auc: 0.6975 - loss: 0.5751\n","Epoch 44: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6952 - auc: 0.6968 - loss: 0.5752 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7881\n","Epoch 45/100\n","\u001b[1m298/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7060 - auc: 0.6210 - loss: 0.5880\n","Epoch 45: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7057 - auc: 0.6223 - loss: 0.5879 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7889\n","Epoch 46/100\n","\u001b[1m302/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7313 - auc: 0.6573 - loss: 0.5600\n","Epoch 46: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7304 - auc: 0.6577 - loss: 0.5604 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7903\n","Epoch 47/100\n","\u001b[1m294/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6926 - auc: 0.6224 - loss: 0.5960\n","Epoch 47: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6930 - auc: 0.6249 - loss: 0.5951 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7919\n","Epoch 48/100\n","\u001b[1m306/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6981 - auc: 0.6292 - loss: 0.5884\n","Epoch 48: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6982 - auc: 0.6296 - loss: 0.5883 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7932\n","Epoch 49/100\n","\u001b[1m293/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6809 - auc: 0.6838 - loss: 0.5810\n","Epoch 49: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6820 - auc: 0.6827 - loss: 0.5807 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7948\n","Epoch 50/100\n","\u001b[1m285/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7088 - auc: 0.6712 - loss: 0.5697\n","Epoch 50: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7082 - auc: 0.6714 - loss: 0.5699 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7964\n","Epoch 51/100\n","\u001b[1m298/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6896 - auc: 0.6866 - loss: 0.5765\n","Epoch 51: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6900 - auc: 0.6862 - loss: 0.5763 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7981\n","Epoch 52/100\n","\u001b[1m298/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7148 - auc: 0.6882 - loss: 0.5580\n","Epoch 52: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7142 - auc: 0.6872 - loss: 0.5587 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.7994\n","Epoch 53/100\n","\u001b[1m303/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7139 - auc: 0.6884 - loss: 0.5597\n","Epoch 53: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7136 - auc: 0.6880 - loss: 0.5600 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8007\n","Epoch 54/100\n","\u001b[1m303/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6950 - auc: 0.6796 - loss: 0.5729\n","Epoch 54: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6951 - auc: 0.6794 - loss: 0.5730 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8018\n","Epoch 55/100\n","\u001b[1m302/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7137 - auc: 0.6581 - loss: 0.5705\n","Epoch 55: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7133 - auc: 0.6580 - loss: 0.5707 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8019\n","Epoch 56/100\n","\u001b[1m299/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6917 - auc: 0.6022 - loss: 0.5960\n","Epoch 56: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6919 - auc: 0.6041 - loss: 0.5954 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8029\n","Epoch 57/100\n","\u001b[1m298/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6969 - auc: 0.6699 - loss: 0.5745\n","Epoch 57: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6970 - auc: 0.6698 - loss: 0.5745 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8038\n","Epoch 58/100\n","\u001b[1m308/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6883 - auc: 0.6765 - loss: 0.5747\n","Epoch 58: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6883 - auc: 0.6764 - loss: 0.5746 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8058\n","Epoch 59/100\n","\u001b[1m303/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6951 - auc: 0.6708 - loss: 0.5753\n","Epoch 59: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6953 - auc: 0.6705 - loss: 0.5753 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8065\n","Epoch 60/100\n","\u001b[1m299/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7003 - auc: 0.6719 - loss: 0.5682\n","Epoch 60: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7004 - auc: 0.6718 - loss: 0.5682 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8084\n","Epoch 61/100\n","\u001b[1m304/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7052 - auc: 0.6492 - loss: 0.5727\n","Epoch 61: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7051 - auc: 0.6496 - loss: 0.5726 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8094\n","Epoch 62/100\n","\u001b[1m295/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7234 - auc: 0.6683 - loss: 0.5589\n","Epoch 62: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7222 - auc: 0.6693 - loss: 0.5592 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8122\n","Epoch 63/100\n","\u001b[1m299/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6931 - auc: 0.6885 - loss: 0.5679\n","Epoch 63: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6934 - auc: 0.6877 - loss: 0.5680 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8135\n","Epoch 64/100\n","\u001b[1m287/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6861 - auc: 0.6642 - loss: 0.5768\n","Epoch 64: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6873 - auc: 0.6638 - loss: 0.5763 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8144\n","Epoch 65/100\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6811 - auc: 0.6597 - loss: 0.5841\n","Epoch 65: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6812 - auc: 0.6597 - loss: 0.5840 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8158\n","Epoch 66/100\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7155 - auc: 0.6480 - loss: 0.5668\n","Epoch 66: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7155 - auc: 0.6481 - loss: 0.5668 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8152\n","Epoch 67/100\n","\u001b[1m285/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6791 - auc: 0.6457 - loss: 0.5931\n","Epoch 67: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6807 - auc: 0.6466 - loss: 0.5917 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8153\n","Epoch 68/100\n","\u001b[1m285/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6997 - auc: 0.6669 - loss: 0.5690\n","Epoch 68: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6998 - auc: 0.6673 - loss: 0.5687 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8179\n","Epoch 69/100\n","\u001b[1m307/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7063 - auc: 0.6705 - loss: 0.5632\n","Epoch 69: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7063 - auc: 0.6704 - loss: 0.5633 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8189\n","Epoch 70/100\n","\u001b[1m304/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7191 - auc: 0.6734 - loss: 0.5540\n","Epoch 70: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7188 - auc: 0.6734 - loss: 0.5542 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8209\n","Epoch 71/100\n","\u001b[1m286/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7104 - auc: 0.6671 - loss: 0.5586\n","Epoch 71: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7099 - auc: 0.6682 - loss: 0.5587 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8227\n","Epoch 72/100\n","\u001b[1m307/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6837 - auc: 0.6521 - loss: 0.5834\n","Epoch 72: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6838 - auc: 0.6521 - loss: 0.5833 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8226\n","Epoch 73/100\n","\u001b[1m302/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6975 - auc: 0.6739 - loss: 0.5647\n","Epoch 73: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6976 - auc: 0.6742 - loss: 0.5646 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8243\n","Epoch 74/100\n","\u001b[1m304/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7163 - auc: 0.6868 - loss: 0.5459\n","Epoch 74: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7160 - auc: 0.6867 - loss: 0.5462 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8256\n","Epoch 75/100\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7064 - auc: 0.6648 - loss: 0.5604\n","Epoch 75: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7064 - auc: 0.6648 - loss: 0.5604 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8271\n","Epoch 76/100\n","\u001b[1m301/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6944 - auc: 0.6676 - loss: 0.5721\n","Epoch 76: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6946 - auc: 0.6679 - loss: 0.5718 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8283\n","Epoch 77/100\n","\u001b[1m297/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6987 - auc: 0.6508 - loss: 0.5734\n","Epoch 77: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6987 - auc: 0.6513 - loss: 0.5732 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8283\n","Epoch 78/100\n","\u001b[1m289/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7017 - auc: 0.6725 - loss: 0.5609\n","Epoch 78: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7016 - auc: 0.6725 - loss: 0.5610 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8298\n","Epoch 79/100\n","\u001b[1m302/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6948 - auc: 0.6641 - loss: 0.5700\n","Epoch 79: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6950 - auc: 0.6644 - loss: 0.5698 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8315\n","Epoch 80/100\n","\u001b[1m306/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7193 - auc: 0.6631 - loss: 0.5556\n","Epoch 80: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7190 - auc: 0.6631 - loss: 0.5558 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8321\n","Epoch 81/100\n","\u001b[1m302/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6956 - auc: 0.6942 - loss: 0.5620\n","Epoch 81: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6957 - auc: 0.6938 - loss: 0.5621 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8328\n","Epoch 82/100\n","\u001b[1m286/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6925 - auc: 0.6461 - loss: 0.5778\n","Epoch 82: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6929 - auc: 0.6489 - loss: 0.5765 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8357\n","Epoch 83/100\n","\u001b[1m304/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6973 - auc: 0.6736 - loss: 0.5654\n","Epoch 83: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6974 - auc: 0.6736 - loss: 0.5654 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8361\n","Epoch 84/100\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6747 - auc: 0.6791 - loss: 0.5789\n","Epoch 84: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6748 - auc: 0.6791 - loss: 0.5788 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8380\n","Epoch 85/100\n","\u001b[1m308/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6962 - auc: 0.7107 - loss: 0.5536\n","Epoch 85: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6962 - auc: 0.7106 - loss: 0.5536 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8416\n","Epoch 86/100\n","\u001b[1m303/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6790 - auc: 0.6833 - loss: 0.5741\n","Epoch 86: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6795 - auc: 0.6832 - loss: 0.5738 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8421\n","Epoch 87/100\n","\u001b[1m306/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6863 - auc: 0.6838 - loss: 0.5661\n","Epoch 87: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6865 - auc: 0.6839 - loss: 0.5660 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8447\n","Epoch 88/100\n","\u001b[1m307/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7038 - auc: 0.6774 - loss: 0.5588\n","Epoch 88: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7038 - auc: 0.6774 - loss: 0.5589 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8456\n","Epoch 89/100\n","\u001b[1m306/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6942 - auc: 0.6525 - loss: 0.5741\n","Epoch 89: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6943 - auc: 0.6527 - loss: 0.5739 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8458\n","Epoch 90/100\n","\u001b[1m303/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6838 - auc: 0.6273 - loss: 0.5890\n","Epoch 90: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6842 - auc: 0.6281 - loss: 0.5885 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8467\n","Epoch 91/100\n","\u001b[1m297/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6636 - auc: 0.6699 - loss: 0.5872\n","Epoch 91: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6652 - auc: 0.6704 - loss: 0.5860 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8477\n","Epoch 92/100\n","\u001b[1m295/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7095 - auc: 0.6902 - loss: 0.5478\n","Epoch 92: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7091 - auc: 0.6898 - loss: 0.5483 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8501\n","Epoch 93/100\n","\u001b[1m297/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7107 - auc: 0.6760 - loss: 0.5511\n","Epoch 93: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7100 - auc: 0.6760 - loss: 0.5516 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8507\n","Epoch 94/100\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7037 - auc: 0.6649 - loss: 0.5593\n","Epoch 94: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7037 - auc: 0.6649 - loss: 0.5593 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8520\n","Epoch 95/100\n","\u001b[1m286/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7111 - auc: 0.7155 - loss: 0.5427\n","Epoch 95: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7103 - auc: 0.7128 - loss: 0.5439 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8531\n","Epoch 96/100\n","\u001b[1m284/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7031 - auc: 0.6225 - loss: 0.5754\n","Epoch 96: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7026 - auc: 0.6277 - loss: 0.5739 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8545\n","Epoch 97/100\n","\u001b[1m306/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6828 - auc: 0.6484 - loss: 0.5839\n","Epoch 97: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6830 - auc: 0.6487 - loss: 0.5836 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8554\n","Epoch 98/100\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7127 - auc: 0.7161 - loss: 0.5363\n","Epoch 98: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7127 - auc: 0.7160 - loss: 0.5363 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8585\n","Epoch 99/100\n","\u001b[1m285/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6903 - auc: 0.6770 - loss: 0.5671\n","Epoch 99: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6909 - auc: 0.6764 - loss: 0.5668 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8593\n","Epoch 100/100\n","\u001b[1m305/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7162 - auc: 0.6849 - loss: 0.5455\n","Epoch 100: val_loss did not improve from 0.61956\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7159 - auc: 0.6851 - loss: 0.5457 - val_acc: 0.6709 - val_auc: 0.0000e+00 - val_loss: 0.8625\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 6 AUC: 0.0263\n","\n","--- Fold 7/10 ---\n"," train | ids:   36 | files:  842 | pos:  290 | neg:  552\n","   val | ids:    4 | files:  220 | pos:   77 | neg:  143\n","  test | ids:    4 | files:  138 | pos:   38 | neg:  100\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 5))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m266/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.4512 - auc: 0.6602 - loss: 0.6869\n","Epoch 1: val_loss improved from inf to 0.68866, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - acc: 0.4533 - auc: 0.6621 - loss: 0.6864 - val_acc: 0.7591 - val_auc: 0.6783 - val_loss: 0.6887\n","Epoch 2/100\n","\u001b[1m280/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6137 - auc: 0.7115 - loss: 0.6618\n","Epoch 2: val_loss improved from 0.68866 to 0.68162, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6139 - auc: 0.7113 - loss: 0.6618 - val_acc: 0.4727 - val_auc: 0.6783 - val_loss: 0.6816\n","Epoch 3/100\n","\u001b[1m271/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7372 - auc: 0.6925 - loss: 0.6561\n","Epoch 3: val_loss improved from 0.68162 to 0.67675, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7364 - auc: 0.6920 - loss: 0.6561 - val_acc: 0.6500 - val_auc: 0.6783 - val_loss: 0.6768\n","Epoch 4/100\n","\u001b[1m277/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7328 - auc: 0.6932 - loss: 0.6507\n","Epoch 4: val_loss improved from 0.67675 to 0.67426, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7330 - auc: 0.6928 - loss: 0.6507 - val_acc: 0.6500 - val_auc: 0.6783 - val_loss: 0.6743\n","Epoch 5/100\n","\u001b[1m277/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7498 - auc: 0.7188 - loss: 0.6403\n","Epoch 5: val_loss improved from 0.67426 to 0.67334, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7497 - auc: 0.7190 - loss: 0.6402 - val_acc: 0.6500 - val_auc: 0.6783 - val_loss: 0.6733\n","Epoch 6/100\n","\u001b[1m277/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7384 - auc: 0.7602 - loss: 0.6300\n","Epoch 6: val_loss improved from 0.67334 to 0.67186, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7382 - auc: 0.7602 - loss: 0.6299 - val_acc: 0.6500 - val_auc: 0.3636 - val_loss: 0.6719\n","Epoch 7/100\n","\u001b[1m280/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7251 - auc: 0.7316 - loss: 0.6232\n","Epoch 7: val_loss improved from 0.67186 to 0.67020, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7250 - auc: 0.7315 - loss: 0.6232 - val_acc: 0.6500 - val_auc: 0.3636 - val_loss: 0.6702\n","Epoch 8/100\n","\u001b[1m280/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7187 - auc: 0.7478 - loss: 0.6161\n","Epoch 8: val_loss improved from 0.67020 to 0.66979, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7187 - auc: 0.7478 - loss: 0.6161 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6698\n","Epoch 9/100\n","\u001b[1m279/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6994 - auc: 0.7251 - loss: 0.6097\n","Epoch 9: val_loss improved from 0.66979 to 0.66923, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6993 - auc: 0.7251 - loss: 0.6097 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6692\n","Epoch 10/100\n","\u001b[1m275/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7152 - auc: 0.7566 - loss: 0.5993\n","Epoch 10: val_loss improved from 0.66923 to 0.66919, saving model to best_tab_only_fold7.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7148 - auc: 0.7560 - loss: 0.5994 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6692\n","Epoch 11/100\n","\u001b[1m259/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6868 - auc: 0.7359 - loss: 0.6027\n","Epoch 11: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6873 - auc: 0.7355 - loss: 0.6024 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6695\n","Epoch 12/100\n","\u001b[1m277/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6765 - auc: 0.7497 - loss: 0.5979\n","Epoch 12: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6768 - auc: 0.7497 - loss: 0.5978 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6699\n","Epoch 13/100\n","\u001b[1m272/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6853 - auc: 0.7241 - loss: 0.6001\n","Epoch 13: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6859 - auc: 0.7248 - loss: 0.5997 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6708\n","Epoch 14/100\n","\u001b[1m274/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6846 - auc: 0.7649 - loss: 0.5898\n","Epoch 14: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6850 - auc: 0.7645 - loss: 0.5896 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6724\n","Epoch 15/100\n","\u001b[1m265/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6842 - auc: 0.7538 - loss: 0.5924\n","Epoch 15: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6858 - auc: 0.7534 - loss: 0.5917 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6742\n","Epoch 16/100\n","\u001b[1m269/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7208 - auc: 0.7448 - loss: 0.5622\n","Epoch 16: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7198 - auc: 0.7446 - loss: 0.5628 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6761\n","Epoch 17/100\n","\u001b[1m280/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6988 - auc: 0.7673 - loss: 0.5665\n","Epoch 17: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6988 - auc: 0.7671 - loss: 0.5665 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6785\n","Epoch 18/100\n","\u001b[1m275/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6892 - auc: 0.7301 - loss: 0.5684\n","Epoch 18: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6892 - auc: 0.7300 - loss: 0.5685 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6801\n","Epoch 19/100\n","\u001b[1m278/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7144 - auc: 0.7582 - loss: 0.5601\n","Epoch 19: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7143 - auc: 0.7578 - loss: 0.5603 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6833\n","Epoch 20/100\n","\u001b[1m278/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7179 - auc: 0.7204 - loss: 0.5640\n","Epoch 20: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7178 - auc: 0.7206 - loss: 0.5640 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6859\n","Epoch 21/100\n","\u001b[1m273/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7219 - auc: 0.7030 - loss: 0.5760\n","Epoch 21: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7222 - auc: 0.7042 - loss: 0.5755 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6887\n","Epoch 22/100\n","\u001b[1m279/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7102 - auc: 0.7341 - loss: 0.5664\n","Epoch 22: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7102 - auc: 0.7341 - loss: 0.5665 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6909\n","Epoch 23/100\n","\u001b[1m256/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6837 - auc: 0.7220 - loss: 0.5779\n","Epoch 23: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6859 - auc: 0.7218 - loss: 0.5768 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6928\n","Epoch 24/100\n","\u001b[1m277/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6964 - auc: 0.7341 - loss: 0.5673\n","Epoch 24: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6965 - auc: 0.7338 - loss: 0.5673 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6942\n","Epoch 25/100\n","\u001b[1m257/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6960 - auc: 0.7459 - loss: 0.5551\n","Epoch 25: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6962 - auc: 0.7447 - loss: 0.5558 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6967\n","Epoch 26/100\n","\u001b[1m278/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7081 - auc: 0.7224 - loss: 0.5784\n","Epoch 26: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7081 - auc: 0.7224 - loss: 0.5782 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.6988\n","Epoch 27/100\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7090 - auc: 0.7534 - loss: 0.5535\n","Epoch 27: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7090 - auc: 0.7533 - loss: 0.5536 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7011\n","Epoch 28/100\n","\u001b[1m270/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7113 - auc: 0.7375 - loss: 0.5499\n","Epoch 28: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7117 - auc: 0.7373 - loss: 0.5500 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7037\n","Epoch 29/100\n","\u001b[1m265/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7050 - auc: 0.7256 - loss: 0.5452\n","Epoch 29: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7050 - auc: 0.7264 - loss: 0.5457 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7062\n","Epoch 30/100\n","\u001b[1m268/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7273 - auc: 0.7492 - loss: 0.5523\n","Epoch 30: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7273 - auc: 0.7490 - loss: 0.5521 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7084\n","Epoch 31/100\n","\u001b[1m267/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6989 - auc: 0.7578 - loss: 0.5509\n","Epoch 31: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7000 - auc: 0.7567 - loss: 0.5510 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7110\n","Epoch 32/100\n","\u001b[1m261/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7059 - auc: 0.7214 - loss: 0.5534\n","Epoch 32: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7051 - auc: 0.7225 - loss: 0.5535 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7130\n","Epoch 33/100\n","\u001b[1m261/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7195 - auc: 0.7460 - loss: 0.5350\n","Epoch 33: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7185 - auc: 0.7448 - loss: 0.5364 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7150\n","Epoch 34/100\n","\u001b[1m280/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7363 - auc: 0.7386 - loss: 0.5394\n","Epoch 34: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7362 - auc: 0.7385 - loss: 0.5394 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7172\n","Epoch 35/100\n","\u001b[1m278/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7074 - auc: 0.7331 - loss: 0.5475\n","Epoch 35: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7075 - auc: 0.7330 - loss: 0.5476 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7189\n","Epoch 36/100\n","\u001b[1m257/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6966 - auc: 0.7286 - loss: 0.5497\n","Epoch 36: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6967 - auc: 0.7294 - loss: 0.5495 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7212\n","Epoch 37/100\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7266 - auc: 0.7302 - loss: 0.5377\n","Epoch 37: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7266 - auc: 0.7302 - loss: 0.5377 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7234\n","Epoch 38/100\n","\u001b[1m277/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7158 - auc: 0.7316 - loss: 0.5521\n","Epoch 38: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7159 - auc: 0.7314 - loss: 0.5520 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7252\n","Epoch 39/100\n","\u001b[1m278/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7180 - auc: 0.7631 - loss: 0.5372\n","Epoch 39: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7179 - auc: 0.7628 - loss: 0.5373 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7282\n","Epoch 40/100\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7278 - auc: 0.7422 - loss: 0.5309\n","Epoch 40: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7278 - auc: 0.7422 - loss: 0.5309 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7306\n","Epoch 41/100\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7105 - auc: 0.7117 - loss: 0.5508\n","Epoch 41: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7105 - auc: 0.7117 - loss: 0.5508 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7317\n","Epoch 42/100\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7499 - auc: 0.7606 - loss: 0.5254\n","Epoch 42: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7498 - auc: 0.7605 - loss: 0.5255 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7330\n","Epoch 43/100\n","\u001b[1m275/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7317 - auc: 0.7754 - loss: 0.5121\n","Epoch 43: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7315 - auc: 0.7747 - loss: 0.5126 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7361\n","Epoch 44/100\n","\u001b[1m270/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7698 - auc: 0.7427 - loss: 0.5170\n","Epoch 44: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7691 - auc: 0.7423 - loss: 0.5179 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7375\n","Epoch 45/100\n","\u001b[1m270/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7200 - auc: 0.7115 - loss: 0.5654\n","Epoch 45: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7210 - auc: 0.7122 - loss: 0.5643 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7388\n","Epoch 46/100\n","\u001b[1m265/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7332 - auc: 0.7403 - loss: 0.5497\n","Epoch 46: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7344 - auc: 0.7404 - loss: 0.5488 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7403\n","Epoch 47/100\n","\u001b[1m279/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7475 - auc: 0.6950 - loss: 0.5511\n","Epoch 47: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7474 - auc: 0.6952 - loss: 0.5511 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7413\n","Epoch 48/100\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7530 - auc: 0.7004 - loss: 0.5489\n","Epoch 48: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7529 - auc: 0.7005 - loss: 0.5489 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7426\n","Epoch 49/100\n","\u001b[1m279/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7205 - auc: 0.7201 - loss: 0.5478\n","Epoch 49: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7209 - auc: 0.7204 - loss: 0.5476 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7439\n","Epoch 50/100\n","\u001b[1m257/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7489 - auc: 0.7560 - loss: 0.5311\n","Epoch 50: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7489 - auc: 0.7544 - loss: 0.5313 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7453\n","Epoch 51/100\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7337 - auc: 0.7403 - loss: 0.5416\n","Epoch 51: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7338 - auc: 0.7402 - loss: 0.5416 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7471\n","Epoch 52/100\n","\u001b[1m279/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7281 - auc: 0.6904 - loss: 0.5509\n","Epoch 52: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7282 - auc: 0.6907 - loss: 0.5507 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7489\n","Epoch 53/100\n","\u001b[1m280/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7346 - auc: 0.6901 - loss: 0.5587\n","Epoch 53: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7347 - auc: 0.6903 - loss: 0.5585 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7503\n","Epoch 54/100\n","\u001b[1m280/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7655 - auc: 0.7503 - loss: 0.5280\n","Epoch 54: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7655 - auc: 0.7501 - loss: 0.5280 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7525\n","Epoch 55/100\n","\u001b[1m260/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7595 - auc: 0.7218 - loss: 0.5376\n","Epoch 55: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7600 - auc: 0.7231 - loss: 0.5366 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7542\n","Epoch 56/100\n","\u001b[1m257/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7479 - auc: 0.7180 - loss: 0.5372\n","Epoch 56: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7479 - auc: 0.7184 - loss: 0.5374 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7553\n","Epoch 57/100\n","\u001b[1m276/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7758 - auc: 0.7482 - loss: 0.5145\n","Epoch 57: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7754 - auc: 0.7477 - loss: 0.5149 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7564\n","Epoch 58/100\n","\u001b[1m279/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7328 - auc: 0.7176 - loss: 0.5421\n","Epoch 58: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7329 - auc: 0.7177 - loss: 0.5419 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7565\n","Epoch 59/100\n","\u001b[1m271/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7527 - auc: 0.6903 - loss: 0.5463\n","Epoch 59: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7529 - auc: 0.6916 - loss: 0.5457 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7569\n","Epoch 60/100\n","\u001b[1m277/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7315 - auc: 0.7164 - loss: 0.5398\n","Epoch 60: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7316 - auc: 0.7165 - loss: 0.5398 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7558\n","Epoch 61/100\n","\u001b[1m266/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7667 - auc: 0.7358 - loss: 0.5115\n","Epoch 61: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7657 - auc: 0.7361 - loss: 0.5124 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7578\n","Epoch 62/100\n","\u001b[1m278/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7618 - auc: 0.7615 - loss: 0.5206\n","Epoch 62: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7616 - auc: 0.7614 - loss: 0.5207 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7595\n","Epoch 63/100\n","\u001b[1m280/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7537 - auc: 0.7286 - loss: 0.5380\n","Epoch 63: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7537 - auc: 0.7286 - loss: 0.5379 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7604\n","Epoch 64/100\n","\u001b[1m257/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7688 - auc: 0.7463 - loss: 0.5157\n","Epoch 64: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7681 - auc: 0.7469 - loss: 0.5159 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7628\n","Epoch 65/100\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7622 - auc: 0.7336 - loss: 0.5248\n","Epoch 65: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7622 - auc: 0.7335 - loss: 0.5249 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7635\n","Epoch 66/100\n","\u001b[1m278/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7519 - auc: 0.6990 - loss: 0.5389\n","Epoch 66: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7519 - auc: 0.6992 - loss: 0.5388 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7636\n","Epoch 67/100\n","\u001b[1m279/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7521 - auc: 0.7478 - loss: 0.5143\n","Epoch 67: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7520 - auc: 0.7477 - loss: 0.5144 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7641\n","Epoch 68/100\n","\u001b[1m276/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7565 - auc: 0.7522 - loss: 0.5010\n","Epoch 68: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7563 - auc: 0.7523 - loss: 0.5013 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7657\n","Epoch 69/100\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7365 - auc: 0.7467 - loss: 0.5271\n","Epoch 69: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7365 - auc: 0.7467 - loss: 0.5271 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7657\n","Epoch 70/100\n","\u001b[1m275/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7546 - auc: 0.7442 - loss: 0.5259\n","Epoch 70: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7547 - auc: 0.7438 - loss: 0.5259 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7658\n","Epoch 71/100\n","\u001b[1m275/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7758 - auc: 0.7525 - loss: 0.5065\n","Epoch 71: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7754 - auc: 0.7525 - loss: 0.5068 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7672\n","Epoch 72/100\n","\u001b[1m257/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7825 - auc: 0.7766 - loss: 0.4969\n","Epoch 72: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7811 - auc: 0.7750 - loss: 0.4981 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7692\n","Epoch 73/100\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7535 - auc: 0.7524 - loss: 0.5130\n","Epoch 73: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7535 - auc: 0.7523 - loss: 0.5130 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7702\n","Epoch 74/100\n","\u001b[1m257/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7364 - auc: 0.7087 - loss: 0.5470\n","Epoch 74: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7388 - auc: 0.7108 - loss: 0.5448 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7707\n","Epoch 75/100\n","\u001b[1m269/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7520 - auc: 0.7197 - loss: 0.5308\n","Epoch 75: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7520 - auc: 0.7206 - loss: 0.5305 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7702\n","Epoch 76/100\n","\u001b[1m273/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7431 - auc: 0.7200 - loss: 0.5323\n","Epoch 76: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7434 - auc: 0.7205 - loss: 0.5319 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7720\n","Epoch 77/100\n","\u001b[1m268/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7938 - auc: 0.7701 - loss: 0.4935\n","Epoch 77: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7925 - auc: 0.7691 - loss: 0.4948 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7732\n","Epoch 78/100\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7569 - auc: 0.7000 - loss: 0.5254\n","Epoch 78: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7569 - auc: 0.7001 - loss: 0.5254 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7725\n","Epoch 79/100\n","\u001b[1m279/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7745 - auc: 0.7716 - loss: 0.4907\n","Epoch 79: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7743 - auc: 0.7712 - loss: 0.4909 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7738\n","Epoch 80/100\n","\u001b[1m279/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7493 - auc: 0.7638 - loss: 0.5097\n","Epoch 80: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7494 - auc: 0.7637 - loss: 0.5097 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7749\n","Epoch 81/100\n","\u001b[1m280/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7374 - auc: 0.7127 - loss: 0.5333\n","Epoch 81: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7375 - auc: 0.7129 - loss: 0.5332 - val_acc: 0.6500 - val_auc: 0.0979 - val_loss: 0.7760\n","Epoch 82/100\n","\u001b[1m258/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7480 - auc: 0.7530 - loss: 0.5137\n","Epoch 82: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7480 - auc: 0.7515 - loss: 0.5146 - val_acc: 0.6500 - val_auc: 0.0979 - val_loss: 0.7757\n","Epoch 83/100\n","\u001b[1m259/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7659 - auc: 0.7638 - loss: 0.5091\n","Epoch 83: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7653 - auc: 0.7629 - loss: 0.5095 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7774\n","Epoch 84/100\n","\u001b[1m279/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7491 - auc: 0.7610 - loss: 0.5149\n","Epoch 84: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7492 - auc: 0.7610 - loss: 0.5148 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7791\n","Epoch 85/100\n","\u001b[1m280/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7817 - auc: 0.7323 - loss: 0.4994\n","Epoch 85: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7817 - auc: 0.7323 - loss: 0.4995 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7798\n","Epoch 86/100\n","\u001b[1m279/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7584 - auc: 0.7139 - loss: 0.5263\n","Epoch 86: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7583 - auc: 0.7141 - loss: 0.5263 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7800\n","Epoch 87/100\n","\u001b[1m280/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7745 - auc: 0.7721 - loss: 0.4908\n","Epoch 87: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7744 - auc: 0.7720 - loss: 0.4909 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7814\n","Epoch 88/100\n","\u001b[1m279/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7559 - auc: 0.7381 - loss: 0.5102\n","Epoch 88: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7558 - auc: 0.7380 - loss: 0.5103 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7810\n","Epoch 89/100\n","\u001b[1m278/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7470 - auc: 0.7251 - loss: 0.5231\n","Epoch 89: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7471 - auc: 0.7254 - loss: 0.5230 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7817\n","Epoch 90/100\n","\u001b[1m275/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7607 - auc: 0.7801 - loss: 0.4960\n","Epoch 90: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7606 - auc: 0.7792 - loss: 0.4964 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7821\n","Epoch 91/100\n","\u001b[1m271/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7468 - auc: 0.7092 - loss: 0.5316\n","Epoch 91: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7474 - auc: 0.7097 - loss: 0.5311 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7818\n","Epoch 92/100\n","\u001b[1m265/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7488 - auc: 0.7535 - loss: 0.5116\n","Epoch 92: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7489 - auc: 0.7524 - loss: 0.5117 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7833\n","Epoch 93/100\n","\u001b[1m279/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7664 - auc: 0.7210 - loss: 0.5113\n","Epoch 93: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7664 - auc: 0.7212 - loss: 0.5112 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7839\n","Epoch 94/100\n","\u001b[1m280/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7573 - auc: 0.7513 - loss: 0.5005\n","Epoch 94: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7573 - auc: 0.7512 - loss: 0.5006 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7844\n","Epoch 95/100\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7445 - auc: 0.7518 - loss: 0.5193\n","Epoch 95: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7446 - auc: 0.7518 - loss: 0.5192 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7862\n","Epoch 96/100\n","\u001b[1m276/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7536 - auc: 0.7710 - loss: 0.4877\n","Epoch 96: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7537 - auc: 0.7705 - loss: 0.4881 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7882\n","Epoch 97/100\n","\u001b[1m270/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7539 - auc: 0.7346 - loss: 0.5138\n","Epoch 97: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7540 - auc: 0.7345 - loss: 0.5138 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7889\n","Epoch 98/100\n","\u001b[1m275/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7671 - auc: 0.7382 - loss: 0.5192\n","Epoch 98: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7670 - auc: 0.7379 - loss: 0.5193 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7880\n","Epoch 99/100\n","\u001b[1m276/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7608 - auc: 0.7595 - loss: 0.4940\n","Epoch 99: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7608 - auc: 0.7595 - loss: 0.4941 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7891\n","Epoch 100/100\n","\u001b[1m279/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7446 - auc: 0.7358 - loss: 0.5240\n","Epoch 100: val_loss did not improve from 0.66919\n","\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7447 - auc: 0.7358 - loss: 0.5238 - val_acc: 0.6500 - val_auc: 0.0490 - val_loss: 0.7898\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 7 AUC: 0.0300\n","\n","--- Fold 8/10 ---\n"," train | ids:   36 | files:  928 | pos:  269 | neg:  659\n","   val | ids:    4 | files:  192 | pos:   77 | neg:  115\n","  test | ids:    4 | files:   80 | pos:   59 | neg:   21\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 5))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m304/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.3515 - auc: 0.3836 - loss: 0.7660\n","Epoch 1: val_loss improved from inf to 0.72212, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - acc: 0.3513 - auc: 0.3841 - loss: 0.7660 - val_acc: 0.4010 - val_auc: 0.2000 - val_loss: 0.7221\n","Epoch 2/100\n","\u001b[1m299/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3506 - auc: 0.3752 - loss: 0.7493\n","Epoch 2: val_loss improved from 0.72212 to 0.70921, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.3511 - auc: 0.3774 - loss: 0.7489 - val_acc: 0.4010 - val_auc: 0.2000 - val_loss: 0.7092\n","Epoch 3/100\n","\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4091 - auc: 0.5715 - loss: 0.7119\n","Epoch 3: val_loss improved from 0.70921 to 0.69960, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.4085 - auc: 0.5709 - loss: 0.7119 - val_acc: 0.5208 - val_auc: 0.2000 - val_loss: 0.6996\n","Epoch 4/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4155 - auc: 0.5551 - loss: 0.6950\n","Epoch 4: val_loss improved from 0.69960 to 0.69276, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.4166 - auc: 0.5548 - loss: 0.6947 - val_acc: 0.5365 - val_auc: 0.2000 - val_loss: 0.6928\n","Epoch 5/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5986 - auc: 0.5280 - loss: 0.6807\n","Epoch 5: val_loss improved from 0.69276 to 0.68728, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.5990 - auc: 0.5281 - loss: 0.6807 - val_acc: 0.5990 - val_auc: 0.2000 - val_loss: 0.6873\n","Epoch 6/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7162 - auc: 0.5111 - loss: 0.6679\n","Epoch 6: val_loss improved from 0.68728 to 0.68302, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7164 - auc: 0.5115 - loss: 0.6679 - val_acc: 0.5990 - val_auc: 0.1000 - val_loss: 0.6830\n","Epoch 7/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7651 - auc: 0.5833 - loss: 0.6509\n","Epoch 7: val_loss improved from 0.68302 to 0.67995, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7648 - auc: 0.5843 - loss: 0.6509 - val_acc: 0.5990 - val_auc: 0.4478 - val_loss: 0.6800\n","Epoch 8/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7811 - auc: 0.6260 - loss: 0.6390\n","Epoch 8: val_loss improved from 0.67995 to 0.67743, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7797 - auc: 0.6252 - loss: 0.6390 - val_acc: 0.5990 - val_auc: 0.6000 - val_loss: 0.6774\n","Epoch 9/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7520 - auc: 0.5297 - loss: 0.6402\n","Epoch 9: val_loss improved from 0.67743 to 0.67563, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7532 - auc: 0.5323 - loss: 0.6398 - val_acc: 0.5990 - val_auc: 0.5000 - val_loss: 0.6756\n","Epoch 10/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7535 - auc: 0.5714 - loss: 0.6282\n","Epoch 10: val_loss improved from 0.67563 to 0.67436, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7536 - auc: 0.5714 - loss: 0.6282 - val_acc: 0.5990 - val_auc: 0.5522 - val_loss: 0.6744\n","Epoch 11/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7728 - auc: 0.5959 - loss: 0.6142\n","Epoch 11: val_loss improved from 0.67436 to 0.67359, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7726 - auc: 0.5955 - loss: 0.6143 - val_acc: 0.5990 - val_auc: 0.4000 - val_loss: 0.6736\n","Epoch 12/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7691 - auc: 0.6183 - loss: 0.6077\n","Epoch 12: val_loss improved from 0.67359 to 0.67323, saving model to best_tab_only_fold8.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7690 - auc: 0.6181 - loss: 0.6077 - val_acc: 0.5990 - val_auc: 0.4522 - val_loss: 0.6732\n","Epoch 13/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7680 - auc: 0.5291 - loss: 0.6043\n","Epoch 13: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7680 - auc: 0.5296 - loss: 0.6043 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.6735\n","Epoch 14/100\n","\u001b[1m300/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7502 - auc: 0.6405 - loss: 0.5989\n","Epoch 14: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7506 - auc: 0.6403 - loss: 0.5986 - val_acc: 0.5990 - val_auc: 0.4522 - val_loss: 0.6742\n","Epoch 15/100\n","\u001b[1m298/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7490 - auc: 0.6188 - loss: 0.5958\n","Epoch 15: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7495 - auc: 0.6187 - loss: 0.5954 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.6753\n","Epoch 16/100\n","\u001b[1m297/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7439 - auc: 0.6427 - loss: 0.5917\n","Epoch 16: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7448 - auc: 0.6415 - loss: 0.5913 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.6771\n","Epoch 17/100\n","\u001b[1m306/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7652 - auc: 0.5832 - loss: 0.5786\n","Epoch 17: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7651 - auc: 0.5835 - loss: 0.5787 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.6794\n","Epoch 18/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7615 - auc: 0.6485 - loss: 0.5681\n","Epoch 18: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7615 - auc: 0.6485 - loss: 0.5681 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.6822\n","Epoch 19/100\n","\u001b[1m284/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7591 - auc: 0.5953 - loss: 0.5727\n","Epoch 19: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7595 - auc: 0.5967 - loss: 0.5724 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.6849\n","Epoch 20/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7703 - auc: 0.5850 - loss: 0.5637\n","Epoch 20: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7701 - auc: 0.5872 - loss: 0.5637 - val_acc: 0.5990 - val_auc: 0.4522 - val_loss: 0.6879\n","Epoch 21/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7820 - auc: 0.6077 - loss: 0.5521\n","Epoch 21: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7818 - auc: 0.6077 - loss: 0.5522 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.6905\n","Epoch 22/100\n","\u001b[1m306/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7415 - auc: 0.6406 - loss: 0.5774\n","Epoch 22: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7418 - auc: 0.6405 - loss: 0.5772 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.6931\n","Epoch 23/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7692 - auc: 0.6188 - loss: 0.5556\n","Epoch 23: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7692 - auc: 0.6188 - loss: 0.5556 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.6951\n","Epoch 24/100\n","\u001b[1m302/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7752 - auc: 0.6041 - loss: 0.5480\n","Epoch 24: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7748 - auc: 0.6042 - loss: 0.5483 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.6973\n","Epoch 25/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7593 - auc: 0.6430 - loss: 0.5497\n","Epoch 25: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7593 - auc: 0.6431 - loss: 0.5497 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.6997\n","Epoch 26/100\n","\u001b[1m303/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7529 - auc: 0.6677 - loss: 0.5512\n","Epoch 26: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7532 - auc: 0.6676 - loss: 0.5510 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7026\n","Epoch 27/100\n","\u001b[1m304/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7659 - auc: 0.6614 - loss: 0.5429\n","Epoch 27: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7658 - auc: 0.6609 - loss: 0.5430 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7044\n","Epoch 28/100\n","\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7780 - auc: 0.5969 - loss: 0.5382\n","Epoch 28: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7777 - auc: 0.5968 - loss: 0.5385 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7059\n","Epoch 29/100\n","\u001b[1m301/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7597 - auc: 0.6056 - loss: 0.5618\n","Epoch 29: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7598 - auc: 0.6060 - loss: 0.5616 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7069\n","Epoch 30/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7502 - auc: 0.5919 - loss: 0.5623\n","Epoch 30: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7509 - auc: 0.5932 - loss: 0.5616 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7084\n","Epoch 31/100\n","\u001b[1m299/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7705 - auc: 0.6275 - loss: 0.5414\n","Epoch 31: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7703 - auc: 0.6280 - loss: 0.5415 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7103\n","Epoch 32/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7513 - auc: 0.5946 - loss: 0.5621\n","Epoch 32: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7513 - auc: 0.5947 - loss: 0.5621 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7115\n","Epoch 33/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7761 - auc: 0.5768 - loss: 0.5441\n","Epoch 33: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7752 - auc: 0.5796 - loss: 0.5444 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7123\n","Epoch 34/100\n","\u001b[1m304/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7890 - auc: 0.6223 - loss: 0.5185\n","Epoch 34: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7885 - auc: 0.6223 - loss: 0.5191 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7132\n","Epoch 35/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7643 - auc: 0.6651 - loss: 0.5397\n","Epoch 35: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7643 - auc: 0.6649 - loss: 0.5397 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7143\n","Epoch 36/100\n","\u001b[1m306/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7568 - auc: 0.6502 - loss: 0.5419\n","Epoch 36: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7569 - auc: 0.6499 - loss: 0.5419 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7155\n","Epoch 37/100\n","\u001b[1m306/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7648 - auc: 0.6243 - loss: 0.5401\n","Epoch 37: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7648 - auc: 0.6245 - loss: 0.5400 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7162\n","Epoch 38/100\n","\u001b[1m303/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7580 - auc: 0.6257 - loss: 0.5493\n","Epoch 38: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7581 - auc: 0.6254 - loss: 0.5492 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7164\n","Epoch 39/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7692 - auc: 0.5975 - loss: 0.5377\n","Epoch 39: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7691 - auc: 0.5975 - loss: 0.5378 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7163\n","Epoch 40/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7642 - auc: 0.6153 - loss: 0.5413\n","Epoch 40: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7642 - auc: 0.6154 - loss: 0.5413 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7174\n","Epoch 41/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7596 - auc: 0.6293 - loss: 0.5455\n","Epoch 41: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7601 - auc: 0.6281 - loss: 0.5452 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7180\n","Epoch 42/100\n","\u001b[1m304/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7743 - auc: 0.6175 - loss: 0.5315\n","Epoch 42: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7741 - auc: 0.6177 - loss: 0.5316 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7183\n","Epoch 43/100\n","\u001b[1m299/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7672 - auc: 0.5999 - loss: 0.5425\n","Epoch 43: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7671 - auc: 0.6004 - loss: 0.5425 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7189\n","Epoch 44/100\n","\u001b[1m302/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7541 - auc: 0.6430 - loss: 0.5445\n","Epoch 44: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7543 - auc: 0.6425 - loss: 0.5444 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7198\n","Epoch 45/100\n","\u001b[1m292/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7433 - auc: 0.5988 - loss: 0.5658\n","Epoch 45: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7444 - auc: 0.5997 - loss: 0.5645 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7198\n","Epoch 46/100\n","\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7510 - auc: 0.5734 - loss: 0.5576\n","Epoch 46: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7513 - auc: 0.5739 - loss: 0.5573 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7197\n","Epoch 47/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7669 - auc: 0.6629 - loss: 0.5279\n","Epoch 47: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7668 - auc: 0.6629 - loss: 0.5279 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7210\n","Epoch 48/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7857 - auc: 0.6648 - loss: 0.5077\n","Epoch 48: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7855 - auc: 0.6647 - loss: 0.5079 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7220\n","Epoch 49/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7711 - auc: 0.6075 - loss: 0.5323\n","Epoch 49: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7706 - auc: 0.6088 - loss: 0.5326 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7223\n","Epoch 50/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7346 - auc: 0.5846 - loss: 0.5721\n","Epoch 50: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7347 - auc: 0.5847 - loss: 0.5720 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7220\n","Epoch 51/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7730 - auc: 0.6024 - loss: 0.5281\n","Epoch 51: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7730 - auc: 0.6024 - loss: 0.5281 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7223\n","Epoch 52/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7812 - auc: 0.6107 - loss: 0.5213\n","Epoch 52: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7810 - auc: 0.6107 - loss: 0.5215 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7216\n","Epoch 53/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7626 - auc: 0.6153 - loss: 0.5344\n","Epoch 53: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7626 - auc: 0.6155 - loss: 0.5344 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7222\n","Epoch 54/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7734 - auc: 0.6429 - loss: 0.5193\n","Epoch 54: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7727 - auc: 0.6428 - loss: 0.5201 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7228\n","Epoch 55/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7397 - auc: 0.6526 - loss: 0.5508\n","Epoch 55: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7414 - auc: 0.6542 - loss: 0.5489 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7239\n","Epoch 56/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7822 - auc: 0.6368 - loss: 0.5126\n","Epoch 56: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7820 - auc: 0.6366 - loss: 0.5129 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7235\n","Epoch 57/100\n","\u001b[1m306/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7530 - auc: 0.6382 - loss: 0.5387\n","Epoch 57: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7532 - auc: 0.6385 - loss: 0.5385 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7244\n","Epoch 58/100\n","\u001b[1m298/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7533 - auc: 0.5882 - loss: 0.5565\n","Epoch 58: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7537 - auc: 0.5906 - loss: 0.5555 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7248\n","Epoch 59/100\n","\u001b[1m302/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7653 - auc: 0.6506 - loss: 0.5282\n","Epoch 59: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7652 - auc: 0.6505 - loss: 0.5283 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7248\n","Epoch 60/100\n","\u001b[1m294/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7516 - auc: 0.6182 - loss: 0.5498\n","Epoch 60: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7521 - auc: 0.6184 - loss: 0.5492 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7240\n","Epoch 61/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7696 - auc: 0.6611 - loss: 0.5242\n","Epoch 61: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7696 - auc: 0.6610 - loss: 0.5242 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7233\n","Epoch 62/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7757 - auc: 0.6414 - loss: 0.5179\n","Epoch 62: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7756 - auc: 0.6413 - loss: 0.5180 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7227\n","Epoch 63/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7475 - auc: 0.6401 - loss: 0.5500\n","Epoch 63: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7488 - auc: 0.6410 - loss: 0.5483 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7229\n","Epoch 64/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7518 - auc: 0.6336 - loss: 0.5401\n","Epoch 64: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7519 - auc: 0.6337 - loss: 0.5401 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7230\n","Epoch 65/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7585 - auc: 0.6570 - loss: 0.5319\n","Epoch 65: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7585 - auc: 0.6570 - loss: 0.5319 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7233\n","Epoch 66/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7931 - auc: 0.6707 - loss: 0.4935\n","Epoch 66: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7907 - auc: 0.6691 - loss: 0.4962 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7235\n","Epoch 67/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7600 - auc: 0.6381 - loss: 0.5349\n","Epoch 67: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7600 - auc: 0.6381 - loss: 0.5349 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7233\n","Epoch 68/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7690 - auc: 0.6155 - loss: 0.5310\n","Epoch 68: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7685 - auc: 0.6161 - loss: 0.5313 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7232\n","Epoch 69/100\n","\u001b[1m306/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7538 - auc: 0.5881 - loss: 0.5482\n","Epoch 69: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7540 - auc: 0.5886 - loss: 0.5480 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7229\n","Epoch 70/100\n","\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7426 - auc: 0.6763 - loss: 0.5402\n","Epoch 70: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7430 - auc: 0.6761 - loss: 0.5399 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7233\n","Epoch 71/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7834 - auc: 0.6531 - loss: 0.5066\n","Epoch 71: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7832 - auc: 0.6530 - loss: 0.5068 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7240\n","Epoch 72/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7719 - auc: 0.5715 - loss: 0.5344\n","Epoch 72: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7719 - auc: 0.5717 - loss: 0.5344 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7229\n","Epoch 73/100\n","\u001b[1m297/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7808 - auc: 0.5564 - loss: 0.5256\n","Epoch 73: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7800 - auc: 0.5598 - loss: 0.5258 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7228\n","Epoch 74/100\n","\u001b[1m303/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7795 - auc: 0.6114 - loss: 0.5201\n","Epoch 74: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7791 - auc: 0.6113 - loss: 0.5206 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7220\n","Epoch 75/100\n","\u001b[1m300/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7653 - auc: 0.5993 - loss: 0.5383\n","Epoch 75: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7653 - auc: 0.6001 - loss: 0.5382 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7218\n","Epoch 76/100\n","\u001b[1m307/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7608 - auc: 0.6113 - loss: 0.5376\n","Epoch 76: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7608 - auc: 0.6114 - loss: 0.5376 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7212\n","Epoch 77/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7604 - auc: 0.6250 - loss: 0.5337\n","Epoch 77: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7604 - auc: 0.6251 - loss: 0.5336 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7214\n","Epoch 78/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7801 - auc: 0.6395 - loss: 0.5133\n","Epoch 78: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7786 - auc: 0.6383 - loss: 0.5149 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7210\n","Epoch 79/100\n","\u001b[1m287/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7553 - auc: 0.6668 - loss: 0.5322\n","Epoch 79: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7562 - auc: 0.6653 - loss: 0.5318 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7217\n","Epoch 80/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7809 - auc: 0.6238 - loss: 0.5146\n","Epoch 80: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7792 - auc: 0.6238 - loss: 0.5164 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7212\n","Epoch 81/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7708 - auc: 0.6360 - loss: 0.5227\n","Epoch 81: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7707 - auc: 0.6359 - loss: 0.5228 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7210\n","Epoch 82/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7485 - auc: 0.6365 - loss: 0.5435\n","Epoch 82: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7497 - auc: 0.6344 - loss: 0.5428 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7203\n","Epoch 83/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7743 - auc: 0.6246 - loss: 0.5224\n","Epoch 83: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7742 - auc: 0.6246 - loss: 0.5225 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7201\n","Epoch 84/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7536 - auc: 0.6171 - loss: 0.5467\n","Epoch 84: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7536 - auc: 0.6171 - loss: 0.5467 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7194\n","Epoch 85/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7459 - auc: 0.6028 - loss: 0.5536\n","Epoch 85: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7466 - auc: 0.6045 - loss: 0.5525 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7198\n","Epoch 86/100\n","\u001b[1m304/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7657 - auc: 0.6289 - loss: 0.5306\n","Epoch 86: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7656 - auc: 0.6288 - loss: 0.5306 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7197\n","Epoch 87/100\n","\u001b[1m305/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7648 - auc: 0.6453 - loss: 0.5246\n","Epoch 87: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7647 - auc: 0.6451 - loss: 0.5247 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7199\n","Epoch 88/100\n","\u001b[1m298/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7744 - auc: 0.5960 - loss: 0.5248\n","Epoch 88: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7740 - auc: 0.5965 - loss: 0.5253 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7195\n","Epoch 89/100\n","\u001b[1m290/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7668 - auc: 0.6160 - loss: 0.5296\n","Epoch 89: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7667 - auc: 0.6167 - loss: 0.5297 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7194\n","Epoch 90/100\n","\u001b[1m301/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7662 - auc: 0.6184 - loss: 0.5308\n","Epoch 90: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7661 - auc: 0.6183 - loss: 0.5309 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7193\n","Epoch 91/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7786 - auc: 0.6496 - loss: 0.5101\n","Epoch 91: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7773 - auc: 0.6489 - loss: 0.5118 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7193\n","Epoch 92/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7770 - auc: 0.6295 - loss: 0.5175\n","Epoch 92: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7757 - auc: 0.6292 - loss: 0.5187 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7195\n","Epoch 93/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7387 - auc: 0.6570 - loss: 0.5445\n","Epoch 93: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7389 - auc: 0.6569 - loss: 0.5443 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7201\n","Epoch 94/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7761 - auc: 0.6620 - loss: 0.5117\n","Epoch 94: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7760 - auc: 0.6619 - loss: 0.5118 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7206\n","Epoch 95/100\n","\u001b[1m285/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7872 - auc: 0.6210 - loss: 0.5048\n","Epoch 95: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7855 - auc: 0.6232 - loss: 0.5063 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7207\n","Epoch 96/100\n","\u001b[1m286/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7596 - auc: 0.6070 - loss: 0.5419\n","Epoch 96: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7600 - auc: 0.6094 - loss: 0.5409 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7207\n","Epoch 97/100\n","\u001b[1m309/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7349 - auc: 0.5915 - loss: 0.5663\n","Epoch 97: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7351 - auc: 0.5917 - loss: 0.5661 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7205\n","Epoch 98/100\n","\u001b[1m308/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7684 - auc: 0.6256 - loss: 0.5268\n","Epoch 98: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7684 - auc: 0.6256 - loss: 0.5268 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7200\n","Epoch 99/100\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7843 - auc: 0.6373 - loss: 0.5077\n","Epoch 99: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7843 - auc: 0.6374 - loss: 0.5077 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7200\n","Epoch 100/100\n","\u001b[1m288/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7605 - auc: 0.6312 - loss: 0.5328\n","Epoch 100: val_loss did not improve from 0.67323\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7607 - auc: 0.6312 - loss: 0.5326 - val_acc: 0.5990 - val_auc: 0.8000 - val_loss: 0.7197\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 8 AUC: 0.0000\n","\n","--- Fold 9/10 ---\n"," train | ids:   36 | files:  844 | pos:  286 | neg:  558\n","   val | ids:    4 | files:  207 | pos:   77 | neg:  130\n","  test | ids:    4 | files:  149 | pos:   42 | neg:  107\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 5))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.3122 - auc: 0.4553 - loss: 0.8714\n","Epoch 1: val_loss improved from inf to 0.76082, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - acc: 0.3136 - auc: 0.4552 - loss: 0.8701 - val_acc: 0.3720 - val_auc: 0.8000 - val_loss: 0.7608\n","Epoch 2/100\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3883 - auc: 0.4751 - loss: 0.7723\n","Epoch 2: val_loss improved from 0.76082 to 0.72788, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.3883 - auc: 0.4752 - loss: 0.7722 - val_acc: 0.3720 - val_auc: 0.9077 - val_loss: 0.7279\n","Epoch 3/100\n","\u001b[1m258/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3954 - auc: 0.4596 - loss: 0.7428\n","Epoch 3: val_loss improved from 0.72788 to 0.70822, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.3940 - auc: 0.4598 - loss: 0.7427 - val_acc: 0.3720 - val_auc: 0.9077 - val_loss: 0.7082\n","Epoch 4/100\n","\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4018 - auc: 0.4751 - loss: 0.7178\n","Epoch 4: val_loss improved from 0.70822 to 0.69498, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.4017 - auc: 0.4748 - loss: 0.7177 - val_acc: 0.3720 - val_auc: 0.8000 - val_loss: 0.6950\n","Epoch 5/100\n","\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4304 - auc: 0.4810 - loss: 0.7027\n","Epoch 5: val_loss improved from 0.69498 to 0.68496, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.4307 - auc: 0.4807 - loss: 0.7027 - val_acc: 0.6280 - val_auc: 0.8000 - val_loss: 0.6850\n","Epoch 6/100\n","\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5612 - auc: 0.4763 - loss: 0.6906\n","Epoch 6: val_loss improved from 0.68496 to 0.67742, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.5615 - auc: 0.4764 - loss: 0.6905 - val_acc: 0.6280 - val_auc: 0.7385 - val_loss: 0.6774\n","Epoch 7/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5981 - auc: 0.4868 - loss: 0.6801\n","Epoch 7: val_loss improved from 0.67742 to 0.67644, saving model to best_tab_only_fold9.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.5981 - auc: 0.4868 - loss: 0.6801 - val_acc: 0.6280 - val_auc: 0.3462 - val_loss: 0.6764\n","Epoch 8/100\n","\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6051 - auc: 0.4484 - loss: 0.6744\n","Epoch 8: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6053 - auc: 0.4491 - loss: 0.6743 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.6765\n","Epoch 9/100\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6466 - auc: 0.5986 - loss: 0.6539\n","Epoch 9: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6466 - auc: 0.5985 - loss: 0.6539 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.6780\n","Epoch 10/100\n","\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6503 - auc: 0.5693 - loss: 0.6555\n","Epoch 10: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6502 - auc: 0.5689 - loss: 0.6555 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.6799\n","Epoch 11/100\n","\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6088 - auc: 0.5461 - loss: 0.6628\n","Epoch 11: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6095 - auc: 0.5468 - loss: 0.6626 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.6823\n","Epoch 12/100\n","\u001b[1m273/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6321 - auc: 0.6124 - loss: 0.6519\n","Epoch 12: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6328 - auc: 0.6116 - loss: 0.6517 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.6860\n","Epoch 13/100\n","\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6703 - auc: 0.5902 - loss: 0.6437\n","Epoch 13: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6702 - auc: 0.5902 - loss: 0.6437 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.6897\n","Epoch 14/100\n","\u001b[1m265/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6526 - auc: 0.6151 - loss: 0.6454\n","Epoch 14: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6540 - auc: 0.6142 - loss: 0.6450 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.6935\n","Epoch 15/100\n","\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6658 - auc: 0.5778 - loss: 0.6419\n","Epoch 15: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6659 - auc: 0.5780 - loss: 0.6419 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.6972\n","Epoch 16/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6735 - auc: 0.6119 - loss: 0.6272\n","Epoch 16: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6735 - auc: 0.6117 - loss: 0.6273 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7010\n","Epoch 17/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7034 - auc: 0.6236 - loss: 0.6161\n","Epoch 17: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7031 - auc: 0.6233 - loss: 0.6163 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7045\n","Epoch 18/100\n","\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6511 - auc: 0.6073 - loss: 0.6422\n","Epoch 18: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6516 - auc: 0.6066 - loss: 0.6421 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7080\n","Epoch 19/100\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6489 - auc: 0.6772 - loss: 0.6303\n","Epoch 19: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6490 - auc: 0.6770 - loss: 0.6303 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7120\n","Epoch 20/100\n","\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6620 - auc: 0.6503 - loss: 0.6307\n","Epoch 20: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6621 - auc: 0.6493 - loss: 0.6307 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7155\n","Epoch 21/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6568 - auc: 0.6118 - loss: 0.6334\n","Epoch 21: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6569 - auc: 0.6115 - loss: 0.6334 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7198\n","Epoch 22/100\n","\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6788 - auc: 0.6234 - loss: 0.6174\n","Epoch 22: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6786 - auc: 0.6231 - loss: 0.6176 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7239\n","Epoch 23/100\n","\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6668 - auc: 0.5971 - loss: 0.6324\n","Epoch 23: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6668 - auc: 0.5973 - loss: 0.6324 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7280\n","Epoch 24/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6507 - auc: 0.6276 - loss: 0.6297\n","Epoch 24: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6509 - auc: 0.6276 - loss: 0.6296 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7327\n","Epoch 25/100\n","\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6522 - auc: 0.5809 - loss: 0.6420\n","Epoch 25: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6524 - auc: 0.5816 - loss: 0.6417 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7378\n","Epoch 26/100\n","\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6522 - auc: 0.6453 - loss: 0.6323\n","Epoch 26: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6524 - auc: 0.6451 - loss: 0.6322 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7415\n","Epoch 27/100\n","\u001b[1m268/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6714 - auc: 0.6630 - loss: 0.6138\n","Epoch 27: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6713 - auc: 0.6620 - loss: 0.6140 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7466\n","Epoch 28/100\n","\u001b[1m264/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6579 - auc: 0.5750 - loss: 0.6388\n","Epoch 28: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6586 - auc: 0.5765 - loss: 0.6382 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7496\n","Epoch 29/100\n","\u001b[1m267/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6812 - auc: 0.6432 - loss: 0.6056\n","Epoch 29: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6805 - auc: 0.6426 - loss: 0.6062 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7536\n","Epoch 30/100\n","\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6738 - auc: 0.6479 - loss: 0.6087\n","Epoch 30: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6738 - auc: 0.6478 - loss: 0.6087 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7573\n","Epoch 31/100\n","\u001b[1m273/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6667 - auc: 0.6577 - loss: 0.6178\n","Epoch 31: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6668 - auc: 0.6580 - loss: 0.6177 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7619\n","Epoch 32/100\n","\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6669 - auc: 0.6655 - loss: 0.6100\n","Epoch 32: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6668 - auc: 0.6654 - loss: 0.6101 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7658\n","Epoch 33/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6585 - auc: 0.6345 - loss: 0.6296\n","Epoch 33: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6586 - auc: 0.6348 - loss: 0.6295 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7696\n","Epoch 34/100\n","\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6676 - auc: 0.6608 - loss: 0.6127\n","Epoch 34: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6676 - auc: 0.6609 - loss: 0.6127 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7732\n","Epoch 35/100\n","\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6662 - auc: 0.6833 - loss: 0.6095\n","Epoch 35: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6662 - auc: 0.6827 - loss: 0.6096 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7767\n","Epoch 36/100\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6404 - auc: 0.6475 - loss: 0.6299\n","Epoch 36: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6405 - auc: 0.6475 - loss: 0.6299 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7792\n","Epoch 37/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6580 - auc: 0.6476 - loss: 0.6228\n","Epoch 37: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6581 - auc: 0.6475 - loss: 0.6228 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7825\n","Epoch 38/100\n","\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6613 - auc: 0.7020 - loss: 0.6151\n","Epoch 38: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6616 - auc: 0.7017 - loss: 0.6149 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7859\n","Epoch 39/100\n","\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6796 - auc: 0.6543 - loss: 0.6082\n","Epoch 39: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6793 - auc: 0.6547 - loss: 0.6082 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7896\n","Epoch 40/100\n","\u001b[1m259/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6587 - auc: 0.6467 - loss: 0.6248\n","Epoch 40: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6597 - auc: 0.6479 - loss: 0.6238 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7932\n","Epoch 41/100\n","\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6972 - auc: 0.6557 - loss: 0.6014\n","Epoch 41: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6966 - auc: 0.6553 - loss: 0.6019 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7944\n","Epoch 42/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6697 - auc: 0.6449 - loss: 0.6138\n","Epoch 42: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6696 - auc: 0.6452 - loss: 0.6137 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.7981\n","Epoch 43/100\n","\u001b[1m269/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6625 - auc: 0.7245 - loss: 0.6049\n","Epoch 43: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6629 - auc: 0.7223 - loss: 0.6050 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8010\n","Epoch 44/100\n","\u001b[1m270/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6631 - auc: 0.6885 - loss: 0.6107\n","Epoch 44: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6635 - auc: 0.6889 - loss: 0.6103 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8066\n","Epoch 45/100\n","\u001b[1m267/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6839 - auc: 0.6614 - loss: 0.6051\n","Epoch 45: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6832 - auc: 0.6616 - loss: 0.6054 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8064\n","Epoch 46/100\n","\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6565 - auc: 0.6421 - loss: 0.6317\n","Epoch 46: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6568 - auc: 0.6424 - loss: 0.6314 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8093\n","Epoch 47/100\n","\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7009 - auc: 0.6616 - loss: 0.5977\n","Epoch 47: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7007 - auc: 0.6615 - loss: 0.5978 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8109\n","Epoch 48/100\n","\u001b[1m259/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6547 - auc: 0.6845 - loss: 0.6181\n","Epoch 48: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6566 - auc: 0.6830 - loss: 0.6172 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8129\n","Epoch 49/100\n","\u001b[1m259/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6985 - auc: 0.6423 - loss: 0.6024\n","Epoch 49: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6968 - auc: 0.6446 - loss: 0.6029 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8170\n","Epoch 50/100\n","\u001b[1m259/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6820 - auc: 0.6587 - loss: 0.6024\n","Epoch 50: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6817 - auc: 0.6606 - loss: 0.6026 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8176\n","Epoch 51/100\n","\u001b[1m260/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7100 - auc: 0.6513 - loss: 0.5847\n","Epoch 51: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7072 - auc: 0.6539 - loss: 0.5859 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8221\n","Epoch 52/100\n","\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6752 - auc: 0.6949 - loss: 0.6032\n","Epoch 52: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6753 - auc: 0.6947 - loss: 0.6031 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8252\n","Epoch 53/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7189 - auc: 0.6833 - loss: 0.5755\n","Epoch 53: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7185 - auc: 0.6836 - loss: 0.5757 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8287\n","Epoch 54/100\n","\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6566 - auc: 0.6954 - loss: 0.6108\n","Epoch 54: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6567 - auc: 0.6953 - loss: 0.6107 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8314\n","Epoch 55/100\n","\u001b[1m257/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6930 - auc: 0.7254 - loss: 0.5791\n","Epoch 55: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6920 - auc: 0.7233 - loss: 0.5804 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8349\n","Epoch 56/100\n","\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6754 - auc: 0.7137 - loss: 0.5944\n","Epoch 56: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6753 - auc: 0.7134 - loss: 0.5945 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8370\n","Epoch 57/100\n","\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7002 - auc: 0.7096 - loss: 0.5865\n","Epoch 57: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6999 - auc: 0.7096 - loss: 0.5867 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8394\n","Epoch 58/100\n","\u001b[1m272/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6729 - auc: 0.6891 - loss: 0.6018\n","Epoch 58: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6733 - auc: 0.6893 - loss: 0.6016 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8422\n","Epoch 59/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6880 - auc: 0.6928 - loss: 0.5945\n","Epoch 59: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6879 - auc: 0.6929 - loss: 0.5945 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8456\n","Epoch 60/100\n","\u001b[1m268/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6652 - auc: 0.7268 - loss: 0.5981\n","Epoch 60: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6660 - auc: 0.7261 - loss: 0.5978 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8476\n","Epoch 61/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6540 - auc: 0.7105 - loss: 0.6101\n","Epoch 61: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6542 - auc: 0.7107 - loss: 0.6099 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8492\n","Epoch 62/100\n","\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6921 - auc: 0.6635 - loss: 0.5925\n","Epoch 62: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6919 - auc: 0.6640 - loss: 0.5925 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8519\n","Epoch 63/100\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6639 - auc: 0.6929 - loss: 0.6061\n","Epoch 63: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6640 - auc: 0.6930 - loss: 0.6061 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8531\n","Epoch 64/100\n","\u001b[1m258/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6826 - auc: 0.7130 - loss: 0.5858\n","Epoch 64: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6818 - auc: 0.7130 - loss: 0.5867 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8557\n","Epoch 65/100\n","\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6694 - auc: 0.7373 - loss: 0.5904\n","Epoch 65: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6695 - auc: 0.7373 - loss: 0.5903 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8587\n","Epoch 66/100\n","\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6809 - auc: 0.7346 - loss: 0.5851\n","Epoch 66: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6809 - auc: 0.7346 - loss: 0.5851 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8634\n","Epoch 67/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6698 - auc: 0.6910 - loss: 0.6002\n","Epoch 67: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6698 - auc: 0.6913 - loss: 0.6001 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8650\n","Epoch 68/100\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6870 - auc: 0.7472 - loss: 0.5775\n","Epoch 68: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6870 - auc: 0.7472 - loss: 0.5775 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8669\n","Epoch 69/100\n","\u001b[1m257/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6909 - auc: 0.7705 - loss: 0.5696\n","Epoch 69: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6900 - auc: 0.7665 - loss: 0.5714 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8697\n","Epoch 70/100\n","\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6860 - auc: 0.6794 - loss: 0.5896\n","Epoch 70: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6859 - auc: 0.6799 - loss: 0.5897 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8704\n","Epoch 71/100\n","\u001b[1m259/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6434 - auc: 0.7167 - loss: 0.6123\n","Epoch 71: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6463 - auc: 0.7192 - loss: 0.6097 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8742\n","Epoch 72/100\n","\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6913 - auc: 0.7365 - loss: 0.5730\n","Epoch 72: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6913 - auc: 0.7364 - loss: 0.5731 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8756\n","Epoch 73/100\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6897 - auc: 0.6976 - loss: 0.5841\n","Epoch 73: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6897 - auc: 0.6977 - loss: 0.5841 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8789\n","Epoch 74/100\n","\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6914 - auc: 0.7403 - loss: 0.5672\n","Epoch 74: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6911 - auc: 0.7399 - loss: 0.5677 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8795\n","Epoch 75/100\n","\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6868 - auc: 0.7532 - loss: 0.5741\n","Epoch 75: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6867 - auc: 0.7531 - loss: 0.5742 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8822\n","Epoch 76/100\n","\u001b[1m270/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6875 - auc: 0.7289 - loss: 0.5779\n","Epoch 76: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6874 - auc: 0.7294 - loss: 0.5780 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8850\n","Epoch 77/100\n","\u001b[1m259/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6682 - auc: 0.7316 - loss: 0.5897\n","Epoch 77: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6706 - auc: 0.7324 - loss: 0.5889 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8883\n","Epoch 78/100\n","\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6962 - auc: 0.7581 - loss: 0.5607\n","Epoch 78: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6961 - auc: 0.7578 - loss: 0.5610 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8896\n","Epoch 79/100\n","\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7220 - auc: 0.7811 - loss: 0.5619\n","Epoch 79: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7218 - auc: 0.7807 - loss: 0.5621 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8935\n","Epoch 80/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7152 - auc: 0.7620 - loss: 0.5757\n","Epoch 80: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7152 - auc: 0.7620 - loss: 0.5757 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8964\n","Epoch 81/100\n","\u001b[1m260/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7246 - auc: 0.6950 - loss: 0.5716\n","Epoch 81: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7240 - auc: 0.6983 - loss: 0.5720 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8971\n","Epoch 82/100\n","\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6814 - auc: 0.7405 - loss: 0.5983\n","Epoch 82: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6818 - auc: 0.7405 - loss: 0.5980 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.8997\n","Epoch 83/100\n","\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7056 - auc: 0.7910 - loss: 0.5711\n","Epoch 83: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7058 - auc: 0.7905 - loss: 0.5709 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9029\n","Epoch 84/100\n","\u001b[1m258/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7472 - auc: 0.7707 - loss: 0.5369\n","Epoch 84: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7447 - auc: 0.7713 - loss: 0.5393 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9060\n","Epoch 85/100\n","\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7554 - auc: 0.7618 - loss: 0.5587\n","Epoch 85: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7552 - auc: 0.7618 - loss: 0.5587 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9082\n","Epoch 86/100\n","\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7191 - auc: 0.7572 - loss: 0.5766\n","Epoch 86: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7190 - auc: 0.7573 - loss: 0.5764 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9094\n","Epoch 87/100\n","\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7146 - auc: 0.7439 - loss: 0.5690\n","Epoch 87: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7146 - auc: 0.7443 - loss: 0.5689 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9123\n","Epoch 88/100\n","\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7144 - auc: 0.7574 - loss: 0.5808\n","Epoch 88: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7150 - auc: 0.7575 - loss: 0.5804 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9131\n","Epoch 89/100\n","\u001b[1m271/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7310 - auc: 0.7757 - loss: 0.5557\n","Epoch 89: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7312 - auc: 0.7757 - loss: 0.5558 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9162\n","Epoch 90/100\n","\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7296 - auc: 0.7547 - loss: 0.5605\n","Epoch 90: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7295 - auc: 0.7551 - loss: 0.5604 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9186\n","Epoch 91/100\n","\u001b[1m272/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7090 - auc: 0.7546 - loss: 0.5740\n","Epoch 91: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7095 - auc: 0.7546 - loss: 0.5736 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9196\n","Epoch 92/100\n","\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7531 - auc: 0.7440 - loss: 0.5516\n","Epoch 92: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7523 - auc: 0.7442 - loss: 0.5519 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9198\n","Epoch 93/100\n","\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7314 - auc: 0.7914 - loss: 0.5622\n","Epoch 93: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7314 - auc: 0.7913 - loss: 0.5621 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9239\n","Epoch 94/100\n","\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7405 - auc: 0.7895 - loss: 0.5461\n","Epoch 94: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7405 - auc: 0.7890 - loss: 0.5463 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9254\n","Epoch 95/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7486 - auc: 0.7971 - loss: 0.5384\n","Epoch 95: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7485 - auc: 0.7971 - loss: 0.5384 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9269\n","Epoch 96/100\n","\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7125 - auc: 0.7732 - loss: 0.5733\n","Epoch 96: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7129 - auc: 0.7732 - loss: 0.5729 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9289\n","Epoch 97/100\n","\u001b[1m257/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7166 - auc: 0.7663 - loss: 0.5629\n","Epoch 97: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7173 - auc: 0.7679 - loss: 0.5616 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9300\n","Epoch 98/100\n","\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7139 - auc: 0.7645 - loss: 0.5537\n","Epoch 98: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7141 - auc: 0.7645 - loss: 0.5537 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9306\n","Epoch 99/100\n","\u001b[1m257/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7375 - auc: 0.7728 - loss: 0.5442\n","Epoch 99: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7378 - auc: 0.7744 - loss: 0.5441 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9348\n","Epoch 100/100\n","\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7301 - auc: 0.7653 - loss: 0.5554\n","Epoch 100: val_loss did not improve from 0.67644\n","\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7301 - auc: 0.7654 - loss: 0.5554 - val_acc: 0.6280 - val_auc: 0.0000e+00 - val_loss: 0.9377\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 9 AUC: 1.0000\n","\n","--- Fold 10/10 ---\n"," train | ids:   36 | files:  874 | pos:  319 | neg:  555\n","   val | ids:    4 | files:  145 | pos:   77 | neg:   68\n","  test | ids:    4 | files:  181 | pos:    9 | neg:  172\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: tab_input\n","Received: inputs=['Tensor(shape=(None, 5))']\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m271/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.4182 - auc: 0.4389 - loss: 0.7780\n","Epoch 1: val_loss improved from inf to 0.66815, saving model to best_tab_only_fold10.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - acc: 0.4182 - auc: 0.4399 - loss: 0.7765 - val_acc: 0.9931 - val_auc: 0.9926 - val_loss: 0.6682\n","Epoch 2/100\n","\u001b[1m290/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5106 - auc: 0.4576 - loss: 0.7240\n","Epoch 2: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.5111 - auc: 0.4581 - loss: 0.7238 - val_acc: 0.4690 - val_auc: 0.9926 - val_loss: 0.6913\n","Epoch 3/100\n","\u001b[1m270/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6264 - auc: 0.5392 - loss: 0.6790\n","Epoch 3: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6254 - auc: 0.5395 - loss: 0.6789 - val_acc: 0.4690 - val_auc: 0.7868 - val_loss: 0.7213\n","Epoch 4/100\n","\u001b[1m269/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5754 - auc: 0.5438 - loss: 0.6669\n","Epoch 4: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.5782 - auc: 0.5449 - loss: 0.6668 - val_acc: 0.4690 - val_auc: 0.2941 - val_loss: 0.7510\n","Epoch 5/100\n","\u001b[1m268/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6132 - auc: 0.5726 - loss: 0.6656\n","Epoch 5: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6130 - auc: 0.5729 - loss: 0.6654 - val_acc: 0.4690 - val_auc: 0.0074 - val_loss: 0.7785\n","Epoch 6/100\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6021 - auc: 0.6145 - loss: 0.6553\n","Epoch 6: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6021 - auc: 0.6145 - loss: 0.6553 - val_acc: 0.4690 - val_auc: 0.0074 - val_loss: 0.7994\n","Epoch 7/100\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6091 - auc: 0.6062 - loss: 0.6422\n","Epoch 7: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6091 - auc: 0.6061 - loss: 0.6423 - val_acc: 0.4690 - val_auc: 0.0074 - val_loss: 0.8179\n","Epoch 8/100\n","\u001b[1m272/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6263 - auc: 0.5848 - loss: 0.6544\n","Epoch 8: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6260 - auc: 0.5852 - loss: 0.6540 - val_acc: 0.4690 - val_auc: 0.0074 - val_loss: 0.8340\n","Epoch 9/100\n","\u001b[1m279/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6417 - auc: 0.6327 - loss: 0.6183\n","Epoch 9: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6406 - auc: 0.6322 - loss: 0.6190 - val_acc: 0.4690 - val_auc: 0.0074 - val_loss: 0.8486\n","Epoch 10/100\n","\u001b[1m272/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6245 - auc: 0.5711 - loss: 0.6574\n","Epoch 10: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6260 - auc: 0.5727 - loss: 0.6565 - val_acc: 0.4690 - val_auc: 0.0074 - val_loss: 0.8578\n","Epoch 11/100\n","\u001b[1m283/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6310 - auc: 0.6131 - loss: 0.6448\n","Epoch 11: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6312 - auc: 0.6135 - loss: 0.6446 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8707\n","Epoch 12/100\n","\u001b[1m273/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6231 - auc: 0.6078 - loss: 0.6537\n","Epoch 12: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6239 - auc: 0.6080 - loss: 0.6528 - val_acc: 0.4690 - val_auc: 0.0074 - val_loss: 0.8783\n","Epoch 13/100\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6565 - auc: 0.6189 - loss: 0.6365\n","Epoch 13: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6564 - auc: 0.6188 - loss: 0.6365 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8791\n","Epoch 14/100\n","\u001b[1m269/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6330 - auc: 0.6291 - loss: 0.6536\n","Epoch 14: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6339 - auc: 0.6248 - loss: 0.6532 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8806\n","Epoch 15/100\n","\u001b[1m288/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6795 - auc: 0.6663 - loss: 0.6098\n","Epoch 15: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6790 - auc: 0.6657 - loss: 0.6102 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8905\n","Epoch 16/100\n","\u001b[1m276/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6780 - auc: 0.6110 - loss: 0.6317\n","Epoch 16: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6773 - auc: 0.6109 - loss: 0.6319 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.8942\n","Epoch 17/100\n","\u001b[1m282/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6438 - auc: 0.6237 - loss: 0.6410\n","Epoch 17: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6438 - auc: 0.6240 - loss: 0.6406 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9000\n","Epoch 18/100\n","\u001b[1m280/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6301 - auc: 0.6264 - loss: 0.6425\n","Epoch 18: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6309 - auc: 0.6261 - loss: 0.6420 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9053\n","Epoch 19/100\n","\u001b[1m283/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6562 - auc: 0.6290 - loss: 0.6289\n","Epoch 19: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6563 - auc: 0.6289 - loss: 0.6289 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9068\n","Epoch 20/100\n","\u001b[1m280/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6274 - auc: 0.6141 - loss: 0.6457\n","Epoch 20: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6283 - auc: 0.6137 - loss: 0.6452 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9095\n","Epoch 21/100\n","\u001b[1m282/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6271 - auc: 0.6302 - loss: 0.6389\n","Epoch 21: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6277 - auc: 0.6298 - loss: 0.6386 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9159\n","Epoch 22/100\n","\u001b[1m283/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6483 - auc: 0.6258 - loss: 0.6309\n","Epoch 22: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6483 - auc: 0.6250 - loss: 0.6310 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9211\n","Epoch 23/100\n","\u001b[1m281/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6376 - auc: 0.6114 - loss: 0.6330\n","Epoch 23: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6379 - auc: 0.6118 - loss: 0.6329 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9257\n","Epoch 24/100\n","\u001b[1m279/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6653 - auc: 0.6345 - loss: 0.6317\n","Epoch 24: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6649 - auc: 0.6338 - loss: 0.6316 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9305\n","Epoch 25/100\n","\u001b[1m287/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6653 - auc: 0.6334 - loss: 0.6274\n","Epoch 25: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6652 - auc: 0.6335 - loss: 0.6273 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9345\n","Epoch 26/100\n","\u001b[1m279/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6651 - auc: 0.6209 - loss: 0.6183\n","Epoch 26: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6642 - auc: 0.6212 - loss: 0.6187 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9377\n","Epoch 27/100\n","\u001b[1m280/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6536 - auc: 0.6229 - loss: 0.6242\n","Epoch 27: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6539 - auc: 0.6239 - loss: 0.6239 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9414\n","Epoch 28/100\n","\u001b[1m281/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6741 - auc: 0.6507 - loss: 0.6133\n","Epoch 28: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6735 - auc: 0.6502 - loss: 0.6137 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9422\n","Epoch 29/100\n","\u001b[1m277/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6372 - auc: 0.6207 - loss: 0.6291\n","Epoch 29: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6381 - auc: 0.6211 - loss: 0.6289 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9473\n","Epoch 30/100\n","\u001b[1m281/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6743 - auc: 0.6196 - loss: 0.6199\n","Epoch 30: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6739 - auc: 0.6203 - loss: 0.6199 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9520\n","Epoch 31/100\n","\u001b[1m269/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6437 - auc: 0.6415 - loss: 0.6233\n","Epoch 31: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6443 - auc: 0.6410 - loss: 0.6229 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9598\n","Epoch 32/100\n","\u001b[1m280/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6658 - auc: 0.6362 - loss: 0.6083\n","Epoch 32: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6655 - auc: 0.6356 - loss: 0.6089 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9619\n","Epoch 33/100\n","\u001b[1m283/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6661 - auc: 0.6316 - loss: 0.6136\n","Epoch 33: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6659 - auc: 0.6312 - loss: 0.6139 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9677\n","Epoch 34/100\n","\u001b[1m283/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6362 - auc: 0.6247 - loss: 0.6369\n","Epoch 34: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6370 - auc: 0.6251 - loss: 0.6363 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9736\n","Epoch 35/100\n","\u001b[1m281/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6516 - auc: 0.6316 - loss: 0.6215\n","Epoch 35: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6516 - auc: 0.6317 - loss: 0.6216 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9771\n","Epoch 36/100\n","\u001b[1m278/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7038 - auc: 0.6566 - loss: 0.5928\n","Epoch 36: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.7014 - auc: 0.6559 - loss: 0.5940 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9809\n","Epoch 37/100\n","\u001b[1m282/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6222 - auc: 0.5986 - loss: 0.6395\n","Epoch 37: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6230 - auc: 0.5994 - loss: 0.6390 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9859\n","Epoch 38/100\n","\u001b[1m275/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6583 - auc: 0.6564 - loss: 0.6155\n","Epoch 38: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6585 - auc: 0.6559 - loss: 0.6153 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9951\n","Epoch 39/100\n","\u001b[1m279/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6940 - auc: 0.6435 - loss: 0.6012\n","Epoch 39: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6927 - auc: 0.6435 - loss: 0.6018 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 0.9998\n","Epoch 40/100\n","\u001b[1m284/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6453 - auc: 0.6684 - loss: 0.6129\n","Epoch 40: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6457 - auc: 0.6682 - loss: 0.6128 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0083\n","Epoch 41/100\n","\u001b[1m284/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6606 - auc: 0.6451 - loss: 0.6139\n","Epoch 41: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6606 - auc: 0.6460 - loss: 0.6137 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0149\n","Epoch 42/100\n","\u001b[1m279/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6604 - auc: 0.6663 - loss: 0.6066\n","Epoch 42: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6603 - auc: 0.6669 - loss: 0.6066 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0235\n","Epoch 43/100\n","\u001b[1m279/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6679 - auc: 0.6704 - loss: 0.5975\n","Epoch 43: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6671 - auc: 0.6709 - loss: 0.5978 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0319\n","Epoch 44/100\n","\u001b[1m280/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6527 - auc: 0.6744 - loss: 0.6009\n","Epoch 44: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6525 - auc: 0.6747 - loss: 0.6011 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0385\n","Epoch 45/100\n","\u001b[1m270/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6561 - auc: 0.6695 - loss: 0.6190\n","Epoch 45: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6566 - auc: 0.6690 - loss: 0.6182 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0436\n","Epoch 46/100\n","\u001b[1m271/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6699 - auc: 0.6751 - loss: 0.5936\n","Epoch 46: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6684 - auc: 0.6748 - loss: 0.5944 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0520\n","Epoch 47/100\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6492 - auc: 0.6289 - loss: 0.6168\n","Epoch 47: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6493 - auc: 0.6290 - loss: 0.6168 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0571\n","Epoch 48/100\n","\u001b[1m278/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6366 - auc: 0.6877 - loss: 0.6025\n","Epoch 48: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6372 - auc: 0.6878 - loss: 0.6023 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0683\n","Epoch 49/100\n","\u001b[1m278/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6345 - auc: 0.6734 - loss: 0.6057\n","Epoch 49: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6349 - auc: 0.6740 - loss: 0.6055 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0717\n","Epoch 50/100\n","\u001b[1m278/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6499 - auc: 0.6996 - loss: 0.5947\n","Epoch 50: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6495 - auc: 0.6987 - loss: 0.5951 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0797\n","Epoch 51/100\n","\u001b[1m282/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6343 - auc: 0.6917 - loss: 0.6077\n","Epoch 51: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6351 - auc: 0.6916 - loss: 0.6073 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0880\n","Epoch 52/100\n","\u001b[1m280/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6607 - auc: 0.6411 - loss: 0.6033\n","Epoch 52: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6601 - auc: 0.6421 - loss: 0.6035 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0952\n","Epoch 53/100\n","\u001b[1m280/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6525 - auc: 0.6514 - loss: 0.6036\n","Epoch 53: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6521 - auc: 0.6514 - loss: 0.6038 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.0989\n","Epoch 54/100\n","\u001b[1m279/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6791 - auc: 0.7187 - loss: 0.5784\n","Epoch 54: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6778 - auc: 0.7173 - loss: 0.5794 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1078\n","Epoch 55/100\n","\u001b[1m281/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6251 - auc: 0.6379 - loss: 0.6256\n","Epoch 55: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6257 - auc: 0.6390 - loss: 0.6249 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1081\n","Epoch 56/100\n","\u001b[1m284/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6859 - auc: 0.6959 - loss: 0.5705\n","Epoch 56: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6844 - auc: 0.6950 - loss: 0.5716 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1123\n","Epoch 57/100\n","\u001b[1m280/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6539 - auc: 0.6928 - loss: 0.5980\n","Epoch 57: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6544 - auc: 0.6922 - loss: 0.5980 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1162\n","Epoch 58/100\n","\u001b[1m278/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6873 - auc: 0.6806 - loss: 0.5721\n","Epoch 58: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6850 - auc: 0.6809 - loss: 0.5734 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1186\n","Epoch 59/100\n","\u001b[1m274/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6773 - auc: 0.6831 - loss: 0.5826\n","Epoch 59: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6750 - auc: 0.6819 - loss: 0.5841 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1212\n","Epoch 60/100\n","\u001b[1m279/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6334 - auc: 0.6355 - loss: 0.6159\n","Epoch 60: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6339 - auc: 0.6370 - loss: 0.6154 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1270\n","Epoch 61/100\n","\u001b[1m269/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6662 - auc: 0.6838 - loss: 0.5883\n","Epoch 61: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6646 - auc: 0.6849 - loss: 0.5886 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1382\n","Epoch 62/100\n","\u001b[1m272/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6572 - auc: 0.7121 - loss: 0.5804\n","Epoch 62: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6563 - auc: 0.7111 - loss: 0.5810 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1451\n","Epoch 63/100\n","\u001b[1m269/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6647 - auc: 0.6788 - loss: 0.5923\n","Epoch 63: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6634 - auc: 0.6784 - loss: 0.5926 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1500\n","Epoch 64/100\n","\u001b[1m285/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6573 - auc: 0.6524 - loss: 0.5988\n","Epoch 64: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6569 - auc: 0.6532 - loss: 0.5988 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1569\n","Epoch 65/100\n","\u001b[1m283/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6316 - auc: 0.6939 - loss: 0.5907\n","Epoch 65: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6318 - auc: 0.6934 - loss: 0.5908 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1570\n","Epoch 66/100\n","\u001b[1m279/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6279 - auc: 0.6923 - loss: 0.5974\n","Epoch 66: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6291 - auc: 0.6924 - loss: 0.5971 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1605\n","Epoch 67/100\n","\u001b[1m286/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7064 - auc: 0.7170 - loss: 0.5643\n","Epoch 67: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7052 - auc: 0.7160 - loss: 0.5651 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1640\n","Epoch 68/100\n","\u001b[1m283/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6587 - auc: 0.6945 - loss: 0.5874\n","Epoch 68: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6579 - auc: 0.6939 - loss: 0.5878 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1675\n","Epoch 69/100\n","\u001b[1m278/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6437 - auc: 0.6832 - loss: 0.6038\n","Epoch 69: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6444 - auc: 0.6837 - loss: 0.6031 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1719\n","Epoch 70/100\n","\u001b[1m279/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6405 - auc: 0.6840 - loss: 0.6034\n","Epoch 70: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6410 - auc: 0.6843 - loss: 0.6029 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1754\n","Epoch 71/100\n","\u001b[1m278/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6426 - auc: 0.7079 - loss: 0.5960\n","Epoch 71: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6428 - auc: 0.7081 - loss: 0.5955 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1845\n","Epoch 72/100\n","\u001b[1m277/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6528 - auc: 0.6949 - loss: 0.5809\n","Epoch 72: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6533 - auc: 0.6952 - loss: 0.5812 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1945\n","Epoch 73/100\n","\u001b[1m285/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6242 - auc: 0.6632 - loss: 0.5977\n","Epoch 73: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6240 - auc: 0.6633 - loss: 0.5978 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1928\n","Epoch 74/100\n","\u001b[1m281/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6691 - auc: 0.6990 - loss: 0.5811\n","Epoch 74: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6683 - auc: 0.6993 - loss: 0.5812 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.1979\n","Epoch 75/100\n","\u001b[1m281/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6432 - auc: 0.7051 - loss: 0.5904\n","Epoch 75: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6434 - auc: 0.7048 - loss: 0.5903 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2028\n","Epoch 76/100\n","\u001b[1m278/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6752 - auc: 0.7232 - loss: 0.5768\n","Epoch 76: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6741 - auc: 0.7225 - loss: 0.5773 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2073\n","Epoch 77/100\n","\u001b[1m273/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6481 - auc: 0.6951 - loss: 0.5744\n","Epoch 77: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6482 - auc: 0.6954 - loss: 0.5752 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2107\n","Epoch 78/100\n","\u001b[1m279/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6561 - auc: 0.6721 - loss: 0.5943\n","Epoch 78: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6559 - auc: 0.6731 - loss: 0.5942 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2147\n","Epoch 79/100\n","\u001b[1m289/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6665 - auc: 0.7111 - loss: 0.5780\n","Epoch 79: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6664 - auc: 0.7110 - loss: 0.5780 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2206\n","Epoch 80/100\n","\u001b[1m282/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6439 - auc: 0.6831 - loss: 0.5756\n","Epoch 80: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6436 - auc: 0.6832 - loss: 0.5762 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2240\n","Epoch 81/100\n","\u001b[1m282/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6434 - auc: 0.7176 - loss: 0.5798\n","Epoch 81: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6435 - auc: 0.7172 - loss: 0.5800 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2289\n","Epoch 82/100\n","\u001b[1m280/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6608 - auc: 0.6925 - loss: 0.5796\n","Epoch 82: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6601 - auc: 0.6931 - loss: 0.5799 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2296\n","Epoch 83/100\n","\u001b[1m282/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6116 - auc: 0.6827 - loss: 0.6019\n","Epoch 83: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6130 - auc: 0.6832 - loss: 0.6014 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2341\n","Epoch 84/100\n","\u001b[1m283/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6842 - auc: 0.7050 - loss: 0.5807\n","Epoch 84: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6834 - auc: 0.7048 - loss: 0.5809 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2386\n","Epoch 85/100\n","\u001b[1m285/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6534 - auc: 0.7100 - loss: 0.5741\n","Epoch 85: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6531 - auc: 0.7100 - loss: 0.5743 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2450\n","Epoch 86/100\n","\u001b[1m276/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6680 - auc: 0.6890 - loss: 0.5825\n","Epoch 86: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6673 - auc: 0.6898 - loss: 0.5824 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2480\n","Epoch 87/100\n","\u001b[1m278/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6584 - auc: 0.7115 - loss: 0.5737\n","Epoch 87: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6581 - auc: 0.7122 - loss: 0.5740 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2535\n","Epoch 88/100\n","\u001b[1m269/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6131 - auc: 0.7047 - loss: 0.5920\n","Epoch 88: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6156 - auc: 0.7054 - loss: 0.5912 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2587\n","Epoch 89/100\n","\u001b[1m279/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6589 - auc: 0.7156 - loss: 0.5783\n","Epoch 89: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6589 - auc: 0.7153 - loss: 0.5784 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2631\n","Epoch 90/100\n","\u001b[1m279/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6815 - auc: 0.7132 - loss: 0.5717\n","Epoch 90: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6801 - auc: 0.7128 - loss: 0.5722 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2639\n","Epoch 91/100\n","\u001b[1m278/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6546 - auc: 0.6849 - loss: 0.5739\n","Epoch 91: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6538 - auc: 0.6862 - loss: 0.5742 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2659\n","Epoch 92/100\n","\u001b[1m279/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6861 - auc: 0.7369 - loss: 0.5617\n","Epoch 92: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6850 - auc: 0.7357 - loss: 0.5626 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2733\n","Epoch 93/100\n","\u001b[1m278/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6621 - auc: 0.6814 - loss: 0.5790\n","Epoch 93: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6614 - auc: 0.6833 - loss: 0.5789 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2803\n","Epoch 94/100\n","\u001b[1m273/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6504 - auc: 0.6763 - loss: 0.5911\n","Epoch 94: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6502 - auc: 0.6781 - loss: 0.5905 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2848\n","Epoch 95/100\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6590 - auc: 0.6728 - loss: 0.6037\n","Epoch 95: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.6590 - auc: 0.6729 - loss: 0.6036 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2889\n","Epoch 96/100\n","\u001b[1m283/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6690 - auc: 0.7266 - loss: 0.5870\n","Epoch 96: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6694 - auc: 0.7263 - loss: 0.5867 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2906\n","Epoch 97/100\n","\u001b[1m283/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6936 - auc: 0.7367 - loss: 0.5663\n","Epoch 97: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6929 - auc: 0.7356 - loss: 0.5667 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2920\n","Epoch 98/100\n","\u001b[1m284/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6402 - auc: 0.6371 - loss: 0.6108\n","Epoch 98: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6407 - auc: 0.6393 - loss: 0.6098 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2949\n","Epoch 99/100\n","\u001b[1m284/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6523 - auc: 0.7257 - loss: 0.5881\n","Epoch 99: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6529 - auc: 0.7254 - loss: 0.5880 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.2951\n","Epoch 100/100\n","\u001b[1m284/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6885 - auc: 0.7342 - loss: 0.5648\n","Epoch 100: val_loss did not improve from 0.66815\n","\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.6879 - auc: 0.7338 - loss: 0.5651 - val_acc: 0.4690 - val_auc: 0.0000e+00 - val_loss: 1.3003\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 10 AUC: 1.0000\n","\n","AUCs per fold: [0.2857142857142857, 0.23875000000000002, 0.027497194163860827, 0.9523809523809523, 0.375, 0.02631578947368418, 0.030000000000000027, 0.0, 1.0, 1.0]\n","Mean AUC: 0.3936 ± 0.4049\n"]}]},{"cell_type":"code","source":["# =========================\n","# Results across folds\n","# =========================\n","print(\"\\nPer-fold AUCs:\")\n","for i, a in enumerate(fold_aucs, start=1):\n","    if np.isnan(a):\n","        print(f\"  Fold {i:2d}: NaN\")\n","    else:\n","        print(f\"  Fold {i:2d}: {a:.4f}\")\n","\n","print(\"\\nAUCs list:\", fold_aucs)\n","\n","valid_aucs = [a for a in fold_aucs if not np.isnan(a)]\n","if valid_aucs:\n","    print(f\"Mean AUC: {np.mean(valid_aucs):.4f} ± {np.std(valid_aucs):.4f}\")\n","    print(f\"Min/Max AUC: {np.min(valid_aucs):.4f} / {np.max(valid_aucs):.4f}\")\n","else:\n","    print(\"All AUCs are NaN; cannot compute summary statistics.\")"],"metadata":{"id":"IrWZ5cUFpHXs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760499681311,"user_tz":300,"elapsed":5,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"outputId":"2fe5b32c-09e5-4c0a-f132-0f5fa9b848d5"},"id":"IrWZ5cUFpHXs","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Per-fold AUCs:\n","  Fold  1: 0.2857\n","  Fold  2: 0.2388\n","  Fold  3: 0.0275\n","  Fold  4: 0.9524\n","  Fold  5: 0.3750\n","  Fold  6: 0.0263\n","  Fold  7: 0.0300\n","  Fold  8: 0.0000\n","  Fold  9: 1.0000\n","  Fold 10: 1.0000\n","\n","AUCs list: [0.2857142857142857, 0.23875000000000002, 0.027497194163860827, 0.9523809523809523, 0.375, 0.02631578947368418, 0.030000000000000027, 0.0, 1.0, 1.0]\n","Mean AUC: 0.3936 ± 0.4049\n","Min/Max AUC: 0.0000 / 1.0000\n"]}]},{"cell_type":"code","source":["# === Plot per-fold AUCs ===\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","fold_indices = np.arange(1, len(fold_aucs) + 1, dtype=int)\n","auc_array = np.array(fold_aucs, dtype=float)\n","\n","plt.figure(figsize=(14, 8))\n","# line+markers; NaNs will break the line, which is fine\n","plt.plot(fold_indices, auc_array, marker=\"o\", linewidth=1)\n","\n","# annotate non-NaN points with their values\n","for i, a in enumerate(auc_array, start=1):\n","    if not np.isnan(a):\n","        plt.text(i, a, f\"{a:.3f}\", ha=\"center\", va=\"bottom\", fontsize=8)\n","\n","# draw mean AUC if available\n","valid_mask = ~np.isnan(auc_array)\n","if valid_mask.any():\n","    mean_auc = auc_array[valid_mask].mean()\n","    plt.axhline(mean_auc, linestyle=\"--\", linewidth=1, label=f\"Mean AUC = {mean_auc:.3f}\")\n","\n","plt.title(\"Per-fold AUC\")\n","plt.xlabel(\"Fold #\")\n","plt.ylabel(\"AUC\")\n","plt.xticks(fold_indices)\n","plt.ylim(0.0, 1.0)\n","plt.grid(True, linewidth=0.3)\n","plt.legend(loc=\"lower right\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"sPOzCNAug4NW","colab":{"base_uri":"https://localhost:8080/","height":807},"executionInfo":{"status":"ok","timestamp":1760499767934,"user_tz":300,"elapsed":259,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"outputId":"9c912ee7-45ca-43e7-e151-35075f923ab2"},"id":"sPOzCNAug4NW","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1400x800 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"xxOkMiS4g4SL"},"id":"xxOkMiS4g4SL","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"ksQMstdc-o-3","metadata":{"id":"ksQMstdc-o-3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"JSdB6j-a-pDF","metadata":{"id":"JSdB6j-a-pDF"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"U7ouQnxD-pF_","metadata":{"id":"U7ouQnxD-pF_"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"WnjxgEPK-pIJ","metadata":{"id":"WnjxgEPK-pIJ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"j28g8Lqp-pKy","metadata":{"id":"j28g8Lqp-pKy"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"DJbv-4-G-pMn","metadata":{"id":"DJbv-4-G-pMn"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"Cxtz-1Fo-pPP","metadata":{"id":"Cxtz-1Fo-pPP"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"JinSNJgh-pRf","metadata":{"id":"JinSNJgh-pRf"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ywg21ljv-pcL","metadata":{"id":"ywg21ljv-pcL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"Jl01Xhpa-pfL","metadata":{"id":"Jl01Xhpa-pfL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ErNrKHRm-pg_","metadata":{"id":"ErNrKHRm-pg_"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"IElgvqQj-pit","metadata":{"id":"IElgvqQj-pit"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"-TADzyG9-pnO","metadata":{"id":"-TADzyG9-pnO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"miiDblbz-ppC","metadata":{"id":"miiDblbz-ppC"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"Bnp7fHxm-pqu","metadata":{"id":"Bnp7fHxm-pqu"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"UiQbsLv47Xu-","metadata":{"id":"UiQbsLv47Xu-"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"hhAiYZZVGIsM","metadata":{"id":"hhAiYZZVGIsM"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"EWQ7UG7zGIuj","metadata":{"id":"EWQ7UG7zGIuj"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"hUObArfBGIw5","metadata":{"id":"hUObArfBGIw5"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ln5ftwRAGI0C","metadata":{"id":"ln5ftwRAGI0C"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"jgczkpH8GI2s","metadata":{"id":"jgczkpH8GI2s"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"CFxtsYm4DJxo","metadata":{"id":"CFxtsYm4DJxo"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"zIo_rXgnDJzw","metadata":{"id":"zIo_rXgnDJzw"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"N4iBf4B0DJ14","metadata":{"id":"N4iBf4B0DJ14"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"mGuWgjhCDJ5y","metadata":{"id":"mGuWgjhCDJ5y"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"mtPQw2LIDJ8A","metadata":{"id":"mtPQw2LIDJ8A"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"VRIqcx7HDJ9m","metadata":{"id":"VRIqcx7HDJ9m"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"HfhdGuLEDJ_u","metadata":{"id":"HfhdGuLEDJ_u"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"virtual ENV","language":"python","name":"environment_instance"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":5}