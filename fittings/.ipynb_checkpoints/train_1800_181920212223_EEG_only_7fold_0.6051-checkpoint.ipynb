{"cells":[{"cell_type":"code","execution_count":1,"id":"8f5a4f5b-bad9-49e3-8dd6-7304666df443","metadata":{"id":"8f5a4f5b-bad9-49e3-8dd6-7304666df443","executionInfo":{"status":"ok","timestamp":1760664108679,"user_tz":300,"elapsed":10141,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","import torchvision\n","import torchvision.transforms as transforms\n","import os\n","import argparse\n","from pathlib import Path\n","import re\n","import random\n","import math\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":2,"id":"dr2Fm7p5mAAN","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17959,"status":"ok","timestamp":1760664126682,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"},"user_tz":300},"id":"dr2Fm7p5mAAN","outputId":"ed5e6fb9-d8e6-48fd-9b1c-3fee822b373b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":[],"metadata":{"id":"gUHWAH8qdC05","executionInfo":{"status":"ok","timestamp":1760664126696,"user_tz":300,"elapsed":5,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"gUHWAH8qdC05","execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L2wH-XagdC3h","executionInfo":{"status":"ok","timestamp":1760664126707,"user_tz":300,"elapsed":3,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"L2wH-XagdC3h","execution_count":2,"outputs":[]},{"cell_type":"markdown","id":"-6k2Q8eaHxYK","metadata":{"id":"-6k2Q8eaHxYK"},"source":["### Normalization across the whole dataset"]},{"cell_type":"code","source":[],"metadata":{"id":"uJrVqvBtpHJK","executionInfo":{"status":"ok","timestamp":1760664126715,"user_tz":300,"elapsed":4,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"uJrVqvBtpHJK","execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"REn1fKi1pHMT","executionInfo":{"status":"ok","timestamp":1760664126726,"user_tz":300,"elapsed":3,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"REn1fKi1pHMT","execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### No normalization!"],"metadata":{"id":"vCi0eO54p2NW"},"id":"vCi0eO54p2NW"},{"cell_type":"code","source":["from pathlib import Path\n","import re, random, math, os\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# =========================\n","# Config\n","# =========================\n","SPLIT_DIR = r\"/content/drive/MyDrive/CD/patient_data_clean_nozero_181920212223_1800\"\n","POS_PATIENTS = {1, 2, 16, 19, 21, 22, 25, 37, 39, 43, 44, 47, 50, 56, 58, 62, 65, 66, 73, 78}\n","\n","BATCH_SIZE       = 3\n","EPOCHS           = 100\n","LR               = 1e-4\n","SEED             = 1\n","K_FOLDS          = 7\n","BEST_MODEL_TPL   = \"best_fold_{:02d}.h5\"\n","\n","# not used for dedup height; kept for reference\n","TARGET_H = 300\n","\n","# =========================\n","# Noise config (train-time augmentation only)\n","# =========================\n","TRAIN_ADD_GAUSS_NOISE = True     # training generator only\n","TRAIN_NOISE_FRAC      = 0.10\n","TRAIN_NOISE_PROB      = 1.0\n","EPS_STD               = 1e-8\n","\n","# =========================\n","# Repro\n","# =========================\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n","for g in tf.config.list_physical_devices('GPU'):\n","    try:\n","        tf.config.experimental.set_memory_growth(g, True)\n","    except Exception:\n","        pass\n","\n","# =========================\n","# Helpers for ID/labels\n","# =========================\n","PATIENT_NUM_RX = re.compile(r'^ID(\\d+)')\n","\n","def patient_num_from_path(pathlike):\n","    stem = Path(pathlike).stem\n","    m = PATIENT_NUM_RX.match(stem)\n","    return int(m.group(1)) if m else None\n","\n","def label_for_file(p: Path) -> int:\n","    pnum = patient_num_from_path(p)\n","    return 1 if (pnum is not None and pnum in POS_PATIENTS) else 0\n","\n","# =========================\n","# List files (all) & labels by patient ID\n","# =========================\n","split_dir = Path(SPLIT_DIR)\n","all_csvs = sorted(split_dir.glob(\"*.csv\"))\n","if not all_csvs:\n","    raise FileNotFoundError(f\"No CSV found in {SPLIT_DIR}\")\n","\n","id_to_files = {}\n","for f in all_csvs:\n","    pid = patient_num_from_path(f)\n","    if pid is None:\n","        continue\n","    id_to_files.setdefault(pid, []).append(f)\n","\n","all_ids = sorted(id_to_files.keys())\n","id_labels = np.array([1 if pid in POS_PATIENTS else 0 for pid in all_ids], dtype=int)\n","print(\"Total IDs:\", len(all_ids), \"| Pos IDs:\", id_labels.sum(), \"| Neg IDs:\", (1 - id_labels).sum())\n","\n","# =========================\n","# Column handling\n","# =========================\n","def _drop_time_cols(df: pd.DataFrame) -> pd.DataFrame:\n","    time_like = [c for c in df.columns if isinstance(c, str) and c.strip().lower() == \"time\"]\n","    return df.drop(columns=time_like, errors=\"ignore\")\n","\n","def _to_numeric_df(df: pd.DataFrame) -> pd.DataFrame:\n","    df = _drop_time_cols(df)\n","    return df.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n","\n","def _pad_crop_2d(x: np.ndarray, H: int, W: int) -> np.ndarray:\n","    h, w = x.shape\n","    if h < H:\n","        pad = np.zeros((H, w), dtype=x.dtype); pad[:h, :] = x; x = pad; h = H\n","    elif h > H:\n","        x = x[:H, :]; h = H\n","    if w < W:\n","        pad = np.zeros((h, W), dtype=x.dtype); pad[:, :w] = x; x = pad\n","    elif w > W:\n","        x = x[:, :W]\n","    return x\n","\n","def _infer_target_width(example_csv: Path) -> int:\n","    df = pd.read_csv(example_csv)\n","    df2 = _to_numeric_df(df)\n","    return df2.shape[1]\n","\n","# Fix width/height ONCE using the whole dataset (so all folds match)\n","TARGET_W = _infer_target_width(all_csvs[0])\n","print(f\"TARGET_W={TARGET_W} (non-Time columns)\")\n","\n","def _dedupe_consecutive_rows(mat: np.ndarray) -> np.ndarray:\n","    if mat.size == 0:\n","        return mat\n","    if mat.ndim == 1:\n","        mat = mat[:, None]\n","    if mat.shape[0] == 1:\n","        return mat\n","    diffs = np.any(mat[1:] != mat[:-1], axis=1)\n","    keep = np.concatenate(([True], diffs))\n","    return mat[keep]\n","\n","def _dedup_len_from_csv(p: Path) -> int:\n","    df = pd.read_csv(p)\n","    mat = _to_numeric_df(df).to_numpy(dtype=np.float32)\n","    mat_d = _dedupe_consecutive_rows(mat)\n","    return int(mat_d.shape[0])\n","\n","TARGET_H_DEDUP = max(_dedup_len_from_csv(f) for f in all_csvs)\n","if TARGET_H_DEDUP <= 0:\n","    raise RuntimeError(\"After de-dup, zero-length found in data.\")\n","print(f\"Fixed input height after de-dup (all IDs): H={TARGET_H_DEDUP}\")\n","\n","def load_csv_as_image_dedup(csv_path: Path) -> np.ndarray:\n","    df  = pd.read_csv(csv_path)\n","    df2 = _to_numeric_df(df)\n","    mat = df2.to_numpy(dtype=np.float32)\n","    if mat.ndim != 2:\n","        mat = mat.reshape(mat.shape[0], -1) if mat.ndim > 2 else mat\n","    mat = _dedupe_consecutive_rows(mat)\n","    if mat.shape[0] == 0:\n","        mat = np.zeros((1, TARGET_W), dtype=np.float32)\n","    mat = _pad_crop_2d(mat, TARGET_H_DEDUP, TARGET_W)\n","    img = np.expand_dims(mat, axis=-1).astype(np.float32)\n","    if img.shape != (TARGET_H_DEDUP, TARGET_W, 1):\n","        raise ValueError(f\"loader produced {img.shape}, expected {(TARGET_H_DEDUP, TARGET_W, 1)} for {csv_path}\")\n","    return img\n","\n","# cache\n","CACHE_DEDUP = {}\n","def load_csv_as_image_cached(csv_path: Path) -> np.ndarray:\n","    key = (\"dedup\", str(csv_path))\n","    if key in CACHE_DEDUP:\n","        return CACHE_DEDUP[key]\n","    img = load_csv_as_image_dedup(csv_path)\n","    CACHE_DEDUP[key] = img\n","    return img\n","\n","print(\"Normalization: NONE. De-dup: remove consecutive duplicate rows (row-wise).\")\n","\n","# =========================\n","# Keras Sequence\n","# =========================\n","class ImageSequence(keras.utils.Sequence):\n","    def __init__(self, files, batch_size=BATCH_SIZE, shuffle=True,\n","                 add_noise=False, noise_frac=TRAIN_NOISE_FRAC, noise_prob=TRAIN_NOISE_PROB):\n","        super().__init__()\n","        self.files = list(files)\n","        self.batch_size = int(batch_size)\n","        self.shuffle = shuffle\n","        self.add_noise = add_noise\n","        self.noise_frac = float(noise_frac)\n","        self.noise_prob = float(noise_prob)\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        return math.ceil(len(self.files) / self.batch_size)\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.files))\n","        if self.shuffle:\n","            np.random.shuffle(self.indexes)\n","\n","    def __getitem__(self, idx):\n","        idxs = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n","        batch_files = [self.files[i] for i in idxs]\n","        B = len(batch_files)\n","        X = np.empty((B, TARGET_H_DEDUP, TARGET_W, 1), dtype=np.float32)\n","        y = np.empty((B,), dtype=np.int32)\n","\n","        for i, f in enumerate(batch_files):\n","            xi = load_csv_as_image_cached(f)\n","            if xi.ndim == 2:\n","                xi = xi[..., None]\n","            if xi.shape != (TARGET_H_DEDUP, TARGET_W, 1):\n","                raise ValueError(f\"Sample shape {xi.shape} for {f}; expected {(TARGET_H_DEDUP, TARGET_W, 1)}\")\n","            X[i] = xi\n","            y[i] = label_for_file(f)\n","\n","        if self.add_noise and self.noise_frac > 0.0 and self.noise_prob > 0.0:\n","            samp_std = X.reshape(B, -1).std(axis=1).astype(np.float32)\n","            samp_std = np.maximum(samp_std, EPS_STD).reshape(B, 1, 1, 1)\n","            noise = np.random.normal(0.0, 1.0, size=X.shape).astype(np.float32)\n","            noise *= (self.noise_frac * samp_std)\n","            if self.noise_prob < 1.0:\n","                mask = (np.random.rand(B, 1, 1, 1) < self.noise_prob).astype(np.float32)\n","                noise *= mask\n","            X = X + noise\n","\n","        if X.shape[1:] != (TARGET_H_DEDUP, TARGET_W, 1):\n","            raise ValueError(f\"Batch X has shape {X.shape}; expected (B, {TARGET_H_DEDUP}, {TARGET_W}, 1)\")\n","        return X, y\n","\n","# =========================\n","# DenseNet-style 2D CNN (binary head)\n","# =========================\n","def build_model(h=TARGET_H_DEDUP, w=TARGET_W, c=1, lr=LR,\n","                growth_rate=4, block_layers=(2, 2, 2, 2),\n","                compression=0.5, dropout=0.2):\n","\n","    inputs = keras.Input(shape=(h, w, c))\n","\n","    def bn_relu_conv(x, filters, ksize, stride=1):\n","        x = layers.ReLU()(x)\n","        x = layers.Conv2D(filters, ksize, strides=stride, padding=\"same\", use_bias=False)(x)\n","        return x\n","\n","    def dense_layer(x):\n","        y = bn_relu_conv(x, 4 * growth_rate, 1)\n","        y = bn_relu_conv(y, growth_rate, 3)\n","        return layers.Concatenate()([x, y])\n","\n","    def dense_block(x, L):\n","        for _ in range(L):\n","            x = dense_layer(x)\n","        return x\n","\n","    def transition_layer(x):\n","        filters = max(8, int(int(x.shape[-1]) * compression))\n","        x = bn_relu_conv(x, filters, 1)\n","        return layers.AveragePooling2D(pool_size=(2, 2), strides=2, padding=\"same\")(x)\n","\n","    x = layers.Conv2D(32, 3, padding=\"same\", use_bias=False)(inputs)\n","    x = layers.ReLU()(x)\n","\n","    for i, L in enumerate(block_layers):\n","        x = dense_block(x, L)\n","        if i != len(block_layers) - 1:\n","            x = transition_layer(x)\n","\n","    x = layers.GlobalAveragePooling2D()(x)\n","    x = layers.Dense(128, activation=\"relu\")(x)\n","    x = layers.Dropout(dropout)(x)\n","    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","\n","    model = keras.Model(inputs, outputs)\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(learning_rate=lr),\n","        loss=\"binary_crossentropy\",\n","        metrics=[keras.metrics.BinaryAccuracy(name=\"acc\"), keras.metrics.AUC(name=\"auc\")],\n","    )\n","    return model\n","\n","# =========================\n","# 7-fold CV by patient ID\n","# =========================\n","skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=SEED)\n","\n","fold_test_accs, fold_test_aucs = [], []\n","rows = []\n","\n","print(f\"\\n=== {K_FOLDS}-Fold CV (by patient ID) ===\")\n","for fold_idx, (train_idx, test_idx) in enumerate(skf.split(all_ids, id_labels), start=1):\n","    ids_train_full = [all_ids[i] for i in train_idx]\n","    ids_test       = [all_ids[i] for i in test_idx]\n","\n","    # small validation split from training IDs (for checkpointing)\n","    train_labels_full = np.array([1 if pid in POS_PATIENTS else 0 for pid in ids_train_full], dtype=int)\n","    try:\n","        ids_tr, ids_val = train_test_split(\n","            ids_train_full, test_size=0.10, random_state=SEED, stratify=train_labels_full\n","        )\n","    except ValueError:\n","        ids_tr, ids_val = train_test_split(ids_train_full, test_size=0.10, random_state=SEED, shuffle=True)\n","        print(f\"(Fold {fold_idx}) Warning: stratified VAL split failed; using unstratified split.\")\n","\n","    # Files for each split\n","    train_files = [f for pid in ids_tr  for f in id_to_files[pid]]\n","    val_files   = [f for pid in ids_val for f in id_to_files[pid]]\n","    test_files  = [f for pid in ids_test for f in id_to_files[pid]]\n","\n","    def split_summary(name, ids, files):\n","        ys = np.array([label_for_file(f) for f in files], dtype=int)\n","        print(f\"{name:>6} | ids: {len(ids):4d} | files: {len(files):5d} | pos files: {(ys==1).sum():4d} | neg files: {(ys==0).sum():4d}\")\n","\n","    print(f\"\\n--- Fold {fold_idx}/{K_FOLDS} ---\")\n","    split_summary(\"train\", ids_tr,  train_files)\n","    split_summary(\"val\",   ids_val, val_files)\n","    split_summary(\"test\",  ids_test, test_files)\n","\n","    # Generators\n","    train_gen = ImageSequence(train_files, batch_size=BATCH_SIZE, shuffle=True,\n","                              add_noise=TRAIN_ADD_GAUSS_NOISE,\n","                              noise_frac=TRAIN_NOISE_FRAC,\n","                              noise_prob=TRAIN_NOISE_PROB)\n","    val_gen   = ImageSequence(val_files,   batch_size=BATCH_SIZE, shuffle=False, add_noise=False)\n","    test_gen  = ImageSequence(test_files,  batch_size=BATCH_SIZE, shuffle=False, add_noise=False)\n","\n","    # Train & pick best by val_loss\n","    model = build_model()\n","    best_path = BEST_MODEL_TPL.format(fold_idx)\n","    ckpt = keras.callbacks.ModelCheckpoint(best_path, monitor=\"val_loss\", mode=\"min\",\n","                                           save_best_only=True, verbose=1)\n","    _ = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS, callbacks=[ckpt], verbose=1)\n","\n","    # Evaluate on TEST\n","    best_model = keras.models.load_model(best_path)\n","    test_probs = best_model.predict(test_gen, verbose=0).ravel().astype(float)\n","    test_y     = np.array([label_for_file(f) for f in test_gen.files], dtype=int)\n","    test_pred  = (test_probs >= 0.5).astype(int)\n","\n","    try:\n","        test_auc = roc_auc_score(test_y, test_probs)\n","    except ValueError:\n","        test_auc = float('nan')\n","    test_acc = accuracy_score(test_y, test_pred)\n","\n","    fold_test_accs.append(float(test_acc))\n","    fold_test_aucs.append(float(test_auc))\n","\n","    print(f\"Fold {fold_idx} | TEST ACC={test_acc:.4f} | TEST AUC={test_auc:.4f} | n={len(test_y)}\")\n","    print(\"Confusion matrix:\\n\", confusion_matrix(test_y, test_pred))\n","    print(\"Classification report:\\n\", classification_report(test_y, test_pred, digits=3))\n","\n","    rows.append({\n","        \"fold\": fold_idx,\n","        \"train_files\": len(train_files),\n","        \"val_files\": len(val_files),\n","        \"test_files\": len(test_files),\n","        \"test_acc\": test_acc,\n","        \"test_auc\": test_auc,\n","    })\n","\n","# =========================\n","# Summary across folds\n","# =========================\n","print(\"\\nPer-fold TEST ACC:\", [round(x,4) for x in fold_test_accs])\n","print(\"Per-fold TEST AUC:\", [None if np.isnan(x) else round(x,4) for x in fold_test_aucs])\n","\n","def mean_std(x):\n","    x = np.asarray(x, dtype=float)\n","    return np.nanmean(x), np.nanstd(x)\n","\n","mACC, sACC = mean_std(fold_test_accs)\n","mAUC, sAUC = mean_std(fold_test_aucs)\n","print(f\"\\nMean TEST ACC: {mACC:.4f} ± {sACC:.4f}\")\n","print(f\"Mean TEST AUC: {mAUC:.4f} ± {sAUC:.4f}\")\n","\n","metrics_df = pd.DataFrame(rows)\n","metrics_df.to_csv(\"cv7_img_fold_metrics.csv\", index=False)\n","print(\"\\nSaved TEST-only per-fold metrics to cv7_img_fold_metrics.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lD7pVdaPpHPi","outputId":"33bea42c-835a-458d-9a7c-2842f6d7d8e1","executionInfo":{"status":"ok","timestamp":1760665393822,"user_tz":300,"elapsed":1007780,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"lD7pVdaPpHPi","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Total IDs: 44 | Pos IDs: 14 | Neg IDs: 30\n","TARGET_W=6 (non-Time columns)\n","Fixed input height after de-dup (all IDs): H=360\n","Normalization: NONE. De-dup: remove consecutive duplicate rows (row-wise).\n","\n","=== 7-Fold CV (by patient ID) ===\n","\n","--- Fold 1/7 ---\n"," train | ids:   33 | files:   797 | pos files:  318 | neg files:  479\n","   val | ids:    4 | files:   116 | pos files:    1 | neg files:  115\n","  test | ids:    7 | files:   287 | pos files:   86 | neg files:  201\n","Epoch 1/100\n","\u001b[1m263/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.5717 - auc: 0.5048 - loss: 0.6913\n","Epoch 1: val_loss improved from inf to 0.63588, saving model to best_fold_01.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 44ms/step - acc: 0.5722 - auc: 0.5048 - loss: 0.6913 - val_acc: 0.9914 - val_auc: 0.4783 - val_loss: 0.6359\n","Epoch 2/100\n","\u001b[1m265/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6283 - auc: 0.4542 - loss: 0.6773\n","Epoch 2: val_loss improved from 0.63588 to 0.56087, saving model to best_fold_01.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6281 - auc: 0.4544 - loss: 0.6773 - val_acc: 0.9914 - val_auc: 0.8783 - val_loss: 0.5609\n","Epoch 3/100\n","\u001b[1m264/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5969 - auc: 0.4508 - loss: 0.6770\n","Epoch 3: val_loss improved from 0.56087 to 0.51573, saving model to best_fold_01.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5970 - auc: 0.4513 - loss: 0.6769 - val_acc: 0.9914 - val_auc: 0.9870 - val_loss: 0.5157\n","Epoch 4/100\n","\u001b[1m255/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5989 - auc: 0.5508 - loss: 0.6714\n","Epoch 4: val_loss improved from 0.51573 to 0.49541, saving model to best_fold_01.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5988 - auc: 0.5504 - loss: 0.6715 - val_acc: 0.9914 - val_auc: 0.9913 - val_loss: 0.4954\n","Epoch 5/100\n","\u001b[1m260/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6157 - auc: 0.5778 - loss: 0.6603\n","Epoch 5: val_loss improved from 0.49541 to 0.48391, saving model to best_fold_01.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6153 - auc: 0.5778 - loss: 0.6605 - val_acc: 0.9914 - val_auc: 0.9957 - val_loss: 0.4839\n","Epoch 6/100\n","\u001b[1m265/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6038 - auc: 0.6142 - loss: 0.6612\n","Epoch 6: val_loss improved from 0.48391 to 0.45822, saving model to best_fold_01.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6038 - auc: 0.6142 - loss: 0.6611 - val_acc: 0.9914 - val_auc: 0.9826 - val_loss: 0.4582\n","Epoch 7/100\n","\u001b[1m262/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6480 - auc: 0.6263 - loss: 0.6508\n","Epoch 7: val_loss did not improve from 0.45822\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6479 - auc: 0.6261 - loss: 0.6508 - val_acc: 0.9914 - val_auc: 0.9913 - val_loss: 0.5074\n","Epoch 8/100\n","\u001b[1m260/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6382 - auc: 0.6018 - loss: 0.6503\n","Epoch 8: val_loss did not improve from 0.45822\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6383 - auc: 0.6025 - loss: 0.6502 - val_acc: 0.9828 - val_auc: 0.9913 - val_loss: 0.4831\n","Epoch 9/100\n","\u001b[1m259/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6463 - auc: 0.6278 - loss: 0.6380\n","Epoch 9: val_loss improved from 0.45822 to 0.38534, saving model to best_fold_01.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6460 - auc: 0.6282 - loss: 0.6381 - val_acc: 0.9914 - val_auc: 0.9913 - val_loss: 0.3853\n","Epoch 10/100\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6384 - auc: 0.6380 - loss: 0.6391\n","Epoch 10: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6384 - auc: 0.6380 - loss: 0.6391 - val_acc: 0.9828 - val_auc: 0.9913 - val_loss: 0.4554\n","Epoch 11/100\n","\u001b[1m265/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5879 - auc: 0.6436 - loss: 0.6417\n","Epoch 11: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5881 - auc: 0.6437 - loss: 0.6416 - val_acc: 0.9914 - val_auc: 0.9913 - val_loss: 0.4835\n","Epoch 12/100\n","\u001b[1m258/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6439 - auc: 0.6563 - loss: 0.6109\n","Epoch 12: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6429 - auc: 0.6562 - loss: 0.6113 - val_acc: 0.9914 - val_auc: 0.9913 - val_loss: 0.4679\n","Epoch 13/100\n","\u001b[1m263/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5986 - auc: 0.6644 - loss: 0.6204\n","Epoch 13: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5989 - auc: 0.6645 - loss: 0.6203 - val_acc: 0.9828 - val_auc: 0.9913 - val_loss: 0.5066\n","Epoch 14/100\n","\u001b[1m255/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6126 - auc: 0.6828 - loss: 0.6050\n","Epoch 14: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6128 - auc: 0.6823 - loss: 0.6051 - val_acc: 0.9828 - val_auc: 0.9913 - val_loss: 0.5107\n","Epoch 15/100\n","\u001b[1m258/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5940 - auc: 0.6646 - loss: 0.6083\n","Epoch 15: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5946 - auc: 0.6651 - loss: 0.6080 - val_acc: 0.9914 - val_auc: 0.9913 - val_loss: 0.4375\n","Epoch 16/100\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6065 - auc: 0.6904 - loss: 0.5968\n","Epoch 16: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6065 - auc: 0.6904 - loss: 0.5968 - val_acc: 0.9914 - val_auc: 0.9913 - val_loss: 0.4406\n","Epoch 17/100\n","\u001b[1m260/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6355 - auc: 0.6767 - loss: 0.5852\n","Epoch 17: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6351 - auc: 0.6770 - loss: 0.5852 - val_acc: 0.9828 - val_auc: 0.9913 - val_loss: 0.5089\n","Epoch 18/100\n","\u001b[1m265/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6100 - auc: 0.6715 - loss: 0.5787\n","Epoch 18: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6100 - auc: 0.6716 - loss: 0.5787 - val_acc: 0.9224 - val_auc: 0.9913 - val_loss: 0.5475\n","Epoch 19/100\n","\u001b[1m261/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5856 - auc: 0.6745 - loss: 0.5771\n","Epoch 19: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5863 - auc: 0.6748 - loss: 0.5770 - val_acc: 0.9828 - val_auc: 0.9913 - val_loss: 0.4165\n","Epoch 20/100\n","\u001b[1m259/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6132 - auc: 0.6995 - loss: 0.5641\n","Epoch 20: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6138 - auc: 0.6999 - loss: 0.5640 - val_acc: 0.9828 - val_auc: 0.9913 - val_loss: 0.4973\n","Epoch 21/100\n","\u001b[1m262/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6427 - auc: 0.7155 - loss: 0.5447\n","Epoch 21: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6424 - auc: 0.7153 - loss: 0.5450 - val_acc: 0.9914 - val_auc: 0.9913 - val_loss: 0.4736\n","Epoch 22/100\n","\u001b[1m258/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5897 - auc: 0.6896 - loss: 0.5646\n","Epoch 22: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5907 - auc: 0.6903 - loss: 0.5643 - val_acc: 0.9914 - val_auc: 0.9913 - val_loss: 0.3871\n","Epoch 23/100\n","\u001b[1m253/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6394 - auc: 0.6873 - loss: 0.5672\n","Epoch 23: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6397 - auc: 0.6890 - loss: 0.5661 - val_acc: 0.9914 - val_auc: 0.9913 - val_loss: 0.3914\n","Epoch 24/100\n","\u001b[1m255/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6035 - auc: 0.6620 - loss: 0.5707\n","Epoch 24: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6053 - auc: 0.6646 - loss: 0.5695 - val_acc: 0.9224 - val_auc: 0.9913 - val_loss: 0.5630\n","Epoch 25/100\n","\u001b[1m253/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6286 - auc: 0.7208 - loss: 0.5370\n","Epoch 25: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6288 - auc: 0.7204 - loss: 0.5376 - val_acc: 0.9914 - val_auc: 0.9913 - val_loss: 0.5092\n","Epoch 26/100\n","\u001b[1m254/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6570 - auc: 0.7352 - loss: 0.5354\n","Epoch 26: val_loss did not improve from 0.38534\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6569 - auc: 0.7353 - loss: 0.5355 - val_acc: 0.9310 - val_auc: 0.9913 - val_loss: 0.5728\n","Epoch 27/100\n","\u001b[1m253/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6429 - auc: 0.7363 - loss: 0.5278\n","Epoch 27: val_loss improved from 0.38534 to 0.36923, saving model to best_fold_01.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6429 - auc: 0.7359 - loss: 0.5283 - val_acc: 0.9914 - val_auc: 0.9913 - val_loss: 0.3692\n","Epoch 28/100\n","\u001b[1m263/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6680 - auc: 0.7397 - loss: 0.5380\n","Epoch 28: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6679 - auc: 0.7397 - loss: 0.5379 - val_acc: 0.8190 - val_auc: 0.9217 - val_loss: 0.5924\n","Epoch 29/100\n","\u001b[1m253/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6909 - auc: 0.7497 - loss: 0.5338\n","Epoch 29: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6899 - auc: 0.7491 - loss: 0.5337 - val_acc: 0.8276 - val_auc: 0.9304 - val_loss: 0.5919\n","Epoch 30/100\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6513 - auc: 0.7496 - loss: 0.5259\n","Epoch 30: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6513 - auc: 0.7495 - loss: 0.5259 - val_acc: 0.9914 - val_auc: 0.8957 - val_loss: 0.4352\n","Epoch 31/100\n","\u001b[1m262/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6741 - auc: 0.7502 - loss: 0.5218\n","Epoch 31: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6739 - auc: 0.7500 - loss: 0.5220 - val_acc: 0.9655 - val_auc: 0.8478 - val_loss: 0.5212\n","Epoch 32/100\n","\u001b[1m259/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6678 - auc: 0.7532 - loss: 0.5316\n","Epoch 32: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6675 - auc: 0.7527 - loss: 0.5316 - val_acc: 0.6207 - val_auc: 0.7391 - val_loss: 0.6536\n","Epoch 33/100\n","\u001b[1m254/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6694 - auc: 0.7336 - loss: 0.5275\n","Epoch 33: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6700 - auc: 0.7347 - loss: 0.5274 - val_acc: 0.6121 - val_auc: 0.7217 - val_loss: 0.6571\n","Epoch 34/100\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6952 - auc: 0.7601 - loss: 0.5084\n","Epoch 34: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6952 - auc: 0.7601 - loss: 0.5084 - val_acc: 0.1810 - val_auc: 0.6913 - val_loss: 0.7808\n","Epoch 35/100\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7045 - auc: 0.7677 - loss: 0.5149\n","Epoch 35: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7044 - auc: 0.7676 - loss: 0.5149 - val_acc: 0.8276 - val_auc: 0.6826 - val_loss: 0.5781\n","Epoch 36/100\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6544 - auc: 0.7341 - loss: 0.5437\n","Epoch 36: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6545 - auc: 0.7342 - loss: 0.5436 - val_acc: 0.7586 - val_auc: 0.6870 - val_loss: 0.6085\n","Epoch 37/100\n","\u001b[1m255/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6632 - auc: 0.7334 - loss: 0.5417\n","Epoch 37: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6641 - auc: 0.7343 - loss: 0.5407 - val_acc: 0.9224 - val_auc: 0.7217 - val_loss: 0.5310\n","Epoch 38/100\n","\u001b[1m252/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6796 - auc: 0.7411 - loss: 0.5202\n","Epoch 38: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6796 - auc: 0.7418 - loss: 0.5204 - val_acc: 0.9741 - val_auc: 0.7391 - val_loss: 0.4810\n","Epoch 39/100\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6967 - auc: 0.7503 - loss: 0.5194\n","Epoch 39: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6967 - auc: 0.7504 - loss: 0.5194 - val_acc: 0.2328 - val_auc: 0.6565 - val_loss: 0.8153\n","Epoch 40/100\n","\u001b[1m252/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6711 - auc: 0.7524 - loss: 0.5222\n","Epoch 40: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6717 - auc: 0.7524 - loss: 0.5219 - val_acc: 0.7759 - val_auc: 0.5043 - val_loss: 0.6044\n","Epoch 41/100\n","\u001b[1m261/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6689 - auc: 0.7554 - loss: 0.5137\n","Epoch 41: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6689 - auc: 0.7552 - loss: 0.5140 - val_acc: 0.9741 - val_auc: 0.6652 - val_loss: 0.4635\n","Epoch 42/100\n","\u001b[1m260/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7286 - auc: 0.7627 - loss: 0.4922\n","Epoch 42: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7278 - auc: 0.7628 - loss: 0.4928 - val_acc: 0.9741 - val_auc: 0.7870 - val_loss: 0.4354\n","Epoch 43/100\n","\u001b[1m259/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6838 - auc: 0.7537 - loss: 0.5181\n","Epoch 43: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6840 - auc: 0.7538 - loss: 0.5182 - val_acc: 0.9914 - val_auc: 0.8565 - val_loss: 0.4649\n","Epoch 44/100\n","\u001b[1m261/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6847 - auc: 0.7597 - loss: 0.5159\n","Epoch 44: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6847 - auc: 0.7597 - loss: 0.5158 - val_acc: 0.5259 - val_auc: 0.4304 - val_loss: 0.6818\n","Epoch 45/100\n","\u001b[1m265/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6937 - auc: 0.7582 - loss: 0.5112\n","Epoch 45: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6938 - auc: 0.7583 - loss: 0.5112 - val_acc: 0.2414 - val_auc: 0.4087 - val_loss: 0.8346\n","Epoch 46/100\n","\u001b[1m253/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6778 - auc: 0.7479 - loss: 0.5357\n","Epoch 46: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6790 - auc: 0.7487 - loss: 0.5346 - val_acc: 0.9914 - val_auc: 0.8000 - val_loss: 0.4454\n","Epoch 47/100\n","\u001b[1m260/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6683 - auc: 0.7273 - loss: 0.5524\n","Epoch 47: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6686 - auc: 0.7279 - loss: 0.5516 - val_acc: 0.9741 - val_auc: 0.7304 - val_loss: 0.4668\n","Epoch 48/100\n","\u001b[1m254/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7231 - auc: 0.7804 - loss: 0.5069\n","Epoch 48: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7228 - auc: 0.7798 - loss: 0.5070 - val_acc: 0.5259 - val_auc: 0.3130 - val_loss: 0.7047\n","Epoch 49/100\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6896 - auc: 0.7638 - loss: 0.5128\n","Epoch 49: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6895 - auc: 0.7638 - loss: 0.5129 - val_acc: 0.1810 - val_auc: 0.3043 - val_loss: 0.8871\n","Epoch 50/100\n","\u001b[1m265/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6931 - auc: 0.7638 - loss: 0.5180\n","Epoch 50: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6930 - auc: 0.7638 - loss: 0.5179 - val_acc: 0.9914 - val_auc: 0.8217 - val_loss: 0.4440\n","Epoch 51/100\n","\u001b[1m252/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6961 - auc: 0.7690 - loss: 0.5034\n","Epoch 51: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6958 - auc: 0.7682 - loss: 0.5042 - val_acc: 0.9741 - val_auc: 0.7217 - val_loss: 0.4506\n","Epoch 52/100\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6672 - auc: 0.7541 - loss: 0.5293\n","Epoch 52: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6672 - auc: 0.7541 - loss: 0.5292 - val_acc: 0.9741 - val_auc: 0.7087 - val_loss: 0.4416\n","Epoch 53/100\n","\u001b[1m264/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6889 - auc: 0.7587 - loss: 0.5177\n","Epoch 53: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6889 - auc: 0.7587 - loss: 0.5177 - val_acc: 0.9483 - val_auc: 0.6217 - val_loss: 0.4975\n","Epoch 54/100\n","\u001b[1m258/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7132 - auc: 0.8052 - loss: 0.4887\n","Epoch 54: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7125 - auc: 0.8042 - loss: 0.4892 - val_acc: 0.7672 - val_auc: 0.4957 - val_loss: 0.6032\n","Epoch 55/100\n","\u001b[1m262/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6851 - auc: 0.7586 - loss: 0.5248\n","Epoch 55: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6853 - auc: 0.7588 - loss: 0.5245 - val_acc: 0.9483 - val_auc: 0.6174 - val_loss: 0.4960\n","Epoch 56/100\n","\u001b[1m254/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7202 - auc: 0.7926 - loss: 0.4905\n","Epoch 56: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7194 - auc: 0.7913 - loss: 0.4914 - val_acc: 0.9914 - val_auc: 0.7913 - val_loss: 0.4143\n","Epoch 57/100\n","\u001b[1m254/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7183 - auc: 0.7461 - loss: 0.5054\n","Epoch 57: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7176 - auc: 0.7467 - loss: 0.5057 - val_acc: 0.9483 - val_auc: 0.5304 - val_loss: 0.4881\n","Epoch 58/100\n","\u001b[1m265/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7012 - auc: 0.7724 - loss: 0.5099\n","Epoch 58: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7011 - auc: 0.7723 - loss: 0.5099 - val_acc: 0.8017 - val_auc: 0.4391 - val_loss: 0.5899\n","Epoch 59/100\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6894 - auc: 0.7805 - loss: 0.5055\n","Epoch 59: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6893 - auc: 0.7804 - loss: 0.5055 - val_acc: 0.5603 - val_auc: 0.3652 - val_loss: 0.6709\n","Epoch 60/100\n","\u001b[1m252/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6989 - auc: 0.7695 - loss: 0.5095\n","Epoch 60: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6990 - auc: 0.7696 - loss: 0.5093 - val_acc: 0.9914 - val_auc: 0.7696 - val_loss: 0.4335\n","Epoch 61/100\n","\u001b[1m252/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7010 - auc: 0.7597 - loss: 0.5220\n","Epoch 61: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7003 - auc: 0.7599 - loss: 0.5213 - val_acc: 0.8621 - val_auc: 0.4391 - val_loss: 0.5430\n","Epoch 62/100\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6962 - auc: 0.7523 - loss: 0.5067\n","Epoch 62: val_loss did not improve from 0.36923\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6962 - auc: 0.7524 - loss: 0.5067 - val_acc: 0.9224 - val_auc: 0.4174 - val_loss: 0.5207\n","Epoch 63/100\n","\u001b[1m264/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7156 - auc: 0.7614 - loss: 0.5208\n","Epoch 63: val_loss improved from 0.36923 to 0.34310, saving model to best_fold_01.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7155 - auc: 0.7615 - loss: 0.5207 - val_acc: 0.9914 - val_auc: 0.9522 - val_loss: 0.3431\n","Epoch 64/100\n","\u001b[1m257/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6825 - auc: 0.7440 - loss: 0.5290\n","Epoch 64: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6832 - auc: 0.7447 - loss: 0.5282 - val_acc: 0.2414 - val_auc: 0.2217 - val_loss: 0.8539\n","Epoch 65/100\n","\u001b[1m256/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6747 - auc: 0.7399 - loss: 0.5299\n","Epoch 65: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6757 - auc: 0.7407 - loss: 0.5292 - val_acc: 0.9914 - val_auc: 0.7478 - val_loss: 0.4304\n","Epoch 66/100\n","\u001b[1m265/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7029 - auc: 0.7784 - loss: 0.5123\n","Epoch 66: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7029 - auc: 0.7783 - loss: 0.5123 - val_acc: 0.7672 - val_auc: 0.3957 - val_loss: 0.6098\n","Epoch 67/100\n","\u001b[1m254/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7362 - auc: 0.8208 - loss: 0.4798\n","Epoch 67: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7350 - auc: 0.8193 - loss: 0.4811 - val_acc: 0.9828 - val_auc: 0.7696 - val_loss: 0.4466\n","Epoch 68/100\n","\u001b[1m256/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7314 - auc: 0.7593 - loss: 0.5074\n","Epoch 68: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7302 - auc: 0.7600 - loss: 0.5072 - val_acc: 0.8448 - val_auc: 0.4435 - val_loss: 0.5527\n","Epoch 69/100\n","\u001b[1m253/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7421 - auc: 0.7985 - loss: 0.4800\n","Epoch 69: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7397 - auc: 0.7968 - loss: 0.4815 - val_acc: 0.7586 - val_auc: 0.3174 - val_loss: 0.6014\n","Epoch 70/100\n","\u001b[1m253/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6983 - auc: 0.7715 - loss: 0.5057\n","Epoch 70: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6979 - auc: 0.7712 - loss: 0.5057 - val_acc: 0.9052 - val_auc: 0.4174 - val_loss: 0.5422\n","Epoch 71/100\n","\u001b[1m261/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7008 - auc: 0.7783 - loss: 0.4961\n","Epoch 71: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7008 - auc: 0.7780 - loss: 0.4964 - val_acc: 0.9310 - val_auc: 0.3870 - val_loss: 0.5232\n","Epoch 72/100\n","\u001b[1m252/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7041 - auc: 0.7913 - loss: 0.4943\n","Epoch 72: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7040 - auc: 0.7901 - loss: 0.4949 - val_acc: 0.9655 - val_auc: 0.5130 - val_loss: 0.5072\n","Epoch 73/100\n","\u001b[1m257/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7030 - auc: 0.7722 - loss: 0.4930\n","Epoch 73: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7032 - auc: 0.7722 - loss: 0.4932 - val_acc: 0.9914 - val_auc: 0.8130 - val_loss: 0.4132\n","Epoch 74/100\n","\u001b[1m252/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7256 - auc: 0.7887 - loss: 0.4943\n","Epoch 74: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7255 - auc: 0.7883 - loss: 0.4944 - val_acc: 0.2931 - val_auc: 0.2087 - val_loss: 0.8522\n","Epoch 75/100\n","\u001b[1m260/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7256 - auc: 0.7848 - loss: 0.4858\n","Epoch 75: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7255 - auc: 0.7846 - loss: 0.4862 - val_acc: 0.9914 - val_auc: 0.8391 - val_loss: 0.3819\n","Epoch 76/100\n","\u001b[1m261/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7111 - auc: 0.7902 - loss: 0.4959\n","Epoch 76: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7111 - auc: 0.7898 - loss: 0.4961 - val_acc: 0.9914 - val_auc: 0.7783 - val_loss: 0.4323\n","Epoch 77/100\n","\u001b[1m265/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7180 - auc: 0.7722 - loss: 0.4954\n","Epoch 77: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7179 - auc: 0.7721 - loss: 0.4954 - val_acc: 0.9914 - val_auc: 0.8217 - val_loss: 0.3863\n","Epoch 78/100\n","\u001b[1m256/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7019 - auc: 0.7834 - loss: 0.5087\n","Epoch 78: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7023 - auc: 0.7833 - loss: 0.5083 - val_acc: 0.8534 - val_auc: 0.4087 - val_loss: 0.5354\n","Epoch 79/100\n","\u001b[1m263/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6922 - auc: 0.7766 - loss: 0.5060\n","Epoch 79: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6924 - auc: 0.7765 - loss: 0.5059 - val_acc: 0.9914 - val_auc: 0.7043 - val_loss: 0.4185\n","Epoch 80/100\n","\u001b[1m254/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6790 - auc: 0.7842 - loss: 0.5050\n","Epoch 80: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6797 - auc: 0.7833 - loss: 0.5050 - val_acc: 0.9828 - val_auc: 0.6130 - val_loss: 0.4722\n","Epoch 81/100\n","\u001b[1m253/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7206 - auc: 0.7550 - loss: 0.4980\n","Epoch 81: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7199 - auc: 0.7557 - loss: 0.4985 - val_acc: 0.5517 - val_auc: 0.3435 - val_loss: 0.6653\n","Epoch 82/100\n","\u001b[1m265/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7226 - auc: 0.7898 - loss: 0.4986\n","Epoch 82: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7225 - auc: 0.7897 - loss: 0.4986 - val_acc: 0.3793 - val_auc: 0.3565 - val_loss: 0.7716\n","Epoch 83/100\n","\u001b[1m263/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6607 - auc: 0.7542 - loss: 0.5177\n","Epoch 83: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6612 - auc: 0.7546 - loss: 0.5175 - val_acc: 0.9397 - val_auc: 0.5652 - val_loss: 0.4850\n","Epoch 84/100\n","\u001b[1m265/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7235 - auc: 0.7955 - loss: 0.5037\n","Epoch 84: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7235 - auc: 0.7954 - loss: 0.5037 - val_acc: 0.8362 - val_auc: 0.3826 - val_loss: 0.5603\n","Epoch 85/100\n","\u001b[1m265/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6898 - auc: 0.7424 - loss: 0.5113\n","Epoch 85: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6900 - auc: 0.7425 - loss: 0.5112 - val_acc: 0.7672 - val_auc: 0.3478 - val_loss: 0.5963\n","Epoch 86/100\n","\u001b[1m255/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7094 - auc: 0.7763 - loss: 0.5000\n","Epoch 86: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7096 - auc: 0.7764 - loss: 0.5000 - val_acc: 0.9914 - val_auc: 0.9043 - val_loss: 0.3464\n","Epoch 87/100\n","\u001b[1m256/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6927 - auc: 0.7552 - loss: 0.5138\n","Epoch 87: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6938 - auc: 0.7562 - loss: 0.5132 - val_acc: 0.8103 - val_auc: 0.4261 - val_loss: 0.5578\n","Epoch 88/100\n","\u001b[1m259/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6703 - auc: 0.7656 - loss: 0.5122\n","Epoch 88: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6711 - auc: 0.7661 - loss: 0.5118 - val_acc: 0.9741 - val_auc: 0.6348 - val_loss: 0.4502\n","Epoch 89/100\n","\u001b[1m253/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7389 - auc: 0.7902 - loss: 0.4824\n","Epoch 89: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7377 - auc: 0.7900 - loss: 0.4831 - val_acc: 0.8621 - val_auc: 0.4043 - val_loss: 0.5363\n","Epoch 90/100\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7049 - auc: 0.7589 - loss: 0.5149\n","Epoch 90: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7049 - auc: 0.7590 - loss: 0.5149 - val_acc: 0.4569 - val_auc: 0.3130 - val_loss: 0.6787\n","Epoch 91/100\n","\u001b[1m264/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7396 - auc: 0.7975 - loss: 0.4834\n","Epoch 91: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7393 - auc: 0.7972 - loss: 0.4835 - val_acc: 0.8966 - val_auc: 0.3870 - val_loss: 0.5061\n","Epoch 92/100\n","\u001b[1m264/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6909 - auc: 0.7539 - loss: 0.5307\n","Epoch 92: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6911 - auc: 0.7543 - loss: 0.5304 - val_acc: 0.8017 - val_auc: 0.4261 - val_loss: 0.5624\n","Epoch 93/100\n","\u001b[1m264/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6871 - auc: 0.7720 - loss: 0.5008\n","Epoch 93: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6873 - auc: 0.7721 - loss: 0.5008 - val_acc: 0.8707 - val_auc: 0.4652 - val_loss: 0.4875\n","Epoch 94/100\n","\u001b[1m265/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7167 - auc: 0.8003 - loss: 0.4960\n","Epoch 94: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7167 - auc: 0.8002 - loss: 0.4961 - val_acc: 0.9914 - val_auc: 0.7783 - val_loss: 0.4056\n","Epoch 95/100\n","\u001b[1m255/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7000 - auc: 0.7723 - loss: 0.5049\n","Epoch 95: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7005 - auc: 0.7724 - loss: 0.5049 - val_acc: 0.9914 - val_auc: 0.8522 - val_loss: 0.3797\n","Epoch 96/100\n","\u001b[1m265/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7077 - auc: 0.7808 - loss: 0.5050\n","Epoch 96: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7078 - auc: 0.7808 - loss: 0.5049 - val_acc: 0.8448 - val_auc: 0.4391 - val_loss: 0.5479\n","Epoch 97/100\n","\u001b[1m260/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7074 - auc: 0.7722 - loss: 0.4847\n","Epoch 97: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7077 - auc: 0.7723 - loss: 0.4851 - val_acc: 0.8621 - val_auc: 0.4609 - val_loss: 0.5224\n","Epoch 98/100\n","\u001b[1m257/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7108 - auc: 0.7795 - loss: 0.5005\n","Epoch 98: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7109 - auc: 0.7797 - loss: 0.5002 - val_acc: 0.9914 - val_auc: 0.8087 - val_loss: 0.3703\n","Epoch 99/100\n","\u001b[1m253/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6743 - auc: 0.7691 - loss: 0.5109\n","Epoch 99: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6754 - auc: 0.7695 - loss: 0.5101 - val_acc: 0.9828 - val_auc: 0.4652 - val_loss: 0.4489\n","Epoch 100/100\n","\u001b[1m261/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6854 - auc: 0.7704 - loss: 0.5135\n","Epoch 100: val_loss did not improve from 0.34310\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6860 - auc: 0.7707 - loss: 0.5130 - val_acc: 0.9741 - val_auc: 0.4435 - val_loss: 0.4691\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 1 | TEST ACC=0.6760 | TEST AUC=0.7264 | n=287\n","Confusion matrix:\n"," [[194   7]\n"," [ 86   0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.693     0.965     0.807       201\n","           1      0.000     0.000     0.000        86\n","\n","    accuracy                          0.676       287\n","   macro avg      0.346     0.483     0.403       287\n","weighted avg      0.485     0.676     0.565       287\n","\n","\n","--- Fold 2/7 ---\n"," train | ids:   33 | files:   974 | pos files:  327 | neg files:  647\n","   val | ids:    4 | files:    90 | pos files:   38 | neg files:   52\n","  test | ids:    7 | files:   136 | pos files:   40 | neg files:   96\n","Epoch 1/100\n","\u001b[1m323/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6805 - auc: 0.4750 - loss: 0.6832\n","Epoch 1: val_loss improved from inf to 0.67739, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - acc: 0.6803 - auc: 0.4749 - loss: 0.6831 - val_acc: 0.5778 - val_auc: 0.5185 - val_loss: 0.6774\n","Epoch 2/100\n","\u001b[1m313/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6713 - auc: 0.4461 - loss: 0.6438\n","Epoch 2: val_loss did not improve from 0.67739\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6710 - auc: 0.4459 - loss: 0.6439 - val_acc: 0.5778 - val_auc: 0.5595 - val_loss: 0.6817\n","Epoch 3/100\n","\u001b[1m322/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6492 - auc: 0.4943 - loss: 0.6493\n","Epoch 3: val_loss did not improve from 0.67739\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6494 - auc: 0.4941 - loss: 0.6492 - val_acc: 0.5778 - val_auc: 0.5729 - val_loss: 0.6835\n","Epoch 4/100\n","\u001b[1m316/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6704 - auc: 0.4971 - loss: 0.6352\n","Epoch 4: val_loss did not improve from 0.67739\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6702 - auc: 0.4982 - loss: 0.6353 - val_acc: 0.5778 - val_auc: 0.5979 - val_loss: 0.6876\n","Epoch 5/100\n","\u001b[1m319/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6830 - auc: 0.5655 - loss: 0.6179\n","Epoch 5: val_loss did not improve from 0.67739\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6827 - auc: 0.5654 - loss: 0.6182 - val_acc: 0.5778 - val_auc: 0.6516 - val_loss: 0.6840\n","Epoch 6/100\n","\u001b[1m312/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6622 - auc: 0.5901 - loss: 0.6315\n","Epoch 6: val_loss improved from 0.67739 to 0.67673, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6623 - auc: 0.5905 - loss: 0.6313 - val_acc: 0.5778 - val_auc: 0.7315 - val_loss: 0.6767\n","Epoch 7/100\n","\u001b[1m317/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6675 - auc: 0.5899 - loss: 0.6257\n","Epoch 7: val_loss improved from 0.67673 to 0.65701, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6674 - auc: 0.5902 - loss: 0.6257 - val_acc: 0.5778 - val_auc: 0.7910 - val_loss: 0.6570\n","Epoch 8/100\n","\u001b[1m315/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6509 - auc: 0.6320 - loss: 0.6240\n","Epoch 8: val_loss improved from 0.65701 to 0.64992, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6514 - auc: 0.6322 - loss: 0.6237 - val_acc: 0.5778 - val_auc: 0.8044 - val_loss: 0.6499\n","Epoch 9/100\n","\u001b[1m311/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6663 - auc: 0.6595 - loss: 0.6055\n","Epoch 9: val_loss improved from 0.64992 to 0.63964, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6664 - auc: 0.6589 - loss: 0.6057 - val_acc: 0.5778 - val_auc: 0.8168 - val_loss: 0.6396\n","Epoch 10/100\n","\u001b[1m324/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6494 - auc: 0.6823 - loss: 0.6141\n","Epoch 10: val_loss did not improve from 0.63964\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6496 - auc: 0.6823 - loss: 0.6140 - val_acc: 0.5778 - val_auc: 0.8282 - val_loss: 0.6642\n","Epoch 11/100\n","\u001b[1m324/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7065 - auc: 0.6580 - loss: 0.5822\n","Epoch 11: val_loss improved from 0.63964 to 0.61224, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7064 - auc: 0.6581 - loss: 0.5823 - val_acc: 0.5778 - val_auc: 0.8492 - val_loss: 0.6122\n","Epoch 12/100\n","\u001b[1m323/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7261 - auc: 0.6550 - loss: 0.5643\n","Epoch 12: val_loss improved from 0.61224 to 0.58656, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7258 - auc: 0.6553 - loss: 0.5645 - val_acc: 0.5889 - val_auc: 0.8659 - val_loss: 0.5866\n","Epoch 13/100\n","\u001b[1m321/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6632 - auc: 0.6666 - loss: 0.5985\n","Epoch 13: val_loss improved from 0.58656 to 0.57425, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6637 - auc: 0.6669 - loss: 0.5983 - val_acc: 0.5778 - val_auc: 0.8823 - val_loss: 0.5742\n","Epoch 14/100\n","\u001b[1m315/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6941 - auc: 0.7062 - loss: 0.5788\n","Epoch 14: val_loss improved from 0.57425 to 0.56630, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6940 - auc: 0.7059 - loss: 0.5787 - val_acc: 0.5778 - val_auc: 0.9076 - val_loss: 0.5663\n","Epoch 15/100\n","\u001b[1m312/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6863 - auc: 0.7326 - loss: 0.5693\n","Epoch 15: val_loss improved from 0.56630 to 0.56377, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6868 - auc: 0.7315 - loss: 0.5694 - val_acc: 0.5778 - val_auc: 0.9145 - val_loss: 0.5638\n","Epoch 16/100\n","\u001b[1m312/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7179 - auc: 0.7050 - loss: 0.5650\n","Epoch 16: val_loss improved from 0.56377 to 0.55159, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7172 - auc: 0.7053 - loss: 0.5649 - val_acc: 0.6000 - val_auc: 0.9150 - val_loss: 0.5516\n","Epoch 17/100\n","\u001b[1m315/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6589 - auc: 0.6986 - loss: 0.5785\n","Epoch 17: val_loss improved from 0.55159 to 0.54723, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6595 - auc: 0.6989 - loss: 0.5778 - val_acc: 0.5778 - val_auc: 0.9405 - val_loss: 0.5472\n","Epoch 18/100\n","\u001b[1m315/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6867 - auc: 0.6870 - loss: 0.5930\n","Epoch 18: val_loss improved from 0.54723 to 0.53523, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6871 - auc: 0.6878 - loss: 0.5918 - val_acc: 0.5889 - val_auc: 0.9289 - val_loss: 0.5352\n","Epoch 19/100\n","\u001b[1m313/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6670 - auc: 0.7167 - loss: 0.5533\n","Epoch 19: val_loss improved from 0.53523 to 0.53295, saving model to best_fold_02.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6679 - auc: 0.7167 - loss: 0.5531 - val_acc: 0.6000 - val_auc: 0.9038 - val_loss: 0.5329\n","Epoch 20/100\n","\u001b[1m324/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6989 - auc: 0.7185 - loss: 0.5255\n","Epoch 20: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6988 - auc: 0.7185 - loss: 0.5256 - val_acc: 0.6000 - val_auc: 0.8735 - val_loss: 0.5402\n","Epoch 21/100\n","\u001b[1m319/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6952 - auc: 0.7048 - loss: 0.5621\n","Epoch 21: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6952 - auc: 0.7051 - loss: 0.5619 - val_acc: 0.6000 - val_auc: 0.8828 - val_loss: 0.5407\n","Epoch 22/100\n","\u001b[1m315/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6792 - auc: 0.7378 - loss: 0.5408\n","Epoch 22: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6795 - auc: 0.7373 - loss: 0.5408 - val_acc: 0.5778 - val_auc: 0.8988 - val_loss: 0.6045\n","Epoch 23/100\n","\u001b[1m321/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6879 - auc: 0.7079 - loss: 0.5525\n","Epoch 23: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6880 - auc: 0.7080 - loss: 0.5524 - val_acc: 0.6000 - val_auc: 0.8497 - val_loss: 0.5532\n","Epoch 24/100\n","\u001b[1m323/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6588 - auc: 0.7105 - loss: 0.5579\n","Epoch 24: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6591 - auc: 0.7106 - loss: 0.5577 - val_acc: 0.6000 - val_auc: 0.8512 - val_loss: 0.5640\n","Epoch 25/100\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6753 - auc: 0.7186 - loss: 0.5466\n","Epoch 25: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6753 - auc: 0.7186 - loss: 0.5466 - val_acc: 0.6000 - val_auc: 0.8365 - val_loss: 0.5628\n","Epoch 26/100\n","\u001b[1m313/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6971 - auc: 0.7183 - loss: 0.5373\n","Epoch 26: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6967 - auc: 0.7187 - loss: 0.5372 - val_acc: 0.5778 - val_auc: 0.8588 - val_loss: 0.6352\n","Epoch 27/100\n","\u001b[1m315/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6885 - auc: 0.7496 - loss: 0.5217\n","Epoch 27: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6886 - auc: 0.7491 - loss: 0.5221 - val_acc: 0.5778 - val_auc: 0.8434 - val_loss: 0.6212\n","Epoch 28/100\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6713 - auc: 0.7400 - loss: 0.5239\n","Epoch 28: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6714 - auc: 0.7400 - loss: 0.5239 - val_acc: 0.5778 - val_auc: 0.8391 - val_loss: 0.6337\n","Epoch 29/100\n","\u001b[1m314/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6928 - auc: 0.7345 - loss: 0.5292\n","Epoch 29: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6931 - auc: 0.7343 - loss: 0.5293 - val_acc: 0.5889 - val_auc: 0.8320 - val_loss: 0.6213\n","Epoch 30/100\n","\u001b[1m324/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6976 - auc: 0.7361 - loss: 0.5105\n","Epoch 30: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6975 - auc: 0.7361 - loss: 0.5106 - val_acc: 0.5778 - val_auc: 0.8322 - val_loss: 0.6468\n","Epoch 31/100\n","\u001b[1m320/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6613 - auc: 0.7339 - loss: 0.5344\n","Epoch 31: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6618 - auc: 0.7338 - loss: 0.5344 - val_acc: 0.6000 - val_auc: 0.8259 - val_loss: 0.6195\n","Epoch 32/100\n","\u001b[1m314/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6788 - auc: 0.7053 - loss: 0.5517\n","Epoch 32: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6793 - auc: 0.7060 - loss: 0.5508 - val_acc: 0.5778 - val_auc: 0.8320 - val_loss: 0.6475\n","Epoch 33/100\n","\u001b[1m313/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7017 - auc: 0.7291 - loss: 0.5329\n","Epoch 33: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7013 - auc: 0.7292 - loss: 0.5325 - val_acc: 0.6000 - val_auc: 0.8140 - val_loss: 0.6278\n","Epoch 34/100\n","\u001b[1m324/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7124 - auc: 0.7329 - loss: 0.5290\n","Epoch 34: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7123 - auc: 0.7329 - loss: 0.5290 - val_acc: 0.6000 - val_auc: 0.8264 - val_loss: 0.6454\n","Epoch 35/100\n","\u001b[1m322/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6736 - auc: 0.6806 - loss: 0.5599\n","Epoch 35: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6739 - auc: 0.6811 - loss: 0.5594 - val_acc: 0.5778 - val_auc: 0.8310 - val_loss: 0.6673\n","Epoch 36/100\n","\u001b[1m312/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6919 - auc: 0.7597 - loss: 0.5107\n","Epoch 36: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6914 - auc: 0.7586 - loss: 0.5113 - val_acc: 0.5778 - val_auc: 0.8224 - val_loss: 0.6599\n","Epoch 37/100\n","\u001b[1m323/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7080 - auc: 0.7282 - loss: 0.5066\n","Epoch 37: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7079 - auc: 0.7282 - loss: 0.5068 - val_acc: 0.5778 - val_auc: 0.8125 - val_loss: 0.6455\n","Epoch 38/100\n","\u001b[1m320/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7195 - auc: 0.7449 - loss: 0.5072\n","Epoch 38: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7192 - auc: 0.7445 - loss: 0.5075 - val_acc: 0.5778 - val_auc: 0.8125 - val_loss: 0.6754\n","Epoch 39/100\n","\u001b[1m324/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6885 - auc: 0.7257 - loss: 0.5300\n","Epoch 39: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6885 - auc: 0.7257 - loss: 0.5300 - val_acc: 0.5778 - val_auc: 0.8138 - val_loss: 0.6661\n","Epoch 40/100\n","\u001b[1m322/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7067 - auc: 0.7584 - loss: 0.4934\n","Epoch 40: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7066 - auc: 0.7581 - loss: 0.4936 - val_acc: 0.5778 - val_auc: 0.8079 - val_loss: 0.6616\n","Epoch 41/100\n","\u001b[1m316/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7152 - auc: 0.7085 - loss: 0.5214\n","Epoch 41: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7149 - auc: 0.7091 - loss: 0.5213 - val_acc: 0.5778 - val_auc: 0.8173 - val_loss: 0.6852\n","Epoch 42/100\n","\u001b[1m311/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7170 - auc: 0.7444 - loss: 0.5032\n","Epoch 42: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7163 - auc: 0.7434 - loss: 0.5038 - val_acc: 0.5778 - val_auc: 0.8031 - val_loss: 0.6615\n","Epoch 43/100\n","\u001b[1m324/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7070 - auc: 0.7514 - loss: 0.4932\n","Epoch 43: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7070 - auc: 0.7513 - loss: 0.4933 - val_acc: 0.5889 - val_auc: 0.8001 - val_loss: 0.6487\n","Epoch 44/100\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7328 - auc: 0.7371 - loss: 0.4882\n","Epoch 44: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7327 - auc: 0.7371 - loss: 0.4883 - val_acc: 0.5889 - val_auc: 0.7943 - val_loss: 0.6618\n","Epoch 45/100\n","\u001b[1m322/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6814 - auc: 0.7318 - loss: 0.5356\n","Epoch 45: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6817 - auc: 0.7320 - loss: 0.5353 - val_acc: 0.5778 - val_auc: 0.8011 - val_loss: 0.6829\n","Epoch 46/100\n","\u001b[1m312/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7027 - auc: 0.7530 - loss: 0.5010\n","Epoch 46: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7026 - auc: 0.7522 - loss: 0.5016 - val_acc: 0.5778 - val_auc: 0.8107 - val_loss: 0.7143\n","Epoch 47/100\n","\u001b[1m323/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6921 - auc: 0.7193 - loss: 0.5270\n","Epoch 47: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6923 - auc: 0.7195 - loss: 0.5269 - val_acc: 0.6000 - val_auc: 0.7905 - val_loss: 0.6216\n","Epoch 48/100\n","\u001b[1m315/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6960 - auc: 0.7411 - loss: 0.5157\n","Epoch 48: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6962 - auc: 0.7409 - loss: 0.5157 - val_acc: 0.5778 - val_auc: 0.8062 - val_loss: 0.7527\n","Epoch 49/100\n","\u001b[1m323/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7217 - auc: 0.7479 - loss: 0.5021\n","Epoch 49: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7216 - auc: 0.7478 - loss: 0.5022 - val_acc: 0.5778 - val_auc: 0.7930 - val_loss: 0.6943\n","Epoch 50/100\n","\u001b[1m322/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6830 - auc: 0.7184 - loss: 0.5282\n","Epoch 50: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6833 - auc: 0.7186 - loss: 0.5280 - val_acc: 0.5778 - val_auc: 0.8011 - val_loss: 0.7485\n","Epoch 51/100\n","\u001b[1m313/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7204 - auc: 0.7315 - loss: 0.5076\n","Epoch 51: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7199 - auc: 0.7320 - loss: 0.5077 - val_acc: 0.5778 - val_auc: 0.7953 - val_loss: 0.7267\n","Epoch 52/100\n","\u001b[1m311/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7309 - auc: 0.7459 - loss: 0.4869\n","Epoch 52: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7298 - auc: 0.7454 - loss: 0.4880 - val_acc: 0.5778 - val_auc: 0.7950 - val_loss: 0.7343\n","Epoch 53/100\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7204 - auc: 0.7203 - loss: 0.5019\n","Epoch 53: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7204 - auc: 0.7203 - loss: 0.5019 - val_acc: 0.5778 - val_auc: 0.7907 - val_loss: 0.7350\n","Epoch 54/100\n","\u001b[1m312/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7212 - auc: 0.7521 - loss: 0.4923\n","Epoch 54: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7206 - auc: 0.7518 - loss: 0.4927 - val_acc: 0.5778 - val_auc: 0.7933 - val_loss: 0.7691\n","Epoch 55/100\n","\u001b[1m311/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7387 - auc: 0.7295 - loss: 0.4907\n","Epoch 55: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7371 - auc: 0.7294 - loss: 0.4918 - val_acc: 0.5778 - val_auc: 0.7756 - val_loss: 0.7293\n","Epoch 56/100\n","\u001b[1m312/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7327 - auc: 0.7215 - loss: 0.4998\n","Epoch 56: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7317 - auc: 0.7225 - loss: 0.5000 - val_acc: 0.5778 - val_auc: 0.7783 - val_loss: 0.7254\n","Epoch 57/100\n","\u001b[1m311/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7456 - auc: 0.7472 - loss: 0.4833\n","Epoch 57: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7442 - auc: 0.7469 - loss: 0.4843 - val_acc: 0.5778 - val_auc: 0.7945 - val_loss: 0.7909\n","Epoch 58/100\n","\u001b[1m312/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7174 - auc: 0.7526 - loss: 0.4982\n","Epoch 58: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7171 - auc: 0.7516 - loss: 0.4986 - val_acc: 0.5778 - val_auc: 0.7766 - val_loss: 0.7307\n","Epoch 59/100\n","\u001b[1m313/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7120 - auc: 0.7522 - loss: 0.5003\n","Epoch 59: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7120 - auc: 0.7514 - loss: 0.5006 - val_acc: 0.5778 - val_auc: 0.7804 - val_loss: 0.7793\n","Epoch 60/100\n","\u001b[1m318/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7253 - auc: 0.7096 - loss: 0.5154\n","Epoch 60: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7249 - auc: 0.7104 - loss: 0.5151 - val_acc: 0.5778 - val_auc: 0.7882 - val_loss: 0.8218\n","Epoch 61/100\n","\u001b[1m311/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7174 - auc: 0.7523 - loss: 0.5094\n","Epoch 61: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7171 - auc: 0.7517 - loss: 0.5094 - val_acc: 0.5778 - val_auc: 0.7672 - val_loss: 0.7401\n","Epoch 62/100\n","\u001b[1m314/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7216 - auc: 0.7583 - loss: 0.4777\n","Epoch 62: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7214 - auc: 0.7578 - loss: 0.4785 - val_acc: 0.5778 - val_auc: 0.7578 - val_loss: 0.7853\n","Epoch 63/100\n","\u001b[1m318/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7222 - auc: 0.7322 - loss: 0.5031\n","Epoch 63: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7219 - auc: 0.7325 - loss: 0.5031 - val_acc: 0.5778 - val_auc: 0.7943 - val_loss: 0.8628\n","Epoch 64/100\n","\u001b[1m313/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7085 - auc: 0.7622 - loss: 0.5008\n","Epoch 64: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7085 - auc: 0.7617 - loss: 0.5010 - val_acc: 0.5778 - val_auc: 0.7885 - val_loss: 0.8561\n","Epoch 65/100\n","\u001b[1m313/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7183 - auc: 0.7295 - loss: 0.5100\n","Epoch 65: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7179 - auc: 0.7297 - loss: 0.5097 - val_acc: 0.5778 - val_auc: 0.7601 - val_loss: 0.8265\n","Epoch 66/100\n","\u001b[1m315/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7142 - auc: 0.7471 - loss: 0.5029\n","Epoch 66: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7139 - auc: 0.7466 - loss: 0.5031 - val_acc: 0.5778 - val_auc: 0.7677 - val_loss: 0.8596\n","Epoch 67/100\n","\u001b[1m315/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7302 - auc: 0.7591 - loss: 0.4831\n","Epoch 67: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7297 - auc: 0.7586 - loss: 0.4837 - val_acc: 0.5778 - val_auc: 0.7743 - val_loss: 0.8578\n","Epoch 68/100\n","\u001b[1m323/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7167 - auc: 0.7450 - loss: 0.4924\n","Epoch 68: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7167 - auc: 0.7450 - loss: 0.4925 - val_acc: 0.5778 - val_auc: 0.7244 - val_loss: 0.8477\n","Epoch 69/100\n","\u001b[1m322/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7183 - auc: 0.7345 - loss: 0.4961\n","Epoch 69: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7182 - auc: 0.7347 - loss: 0.4962 - val_acc: 0.5778 - val_auc: 0.7161 - val_loss: 0.7265\n","Epoch 70/100\n","\u001b[1m318/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7180 - auc: 0.7676 - loss: 0.4789\n","Epoch 70: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7177 - auc: 0.7673 - loss: 0.4794 - val_acc: 0.5778 - val_auc: 0.7434 - val_loss: 0.8900\n","Epoch 71/100\n","\u001b[1m314/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7378 - auc: 0.7463 - loss: 0.4791\n","Epoch 71: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7368 - auc: 0.7465 - loss: 0.4798 - val_acc: 0.5778 - val_auc: 0.6900 - val_loss: 0.8325\n","Epoch 72/100\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7058 - auc: 0.7541 - loss: 0.4998\n","Epoch 72: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7058 - auc: 0.7541 - loss: 0.4998 - val_acc: 0.5778 - val_auc: 0.7080 - val_loss: 0.8164\n","Epoch 73/100\n","\u001b[1m314/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6913 - auc: 0.7372 - loss: 0.5097\n","Epoch 73: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6921 - auc: 0.7376 - loss: 0.5093 - val_acc: 0.5778 - val_auc: 0.7487 - val_loss: 0.9104\n","Epoch 74/100\n","\u001b[1m314/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7145 - auc: 0.7180 - loss: 0.5082\n","Epoch 74: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7143 - auc: 0.7187 - loss: 0.5079 - val_acc: 0.5778 - val_auc: 0.6323 - val_loss: 0.7544\n","Epoch 75/100\n","\u001b[1m324/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7099 - auc: 0.7240 - loss: 0.5016\n","Epoch 75: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7099 - auc: 0.7242 - loss: 0.5016 - val_acc: 0.5778 - val_auc: 0.7072 - val_loss: 0.9488\n","Epoch 76/100\n","\u001b[1m323/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7159 - auc: 0.7461 - loss: 0.5022\n","Epoch 76: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7159 - auc: 0.7462 - loss: 0.5021 - val_acc: 0.5778 - val_auc: 0.6359 - val_loss: 0.9013\n","Epoch 77/100\n","\u001b[1m311/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7547 - auc: 0.7669 - loss: 0.4743\n","Epoch 77: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7528 - auc: 0.7670 - loss: 0.4752 - val_acc: 0.5778 - val_auc: 0.6645 - val_loss: 0.9509\n","Epoch 78/100\n","\u001b[1m317/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7326 - auc: 0.7679 - loss: 0.4735\n","Epoch 78: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7321 - auc: 0.7676 - loss: 0.4743 - val_acc: 0.5778 - val_auc: 0.6215 - val_loss: 0.9268\n","Epoch 79/100\n","\u001b[1m313/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7129 - auc: 0.7421 - loss: 0.4964\n","Epoch 79: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7131 - auc: 0.7424 - loss: 0.4965 - val_acc: 0.5778 - val_auc: 0.6318 - val_loss: 0.9405\n","Epoch 80/100\n","\u001b[1m312/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7043 - auc: 0.7512 - loss: 0.5041\n","Epoch 80: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7046 - auc: 0.7518 - loss: 0.5039 - val_acc: 0.5778 - val_auc: 0.6108 - val_loss: 0.9000\n","Epoch 81/100\n","\u001b[1m315/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7175 - auc: 0.7612 - loss: 0.4896\n","Epoch 81: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7173 - auc: 0.7606 - loss: 0.4899 - val_acc: 0.5778 - val_auc: 0.6356 - val_loss: 1.0083\n","Epoch 82/100\n","\u001b[1m324/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7386 - auc: 0.7488 - loss: 0.4903\n","Epoch 82: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7384 - auc: 0.7488 - loss: 0.4904 - val_acc: 0.5778 - val_auc: 0.5886 - val_loss: 0.9371\n","Epoch 83/100\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7257 - auc: 0.7752 - loss: 0.4765\n","Epoch 83: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7257 - auc: 0.7752 - loss: 0.4766 - val_acc: 0.5778 - val_auc: 0.6113 - val_loss: 0.9684\n","Epoch 84/100\n","\u001b[1m312/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7106 - auc: 0.7665 - loss: 0.4958\n","Epoch 84: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7108 - auc: 0.7667 - loss: 0.4957 - val_acc: 0.5778 - val_auc: 0.6581 - val_loss: 1.0732\n","Epoch 85/100\n","\u001b[1m313/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7053 - auc: 0.7349 - loss: 0.4971\n","Epoch 85: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7056 - auc: 0.7356 - loss: 0.4971 - val_acc: 0.5778 - val_auc: 0.5903 - val_loss: 0.9851\n","Epoch 86/100\n","\u001b[1m315/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7031 - auc: 0.8002 - loss: 0.4940\n","Epoch 86: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7035 - auc: 0.7997 - loss: 0.4941 - val_acc: 0.5778 - val_auc: 0.6204 - val_loss: 1.0028\n","Epoch 87/100\n","\u001b[1m322/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7402 - auc: 0.7399 - loss: 0.4810\n","Epoch 87: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7399 - auc: 0.7401 - loss: 0.4812 - val_acc: 0.5778 - val_auc: 0.7133 - val_loss: 1.2239\n","Epoch 88/100\n","\u001b[1m313/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7153 - auc: 0.7309 - loss: 0.5268\n","Epoch 88: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7154 - auc: 0.7320 - loss: 0.5256 - val_acc: 0.5778 - val_auc: 0.5906 - val_loss: 1.0624\n","Epoch 89/100\n","\u001b[1m318/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6954 - auc: 0.7473 - loss: 0.5113\n","Epoch 89: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6957 - auc: 0.7476 - loss: 0.5110 - val_acc: 0.5778 - val_auc: 0.6166 - val_loss: 1.1450\n","Epoch 90/100\n","\u001b[1m312/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7115 - auc: 0.7469 - loss: 0.5026\n","Epoch 90: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7119 - auc: 0.7474 - loss: 0.5024 - val_acc: 0.5778 - val_auc: 0.7120 - val_loss: 1.1674\n","Epoch 91/100\n","\u001b[1m322/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7230 - auc: 0.7746 - loss: 0.4839\n","Epoch 91: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7229 - auc: 0.7745 - loss: 0.4840 - val_acc: 0.5778 - val_auc: 0.5698 - val_loss: 1.0077\n","Epoch 92/100\n","\u001b[1m324/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7036 - auc: 0.7598 - loss: 0.4947\n","Epoch 92: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7036 - auc: 0.7598 - loss: 0.4948 - val_acc: 0.5778 - val_auc: 0.5759 - val_loss: 1.0509\n","Epoch 93/100\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6920 - auc: 0.7671 - loss: 0.4890\n","Epoch 93: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6920 - auc: 0.7672 - loss: 0.4890 - val_acc: 0.5778 - val_auc: 0.7174 - val_loss: 1.2281\n","Epoch 94/100\n","\u001b[1m321/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7088 - auc: 0.7475 - loss: 0.5123\n","Epoch 94: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7089 - auc: 0.7477 - loss: 0.5120 - val_acc: 0.5778 - val_auc: 0.5850 - val_loss: 1.1816\n","Epoch 95/100\n","\u001b[1m323/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7050 - auc: 0.7683 - loss: 0.5115\n","Epoch 95: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7051 - auc: 0.7683 - loss: 0.5113 - val_acc: 0.5778 - val_auc: 0.5693 - val_loss: 1.1267\n","Epoch 96/100\n","\u001b[1m312/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7184 - auc: 0.7676 - loss: 0.4750\n","Epoch 96: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7182 - auc: 0.7672 - loss: 0.4758 - val_acc: 0.5778 - val_auc: 0.5281 - val_loss: 1.0774\n","Epoch 97/100\n","\u001b[1m316/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7009 - auc: 0.7630 - loss: 0.5111\n","Epoch 97: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7012 - auc: 0.7630 - loss: 0.5107 - val_acc: 0.5778 - val_auc: 0.5506 - val_loss: 1.1916\n","Epoch 98/100\n","\u001b[1m324/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7157 - auc: 0.7852 - loss: 0.4891\n","Epoch 98: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7157 - auc: 0.7851 - loss: 0.4891 - val_acc: 0.5778 - val_auc: 0.5698 - val_loss: 1.2176\n","Epoch 99/100\n","\u001b[1m324/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7393 - auc: 0.8061 - loss: 0.4662\n","Epoch 99: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7392 - auc: 0.8060 - loss: 0.4663 - val_acc: 0.5778 - val_auc: 0.5635 - val_loss: 1.2218\n","Epoch 100/100\n","\u001b[1m313/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7268 - auc: 0.7740 - loss: 0.4910\n","Epoch 100: val_loss did not improve from 0.53295\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7268 - auc: 0.7749 - loss: 0.4907 - val_acc: 0.5222 - val_auc: 0.5552 - val_loss: 1.3075\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 2 | TEST ACC=0.5809 | TEST AUC=0.5010 | n=136\n","Confusion matrix:\n"," [[74 22]\n"," [35  5]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.679     0.771     0.722        96\n","           1      0.185     0.125     0.149        40\n","\n","    accuracy                          0.581       136\n","   macro avg      0.432     0.448     0.436       136\n","weighted avg      0.534     0.581     0.554       136\n","\n","\n","--- Fold 3/7 ---\n"," train | ids:   34 | files:   992 | pos files:  323 | neg files:  669\n","   val | ids:    4 | files:    69 | pos files:    1 | neg files:   68\n","  test | ids:    6 | files:   139 | pos files:   81 | neg files:   58\n","Epoch 1/100\n","\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5750 - auc: 0.4788 - loss: 0.6897\n","Epoch 1: val_loss improved from inf to 0.55304, saving model to best_fold_03.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - acc: 0.5779 - auc: 0.4801 - loss: 0.6893 - val_acc: 0.9855 - val_auc: 0.2206 - val_loss: 0.5530\n","Epoch 2/100\n","\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6678 - auc: 0.4439 - loss: 0.6460\n","Epoch 2: val_loss improved from 0.55304 to 0.39419, saving model to best_fold_03.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6682 - auc: 0.4448 - loss: 0.6457 - val_acc: 0.9855 - val_auc: 0.4118 - val_loss: 0.3942\n","Epoch 3/100\n","\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6716 - auc: 0.4355 - loss: 0.6407\n","Epoch 3: val_loss did not improve from 0.39419\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6717 - auc: 0.4364 - loss: 0.6405 - val_acc: 0.9855 - val_auc: 0.5368 - val_loss: 0.4105\n","Epoch 4/100\n","\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6496 - auc: 0.5057 - loss: 0.6493\n","Epoch 4: val_loss improved from 0.39419 to 0.38170, saving model to best_fold_03.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6499 - auc: 0.5059 - loss: 0.6491 - val_acc: 0.9855 - val_auc: 0.6838 - val_loss: 0.3817\n","Epoch 5/100\n","\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6754 - auc: 0.5592 - loss: 0.6251\n","Epoch 5: val_loss did not improve from 0.38170\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6754 - auc: 0.5587 - loss: 0.6252 - val_acc: 0.9855 - val_auc: 0.7279 - val_loss: 0.4318\n","Epoch 6/100\n","\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6902 - auc: 0.5503 - loss: 0.6159\n","Epoch 6: val_loss did not improve from 0.38170\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6899 - auc: 0.5503 - loss: 0.6162 - val_acc: 0.9855 - val_auc: 0.7647 - val_loss: 0.4202\n","Epoch 7/100\n","\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6816 - auc: 0.5830 - loss: 0.6160\n","Epoch 7: val_loss did not improve from 0.38170\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6813 - auc: 0.5829 - loss: 0.6162 - val_acc: 0.9855 - val_auc: 0.7647 - val_loss: 0.4220\n","Epoch 8/100\n","\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6743 - auc: 0.6284 - loss: 0.6132\n","Epoch 8: val_loss improved from 0.38170 to 0.36770, saving model to best_fold_03.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6743 - auc: 0.6278 - loss: 0.6133 - val_acc: 0.9855 - val_auc: 0.8162 - val_loss: 0.3677\n","Epoch 9/100\n","\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6704 - auc: 0.6027 - loss: 0.6180\n","Epoch 9: val_loss did not improve from 0.36770\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6704 - auc: 0.6031 - loss: 0.6179 - val_acc: 0.9855 - val_auc: 0.8088 - val_loss: 0.4274\n","Epoch 10/100\n","\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6678 - auc: 0.6644 - loss: 0.6008\n","Epoch 10: val_loss did not improve from 0.36770\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6679 - auc: 0.6639 - loss: 0.6008 - val_acc: 0.9855 - val_auc: 0.8235 - val_loss: 0.4080\n","Epoch 11/100\n","\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6961 - auc: 0.6257 - loss: 0.5782\n","Epoch 11: val_loss did not improve from 0.36770\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6954 - auc: 0.6262 - loss: 0.5786 - val_acc: 0.9855 - val_auc: 0.8529 - val_loss: 0.4024\n","Epoch 12/100\n","\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6610 - auc: 0.6591 - loss: 0.5928\n","Epoch 12: val_loss did not improve from 0.36770\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6613 - auc: 0.6586 - loss: 0.5926 - val_acc: 0.9855 - val_auc: 0.8235 - val_loss: 0.3992\n","Epoch 13/100\n","\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6866 - auc: 0.6630 - loss: 0.5647\n","Epoch 13: val_loss did not improve from 0.36770\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6862 - auc: 0.6626 - loss: 0.5652 - val_acc: 0.9855 - val_auc: 0.8015 - val_loss: 0.3916\n","Epoch 14/100\n","\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6957 - auc: 0.6559 - loss: 0.5630\n","Epoch 14: val_loss did not improve from 0.36770\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6950 - auc: 0.6558 - loss: 0.5633 - val_acc: 0.9855 - val_auc: 0.8088 - val_loss: 0.4012\n","Epoch 15/100\n","\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6884 - auc: 0.6473 - loss: 0.5659\n","Epoch 15: val_loss did not improve from 0.36770\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6880 - auc: 0.6476 - loss: 0.5659 - val_acc: 0.9855 - val_auc: 0.8676 - val_loss: 0.4036\n","Epoch 16/100\n","\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6845 - auc: 0.6785 - loss: 0.5478\n","Epoch 16: val_loss did not improve from 0.36770\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6844 - auc: 0.6783 - loss: 0.5479 - val_acc: 0.9855 - val_auc: 0.8603 - val_loss: 0.3969\n","Epoch 17/100\n","\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6847 - auc: 0.6531 - loss: 0.5506\n","Epoch 17: val_loss did not improve from 0.36770\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6844 - auc: 0.6534 - loss: 0.5507 - val_acc: 0.9855 - val_auc: 0.7941 - val_loss: 0.4234\n","Epoch 18/100\n","\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6687 - auc: 0.6545 - loss: 0.5684\n","Epoch 18: val_loss did not improve from 0.36770\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6688 - auc: 0.6546 - loss: 0.5682 - val_acc: 0.9855 - val_auc: 0.7574 - val_loss: 0.3725\n","Epoch 19/100\n","\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6550 - auc: 0.6584 - loss: 0.5595\n","Epoch 19: val_loss did not improve from 0.36770\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6553 - auc: 0.6586 - loss: 0.5593 - val_acc: 0.9855 - val_auc: 0.7132 - val_loss: 0.3779\n","Epoch 20/100\n","\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6809 - auc: 0.6618 - loss: 0.5494\n","Epoch 20: val_loss improved from 0.36770 to 0.34485, saving model to best_fold_03.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6809 - auc: 0.6620 - loss: 0.5494 - val_acc: 0.9855 - val_auc: 0.5294 - val_loss: 0.3448\n","Epoch 21/100\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6802 - auc: 0.6812 - loss: 0.5590\n","Epoch 21: val_loss did not improve from 0.34485\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6802 - auc: 0.6813 - loss: 0.5590 - val_acc: 0.9855 - val_auc: 0.4485 - val_loss: 0.3598\n","Epoch 22/100\n","\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6957 - auc: 0.6833 - loss: 0.5494\n","Epoch 22: val_loss did not improve from 0.34485\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6957 - auc: 0.6834 - loss: 0.5494 - val_acc: 0.9855 - val_auc: 0.4191 - val_loss: 0.4201\n","Epoch 23/100\n","\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7258 - auc: 0.7197 - loss: 0.5240\n","Epoch 23: val_loss did not improve from 0.34485\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7254 - auc: 0.7202 - loss: 0.5242 - val_acc: 0.9855 - val_auc: 0.3971 - val_loss: 0.3896\n","Epoch 24/100\n","\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7217 - auc: 0.7469 - loss: 0.5129\n","Epoch 24: val_loss improved from 0.34485 to 0.32973, saving model to best_fold_03.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7218 - auc: 0.7470 - loss: 0.5129 - val_acc: 0.9855 - val_auc: 0.3676 - val_loss: 0.3297\n","Epoch 25/100\n","\u001b[1m317/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7550 - auc: 0.7301 - loss: 0.4981\n","Epoch 25: val_loss did not improve from 0.32973\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7540 - auc: 0.7311 - loss: 0.4989 - val_acc: 0.7681 - val_auc: 0.3529 - val_loss: 0.4380\n","Epoch 26/100\n","\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7090 - auc: 0.7394 - loss: 0.5158\n","Epoch 26: val_loss did not improve from 0.32973\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7091 - auc: 0.7396 - loss: 0.5157 - val_acc: 0.8551 - val_auc: 0.3529 - val_loss: 0.4161\n","Epoch 27/100\n","\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7171 - auc: 0.7740 - loss: 0.4981\n","Epoch 27: val_loss improved from 0.32973 to 0.26408, saving model to best_fold_03.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7169 - auc: 0.7738 - loss: 0.4983 - val_acc: 0.9855 - val_auc: 0.3529 - val_loss: 0.2641\n","Epoch 28/100\n","\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6967 - auc: 0.7770 - loss: 0.5122\n","Epoch 28: val_loss did not improve from 0.26408\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6969 - auc: 0.7767 - loss: 0.5119 - val_acc: 0.6377 - val_auc: 0.3529 - val_loss: 0.4664\n","Epoch 29/100\n","\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7400 - auc: 0.7717 - loss: 0.4910\n","Epoch 29: val_loss did not improve from 0.26408\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7400 - auc: 0.7717 - loss: 0.4910 - val_acc: 0.7246 - val_auc: 0.3676 - val_loss: 0.4196\n","Epoch 30/100\n","\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7119 - auc: 0.7650 - loss: 0.5161\n","Epoch 30: val_loss did not improve from 0.26408\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7122 - auc: 0.7651 - loss: 0.5158 - val_acc: 0.9565 - val_auc: 0.3529 - val_loss: 0.3329\n","Epoch 31/100\n","\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7403 - auc: 0.7901 - loss: 0.4822\n","Epoch 31: val_loss did not improve from 0.26408\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7400 - auc: 0.7898 - loss: 0.4825 - val_acc: 0.6087 - val_auc: 0.3824 - val_loss: 0.4898\n","Epoch 32/100\n","\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7630 - auc: 0.7923 - loss: 0.4658\n","Epoch 32: val_loss improved from 0.26408 to 0.20427, saving model to best_fold_03.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7621 - auc: 0.7920 - loss: 0.4668 - val_acc: 0.9855 - val_auc: 0.3529 - val_loss: 0.2043\n","Epoch 33/100\n","\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7180 - auc: 0.7724 - loss: 0.4995\n","Epoch 33: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7181 - auc: 0.7726 - loss: 0.4992 - val_acc: 0.9565 - val_auc: 0.3529 - val_loss: 0.3080\n","Epoch 34/100\n","\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7221 - auc: 0.7833 - loss: 0.4997\n","Epoch 34: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7221 - auc: 0.7833 - loss: 0.4993 - val_acc: 0.9855 - val_auc: 0.3529 - val_loss: 0.2844\n","Epoch 35/100\n","\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7281 - auc: 0.7836 - loss: 0.4870\n","Epoch 35: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7281 - auc: 0.7836 - loss: 0.4869 - val_acc: 0.9130 - val_auc: 0.3529 - val_loss: 0.3744\n","Epoch 36/100\n","\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7247 - auc: 0.7904 - loss: 0.4954\n","Epoch 36: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7249 - auc: 0.7907 - loss: 0.4951 - val_acc: 0.8261 - val_auc: 0.3529 - val_loss: 0.4061\n","Epoch 37/100\n","\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7587 - auc: 0.8180 - loss: 0.4626\n","Epoch 37: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7582 - auc: 0.8177 - loss: 0.4629 - val_acc: 0.8841 - val_auc: 0.3529 - val_loss: 0.3569\n","Epoch 38/100\n","\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7134 - auc: 0.7882 - loss: 0.4937\n","Epoch 38: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7137 - auc: 0.7883 - loss: 0.4934 - val_acc: 0.5942 - val_auc: 0.3824 - val_loss: 0.4998\n","Epoch 39/100\n","\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7508 - auc: 0.7862 - loss: 0.4708\n","Epoch 39: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7503 - auc: 0.7863 - loss: 0.4711 - val_acc: 0.8116 - val_auc: 0.3382 - val_loss: 0.4162\n","Epoch 40/100\n","\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7424 - auc: 0.7820 - loss: 0.4793\n","Epoch 40: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7417 - auc: 0.7818 - loss: 0.4798 - val_acc: 0.8696 - val_auc: 0.3235 - val_loss: 0.3945\n","Epoch 41/100\n","\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7560 - auc: 0.8192 - loss: 0.4536\n","Epoch 41: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7555 - auc: 0.8186 - loss: 0.4545 - val_acc: 0.9565 - val_auc: 0.3529 - val_loss: 0.2930\n","Epoch 42/100\n","\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7443 - auc: 0.7935 - loss: 0.4831\n","Epoch 42: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7440 - auc: 0.7937 - loss: 0.4829 - val_acc: 0.8116 - val_auc: 0.3529 - val_loss: 0.3962\n","Epoch 43/100\n","\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7434 - auc: 0.8020 - loss: 0.4633\n","Epoch 43: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7435 - auc: 0.8020 - loss: 0.4635 - val_acc: 0.9275 - val_auc: 0.3529 - val_loss: 0.3300\n","Epoch 44/100\n","\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7255 - auc: 0.7907 - loss: 0.4765\n","Epoch 44: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7256 - auc: 0.7906 - loss: 0.4766 - val_acc: 0.8986 - val_auc: 0.3309 - val_loss: 0.3810\n","Epoch 45/100\n","\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7564 - auc: 0.8064 - loss: 0.4551\n","Epoch 45: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7563 - auc: 0.8064 - loss: 0.4554 - val_acc: 0.8986 - val_auc: 0.3529 - val_loss: 0.3552\n","Epoch 46/100\n","\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7366 - auc: 0.8038 - loss: 0.4812\n","Epoch 46: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7366 - auc: 0.8038 - loss: 0.4811 - val_acc: 0.9855 - val_auc: 0.3235 - val_loss: 0.2921\n","Epoch 47/100\n","\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7301 - auc: 0.7890 - loss: 0.4949\n","Epoch 47: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7302 - auc: 0.7890 - loss: 0.4948 - val_acc: 0.9565 - val_auc: 0.3382 - val_loss: 0.3213\n","Epoch 48/100\n","\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7655 - auc: 0.8124 - loss: 0.4677\n","Epoch 48: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7653 - auc: 0.8122 - loss: 0.4678 - val_acc: 0.9565 - val_auc: 0.3529 - val_loss: 0.3360\n","Epoch 49/100\n","\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7366 - auc: 0.7911 - loss: 0.4906\n","Epoch 49: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7367 - auc: 0.7912 - loss: 0.4903 - val_acc: 0.8116 - val_auc: 0.3235 - val_loss: 0.4068\n","Epoch 50/100\n","\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7658 - auc: 0.8189 - loss: 0.4483\n","Epoch 50: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7657 - auc: 0.8188 - loss: 0.4484 - val_acc: 0.7536 - val_auc: 0.3529 - val_loss: 0.4393\n","Epoch 51/100\n","\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7511 - auc: 0.7994 - loss: 0.4782\n","Epoch 51: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7510 - auc: 0.7995 - loss: 0.4781 - val_acc: 0.8406 - val_auc: 0.2647 - val_loss: 0.4176\n","Epoch 52/100\n","\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7396 - auc: 0.7870 - loss: 0.4596\n","Epoch 52: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7399 - auc: 0.7875 - loss: 0.4599 - val_acc: 0.9130 - val_auc: 0.3235 - val_loss: 0.3434\n","Epoch 53/100\n","\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7535 - auc: 0.8125 - loss: 0.4558\n","Epoch 53: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7534 - auc: 0.8124 - loss: 0.4562 - val_acc: 0.8986 - val_auc: 0.3529 - val_loss: 0.3455\n","Epoch 54/100\n","\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7720 - auc: 0.8395 - loss: 0.4315\n","Epoch 54: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7711 - auc: 0.8387 - loss: 0.4325 - val_acc: 0.9565 - val_auc: 0.3382 - val_loss: 0.3280\n","Epoch 55/100\n","\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7446 - auc: 0.8014 - loss: 0.4713\n","Epoch 55: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7446 - auc: 0.8014 - loss: 0.4713 - val_acc: 0.9565 - val_auc: 0.3235 - val_loss: 0.3342\n","Epoch 56/100\n","\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7539 - auc: 0.7767 - loss: 0.4745\n","Epoch 56: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7541 - auc: 0.7776 - loss: 0.4742 - val_acc: 0.9275 - val_auc: 0.3162 - val_loss: 0.3559\n","Epoch 57/100\n","\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7452 - auc: 0.8015 - loss: 0.4714\n","Epoch 57: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7451 - auc: 0.8017 - loss: 0.4713 - val_acc: 0.9565 - val_auc: 0.3529 - val_loss: 0.2921\n","Epoch 58/100\n","\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7665 - auc: 0.8239 - loss: 0.4613\n","Epoch 58: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7661 - auc: 0.8237 - loss: 0.4611 - val_acc: 0.9855 - val_auc: 0.3824 - val_loss: 0.2640\n","Epoch 59/100\n","\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7503 - auc: 0.7959 - loss: 0.4713\n","Epoch 59: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7500 - auc: 0.7962 - loss: 0.4712 - val_acc: 0.9565 - val_auc: 0.3382 - val_loss: 0.2628\n","Epoch 60/100\n","\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7626 - auc: 0.8252 - loss: 0.4540\n","Epoch 60: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7623 - auc: 0.8250 - loss: 0.4542 - val_acc: 0.9420 - val_auc: 0.3382 - val_loss: 0.3564\n","Epoch 61/100\n","\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7405 - auc: 0.8135 - loss: 0.4663\n","Epoch 61: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7405 - auc: 0.8135 - loss: 0.4662 - val_acc: 0.9130 - val_auc: 0.3529 - val_loss: 0.3654\n","Epoch 62/100\n","\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7718 - auc: 0.8140 - loss: 0.4572\n","Epoch 62: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7714 - auc: 0.8139 - loss: 0.4574 - val_acc: 0.8696 - val_auc: 0.3382 - val_loss: 0.3754\n","Epoch 63/100\n","\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7629 - auc: 0.8319 - loss: 0.4438\n","Epoch 63: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7624 - auc: 0.8311 - loss: 0.4446 - val_acc: 0.8406 - val_auc: 0.3529 - val_loss: 0.4043\n","Epoch 64/100\n","\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7329 - auc: 0.7998 - loss: 0.4843\n","Epoch 64: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7331 - auc: 0.8000 - loss: 0.4838 - val_acc: 0.9420 - val_auc: 0.3382 - val_loss: 0.3462\n","Epoch 65/100\n","\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7600 - auc: 0.8481 - loss: 0.4344\n","Epoch 65: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7599 - auc: 0.8475 - loss: 0.4349 - val_acc: 0.9565 - val_auc: 0.3456 - val_loss: 0.2936\n","Epoch 66/100\n","\u001b[1m328/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7372 - auc: 0.8038 - loss: 0.4624\n","Epoch 66: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7372 - auc: 0.8039 - loss: 0.4624 - val_acc: 0.9565 - val_auc: 0.3529 - val_loss: 0.3414\n","Epoch 67/100\n","\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7501 - auc: 0.7826 - loss: 0.4679\n","Epoch 67: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7499 - auc: 0.7832 - loss: 0.4678 - val_acc: 0.9565 - val_auc: 0.3382 - val_loss: 0.2791\n","Epoch 68/100\n","\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7634 - auc: 0.8271 - loss: 0.4381\n","Epoch 68: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7632 - auc: 0.8269 - loss: 0.4384 - val_acc: 0.9420 - val_auc: 0.3382 - val_loss: 0.3455\n","Epoch 69/100\n","\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7530 - auc: 0.7781 - loss: 0.4766\n","Epoch 69: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7530 - auc: 0.7785 - loss: 0.4764 - val_acc: 0.9565 - val_auc: 0.3382 - val_loss: 0.2662\n","Epoch 70/100\n","\u001b[1m323/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7413 - auc: 0.8020 - loss: 0.4612\n","Epoch 70: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7416 - auc: 0.8021 - loss: 0.4612 - val_acc: 0.9855 - val_auc: 0.3382 - val_loss: 0.2626\n","Epoch 71/100\n","\u001b[1m319/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7414 - auc: 0.8166 - loss: 0.4683\n","Epoch 71: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7417 - auc: 0.8168 - loss: 0.4678 - val_acc: 0.9710 - val_auc: 0.3162 - val_loss: 0.2826\n","Epoch 72/100\n","\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7331 - auc: 0.8090 - loss: 0.4928\n","Epoch 72: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7336 - auc: 0.8091 - loss: 0.4919 - val_acc: 0.9710 - val_auc: 0.3382 - val_loss: 0.2556\n","Epoch 73/100\n","\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7710 - auc: 0.8074 - loss: 0.4674\n","Epoch 73: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7706 - auc: 0.8075 - loss: 0.4672 - val_acc: 0.9565 - val_auc: 0.3529 - val_loss: 0.3400\n","Epoch 74/100\n","\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7653 - auc: 0.8166 - loss: 0.4311\n","Epoch 74: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7650 - auc: 0.8164 - loss: 0.4318 - val_acc: 0.9420 - val_auc: 0.3235 - val_loss: 0.3448\n","Epoch 75/100\n","\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7478 - auc: 0.8083 - loss: 0.4665\n","Epoch 75: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7478 - auc: 0.8082 - loss: 0.4665 - val_acc: 0.9420 - val_auc: 0.3529 - val_loss: 0.3621\n","Epoch 76/100\n","\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7831 - auc: 0.8279 - loss: 0.4262\n","Epoch 76: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7815 - auc: 0.8274 - loss: 0.4274 - val_acc: 0.9130 - val_auc: 0.3235 - val_loss: 0.3703\n","Epoch 77/100\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7528 - auc: 0.8268 - loss: 0.4450\n","Epoch 77: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7528 - auc: 0.8268 - loss: 0.4450 - val_acc: 0.7681 - val_auc: 0.3529 - val_loss: 0.4267\n","Epoch 78/100\n","\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7608 - auc: 0.8225 - loss: 0.4489\n","Epoch 78: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7608 - auc: 0.8223 - loss: 0.4490 - val_acc: 0.9855 - val_auc: 0.2574 - val_loss: 0.2694\n","Epoch 79/100\n","\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7765 - auc: 0.8163 - loss: 0.4543\n","Epoch 79: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7761 - auc: 0.8162 - loss: 0.4544 - val_acc: 0.8986 - val_auc: 0.3235 - val_loss: 0.4008\n","Epoch 80/100\n","\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7372 - auc: 0.7987 - loss: 0.4759\n","Epoch 80: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7377 - auc: 0.7991 - loss: 0.4756 - val_acc: 0.9565 - val_auc: 0.3235 - val_loss: 0.3047\n","Epoch 81/100\n","\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7716 - auc: 0.8284 - loss: 0.4271\n","Epoch 81: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7712 - auc: 0.8282 - loss: 0.4276 - val_acc: 0.9710 - val_auc: 0.3235 - val_loss: 0.2884\n","Epoch 82/100\n","\u001b[1m318/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7585 - auc: 0.8166 - loss: 0.4601\n","Epoch 82: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7587 - auc: 0.8164 - loss: 0.4601 - val_acc: 0.9565 - val_auc: 0.3529 - val_loss: 0.3239\n","Epoch 83/100\n","\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7884 - auc: 0.8289 - loss: 0.4197\n","Epoch 83: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7879 - auc: 0.8288 - loss: 0.4202 - val_acc: 0.6087 - val_auc: 0.3529 - val_loss: 0.5030\n","Epoch 84/100\n","\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7210 - auc: 0.8070 - loss: 0.4634\n","Epoch 84: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7217 - auc: 0.8071 - loss: 0.4633 - val_acc: 0.9565 - val_auc: 0.3382 - val_loss: 0.3322\n","Epoch 85/100\n","\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7311 - auc: 0.7924 - loss: 0.4715\n","Epoch 85: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7317 - auc: 0.7933 - loss: 0.4709 - val_acc: 0.9420 - val_auc: 0.3529 - val_loss: 0.3487\n","Epoch 86/100\n","\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7338 - auc: 0.7894 - loss: 0.4842\n","Epoch 86: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7340 - auc: 0.7898 - loss: 0.4837 - val_acc: 0.9565 - val_auc: 0.3382 - val_loss: 0.2472\n","Epoch 87/100\n","\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7557 - auc: 0.8234 - loss: 0.4510\n","Epoch 87: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7557 - auc: 0.8233 - loss: 0.4511 - val_acc: 0.9130 - val_auc: 0.3382 - val_loss: 0.3905\n","Epoch 88/100\n","\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7480 - auc: 0.8290 - loss: 0.4508\n","Epoch 88: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7480 - auc: 0.8289 - loss: 0.4509 - val_acc: 0.9420 - val_auc: 0.3235 - val_loss: 0.3299\n","Epoch 89/100\n","\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7863 - auc: 0.8242 - loss: 0.4295\n","Epoch 89: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7854 - auc: 0.8239 - loss: 0.4305 - val_acc: 0.8841 - val_auc: 0.3382 - val_loss: 0.3924\n","Epoch 90/100\n","\u001b[1m326/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7492 - auc: 0.8051 - loss: 0.4544\n","Epoch 90: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7491 - auc: 0.8052 - loss: 0.4545 - val_acc: 0.9565 - val_auc: 0.3529 - val_loss: 0.3057\n","Epoch 91/100\n","\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7523 - auc: 0.8259 - loss: 0.4411\n","Epoch 91: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7526 - auc: 0.8259 - loss: 0.4413 - val_acc: 0.9420 - val_auc: 0.3088 - val_loss: 0.3453\n","Epoch 92/100\n","\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7812 - auc: 0.8328 - loss: 0.4253\n","Epoch 92: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7804 - auc: 0.8323 - loss: 0.4263 - val_acc: 0.8986 - val_auc: 0.3382 - val_loss: 0.3995\n","Epoch 93/100\n","\u001b[1m321/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7854 - auc: 0.8406 - loss: 0.4315\n","Epoch 93: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7848 - auc: 0.8399 - loss: 0.4321 - val_acc: 0.8986 - val_auc: 0.3529 - val_loss: 0.3648\n","Epoch 94/100\n","\u001b[1m324/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7108 - auc: 0.7967 - loss: 0.4892\n","Epoch 94: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7117 - auc: 0.7972 - loss: 0.4883 - val_acc: 0.9855 - val_auc: 0.3529 - val_loss: 0.2084\n","Epoch 95/100\n","\u001b[1m320/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7738 - auc: 0.8229 - loss: 0.4315\n","Epoch 95: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7731 - auc: 0.8224 - loss: 0.4324 - val_acc: 0.8841 - val_auc: 0.3529 - val_loss: 0.3966\n","Epoch 96/100\n","\u001b[1m330/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7610 - auc: 0.8118 - loss: 0.4385\n","Epoch 96: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7610 - auc: 0.8118 - loss: 0.4386 - val_acc: 0.9855 - val_auc: 0.3382 - val_loss: 0.2677\n","Epoch 97/100\n","\u001b[1m322/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7355 - auc: 0.8040 - loss: 0.4646\n","Epoch 97: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7359 - auc: 0.8044 - loss: 0.4642 - val_acc: 0.9420 - val_auc: 0.3382 - val_loss: 0.3313\n","Epoch 98/100\n","\u001b[1m325/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7553 - auc: 0.8255 - loss: 0.4423\n","Epoch 98: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7553 - auc: 0.8252 - loss: 0.4426 - val_acc: 0.9565 - val_auc: 0.3529 - val_loss: 0.3220\n","Epoch 99/100\n","\u001b[1m327/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7720 - auc: 0.8357 - loss: 0.4425\n","Epoch 99: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7717 - auc: 0.8354 - loss: 0.4428 - val_acc: 0.9565 - val_auc: 0.3676 - val_loss: 0.3174\n","Epoch 100/100\n","\u001b[1m329/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7490 - auc: 0.7945 - loss: 0.4505\n","Epoch 100: val_loss did not improve from 0.20427\n","\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7491 - auc: 0.7947 - loss: 0.4506 - val_acc: 0.9420 - val_auc: 0.3382 - val_loss: 0.3207\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 3 | TEST ACC=0.4173 | TEST AUC=0.6511 | n=139\n","Confusion matrix:\n"," [[58  0]\n"," [81  0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.417     1.000     0.589        58\n","           1      0.000     0.000     0.000        81\n","\n","    accuracy                          0.417       139\n","   macro avg      0.209     0.500     0.294       139\n","weighted avg      0.174     0.417     0.246       139\n","\n","\n","--- Fold 4/7 ---\n"," train | ids:   34 | files:   935 | pos files:  337 | neg files:  598\n","   val | ids:    4 | files:   195 | pos files:   38 | neg files:  157\n","  test | ids:    6 | files:    70 | pos files:   30 | neg files:   40\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5627 - auc: 0.4574 - loss: 0.6886\n","Epoch 1: val_loss improved from inf to 0.59746, saving model to best_fold_04.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - acc: 0.5630 - auc: 0.4576 - loss: 0.6885 - val_acc: 0.8051 - val_auc: 0.3937 - val_loss: 0.5975\n","Epoch 2/100\n","\u001b[1m299/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6470 - auc: 0.5136 - loss: 0.6508\n","Epoch 2: val_loss improved from 0.59746 to 0.56103, saving model to best_fold_04.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6466 - auc: 0.5140 - loss: 0.6509 - val_acc: 0.8051 - val_auc: 0.4028 - val_loss: 0.5610\n","Epoch 3/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6346 - auc: 0.5862 - loss: 0.6498\n","Epoch 3: val_loss did not improve from 0.56103\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6346 - auc: 0.5862 - loss: 0.6498 - val_acc: 0.8051 - val_auc: 0.4774 - val_loss: 0.5642\n","Epoch 4/100\n","\u001b[1m301/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6408 - auc: 0.5659 - loss: 0.6466\n","Epoch 4: val_loss improved from 0.56103 to 0.55213, saving model to best_fold_04.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6407 - auc: 0.5672 - loss: 0.6465 - val_acc: 0.8051 - val_auc: 0.5496 - val_loss: 0.5521\n","Epoch 5/100\n","\u001b[1m303/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6492 - auc: 0.6438 - loss: 0.6223\n","Epoch 5: val_loss did not improve from 0.55213\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6489 - auc: 0.6430 - loss: 0.6226 - val_acc: 0.8051 - val_auc: 0.6410 - val_loss: 0.5795\n","Epoch 6/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6297 - auc: 0.6435 - loss: 0.6329\n","Epoch 6: val_loss improved from 0.55213 to 0.52170, saving model to best_fold_04.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6298 - auc: 0.6435 - loss: 0.6328 - val_acc: 0.8051 - val_auc: 0.6375 - val_loss: 0.5217\n","Epoch 7/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6286 - auc: 0.6436 - loss: 0.6288\n","Epoch 7: val_loss improved from 0.52170 to 0.51116, saving model to best_fold_04.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6288 - auc: 0.6438 - loss: 0.6286 - val_acc: 0.8051 - val_auc: 0.6569 - val_loss: 0.5112\n","Epoch 8/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6647 - auc: 0.6936 - loss: 0.5839\n","Epoch 8: val_loss did not improve from 0.51116\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6645 - auc: 0.6932 - loss: 0.5843 - val_acc: 0.8051 - val_auc: 0.6710 - val_loss: 0.5305\n","Epoch 9/100\n","\u001b[1m303/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6296 - auc: 0.6383 - loss: 0.6152\n","Epoch 9: val_loss improved from 0.51116 to 0.47691, saving model to best_fold_04.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6302 - auc: 0.6394 - loss: 0.6147 - val_acc: 0.8051 - val_auc: 0.6695 - val_loss: 0.4769\n","Epoch 10/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6470 - auc: 0.6832 - loss: 0.6098\n","Epoch 10: val_loss did not improve from 0.47691\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6468 - auc: 0.6829 - loss: 0.6096 - val_acc: 0.7744 - val_auc: 0.6845 - val_loss: 0.5445\n","Epoch 11/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6864 - auc: 0.6835 - loss: 0.5812\n","Epoch 11: val_loss did not improve from 0.47691\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6859 - auc: 0.6833 - loss: 0.5814 - val_acc: 0.7846 - val_auc: 0.6783 - val_loss: 0.5202\n","Epoch 12/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6323 - auc: 0.6683 - loss: 0.5778\n","Epoch 12: val_loss did not improve from 0.47691\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6324 - auc: 0.6685 - loss: 0.5781 - val_acc: 0.8051 - val_auc: 0.6815 - val_loss: 0.4809\n","Epoch 13/100\n","\u001b[1m303/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6137 - auc: 0.6620 - loss: 0.6017\n","Epoch 13: val_loss did not improve from 0.47691\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6149 - auc: 0.6625 - loss: 0.6012 - val_acc: 0.7846 - val_auc: 0.6737 - val_loss: 0.5365\n","Epoch 14/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6676 - auc: 0.6692 - loss: 0.5900\n","Epoch 14: val_loss improved from 0.47691 to 0.47568, saving model to best_fold_04.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6675 - auc: 0.6693 - loss: 0.5899 - val_acc: 0.8051 - val_auc: 0.6830 - val_loss: 0.4757\n","Epoch 15/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6537 - auc: 0.6610 - loss: 0.5855\n","Epoch 15: val_loss did not improve from 0.47568\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6538 - auc: 0.6613 - loss: 0.5854 - val_acc: 0.7641 - val_auc: 0.6786 - val_loss: 0.5392\n","Epoch 16/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6916 - auc: 0.7121 - loss: 0.5694\n","Epoch 16: val_loss did not improve from 0.47568\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6913 - auc: 0.7118 - loss: 0.5696 - val_acc: 0.7795 - val_auc: 0.6836 - val_loss: 0.5091\n","Epoch 17/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6854 - auc: 0.6611 - loss: 0.5828\n","Epoch 17: val_loss did not improve from 0.47568\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6853 - auc: 0.6614 - loss: 0.5827 - val_acc: 0.7641 - val_auc: 0.6817 - val_loss: 0.4830\n","Epoch 18/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6254 - auc: 0.6949 - loss: 0.5727\n","Epoch 18: val_loss did not improve from 0.47568\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6256 - auc: 0.6948 - loss: 0.5728 - val_acc: 0.7897 - val_auc: 0.6799 - val_loss: 0.4825\n","Epoch 19/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6565 - auc: 0.6832 - loss: 0.5687\n","Epoch 19: val_loss did not improve from 0.47568\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6565 - auc: 0.6833 - loss: 0.5689 - val_acc: 0.7590 - val_auc: 0.6832 - val_loss: 0.5276\n","Epoch 20/100\n","\u001b[1m302/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6339 - auc: 0.6715 - loss: 0.5805\n","Epoch 20: val_loss did not improve from 0.47568\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6347 - auc: 0.6720 - loss: 0.5802 - val_acc: 0.7590 - val_auc: 0.6863 - val_loss: 0.5131\n","Epoch 21/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6522 - auc: 0.6953 - loss: 0.5891\n","Epoch 21: val_loss improved from 0.47568 to 0.46662, saving model to best_fold_04.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6522 - auc: 0.6952 - loss: 0.5890 - val_acc: 0.7897 - val_auc: 0.6813 - val_loss: 0.4666\n","Epoch 22/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6241 - auc: 0.7129 - loss: 0.5466\n","Epoch 22: val_loss did not improve from 0.46662\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6242 - auc: 0.7127 - loss: 0.5467 - val_acc: 0.7846 - val_auc: 0.6861 - val_loss: 0.4904\n","Epoch 23/100\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6390 - auc: 0.6764 - loss: 0.5731\n","Epoch 23: val_loss did not improve from 0.46662\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6390 - auc: 0.6764 - loss: 0.5731 - val_acc: 0.7846 - val_auc: 0.6769 - val_loss: 0.4703\n","Epoch 24/100\n","\u001b[1m298/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6822 - auc: 0.7095 - loss: 0.5742\n","Epoch 24: val_loss did not improve from 0.46662\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6810 - auc: 0.7088 - loss: 0.5742 - val_acc: 0.7692 - val_auc: 0.6809 - val_loss: 0.4847\n","Epoch 25/100\n","\u001b[1m303/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6509 - auc: 0.7013 - loss: 0.5781\n","Epoch 25: val_loss improved from 0.46662 to 0.44988, saving model to best_fold_04.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6512 - auc: 0.7010 - loss: 0.5778 - val_acc: 0.7846 - val_auc: 0.6664 - val_loss: 0.4499\n","Epoch 26/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6431 - auc: 0.6967 - loss: 0.5836\n","Epoch 26: val_loss improved from 0.44988 to 0.44873, saving model to best_fold_04.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6431 - auc: 0.6966 - loss: 0.5835 - val_acc: 0.7846 - val_auc: 0.6597 - val_loss: 0.4487\n","Epoch 27/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6298 - auc: 0.6996 - loss: 0.5662\n","Epoch 27: val_loss did not improve from 0.44873\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6303 - auc: 0.6994 - loss: 0.5663 - val_acc: 0.7692 - val_auc: 0.6814 - val_loss: 0.5006\n","Epoch 28/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6494 - auc: 0.7166 - loss: 0.5752\n","Epoch 28: val_loss improved from 0.44873 to 0.44511, saving model to best_fold_04.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6494 - auc: 0.7163 - loss: 0.5752 - val_acc: 0.8051 - val_auc: 0.6655 - val_loss: 0.4451\n","Epoch 29/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6709 - auc: 0.6910 - loss: 0.5665\n","Epoch 29: val_loss did not improve from 0.44511\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6708 - auc: 0.6913 - loss: 0.5665 - val_acc: 0.7692 - val_auc: 0.6734 - val_loss: 0.4743\n","Epoch 30/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6461 - auc: 0.6859 - loss: 0.5757\n","Epoch 30: val_loss did not improve from 0.44511\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6462 - auc: 0.6860 - loss: 0.5756 - val_acc: 0.7846 - val_auc: 0.6664 - val_loss: 0.4560\n","Epoch 31/100\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6731 - auc: 0.6664 - loss: 0.5953\n","Epoch 31: val_loss did not improve from 0.44511\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6731 - auc: 0.6664 - loss: 0.5952 - val_acc: 0.7436 - val_auc: 0.6665 - val_loss: 0.4697\n","Epoch 32/100\n","\u001b[1m303/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6039 - auc: 0.6792 - loss: 0.5804\n","Epoch 32: val_loss did not improve from 0.44511\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6050 - auc: 0.6798 - loss: 0.5800 - val_acc: 0.7692 - val_auc: 0.6707 - val_loss: 0.4868\n","Epoch 33/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6345 - auc: 0.6856 - loss: 0.5884\n","Epoch 33: val_loss improved from 0.44511 to 0.42301, saving model to best_fold_04.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6348 - auc: 0.6857 - loss: 0.5880 - val_acc: 0.8051 - val_auc: 0.6526 - val_loss: 0.4230\n","Epoch 34/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6813 - auc: 0.7081 - loss: 0.5695\n","Epoch 34: val_loss did not improve from 0.42301\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6811 - auc: 0.7079 - loss: 0.5696 - val_acc: 0.7179 - val_auc: 0.6734 - val_loss: 0.4935\n","Epoch 35/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6707 - auc: 0.6964 - loss: 0.5696\n","Epoch 35: val_loss did not improve from 0.42301\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6704 - auc: 0.6966 - loss: 0.5696 - val_acc: 0.7692 - val_auc: 0.6525 - val_loss: 0.4442\n","Epoch 36/100\n","\u001b[1m298/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6646 - auc: 0.6983 - loss: 0.5587\n","Epoch 36: val_loss did not improve from 0.42301\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6642 - auc: 0.6983 - loss: 0.5590 - val_acc: 0.6564 - val_auc: 0.6725 - val_loss: 0.5241\n","Epoch 37/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6572 - auc: 0.6839 - loss: 0.5768\n","Epoch 37: val_loss did not improve from 0.42301\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6572 - auc: 0.6842 - loss: 0.5766 - val_acc: 0.7641 - val_auc: 0.6529 - val_loss: 0.4376\n","Epoch 38/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6491 - auc: 0.7279 - loss: 0.5452\n","Epoch 38: val_loss did not improve from 0.42301\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6491 - auc: 0.7277 - loss: 0.5453 - val_acc: 0.7538 - val_auc: 0.6638 - val_loss: 0.4805\n","Epoch 39/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6313 - auc: 0.7021 - loss: 0.5606\n","Epoch 39: val_loss improved from 0.42301 to 0.41492, saving model to best_fold_04.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6315 - auc: 0.7019 - loss: 0.5606 - val_acc: 0.8051 - val_auc: 0.6510 - val_loss: 0.4149\n","Epoch 40/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7021 - auc: 0.7035 - loss: 0.5487\n","Epoch 40: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7017 - auc: 0.7035 - loss: 0.5488 - val_acc: 0.7846 - val_auc: 0.6509 - val_loss: 0.4208\n","Epoch 41/100\n","\u001b[1m302/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6293 - auc: 0.6891 - loss: 0.5691\n","Epoch 41: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6304 - auc: 0.6897 - loss: 0.5687 - val_acc: 0.7641 - val_auc: 0.6580 - val_loss: 0.4529\n","Epoch 42/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6952 - auc: 0.7222 - loss: 0.5345\n","Epoch 42: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6949 - auc: 0.7221 - loss: 0.5348 - val_acc: 0.7590 - val_auc: 0.6536 - val_loss: 0.4379\n","Epoch 43/100\n","\u001b[1m299/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6544 - auc: 0.6999 - loss: 0.5740\n","Epoch 43: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6545 - auc: 0.6996 - loss: 0.5737 - val_acc: 0.7692 - val_auc: 0.6528 - val_loss: 0.4246\n","Epoch 44/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6479 - auc: 0.7299 - loss: 0.5572\n","Epoch 44: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6480 - auc: 0.7298 - loss: 0.5572 - val_acc: 0.7846 - val_auc: 0.6527 - val_loss: 0.4203\n","Epoch 45/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6899 - auc: 0.7307 - loss: 0.5270\n","Epoch 45: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6893 - auc: 0.7304 - loss: 0.5275 - val_acc: 0.7846 - val_auc: 0.6591 - val_loss: 0.4205\n","Epoch 46/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6508 - auc: 0.7086 - loss: 0.5539\n","Epoch 46: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6510 - auc: 0.7087 - loss: 0.5539 - val_acc: 0.7949 - val_auc: 0.6662 - val_loss: 0.4248\n","Epoch 47/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6459 - auc: 0.6811 - loss: 0.5660\n","Epoch 47: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6460 - auc: 0.6813 - loss: 0.5659 - val_acc: 0.7487 - val_auc: 0.6680 - val_loss: 0.4397\n","Epoch 48/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6711 - auc: 0.6970 - loss: 0.5589\n","Epoch 48: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6710 - auc: 0.6970 - loss: 0.5589 - val_acc: 0.7692 - val_auc: 0.6777 - val_loss: 0.4321\n","Epoch 49/100\n","\u001b[1m300/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6874 - auc: 0.7092 - loss: 0.5317\n","Epoch 49: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6871 - auc: 0.7096 - loss: 0.5322 - val_acc: 0.7282 - val_auc: 0.6851 - val_loss: 0.4517\n","Epoch 50/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6828 - auc: 0.6959 - loss: 0.5418\n","Epoch 50: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6823 - auc: 0.6961 - loss: 0.5421 - val_acc: 0.8051 - val_auc: 0.6867 - val_loss: 0.4330\n","Epoch 51/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6607 - auc: 0.7064 - loss: 0.5578\n","Epoch 51: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6608 - auc: 0.7066 - loss: 0.5575 - val_acc: 0.8051 - val_auc: 0.7073 - val_loss: 0.4377\n","Epoch 52/100\n","\u001b[1m299/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6889 - auc: 0.7296 - loss: 0.5359\n","Epoch 52: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6885 - auc: 0.7294 - loss: 0.5361 - val_acc: 0.7846 - val_auc: 0.7218 - val_loss: 0.4479\n","Epoch 53/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6694 - auc: 0.6948 - loss: 0.5506\n","Epoch 53: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6693 - auc: 0.6955 - loss: 0.5503 - val_acc: 0.8051 - val_auc: 0.6969 - val_loss: 0.4489\n","Epoch 54/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6405 - auc: 0.7132 - loss: 0.5569\n","Epoch 54: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6408 - auc: 0.7134 - loss: 0.5566 - val_acc: 0.7846 - val_auc: 0.7487 - val_loss: 0.4586\n","Epoch 55/100\n","\u001b[1m301/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6259 - auc: 0.6967 - loss: 0.5488\n","Epoch 55: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6275 - auc: 0.6975 - loss: 0.5484 - val_acc: 0.7897 - val_auc: 0.7393 - val_loss: 0.4407\n","Epoch 56/100\n","\u001b[1m298/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6880 - auc: 0.7549 - loss: 0.4999\n","Epoch 56: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6874 - auc: 0.7534 - loss: 0.5014 - val_acc: 0.7897 - val_auc: 0.7565 - val_loss: 0.4489\n","Epoch 57/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6518 - auc: 0.7253 - loss: 0.5455\n","Epoch 57: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6520 - auc: 0.7253 - loss: 0.5454 - val_acc: 0.8103 - val_auc: 0.7406 - val_loss: 0.4693\n","Epoch 58/100\n","\u001b[1m299/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6685 - auc: 0.7390 - loss: 0.5147\n","Epoch 58: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6687 - auc: 0.7389 - loss: 0.5154 - val_acc: 0.8667 - val_auc: 0.7783 - val_loss: 0.4582\n","Epoch 59/100\n","\u001b[1m301/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7080 - auc: 0.7494 - loss: 0.5125\n","Epoch 59: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7074 - auc: 0.7491 - loss: 0.5131 - val_acc: 0.8103 - val_auc: 0.7748 - val_loss: 0.4923\n","Epoch 60/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7165 - auc: 0.7299 - loss: 0.5080\n","Epoch 60: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7160 - auc: 0.7300 - loss: 0.5083 - val_acc: 0.8103 - val_auc: 0.7792 - val_loss: 0.4887\n","Epoch 61/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6523 - auc: 0.7044 - loss: 0.5454\n","Epoch 61: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6530 - auc: 0.7050 - loss: 0.5450 - val_acc: 0.8513 - val_auc: 0.7570 - val_loss: 0.4728\n","Epoch 62/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6053 - auc: 0.6964 - loss: 0.5517\n","Epoch 62: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6059 - auc: 0.6969 - loss: 0.5515 - val_acc: 0.8462 - val_auc: 0.7854 - val_loss: 0.4721\n","Epoch 63/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6944 - auc: 0.7652 - loss: 0.5273\n","Epoch 63: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6944 - auc: 0.7650 - loss: 0.5273 - val_acc: 0.7231 - val_auc: 0.7488 - val_loss: 0.4798\n","Epoch 64/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6711 - auc: 0.7489 - loss: 0.5208\n","Epoch 64: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6710 - auc: 0.7486 - loss: 0.5209 - val_acc: 0.8154 - val_auc: 0.7743 - val_loss: 0.4827\n","Epoch 65/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6695 - auc: 0.7431 - loss: 0.5358\n","Epoch 65: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6698 - auc: 0.7431 - loss: 0.5357 - val_acc: 0.8051 - val_auc: 0.7721 - val_loss: 0.4788\n","Epoch 66/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7066 - auc: 0.7305 - loss: 0.5303\n","Epoch 66: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7065 - auc: 0.7308 - loss: 0.5303 - val_acc: 0.7846 - val_auc: 0.7690 - val_loss: 0.5010\n","Epoch 67/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6836 - auc: 0.7330 - loss: 0.5338\n","Epoch 67: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6834 - auc: 0.7332 - loss: 0.5337 - val_acc: 0.8462 - val_auc: 0.7756 - val_loss: 0.4921\n","Epoch 68/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6998 - auc: 0.7549 - loss: 0.5102\n","Epoch 68: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6997 - auc: 0.7548 - loss: 0.5103 - val_acc: 0.8051 - val_auc: 0.7696 - val_loss: 0.4921\n","Epoch 69/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6742 - auc: 0.7405 - loss: 0.5221\n","Epoch 69: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6744 - auc: 0.7406 - loss: 0.5221 - val_acc: 0.7744 - val_auc: 0.7763 - val_loss: 0.4977\n","Epoch 70/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7006 - auc: 0.7670 - loss: 0.5126\n","Epoch 70: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7005 - auc: 0.7668 - loss: 0.5128 - val_acc: 0.8256 - val_auc: 0.7673 - val_loss: 0.5006\n","Epoch 71/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7167 - auc: 0.7719 - loss: 0.5181\n","Epoch 71: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7167 - auc: 0.7718 - loss: 0.5182 - val_acc: 0.8256 - val_auc: 0.7816 - val_loss: 0.4891\n","Epoch 72/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6800 - auc: 0.7435 - loss: 0.5285\n","Epoch 72: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6802 - auc: 0.7436 - loss: 0.5284 - val_acc: 0.7282 - val_auc: 0.7655 - val_loss: 0.5189\n","Epoch 73/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6874 - auc: 0.7056 - loss: 0.5366\n","Epoch 73: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6876 - auc: 0.7066 - loss: 0.5362 - val_acc: 0.8308 - val_auc: 0.7590 - val_loss: 0.5278\n","Epoch 74/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6748 - auc: 0.7228 - loss: 0.5431\n","Epoch 74: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6750 - auc: 0.7231 - loss: 0.5428 - val_acc: 0.8103 - val_auc: 0.7558 - val_loss: 0.5336\n","Epoch 75/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7003 - auc: 0.7362 - loss: 0.5239\n","Epoch 75: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7004 - auc: 0.7365 - loss: 0.5237 - val_acc: 0.8359 - val_auc: 0.7727 - val_loss: 0.5400\n","Epoch 76/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6972 - auc: 0.7643 - loss: 0.4979\n","Epoch 76: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6972 - auc: 0.7642 - loss: 0.4980 - val_acc: 0.8154 - val_auc: 0.7653 - val_loss: 0.5257\n","Epoch 77/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6897 - auc: 0.7280 - loss: 0.5305\n","Epoch 77: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6897 - auc: 0.7281 - loss: 0.5304 - val_acc: 0.8256 - val_auc: 0.7513 - val_loss: 0.5448\n","Epoch 78/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7059 - auc: 0.7641 - loss: 0.4948\n","Epoch 78: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7056 - auc: 0.7638 - loss: 0.4953 - val_acc: 0.8051 - val_auc: 0.7527 - val_loss: 0.5625\n","Epoch 79/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7147 - auc: 0.7666 - loss: 0.5165\n","Epoch 79: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7147 - auc: 0.7662 - loss: 0.5165 - val_acc: 0.8000 - val_auc: 0.7535 - val_loss: 0.5525\n","Epoch 80/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6977 - auc: 0.7424 - loss: 0.5065\n","Epoch 80: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6978 - auc: 0.7426 - loss: 0.5066 - val_acc: 0.8051 - val_auc: 0.7567 - val_loss: 0.5827\n","Epoch 81/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6928 - auc: 0.7550 - loss: 0.5162\n","Epoch 81: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6928 - auc: 0.7549 - loss: 0.5162 - val_acc: 0.8205 - val_auc: 0.7620 - val_loss: 0.5327\n","Epoch 82/100\n","\u001b[1m307/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7233 - auc: 0.7700 - loss: 0.5069\n","Epoch 82: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7229 - auc: 0.7697 - loss: 0.5071 - val_acc: 0.8205 - val_auc: 0.7784 - val_loss: 0.5379\n","Epoch 83/100\n","\u001b[1m303/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7008 - auc: 0.7568 - loss: 0.5173\n","Epoch 83: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7008 - auc: 0.7569 - loss: 0.5172 - val_acc: 0.8205 - val_auc: 0.7676 - val_loss: 0.5447\n","Epoch 84/100\n","\u001b[1m298/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7004 - auc: 0.7576 - loss: 0.5114\n","Epoch 84: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7004 - auc: 0.7574 - loss: 0.5114 - val_acc: 0.8154 - val_auc: 0.7567 - val_loss: 0.5766\n","Epoch 85/100\n","\u001b[1m301/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7138 - auc: 0.7549 - loss: 0.5111\n","Epoch 85: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7136 - auc: 0.7552 - loss: 0.5110 - val_acc: 0.8205 - val_auc: 0.7518 - val_loss: 0.5924\n","Epoch 86/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7332 - auc: 0.7727 - loss: 0.5050\n","Epoch 86: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7328 - auc: 0.7726 - loss: 0.5051 - val_acc: 0.8462 - val_auc: 0.7815 - val_loss: 0.5537\n","Epoch 87/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7270 - auc: 0.7728 - loss: 0.4895\n","Epoch 87: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7266 - auc: 0.7726 - loss: 0.4901 - val_acc: 0.7949 - val_auc: 0.6904 - val_loss: 0.6130\n","Epoch 88/100\n","\u001b[1m306/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6967 - auc: 0.7547 - loss: 0.4910\n","Epoch 88: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6970 - auc: 0.7548 - loss: 0.4912 - val_acc: 0.8051 - val_auc: 0.7472 - val_loss: 0.5888\n","Epoch 89/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6867 - auc: 0.7560 - loss: 0.5297\n","Epoch 89: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6869 - auc: 0.7561 - loss: 0.5291 - val_acc: 0.8205 - val_auc: 0.7487 - val_loss: 0.5816\n","Epoch 90/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6887 - auc: 0.7308 - loss: 0.5263\n","Epoch 90: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6888 - auc: 0.7310 - loss: 0.5261 - val_acc: 0.8051 - val_auc: 0.7662 - val_loss: 0.5914\n","Epoch 91/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7372 - auc: 0.7716 - loss: 0.5051\n","Epoch 91: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7368 - auc: 0.7713 - loss: 0.5052 - val_acc: 0.8051 - val_auc: 0.7506 - val_loss: 0.5974\n","Epoch 92/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7005 - auc: 0.7229 - loss: 0.5119\n","Epoch 92: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7006 - auc: 0.7231 - loss: 0.5118 - val_acc: 0.8103 - val_auc: 0.6799 - val_loss: 0.6491\n","Epoch 93/100\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6950 - auc: 0.7616 - loss: 0.5098\n","Epoch 93: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6950 - auc: 0.7616 - loss: 0.5098 - val_acc: 0.7795 - val_auc: 0.6838 - val_loss: 0.6295\n","Epoch 94/100\n","\u001b[1m308/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7306 - auc: 0.7740 - loss: 0.4906\n","Epoch 94: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7301 - auc: 0.7737 - loss: 0.4908 - val_acc: 0.8051 - val_auc: 0.7100 - val_loss: 0.6580\n","Epoch 95/100\n","\u001b[1m305/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6887 - auc: 0.7637 - loss: 0.5120\n","Epoch 95: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6891 - auc: 0.7638 - loss: 0.5117 - val_acc: 0.8205 - val_auc: 0.7349 - val_loss: 0.6250\n","Epoch 96/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6764 - auc: 0.7315 - loss: 0.5240\n","Epoch 96: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6768 - auc: 0.7318 - loss: 0.5237 - val_acc: 0.7333 - val_auc: 0.7238 - val_loss: 0.6531\n","Epoch 97/100\n","\u001b[1m309/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6822 - auc: 0.7186 - loss: 0.5499\n","Epoch 97: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6824 - auc: 0.7192 - loss: 0.5494 - val_acc: 0.8051 - val_auc: 0.7389 - val_loss: 0.6173\n","Epoch 98/100\n","\u001b[1m302/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7097 - auc: 0.7825 - loss: 0.5041\n","Epoch 98: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7096 - auc: 0.7821 - loss: 0.5041 - val_acc: 0.8000 - val_auc: 0.7518 - val_loss: 0.5339\n","Epoch 99/100\n","\u001b[1m311/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7134 - auc: 0.7541 - loss: 0.5164\n","Epoch 99: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7134 - auc: 0.7542 - loss: 0.5163 - val_acc: 0.8308 - val_auc: 0.6990 - val_loss: 0.6676\n","Epoch 100/100\n","\u001b[1m310/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7265 - auc: 0.7720 - loss: 0.5012\n","Epoch 100: val_loss did not improve from 0.41492\n","\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7264 - auc: 0.7720 - loss: 0.5012 - val_acc: 0.8051 - val_auc: 0.7073 - val_loss: 0.6801\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 4 | TEST ACC=0.6286 | TEST AUC=0.6492 | n=70\n","Confusion matrix:\n"," [[40  0]\n"," [26  4]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.606     1.000     0.755        40\n","           1      1.000     0.133     0.235        30\n","\n","    accuracy                          0.629        70\n","   macro avg      0.803     0.567     0.495        70\n","weighted avg      0.775     0.629     0.532        70\n","\n","\n","--- Fold 5/7 ---\n"," train | ids:   34 | files:  1026 | pos files:  384 | neg files:  642\n","   val | ids:    4 | files:    53 | pos files:    1 | neg files:   52\n","  test | ids:    6 | files:   121 | pos files:   20 | neg files:  101\n","Epoch 1/100\n","\u001b[1m334/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5885 - auc: 0.4717 - loss: 0.6885\n","Epoch 1: val_loss improved from inf to 0.56432, saving model to best_fold_05.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - acc: 0.5893 - auc: 0.4724 - loss: 0.6883 - val_acc: 0.9811 - val_auc: 0.5865 - val_loss: 0.5643\n","Epoch 2/100\n","\u001b[1m340/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6095 - auc: 0.5086 - loss: 0.6702\n","Epoch 2: val_loss improved from 0.56432 to 0.47437, saving model to best_fold_05.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6096 - auc: 0.5087 - loss: 0.6701 - val_acc: 0.9811 - val_auc: 0.5385 - val_loss: 0.4744\n","Epoch 3/100\n","\u001b[1m329/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6291 - auc: 0.5723 - loss: 0.6531\n","Epoch 3: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6291 - auc: 0.5730 - loss: 0.6531 - val_acc: 0.9811 - val_auc: 0.7596 - val_loss: 0.4931\n","Epoch 4/100\n","\u001b[1m340/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6505 - auc: 0.6296 - loss: 0.6289\n","Epoch 4: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6503 - auc: 0.6296 - loss: 0.6290 - val_acc: 0.9811 - val_auc: 0.8077 - val_loss: 0.5613\n","Epoch 5/100\n","\u001b[1m330/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6437 - auc: 0.6833 - loss: 0.6148\n","Epoch 5: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6437 - auc: 0.6832 - loss: 0.6149 - val_acc: 0.6792 - val_auc: 0.8077 - val_loss: 0.6296\n","Epoch 6/100\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6471 - auc: 0.6791 - loss: 0.6035\n","Epoch 6: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6470 - auc: 0.6792 - loss: 0.6035 - val_acc: 0.4906 - val_auc: 0.8173 - val_loss: 0.6775\n","Epoch 7/100\n","\u001b[1m336/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6691 - auc: 0.7403 - loss: 0.5769\n","Epoch 7: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6685 - auc: 0.7396 - loss: 0.5771 - val_acc: 0.4151 - val_auc: 0.8269 - val_loss: 0.7054\n","Epoch 8/100\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6109 - auc: 0.7087 - loss: 0.5868\n","Epoch 8: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6109 - auc: 0.7087 - loss: 0.5867 - val_acc: 0.6415 - val_auc: 0.8173 - val_loss: 0.6211\n","Epoch 9/100\n","\u001b[1m332/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6309 - auc: 0.7032 - loss: 0.5789\n","Epoch 9: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6313 - auc: 0.7038 - loss: 0.5787 - val_acc: 0.4151 - val_auc: 0.8173 - val_loss: 0.6973\n","Epoch 10/100\n","\u001b[1m336/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6544 - auc: 0.7175 - loss: 0.5683\n","Epoch 10: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6541 - auc: 0.7173 - loss: 0.5683 - val_acc: 0.4151 - val_auc: 0.8365 - val_loss: 0.6718\n","Epoch 11/100\n","\u001b[1m338/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6341 - auc: 0.7109 - loss: 0.5690\n","Epoch 11: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6341 - auc: 0.7110 - loss: 0.5690 - val_acc: 0.6415 - val_auc: 0.8173 - val_loss: 0.6184\n","Epoch 12/100\n","\u001b[1m339/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6322 - auc: 0.6966 - loss: 0.5792\n","Epoch 12: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6324 - auc: 0.6969 - loss: 0.5790 - val_acc: 0.2453 - val_auc: 0.8365 - val_loss: 0.7339\n","Epoch 13/100\n","\u001b[1m335/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6502 - auc: 0.7290 - loss: 0.5593\n","Epoch 13: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6501 - auc: 0.7289 - loss: 0.5595 - val_acc: 0.1887 - val_auc: 0.8558 - val_loss: 0.7472\n","Epoch 14/100\n","\u001b[1m337/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6629 - auc: 0.7564 - loss: 0.5311\n","Epoch 14: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6626 - auc: 0.7558 - loss: 0.5316 - val_acc: 0.2264 - val_auc: 0.8365 - val_loss: 0.7317\n","Epoch 15/100\n","\u001b[1m336/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6508 - auc: 0.7339 - loss: 0.5438\n","Epoch 15: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6506 - auc: 0.7337 - loss: 0.5440 - val_acc: 0.2453 - val_auc: 0.8365 - val_loss: 0.7222\n","Epoch 16/100\n","\u001b[1m335/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6916 - auc: 0.7681 - loss: 0.5217\n","Epoch 16: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6905 - auc: 0.7669 - loss: 0.5225 - val_acc: 0.2453 - val_auc: 0.8365 - val_loss: 0.7151\n","Epoch 17/100\n","\u001b[1m336/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6277 - auc: 0.6999 - loss: 0.5709\n","Epoch 17: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6279 - auc: 0.7003 - loss: 0.5707 - val_acc: 0.4528 - val_auc: 0.8077 - val_loss: 0.6608\n","Epoch 18/100\n","\u001b[1m336/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6642 - auc: 0.7565 - loss: 0.5399\n","Epoch 18: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6641 - auc: 0.7560 - loss: 0.5402 - val_acc: 0.1321 - val_auc: 0.8365 - val_loss: 0.7437\n","Epoch 19/100\n","\u001b[1m338/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6477 - auc: 0.7265 - loss: 0.5639\n","Epoch 19: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6478 - auc: 0.7266 - loss: 0.5638 - val_acc: 0.5849 - val_auc: 0.8173 - val_loss: 0.6713\n","Epoch 20/100\n","\u001b[1m338/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6438 - auc: 0.7153 - loss: 0.5720\n","Epoch 20: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6440 - auc: 0.7155 - loss: 0.5717 - val_acc: 0.2453 - val_auc: 0.8173 - val_loss: 0.7275\n","Epoch 21/100\n","\u001b[1m332/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6435 - auc: 0.7244 - loss: 0.5463\n","Epoch 21: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6437 - auc: 0.7248 - loss: 0.5463 - val_acc: 0.5283 - val_auc: 0.8173 - val_loss: 0.6709\n","Epoch 22/100\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6805 - auc: 0.7588 - loss: 0.5296\n","Epoch 22: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6805 - auc: 0.7588 - loss: 0.5297 - val_acc: 0.3208 - val_auc: 0.8269 - val_loss: 0.6968\n","Epoch 23/100\n","\u001b[1m340/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6701 - auc: 0.7319 - loss: 0.5325\n","Epoch 23: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6701 - auc: 0.7320 - loss: 0.5326 - val_acc: 0.5849 - val_auc: 0.8077 - val_loss: 0.6484\n","Epoch 24/100\n","\u001b[1m338/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6596 - auc: 0.7250 - loss: 0.5511\n","Epoch 24: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6595 - auc: 0.7252 - loss: 0.5509 - val_acc: 0.2453 - val_auc: 0.8173 - val_loss: 0.7296\n","Epoch 25/100\n","\u001b[1m335/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6571 - auc: 0.7375 - loss: 0.5355\n","Epoch 25: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6569 - auc: 0.7373 - loss: 0.5357 - val_acc: 0.6038 - val_auc: 0.8173 - val_loss: 0.6719\n","Epoch 26/100\n","\u001b[1m333/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6649 - auc: 0.7567 - loss: 0.5323\n","Epoch 26: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6647 - auc: 0.7565 - loss: 0.5325 - val_acc: 0.6226 - val_auc: 0.8173 - val_loss: 0.6362\n","Epoch 27/100\n","\u001b[1m339/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6284 - auc: 0.7095 - loss: 0.5556\n","Epoch 27: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6286 - auc: 0.7097 - loss: 0.5555 - val_acc: 0.2642 - val_auc: 0.8269 - val_loss: 0.7214\n","Epoch 28/100\n","\u001b[1m337/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6782 - auc: 0.7451 - loss: 0.5370\n","Epoch 28: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6781 - auc: 0.7452 - loss: 0.5371 - val_acc: 0.2264 - val_auc: 0.8173 - val_loss: 0.7457\n","Epoch 29/100\n","\u001b[1m336/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6471 - auc: 0.7140 - loss: 0.5623\n","Epoch 29: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6474 - auc: 0.7146 - loss: 0.5618 - val_acc: 0.4528 - val_auc: 0.8269 - val_loss: 0.6908\n","Epoch 30/100\n","\u001b[1m333/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6234 - auc: 0.7253 - loss: 0.5398\n","Epoch 30: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6240 - auc: 0.7257 - loss: 0.5397 - val_acc: 0.6038 - val_auc: 0.8269 - val_loss: 0.6650\n","Epoch 31/100\n","\u001b[1m341/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6857 - auc: 0.7773 - loss: 0.5207\n","Epoch 31: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6855 - auc: 0.7771 - loss: 0.5208 - val_acc: 0.2453 - val_auc: 0.8269 - val_loss: 0.7310\n","Epoch 32/100\n","\u001b[1m336/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6444 - auc: 0.7285 - loss: 0.5402\n","Epoch 32: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6444 - auc: 0.7285 - loss: 0.5401 - val_acc: 0.3585 - val_auc: 0.8173 - val_loss: 0.7206\n","Epoch 33/100\n","\u001b[1m334/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6462 - auc: 0.7441 - loss: 0.5330\n","Epoch 33: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6466 - auc: 0.7443 - loss: 0.5330 - val_acc: 0.1887 - val_auc: 0.8269 - val_loss: 0.7546\n","Epoch 34/100\n","\u001b[1m338/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6672 - auc: 0.7669 - loss: 0.5189\n","Epoch 34: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6671 - auc: 0.7666 - loss: 0.5191 - val_acc: 0.3585 - val_auc: 0.8173 - val_loss: 0.7191\n","Epoch 35/100\n","\u001b[1m336/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6865 - auc: 0.7532 - loss: 0.5328\n","Epoch 35: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6863 - auc: 0.7532 - loss: 0.5329 - val_acc: 0.3585 - val_auc: 0.8077 - val_loss: 0.6960\n","Epoch 36/100\n","\u001b[1m335/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6456 - auc: 0.7361 - loss: 0.5389\n","Epoch 36: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6459 - auc: 0.7363 - loss: 0.5388 - val_acc: 0.6981 - val_auc: 0.8173 - val_loss: 0.6554\n","Epoch 37/100\n","\u001b[1m339/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6853 - auc: 0.7711 - loss: 0.5095\n","Epoch 37: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6853 - auc: 0.7709 - loss: 0.5097 - val_acc: 0.2453 - val_auc: 0.8077 - val_loss: 0.7316\n","Epoch 38/100\n","\u001b[1m337/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7045 - auc: 0.7889 - loss: 0.5102\n","Epoch 38: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7042 - auc: 0.7883 - loss: 0.5106 - val_acc: 0.4528 - val_auc: 0.7981 - val_loss: 0.6836\n","Epoch 39/100\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7115 - auc: 0.7766 - loss: 0.5016\n","Epoch 39: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7114 - auc: 0.7765 - loss: 0.5017 - val_acc: 0.1509 - val_auc: 0.7981 - val_loss: 0.7785\n","Epoch 40/100\n","\u001b[1m340/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6578 - auc: 0.7554 - loss: 0.5351\n","Epoch 40: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6579 - auc: 0.7555 - loss: 0.5350 - val_acc: 0.8868 - val_auc: 0.8462 - val_loss: 0.6180\n","Epoch 41/100\n","\u001b[1m335/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7043 - auc: 0.7513 - loss: 0.5264\n","Epoch 41: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7039 - auc: 0.7516 - loss: 0.5264 - val_acc: 0.3019 - val_auc: 0.7981 - val_loss: 0.6984\n","Epoch 42/100\n","\u001b[1m332/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6866 - auc: 0.7618 - loss: 0.5170\n","Epoch 42: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6863 - auc: 0.7618 - loss: 0.5173 - val_acc: 0.1698 - val_auc: 0.6731 - val_loss: 0.7504\n","Epoch 43/100\n","\u001b[1m336/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7203 - auc: 0.7920 - loss: 0.5030\n","Epoch 43: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7198 - auc: 0.7917 - loss: 0.5033 - val_acc: 0.4528 - val_auc: 0.5577 - val_loss: 0.6611\n","Epoch 44/100\n","\u001b[1m334/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6760 - auc: 0.7625 - loss: 0.5243\n","Epoch 44: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6766 - auc: 0.7629 - loss: 0.5241 - val_acc: 0.1887 - val_auc: 0.5962 - val_loss: 0.7523\n","Epoch 45/100\n","\u001b[1m338/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6979 - auc: 0.7918 - loss: 0.5051\n","Epoch 45: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6978 - auc: 0.7915 - loss: 0.5052 - val_acc: 0.9434 - val_auc: 0.6442 - val_loss: 0.5818\n","Epoch 46/100\n","\u001b[1m338/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7021 - auc: 0.7792 - loss: 0.5210\n","Epoch 46: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7020 - auc: 0.7791 - loss: 0.5210 - val_acc: 0.0943 - val_auc: 0.3942 - val_loss: 0.8774\n","Epoch 47/100\n","\u001b[1m340/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7054 - auc: 0.7903 - loss: 0.5009\n","Epoch 47: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7053 - auc: 0.7902 - loss: 0.5011 - val_acc: 0.9623 - val_auc: 0.7308 - val_loss: 0.5821\n","Epoch 48/100\n","\u001b[1m333/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6953 - auc: 0.7668 - loss: 0.5222\n","Epoch 48: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6953 - auc: 0.7670 - loss: 0.5220 - val_acc: 0.9811 - val_auc: 0.5481 - val_loss: 0.5721\n","Epoch 49/100\n","\u001b[1m340/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7099 - auc: 0.7998 - loss: 0.4920\n","Epoch 49: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7099 - auc: 0.7997 - loss: 0.4922 - val_acc: 0.9811 - val_auc: 0.4519 - val_loss: 0.5451\n","Epoch 50/100\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6940 - auc: 0.7737 - loss: 0.5169\n","Epoch 50: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6940 - auc: 0.7737 - loss: 0.5169 - val_acc: 0.9623 - val_auc: 0.6250 - val_loss: 0.5877\n","Epoch 51/100\n","\u001b[1m337/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6899 - auc: 0.7626 - loss: 0.5195\n","Epoch 51: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6903 - auc: 0.7629 - loss: 0.5194 - val_acc: 0.3019 - val_auc: 0.2981 - val_loss: 0.7457\n","Epoch 52/100\n","\u001b[1m338/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6918 - auc: 0.7837 - loss: 0.5134\n","Epoch 52: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6919 - auc: 0.7836 - loss: 0.5133 - val_acc: 0.8113 - val_auc: 0.3558 - val_loss: 0.6367\n","Epoch 53/100\n","\u001b[1m340/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6965 - auc: 0.7706 - loss: 0.5255\n","Epoch 53: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6966 - auc: 0.7708 - loss: 0.5253 - val_acc: 0.3019 - val_auc: 0.2885 - val_loss: 0.8222\n","Epoch 54/100\n","\u001b[1m340/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7042 - auc: 0.7902 - loss: 0.5063\n","Epoch 54: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7043 - auc: 0.7902 - loss: 0.5062 - val_acc: 0.3208 - val_auc: 0.2981 - val_loss: 0.7424\n","Epoch 55/100\n","\u001b[1m332/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7174 - auc: 0.7875 - loss: 0.5019\n","Epoch 55: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7171 - auc: 0.7873 - loss: 0.5021 - val_acc: 0.1132 - val_auc: 0.2115 - val_loss: 0.9284\n","Epoch 56/100\n","\u001b[1m340/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7082 - auc: 0.7974 - loss: 0.5138\n","Epoch 56: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7082 - auc: 0.7973 - loss: 0.5138 - val_acc: 0.9057 - val_auc: 0.4231 - val_loss: 0.5988\n","Epoch 57/100\n","\u001b[1m337/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7204 - auc: 0.7973 - loss: 0.4934\n","Epoch 57: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7202 - auc: 0.7970 - loss: 0.4936 - val_acc: 0.9057 - val_auc: 0.3365 - val_loss: 0.5748\n","Epoch 58/100\n","\u001b[1m332/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7114 - auc: 0.7922 - loss: 0.4975\n","Epoch 58: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7112 - auc: 0.7918 - loss: 0.4977 - val_acc: 0.6226 - val_auc: 0.4808 - val_loss: 0.6536\n","Epoch 59/100\n","\u001b[1m334/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6944 - auc: 0.7768 - loss: 0.5201\n","Epoch 59: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6947 - auc: 0.7772 - loss: 0.5195 - val_acc: 0.3019 - val_auc: 0.2115 - val_loss: 0.7894\n","Epoch 60/100\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6973 - auc: 0.7881 - loss: 0.5007\n","Epoch 60: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6974 - auc: 0.7881 - loss: 0.5007 - val_acc: 0.2642 - val_auc: 0.2500 - val_loss: 0.8804\n","Epoch 61/100\n","\u001b[1m334/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7246 - auc: 0.8073 - loss: 0.4953\n","Epoch 61: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7242 - auc: 0.8069 - loss: 0.4955 - val_acc: 0.6226 - val_auc: 0.3173 - val_loss: 0.7002\n","Epoch 62/100\n","\u001b[1m338/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6930 - auc: 0.7735 - loss: 0.5239\n","Epoch 62: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6933 - auc: 0.7736 - loss: 0.5236 - val_acc: 0.4151 - val_auc: 0.3173 - val_loss: 0.7232\n","Epoch 63/100\n","\u001b[1m340/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7186 - auc: 0.8057 - loss: 0.4906\n","Epoch 63: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7186 - auc: 0.8055 - loss: 0.4907 - val_acc: 0.8113 - val_auc: 0.3077 - val_loss: 0.6295\n","Epoch 64/100\n","\u001b[1m340/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7371 - auc: 0.7932 - loss: 0.4966\n","Epoch 64: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7370 - auc: 0.7932 - loss: 0.4967 - val_acc: 0.9811 - val_auc: 0.4231 - val_loss: 0.5631\n","Epoch 65/100\n","\u001b[1m336/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7259 - auc: 0.7907 - loss: 0.4779\n","Epoch 65: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7258 - auc: 0.7910 - loss: 0.4782 - val_acc: 0.1321 - val_auc: 0.3365 - val_loss: 0.9243\n","Epoch 66/100\n","\u001b[1m332/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7040 - auc: 0.7792 - loss: 0.5155\n","Epoch 66: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7043 - auc: 0.7797 - loss: 0.5151 - val_acc: 0.8868 - val_auc: 0.3846 - val_loss: 0.5910\n","Epoch 67/100\n","\u001b[1m332/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7118 - auc: 0.7962 - loss: 0.4929\n","Epoch 67: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7117 - auc: 0.7962 - loss: 0.4931 - val_acc: 0.9811 - val_auc: 0.7019 - val_loss: 0.5547\n","Epoch 68/100\n","\u001b[1m333/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7406 - auc: 0.8018 - loss: 0.4881\n","Epoch 68: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7400 - auc: 0.8016 - loss: 0.4884 - val_acc: 0.3774 - val_auc: 0.3558 - val_loss: 0.7729\n","Epoch 69/100\n","\u001b[1m338/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7087 - auc: 0.7890 - loss: 0.5084\n","Epoch 69: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7089 - auc: 0.7891 - loss: 0.5082 - val_acc: 0.5094 - val_auc: 0.4327 - val_loss: 0.6890\n","Epoch 70/100\n","\u001b[1m332/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7231 - auc: 0.7696 - loss: 0.5080\n","Epoch 70: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7231 - auc: 0.7703 - loss: 0.5077 - val_acc: 0.4151 - val_auc: 0.4038 - val_loss: 0.7413\n","Epoch 71/100\n","\u001b[1m336/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7535 - auc: 0.8200 - loss: 0.4790\n","Epoch 71: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7528 - auc: 0.8195 - loss: 0.4795 - val_acc: 0.9811 - val_auc: 0.5673 - val_loss: 0.5655\n","Epoch 72/100\n","\u001b[1m329/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7057 - auc: 0.7780 - loss: 0.5152\n","Epoch 72: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7063 - auc: 0.7789 - loss: 0.5145 - val_acc: 0.3774 - val_auc: 0.3846 - val_loss: 0.7930\n","Epoch 73/100\n","\u001b[1m338/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7141 - auc: 0.7770 - loss: 0.5173\n","Epoch 73: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7143 - auc: 0.7772 - loss: 0.5170 - val_acc: 0.3396 - val_auc: 0.4712 - val_loss: 0.7623\n","Epoch 74/100\n","\u001b[1m332/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6849 - auc: 0.7872 - loss: 0.4964\n","Epoch 74: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6855 - auc: 0.7874 - loss: 0.4963 - val_acc: 0.9434 - val_auc: 0.4712 - val_loss: 0.5426\n","Epoch 75/100\n","\u001b[1m332/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7398 - auc: 0.7999 - loss: 0.4938\n","Epoch 75: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7395 - auc: 0.8000 - loss: 0.4937 - val_acc: 0.0943 - val_auc: 0.4038 - val_loss: 1.1015\n","Epoch 76/100\n","\u001b[1m340/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6895 - auc: 0.8080 - loss: 0.4732\n","Epoch 76: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6896 - auc: 0.8079 - loss: 0.4734 - val_acc: 0.9811 - val_auc: 0.7115 - val_loss: 0.5358\n","Epoch 77/100\n","\u001b[1m341/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7182 - auc: 0.7902 - loss: 0.4980\n","Epoch 77: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7182 - auc: 0.7902 - loss: 0.4980 - val_acc: 0.9811 - val_auc: 0.4904 - val_loss: 0.5437\n","Epoch 78/100\n","\u001b[1m331/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7110 - auc: 0.8100 - loss: 0.4883\n","Epoch 78: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7110 - auc: 0.8094 - loss: 0.4886 - val_acc: 0.9811 - val_auc: 0.5673 - val_loss: 0.5887\n","Epoch 79/100\n","\u001b[1m334/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7088 - auc: 0.8102 - loss: 0.4902\n","Epoch 79: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7090 - auc: 0.8100 - loss: 0.4904 - val_acc: 0.5094 - val_auc: 0.3077 - val_loss: 0.6959\n","Epoch 80/100\n","\u001b[1m336/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7118 - auc: 0.7873 - loss: 0.4982\n","Epoch 80: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7120 - auc: 0.7875 - loss: 0.4982 - val_acc: 0.3019 - val_auc: 0.3077 - val_loss: 0.7694\n","Epoch 81/100\n","\u001b[1m335/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7104 - auc: 0.8038 - loss: 0.4946\n","Epoch 81: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7106 - auc: 0.8038 - loss: 0.4945 - val_acc: 0.5849 - val_auc: 0.3269 - val_loss: 0.6955\n","Epoch 82/100\n","\u001b[1m337/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6978 - auc: 0.7988 - loss: 0.5068\n","Epoch 82: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6980 - auc: 0.7987 - loss: 0.5067 - val_acc: 0.6038 - val_auc: 0.5577 - val_loss: 0.6710\n","Epoch 83/100\n","\u001b[1m335/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7412 - auc: 0.8217 - loss: 0.4532\n","Epoch 83: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7405 - auc: 0.8210 - loss: 0.4542 - val_acc: 0.8302 - val_auc: 0.4231 - val_loss: 0.6205\n","Epoch 84/100\n","\u001b[1m336/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7394 - auc: 0.8179 - loss: 0.4748\n","Epoch 84: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7390 - auc: 0.8176 - loss: 0.4751 - val_acc: 0.4528 - val_auc: 0.3654 - val_loss: 0.7226\n","Epoch 85/100\n","\u001b[1m336/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7289 - auc: 0.7960 - loss: 0.4889\n","Epoch 85: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7290 - auc: 0.7963 - loss: 0.4888 - val_acc: 0.9811 - val_auc: 0.4327 - val_loss: 0.5336\n","Epoch 86/100\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7215 - auc: 0.8067 - loss: 0.4871\n","Epoch 86: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7215 - auc: 0.8067 - loss: 0.4871 - val_acc: 0.4906 - val_auc: 0.3462 - val_loss: 0.7208\n","Epoch 87/100\n","\u001b[1m333/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7446 - auc: 0.7980 - loss: 0.4915\n","Epoch 87: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7442 - auc: 0.7982 - loss: 0.4914 - val_acc: 0.3774 - val_auc: 0.3846 - val_loss: 0.8317\n","Epoch 88/100\n","\u001b[1m330/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7181 - auc: 0.7907 - loss: 0.4968\n","Epoch 88: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7188 - auc: 0.7912 - loss: 0.4965 - val_acc: 0.8679 - val_auc: 0.6442 - val_loss: 0.5581\n","Epoch 89/100\n","\u001b[1m338/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7340 - auc: 0.7938 - loss: 0.4991\n","Epoch 89: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7339 - auc: 0.7938 - loss: 0.4991 - val_acc: 0.8491 - val_auc: 0.5769 - val_loss: 0.5989\n","Epoch 90/100\n","\u001b[1m337/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7095 - auc: 0.8032 - loss: 0.4947\n","Epoch 90: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7095 - auc: 0.8031 - loss: 0.4947 - val_acc: 0.5283 - val_auc: 0.5673 - val_loss: 0.7010\n","Epoch 91/100\n","\u001b[1m335/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7275 - auc: 0.7981 - loss: 0.4938\n","Epoch 91: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7273 - auc: 0.7982 - loss: 0.4937 - val_acc: 0.4717 - val_auc: 0.3750 - val_loss: 0.7207\n","Epoch 92/100\n","\u001b[1m330/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7200 - auc: 0.7910 - loss: 0.5106\n","Epoch 92: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7201 - auc: 0.7913 - loss: 0.5099 - val_acc: 0.6038 - val_auc: 0.4135 - val_loss: 0.6874\n","Epoch 93/100\n","\u001b[1m335/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7027 - auc: 0.7824 - loss: 0.5062\n","Epoch 93: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7031 - auc: 0.7830 - loss: 0.5058 - val_acc: 0.8302 - val_auc: 0.4327 - val_loss: 0.6001\n","Epoch 94/100\n","\u001b[1m329/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7332 - auc: 0.8185 - loss: 0.4697\n","Epoch 94: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7329 - auc: 0.8183 - loss: 0.4704 - val_acc: 0.7925 - val_auc: 0.4038 - val_loss: 0.6284\n","Epoch 95/100\n","\u001b[1m339/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7438 - auc: 0.8233 - loss: 0.4749\n","Epoch 95: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7436 - auc: 0.8231 - loss: 0.4750 - val_acc: 0.6981 - val_auc: 0.4519 - val_loss: 0.6774\n","Epoch 96/100\n","\u001b[1m340/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7409 - auc: 0.8052 - loss: 0.4804\n","Epoch 96: val_loss did not improve from 0.47437\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7407 - auc: 0.8053 - loss: 0.4804 - val_acc: 0.2830 - val_auc: 0.2788 - val_loss: 0.9033\n","Epoch 97/100\n","\u001b[1m333/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7194 - auc: 0.7935 - loss: 0.4932\n","Epoch 97: val_loss improved from 0.47437 to 0.47059, saving model to best_fold_05.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7197 - auc: 0.7940 - loss: 0.4930 - val_acc: 0.9811 - val_auc: 0.9038 - val_loss: 0.4706\n","Epoch 98/100\n","\u001b[1m339/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7193 - auc: 0.7957 - loss: 0.4975\n","Epoch 98: val_loss did not improve from 0.47059\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7192 - auc: 0.7957 - loss: 0.4974 - val_acc: 0.7547 - val_auc: 0.8173 - val_loss: 0.6505\n","Epoch 99/100\n","\u001b[1m337/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7190 - auc: 0.7910 - loss: 0.4847\n","Epoch 99: val_loss did not improve from 0.47059\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7190 - auc: 0.7913 - loss: 0.4847 - val_acc: 0.2830 - val_auc: 0.5288 - val_loss: 0.9316\n","Epoch 100/100\n","\u001b[1m339/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7089 - auc: 0.7957 - loss: 0.5029\n","Epoch 100: val_loss did not improve from 0.47059\n","\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7091 - auc: 0.7960 - loss: 0.5027 - val_acc: 0.0755 - val_auc: 0.5288 - val_loss: 1.1753\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 5 | TEST ACC=0.7851 | TEST AUC=0.3673 | n=121\n","Confusion matrix:\n"," [[95  6]\n"," [20  0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.826     0.941     0.880       101\n","           1      0.000     0.000     0.000        20\n","\n","    accuracy                          0.785       121\n","   macro avg      0.413     0.470     0.440       121\n","weighted avg      0.690     0.785     0.734       121\n","\n","\n","--- Fold 6/7 ---\n"," train | ids:   34 | files:   862 | pos files:  307 | neg files:  555\n","   val | ids:    4 | files:   131 | pos files:    1 | neg files:  130\n","  test | ids:    6 | files:   207 | pos files:   97 | neg files:  110\n","Epoch 1/100\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - acc: 0.5301 - auc: 0.5345 - loss: 0.6894\n","Epoch 1: val_loss improved from inf to 0.54495, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 30ms/step - acc: 0.5304 - auc: 0.5344 - loss: 0.6894 - val_acc: 0.9924 - val_auc: 0.2923 - val_loss: 0.5449\n","Epoch 2/100\n","\u001b[1m280/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6236 - auc: 0.4472 - loss: 0.6671\n","Epoch 2: val_loss improved from 0.54495 to 0.41893, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6244 - auc: 0.4486 - loss: 0.6667 - val_acc: 0.9924 - val_auc: 0.4192 - val_loss: 0.4189\n","Epoch 3/100\n","\u001b[1m286/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6494 - auc: 0.4713 - loss: 0.6510\n","Epoch 3: val_loss did not improve from 0.41893\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6494 - auc: 0.4713 - loss: 0.6510 - val_acc: 0.9924 - val_auc: 0.7115 - val_loss: 0.4738\n","Epoch 4/100\n","\u001b[1m286/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6399 - auc: 0.4644 - loss: 0.6568\n","Epoch 4: val_loss did not improve from 0.41893\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6399 - auc: 0.4647 - loss: 0.6567 - val_acc: 0.9924 - val_auc: 0.7577 - val_loss: 0.4631\n","Epoch 5/100\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6176 - auc: 0.4899 - loss: 0.6682\n","Epoch 5: val_loss did not improve from 0.41893\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6177 - auc: 0.4900 - loss: 0.6681 - val_acc: 0.9924 - val_auc: 0.8538 - val_loss: 0.4360\n","Epoch 6/100\n","\u001b[1m277/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6441 - auc: 0.5342 - loss: 0.6486\n","Epoch 6: val_loss did not improve from 0.41893\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6442 - auc: 0.5344 - loss: 0.6485 - val_acc: 0.9924 - val_auc: 0.8962 - val_loss: 0.4240\n","Epoch 7/100\n","\u001b[1m277/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6362 - auc: 0.5620 - loss: 0.6493\n","Epoch 7: val_loss did not improve from 0.41893\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6366 - auc: 0.5618 - loss: 0.6492 - val_acc: 0.9924 - val_auc: 0.9115 - val_loss: 0.4354\n","Epoch 8/100\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6524 - auc: 0.5678 - loss: 0.6361\n","Epoch 8: val_loss improved from 0.41893 to 0.39588, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6523 - auc: 0.5679 - loss: 0.6361 - val_acc: 0.9924 - val_auc: 0.9538 - val_loss: 0.3959\n","Epoch 9/100\n","\u001b[1m279/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6554 - auc: 0.5672 - loss: 0.6299\n","Epoch 9: val_loss improved from 0.39588 to 0.36749, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.6550 - auc: 0.5680 - loss: 0.6300 - val_acc: 0.9924 - val_auc: 0.9577 - val_loss: 0.3675\n","Epoch 10/100\n","\u001b[1m284/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6090 - auc: 0.6214 - loss: 0.6315\n","Epoch 10: val_loss improved from 0.36749 to 0.26657, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6096 - auc: 0.6215 - loss: 0.6311 - val_acc: 0.9924 - val_auc: 0.9346 - val_loss: 0.2666\n","Epoch 11/100\n","\u001b[1m277/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6509 - auc: 0.6249 - loss: 0.6029\n","Epoch 11: val_loss did not improve from 0.26657\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6506 - auc: 0.6250 - loss: 0.6028 - val_acc: 0.9924 - val_auc: 0.9577 - val_loss: 0.3150\n","Epoch 12/100\n","\u001b[1m287/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6438 - auc: 0.6335 - loss: 0.5916\n","Epoch 12: val_loss did not improve from 0.26657\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6438 - auc: 0.6334 - loss: 0.5915 - val_acc: 0.9924 - val_auc: 0.8577 - val_loss: 0.3470\n","Epoch 13/100\n","\u001b[1m285/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6302 - auc: 0.6517 - loss: 0.5781\n","Epoch 13: val_loss did not improve from 0.26657\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6304 - auc: 0.6511 - loss: 0.5782 - val_acc: 0.9924 - val_auc: 0.9115 - val_loss: 0.2728\n","Epoch 14/100\n","\u001b[1m276/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6612 - auc: 0.6295 - loss: 0.5632\n","Epoch 14: val_loss did not improve from 0.26657\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6605 - auc: 0.6295 - loss: 0.5637 - val_acc: 0.9924 - val_auc: 0.8962 - val_loss: 0.2732\n","Epoch 15/100\n","\u001b[1m287/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6436 - auc: 0.6582 - loss: 0.5642\n","Epoch 15: val_loss improved from 0.26657 to 0.20615, saving model to best_fold_06.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6436 - auc: 0.6581 - loss: 0.5643 - val_acc: 0.9924 - val_auc: 0.9346 - val_loss: 0.2061\n","Epoch 16/100\n","\u001b[1m275/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6515 - auc: 0.6720 - loss: 0.5459\n","Epoch 16: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6511 - auc: 0.6702 - loss: 0.5470 - val_acc: 0.9924 - val_auc: 0.8385 - val_loss: 0.2458\n","Epoch 17/100\n","\u001b[1m275/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6561 - auc: 0.6695 - loss: 0.5471\n","Epoch 17: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6555 - auc: 0.6685 - loss: 0.5485 - val_acc: 0.9924 - val_auc: 0.8923 - val_loss: 0.2524\n","Epoch 18/100\n","\u001b[1m283/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6332 - auc: 0.6369 - loss: 0.5875\n","Epoch 18: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6334 - auc: 0.6370 - loss: 0.5871 - val_acc: 0.9924 - val_auc: 0.7692 - val_loss: 0.2580\n","Epoch 19/100\n","\u001b[1m275/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6634 - auc: 0.6436 - loss: 0.5587\n","Epoch 19: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6625 - auc: 0.6440 - loss: 0.5594 - val_acc: 0.9924 - val_auc: 0.9115 - val_loss: 0.2307\n","Epoch 20/100\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6531 - auc: 0.6501 - loss: 0.5659\n","Epoch 20: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6531 - auc: 0.6500 - loss: 0.5659 - val_acc: 0.9924 - val_auc: 0.7500 - val_loss: 0.2634\n","Epoch 21/100\n","\u001b[1m281/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6455 - auc: 0.6392 - loss: 0.5748\n","Epoch 21: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6454 - auc: 0.6395 - loss: 0.5748 - val_acc: 0.9924 - val_auc: 0.7962 - val_loss: 0.2466\n","Epoch 22/100\n","\u001b[1m276/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6505 - auc: 0.6409 - loss: 0.5511\n","Epoch 22: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6502 - auc: 0.6406 - loss: 0.5519 - val_acc: 0.9924 - val_auc: 0.8846 - val_loss: 0.2506\n","Epoch 23/100\n","\u001b[1m275/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6694 - auc: 0.6348 - loss: 0.5467\n","Epoch 23: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6682 - auc: 0.6361 - loss: 0.5477 - val_acc: 0.9924 - val_auc: 0.7654 - val_loss: 0.2574\n","Epoch 24/100\n","\u001b[1m276/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6294 - auc: 0.6315 - loss: 0.5790\n","Epoch 24: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6301 - auc: 0.6324 - loss: 0.5786 - val_acc: 0.9924 - val_auc: 0.8385 - val_loss: 0.2458\n","Epoch 25/100\n","\u001b[1m275/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6555 - auc: 0.6642 - loss: 0.5597\n","Epoch 25: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6549 - auc: 0.6644 - loss: 0.5602 - val_acc: 0.9924 - val_auc: 0.8192 - val_loss: 0.2272\n","Epoch 26/100\n","\u001b[1m274/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6502 - auc: 0.6181 - loss: 0.5793\n","Epoch 26: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6498 - auc: 0.6205 - loss: 0.5789 - val_acc: 0.9924 - val_auc: 0.6846 - val_loss: 0.2717\n","Epoch 27/100\n","\u001b[1m276/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6360 - auc: 0.6821 - loss: 0.5651\n","Epoch 27: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6362 - auc: 0.6819 - loss: 0.5653 - val_acc: 0.9924 - val_auc: 0.6846 - val_loss: 0.2745\n","Epoch 28/100\n","\u001b[1m281/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6484 - auc: 0.6675 - loss: 0.5723\n","Epoch 28: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6483 - auc: 0.6681 - loss: 0.5722 - val_acc: 0.9924 - val_auc: 0.7808 - val_loss: 0.2322\n","Epoch 29/100\n","\u001b[1m279/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6431 - auc: 0.6632 - loss: 0.5828\n","Epoch 29: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6431 - auc: 0.6641 - loss: 0.5822 - val_acc: 0.9924 - val_auc: 0.7846 - val_loss: 0.2293\n","Epoch 30/100\n","\u001b[1m278/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6283 - auc: 0.6779 - loss: 0.5717\n","Epoch 30: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6289 - auc: 0.6786 - loss: 0.5716 - val_acc: 0.9924 - val_auc: 0.7385 - val_loss: 0.2469\n","Epoch 31/100\n","\u001b[1m287/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6449 - auc: 0.6854 - loss: 0.5842\n","Epoch 31: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6449 - auc: 0.6854 - loss: 0.5841 - val_acc: 0.9924 - val_auc: 0.7115 - val_loss: 0.2537\n","Epoch 32/100\n","\u001b[1m280/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6719 - auc: 0.6735 - loss: 0.5568\n","Epoch 32: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6711 - auc: 0.6741 - loss: 0.5571 - val_acc: 0.9924 - val_auc: 0.6769 - val_loss: 0.2588\n","Epoch 33/100\n","\u001b[1m287/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6190 - auc: 0.7387 - loss: 0.5566\n","Epoch 33: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6191 - auc: 0.7385 - loss: 0.5566 - val_acc: 0.9924 - val_auc: 0.7885 - val_loss: 0.2216\n","Epoch 34/100\n","\u001b[1m276/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6441 - auc: 0.6968 - loss: 0.5603\n","Epoch 34: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6440 - auc: 0.6971 - loss: 0.5606 - val_acc: 0.9924 - val_auc: 0.6923 - val_loss: 0.2437\n","Epoch 35/100\n","\u001b[1m279/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6461 - auc: 0.7168 - loss: 0.5715\n","Epoch 35: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6462 - auc: 0.7168 - loss: 0.5713 - val_acc: 0.9924 - val_auc: 0.6885 - val_loss: 0.2435\n","Epoch 36/100\n","\u001b[1m282/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6213 - auc: 0.7181 - loss: 0.5595\n","Epoch 36: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6219 - auc: 0.7177 - loss: 0.5596 - val_acc: 0.9924 - val_auc: 0.6577 - val_loss: 0.2629\n","Epoch 37/100\n","\u001b[1m279/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6530 - auc: 0.7343 - loss: 0.5586\n","Epoch 37: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6530 - auc: 0.7341 - loss: 0.5586 - val_acc: 0.9771 - val_auc: 0.6962 - val_loss: 0.2457\n","Epoch 38/100\n","\u001b[1m282/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6696 - auc: 0.7530 - loss: 0.5502\n","Epoch 38: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6695 - auc: 0.7528 - loss: 0.5504 - val_acc: 0.9466 - val_auc: 0.6462 - val_loss: 0.2639\n","Epoch 39/100\n","\u001b[1m284/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6692 - auc: 0.7528 - loss: 0.5449\n","Epoch 39: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6692 - auc: 0.7523 - loss: 0.5451 - val_acc: 0.9389 - val_auc: 0.6462 - val_loss: 0.2568\n","Epoch 40/100\n","\u001b[1m287/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6618 - auc: 0.7401 - loss: 0.5695\n","Epoch 40: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6619 - auc: 0.7401 - loss: 0.5695 - val_acc: 0.8779 - val_auc: 0.7500 - val_loss: 0.2312\n","Epoch 41/100\n","\u001b[1m277/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6800 - auc: 0.7416 - loss: 0.5660\n","Epoch 41: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6797 - auc: 0.7415 - loss: 0.5659 - val_acc: 0.7863 - val_auc: 0.6615 - val_loss: 0.2764\n","Epoch 42/100\n","\u001b[1m286/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7061 - auc: 0.7623 - loss: 0.5445\n","Epoch 42: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7057 - auc: 0.7619 - loss: 0.5446 - val_acc: 0.8550 - val_auc: 0.6462 - val_loss: 0.2760\n","Epoch 43/100\n","\u001b[1m276/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6348 - auc: 0.7171 - loss: 0.5861\n","Epoch 43: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6367 - auc: 0.7183 - loss: 0.5848 - val_acc: 0.8779 - val_auc: 0.6615 - val_loss: 0.2481\n","Epoch 44/100\n","\u001b[1m277/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6798 - auc: 0.7420 - loss: 0.5427\n","Epoch 44: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6802 - auc: 0.7427 - loss: 0.5430 - val_acc: 0.7939 - val_auc: 0.6615 - val_loss: 0.2717\n","Epoch 45/100\n","\u001b[1m276/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7197 - auc: 0.7516 - loss: 0.5392\n","Epoch 45: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7191 - auc: 0.7516 - loss: 0.5397 - val_acc: 0.8321 - val_auc: 0.6846 - val_loss: 0.2512\n","Epoch 46/100\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6908 - auc: 0.7594 - loss: 0.5573\n","Epoch 46: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6908 - auc: 0.7594 - loss: 0.5573 - val_acc: 0.8092 - val_auc: 0.6692 - val_loss: 0.2615\n","Epoch 47/100\n","\u001b[1m279/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6833 - auc: 0.7446 - loss: 0.5640\n","Epoch 47: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6843 - auc: 0.7449 - loss: 0.5635 - val_acc: 0.8321 - val_auc: 0.6615 - val_loss: 0.2580\n","Epoch 48/100\n","\u001b[1m279/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6755 - auc: 0.7455 - loss: 0.5475\n","Epoch 48: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6763 - auc: 0.7457 - loss: 0.5475 - val_acc: 0.7634 - val_auc: 0.7654 - val_loss: 0.2919\n","Epoch 49/100\n","\u001b[1m277/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7181 - auc: 0.7663 - loss: 0.5406\n","Epoch 49: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7178 - auc: 0.7661 - loss: 0.5407 - val_acc: 0.8244 - val_auc: 0.7269 - val_loss: 0.2554\n","Epoch 50/100\n","\u001b[1m285/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7156 - auc: 0.7441 - loss: 0.5579\n","Epoch 50: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7157 - auc: 0.7442 - loss: 0.5576 - val_acc: 0.8168 - val_auc: 0.8308 - val_loss: 0.2664\n","Epoch 51/100\n","\u001b[1m277/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7151 - auc: 0.7447 - loss: 0.5557\n","Epoch 51: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7149 - auc: 0.7449 - loss: 0.5551 - val_acc: 0.7557 - val_auc: 0.7308 - val_loss: 0.3123\n","Epoch 52/100\n","\u001b[1m274/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7180 - auc: 0.7673 - loss: 0.5332\n","Epoch 52: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7182 - auc: 0.7674 - loss: 0.5332 - val_acc: 0.8244 - val_auc: 0.6615 - val_loss: 0.2836\n","Epoch 53/100\n","\u001b[1m286/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7074 - auc: 0.7195 - loss: 0.5545\n","Epoch 53: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7075 - auc: 0.7201 - loss: 0.5543 - val_acc: 0.7405 - val_auc: 0.7615 - val_loss: 0.3339\n","Epoch 54/100\n","\u001b[1m287/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6957 - auc: 0.7734 - loss: 0.5367\n","Epoch 54: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6957 - auc: 0.7733 - loss: 0.5368 - val_acc: 0.8855 - val_auc: 0.6538 - val_loss: 0.2672\n","Epoch 55/100\n","\u001b[1m287/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7165 - auc: 0.7455 - loss: 0.5229\n","Epoch 55: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7165 - auc: 0.7456 - loss: 0.5230 - val_acc: 0.7939 - val_auc: 0.6654 - val_loss: 0.3170\n","Epoch 56/100\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7442 - auc: 0.7659 - loss: 0.5371\n","Epoch 56: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7442 - auc: 0.7659 - loss: 0.5370 - val_acc: 0.8321 - val_auc: 0.6538 - val_loss: 0.2871\n","Epoch 57/100\n","\u001b[1m276/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7119 - auc: 0.7740 - loss: 0.5304\n","Epoch 57: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7116 - auc: 0.7732 - loss: 0.5306 - val_acc: 0.8015 - val_auc: 0.7000 - val_loss: 0.2989\n","Epoch 58/100\n","\u001b[1m283/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7540 - auc: 0.7787 - loss: 0.5076\n","Epoch 58: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7535 - auc: 0.7783 - loss: 0.5082 - val_acc: 0.7786 - val_auc: 0.7346 - val_loss: 0.2926\n","Epoch 59/100\n","\u001b[1m281/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7329 - auc: 0.7506 - loss: 0.5148\n","Epoch 59: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7327 - auc: 0.7511 - loss: 0.5151 - val_acc: 0.8626 - val_auc: 0.6615 - val_loss: 0.2687\n","Epoch 60/100\n","\u001b[1m274/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7387 - auc: 0.7778 - loss: 0.5130\n","Epoch 60: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7380 - auc: 0.7774 - loss: 0.5140 - val_acc: 0.8168 - val_auc: 0.6769 - val_loss: 0.2952\n","Epoch 61/100\n","\u001b[1m275/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7464 - auc: 0.7954 - loss: 0.5014\n","Epoch 61: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7448 - auc: 0.7942 - loss: 0.5028 - val_acc: 0.8855 - val_auc: 0.6385 - val_loss: 0.2890\n","Epoch 62/100\n","\u001b[1m275/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7169 - auc: 0.7837 - loss: 0.5281\n","Epoch 62: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7168 - auc: 0.7829 - loss: 0.5283 - val_acc: 0.8015 - val_auc: 0.6923 - val_loss: 0.2818\n","Epoch 63/100\n","\u001b[1m287/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7240 - auc: 0.7439 - loss: 0.5644\n","Epoch 63: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7241 - auc: 0.7441 - loss: 0.5642 - val_acc: 0.9084 - val_auc: 0.6500 - val_loss: 0.2599\n","Epoch 64/100\n","\u001b[1m278/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7267 - auc: 0.7858 - loss: 0.5176\n","Epoch 64: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7265 - auc: 0.7857 - loss: 0.5178 - val_acc: 0.8321 - val_auc: 0.6538 - val_loss: 0.3004\n","Epoch 65/100\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7488 - auc: 0.7913 - loss: 0.5060\n","Epoch 65: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7487 - auc: 0.7912 - loss: 0.5060 - val_acc: 0.7710 - val_auc: 0.7500 - val_loss: 0.3152\n","Epoch 66/100\n","\u001b[1m275/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7225 - auc: 0.7424 - loss: 0.5328\n","Epoch 66: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7227 - auc: 0.7435 - loss: 0.5326 - val_acc: 0.7634 - val_auc: 0.7308 - val_loss: 0.3268\n","Epoch 67/100\n","\u001b[1m287/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7284 - auc: 0.7505 - loss: 0.5120\n","Epoch 67: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7284 - auc: 0.7506 - loss: 0.5120 - val_acc: 0.8168 - val_auc: 0.6577 - val_loss: 0.3006\n","Epoch 68/100\n","\u001b[1m284/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7273 - auc: 0.7553 - loss: 0.5370\n","Epoch 68: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7273 - auc: 0.7555 - loss: 0.5369 - val_acc: 0.7634 - val_auc: 0.7462 - val_loss: 0.3250\n","Epoch 69/100\n","\u001b[1m287/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7333 - auc: 0.7647 - loss: 0.5317\n","Epoch 69: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7332 - auc: 0.7647 - loss: 0.5317 - val_acc: 0.8931 - val_auc: 0.6231 - val_loss: 0.2868\n","Epoch 70/100\n","\u001b[1m286/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7348 - auc: 0.7779 - loss: 0.5210\n","Epoch 70: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7347 - auc: 0.7779 - loss: 0.5210 - val_acc: 0.8092 - val_auc: 0.8615 - val_loss: 0.3196\n","Epoch 71/100\n","\u001b[1m278/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7436 - auc: 0.7889 - loss: 0.5056\n","Epoch 71: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7430 - auc: 0.7883 - loss: 0.5063 - val_acc: 0.8092 - val_auc: 0.6692 - val_loss: 0.2917\n","Epoch 72/100\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7512 - auc: 0.8025 - loss: 0.5109\n","Epoch 72: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7511 - auc: 0.8024 - loss: 0.5109 - val_acc: 0.8168 - val_auc: 0.7192 - val_loss: 0.2839\n","Epoch 73/100\n","\u001b[1m277/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7119 - auc: 0.7582 - loss: 0.5471\n","Epoch 73: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7136 - auc: 0.7594 - loss: 0.5457 - val_acc: 0.8702 - val_auc: 0.6538 - val_loss: 0.2909\n","Epoch 74/100\n","\u001b[1m277/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7160 - auc: 0.7704 - loss: 0.5186\n","Epoch 74: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7166 - auc: 0.7702 - loss: 0.5190 - val_acc: 0.9084 - val_auc: 0.6269 - val_loss: 0.2790\n","Epoch 75/100\n","\u001b[1m275/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6834 - auc: 0.7647 - loss: 0.5398\n","Epoch 75: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6856 - auc: 0.7651 - loss: 0.5391 - val_acc: 0.9008 - val_auc: 0.6462 - val_loss: 0.2784\n","Epoch 76/100\n","\u001b[1m283/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7248 - auc: 0.7509 - loss: 0.5345\n","Epoch 76: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7248 - auc: 0.7512 - loss: 0.5343 - val_acc: 0.7863 - val_auc: 0.7462 - val_loss: 0.3353\n","Epoch 77/100\n","\u001b[1m275/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7319 - auc: 0.7822 - loss: 0.5221\n","Epoch 77: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7315 - auc: 0.7818 - loss: 0.5221 - val_acc: 0.8626 - val_auc: 0.6615 - val_loss: 0.2736\n","Epoch 78/100\n","\u001b[1m276/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7345 - auc: 0.7377 - loss: 0.5231\n","Epoch 78: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7338 - auc: 0.7386 - loss: 0.5234 - val_acc: 0.7863 - val_auc: 0.7462 - val_loss: 0.3052\n","Epoch 79/100\n","\u001b[1m277/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7185 - auc: 0.7467 - loss: 0.5319\n","Epoch 79: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7188 - auc: 0.7475 - loss: 0.5317 - val_acc: 0.7710 - val_auc: 0.7615 - val_loss: 0.3227\n","Epoch 80/100\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7292 - auc: 0.7627 - loss: 0.5560\n","Epoch 80: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7292 - auc: 0.7628 - loss: 0.5560 - val_acc: 0.8092 - val_auc: 0.7115 - val_loss: 0.2969\n","Epoch 81/100\n","\u001b[1m276/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7213 - auc: 0.7526 - loss: 0.5180\n","Epoch 81: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7217 - auc: 0.7533 - loss: 0.5182 - val_acc: 0.8779 - val_auc: 0.6615 - val_loss: 0.2800\n","Epoch 82/100\n","\u001b[1m286/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7335 - auc: 0.7866 - loss: 0.5067\n","Epoch 82: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7334 - auc: 0.7865 - loss: 0.5068 - val_acc: 0.8702 - val_auc: 0.6308 - val_loss: 0.3051\n","Epoch 83/100\n","\u001b[1m277/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7537 - auc: 0.7761 - loss: 0.5126\n","Epoch 83: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7526 - auc: 0.7758 - loss: 0.5131 - val_acc: 0.8321 - val_auc: 0.6615 - val_loss: 0.2878\n","Epoch 84/100\n","\u001b[1m280/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7250 - auc: 0.7682 - loss: 0.5320\n","Epoch 84: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7253 - auc: 0.7685 - loss: 0.5317 - val_acc: 0.9008 - val_auc: 0.6500 - val_loss: 0.2728\n","Epoch 85/100\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7356 - auc: 0.7927 - loss: 0.5054\n","Epoch 85: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7355 - auc: 0.7926 - loss: 0.5055 - val_acc: 0.8168 - val_auc: 0.6615 - val_loss: 0.3081\n","Epoch 86/100\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7447 - auc: 0.7854 - loss: 0.5145\n","Epoch 86: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7446 - auc: 0.7853 - loss: 0.5145 - val_acc: 0.8244 - val_auc: 0.7423 - val_loss: 0.2776\n","Epoch 87/100\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7216 - auc: 0.7677 - loss: 0.5240\n","Epoch 87: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7216 - auc: 0.7677 - loss: 0.5240 - val_acc: 0.8931 - val_auc: 0.6385 - val_loss: 0.2733\n","Epoch 88/100\n","\u001b[1m275/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7336 - auc: 0.7865 - loss: 0.5180\n","Epoch 88: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7337 - auc: 0.7863 - loss: 0.5180 - val_acc: 0.7939 - val_auc: 0.7462 - val_loss: 0.3066\n","Epoch 89/100\n","\u001b[1m280/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7324 - auc: 0.7794 - loss: 0.5334\n","Epoch 89: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7325 - auc: 0.7792 - loss: 0.5330 - val_acc: 0.8626 - val_auc: 0.6577 - val_loss: 0.2780\n","Epoch 90/100\n","\u001b[1m281/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7566 - auc: 0.8024 - loss: 0.4993\n","Epoch 90: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7561 - auc: 0.8018 - loss: 0.4997 - val_acc: 0.8015 - val_auc: 0.7462 - val_loss: 0.2973\n","Epoch 91/100\n","\u001b[1m274/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7197 - auc: 0.7552 - loss: 0.5187\n","Epoch 91: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7201 - auc: 0.7566 - loss: 0.5188 - val_acc: 0.7863 - val_auc: 0.7269 - val_loss: 0.3331\n","Epoch 92/100\n","\u001b[1m278/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7520 - auc: 0.7831 - loss: 0.5251\n","Epoch 92: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7512 - auc: 0.7828 - loss: 0.5249 - val_acc: 0.9237 - val_auc: 0.6385 - val_loss: 0.2492\n","Epoch 93/100\n","\u001b[1m285/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7267 - auc: 0.7563 - loss: 0.5294\n","Epoch 93: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7269 - auc: 0.7566 - loss: 0.5293 - val_acc: 0.8779 - val_auc: 0.6423 - val_loss: 0.2893\n","Epoch 94/100\n","\u001b[1m287/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7346 - auc: 0.7820 - loss: 0.5061\n","Epoch 94: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7346 - auc: 0.7819 - loss: 0.5061 - val_acc: 0.8550 - val_auc: 0.6654 - val_loss: 0.3079\n","Epoch 95/100\n","\u001b[1m287/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7380 - auc: 0.7843 - loss: 0.4998\n","Epoch 95: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7379 - auc: 0.7842 - loss: 0.5000 - val_acc: 0.8321 - val_auc: 0.6615 - val_loss: 0.3091\n","Epoch 96/100\n","\u001b[1m284/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7265 - auc: 0.7651 - loss: 0.5232\n","Epoch 96: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7267 - auc: 0.7653 - loss: 0.5230 - val_acc: 0.8702 - val_auc: 0.6423 - val_loss: 0.3004\n","Epoch 97/100\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7262 - auc: 0.7820 - loss: 0.4962\n","Epoch 97: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7262 - auc: 0.7820 - loss: 0.4963 - val_acc: 0.8626 - val_auc: 0.6385 - val_loss: 0.2982\n","Epoch 98/100\n","\u001b[1m286/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7071 - auc: 0.7667 - loss: 0.5393\n","Epoch 98: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7074 - auc: 0.7668 - loss: 0.5391 - val_acc: 0.8244 - val_auc: 0.7385 - val_loss: 0.2940\n","Epoch 99/100\n","\u001b[1m279/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7236 - auc: 0.7622 - loss: 0.5261\n","Epoch 99: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7238 - auc: 0.7626 - loss: 0.5259 - val_acc: 0.8015 - val_auc: 0.6808 - val_loss: 0.3146\n","Epoch 100/100\n","\u001b[1m276/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7158 - auc: 0.7475 - loss: 0.5497\n","Epoch 100: val_loss did not improve from 0.20615\n","\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7165 - auc: 0.7484 - loss: 0.5484 - val_acc: 0.7939 - val_auc: 0.7269 - val_loss: 0.3048\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 6 | TEST ACC=0.5314 | TEST AUC=0.5246 | n=207\n","Confusion matrix:\n"," [[110   0]\n"," [ 97   0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.531     1.000     0.694       110\n","           1      0.000     0.000     0.000        97\n","\n","    accuracy                          0.531       207\n","   macro avg      0.266     0.500     0.347       207\n","weighted avg      0.282     0.531     0.369       207\n","\n","\n","--- Fold 7/7 ---\n"," train | ids:   34 | files:   891 | pos files:  353 | neg files:  538\n","   val | ids:    4 | files:    69 | pos files:    1 | neg files:   68\n","  test | ids:    6 | files:   240 | pos files:   51 | neg files:  189\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6091 - auc: 0.4955 - loss: 0.6904\n","Epoch 1: val_loss improved from inf to 0.64477, saving model to best_fold_07.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - acc: 0.6091 - auc: 0.4955 - loss: 0.6904 - val_acc: 0.9855 - val_auc: 0.5588 - val_loss: 0.6448\n","Epoch 2/100\n","\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6405 - auc: 0.4750 - loss: 0.6751\n","Epoch 2: val_loss improved from 0.64477 to 0.55048, saving model to best_fold_07.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6393 - auc: 0.4764 - loss: 0.6751 - val_acc: 0.9855 - val_auc: 0.6397 - val_loss: 0.5505\n","Epoch 3/100\n","\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6009 - auc: 0.6183 - loss: 0.6649\n","Epoch 3: val_loss improved from 0.55048 to 0.47657, saving model to best_fold_07.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6009 - auc: 0.6183 - loss: 0.6648 - val_acc: 0.9855 - val_auc: 0.7574 - val_loss: 0.4766\n","Epoch 4/100\n","\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5754 - auc: 0.6330 - loss: 0.6687\n","Epoch 4: val_loss improved from 0.47657 to 0.43908, saving model to best_fold_07.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.5762 - auc: 0.6335 - loss: 0.6683 - val_acc: 0.9855 - val_auc: 0.8235 - val_loss: 0.4391\n","Epoch 5/100\n","\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6377 - auc: 0.6844 - loss: 0.6301\n","Epoch 5: val_loss did not improve from 0.43908\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6378 - auc: 0.6842 - loss: 0.6301 - val_acc: 0.8551 - val_auc: 0.8676 - val_loss: 0.5088\n","Epoch 6/100\n","\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6585 - auc: 0.6976 - loss: 0.6174\n","Epoch 6: val_loss did not improve from 0.43908\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6579 - auc: 0.6972 - loss: 0.6173 - val_acc: 0.8696 - val_auc: 0.8603 - val_loss: 0.4535\n","Epoch 7/100\n","\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6512 - auc: 0.7130 - loss: 0.6080\n","Epoch 7: val_loss did not improve from 0.43908\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6510 - auc: 0.7121 - loss: 0.6083 - val_acc: 0.7246 - val_auc: 0.8750 - val_loss: 0.6306\n","Epoch 8/100\n","\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6216 - auc: 0.6717 - loss: 0.6238\n","Epoch 8: val_loss did not improve from 0.43908\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6223 - auc: 0.6721 - loss: 0.6234 - val_acc: 0.8406 - val_auc: 0.8676 - val_loss: 0.4641\n","Epoch 9/100\n","\u001b[1m284/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6430 - auc: 0.6814 - loss: 0.6221\n","Epoch 9: val_loss did not improve from 0.43908\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6430 - auc: 0.6814 - loss: 0.6218 - val_acc: 0.8406 - val_auc: 0.8603 - val_loss: 0.4892\n","Epoch 10/100\n","\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6212 - auc: 0.6829 - loss: 0.6127\n","Epoch 10: val_loss did not improve from 0.43908\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6216 - auc: 0.6830 - loss: 0.6126 - val_acc: 0.8406 - val_auc: 0.8603 - val_loss: 0.4959\n","Epoch 11/100\n","\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6368 - auc: 0.6698 - loss: 0.6179\n","Epoch 11: val_loss did not improve from 0.43908\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6371 - auc: 0.6702 - loss: 0.6177 - val_acc: 0.8261 - val_auc: 0.8529 - val_loss: 0.5118\n","Epoch 12/100\n","\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6958 - auc: 0.7436 - loss: 0.5743\n","Epoch 12: val_loss improved from 0.43908 to 0.41775, saving model to best_fold_07.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6948 - auc: 0.7421 - loss: 0.5751 - val_acc: 0.8696 - val_auc: 0.8529 - val_loss: 0.4178\n","Epoch 13/100\n","\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6766 - auc: 0.7082 - loss: 0.5995\n","Epoch 13: val_loss did not improve from 0.41775\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6764 - auc: 0.7080 - loss: 0.5995 - val_acc: 0.8261 - val_auc: 0.8603 - val_loss: 0.5057\n","Epoch 14/100\n","\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6700 - auc: 0.6852 - loss: 0.5997\n","Epoch 14: val_loss did not improve from 0.41775\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6693 - auc: 0.6857 - loss: 0.5997 - val_acc: 0.7391 - val_auc: 0.8603 - val_loss: 0.5852\n","Epoch 15/100\n","\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6122 - auc: 0.6690 - loss: 0.6192\n","Epoch 15: val_loss did not improve from 0.41775\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6129 - auc: 0.6696 - loss: 0.6188 - val_acc: 0.7536 - val_auc: 0.8603 - val_loss: 0.5418\n","Epoch 16/100\n","\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6559 - auc: 0.7092 - loss: 0.5947\n","Epoch 16: val_loss did not improve from 0.41775\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6556 - auc: 0.7088 - loss: 0.5948 - val_acc: 0.8551 - val_auc: 0.8456 - val_loss: 0.4670\n","Epoch 17/100\n","\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6831 - auc: 0.7157 - loss: 0.5895\n","Epoch 17: val_loss did not improve from 0.41775\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6828 - auc: 0.7156 - loss: 0.5896 - val_acc: 0.8406 - val_auc: 0.8603 - val_loss: 0.4618\n","Epoch 18/100\n","\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6529 - auc: 0.6878 - loss: 0.6061\n","Epoch 18: val_loss did not improve from 0.41775\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6531 - auc: 0.6881 - loss: 0.6058 - val_acc: 0.7681 - val_auc: 0.8529 - val_loss: 0.5215\n","Epoch 19/100\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6239 - auc: 0.6647 - loss: 0.6024\n","Epoch 19: val_loss did not improve from 0.41775\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6240 - auc: 0.6648 - loss: 0.6023 - val_acc: 0.8406 - val_auc: 0.8529 - val_loss: 0.4613\n","Epoch 20/100\n","\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6407 - auc: 0.6911 - loss: 0.5983\n","Epoch 20: val_loss did not improve from 0.41775\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6409 - auc: 0.6911 - loss: 0.5983 - val_acc: 0.8116 - val_auc: 0.8529 - val_loss: 0.5090\n","Epoch 21/100\n","\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6082 - auc: 0.6589 - loss: 0.6114\n","Epoch 21: val_loss did not improve from 0.41775\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6093 - auc: 0.6605 - loss: 0.6106 - val_acc: 0.8116 - val_auc: 0.8529 - val_loss: 0.4982\n","Epoch 22/100\n","\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6716 - auc: 0.7346 - loss: 0.5620\n","Epoch 22: val_loss improved from 0.41775 to 0.40864, saving model to best_fold_07.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6706 - auc: 0.7337 - loss: 0.5627 - val_acc: 0.8696 - val_auc: 0.8456 - val_loss: 0.4086\n","Epoch 23/100\n","\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6756 - auc: 0.6799 - loss: 0.5945\n","Epoch 23: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6745 - auc: 0.6804 - loss: 0.5945 - val_acc: 0.7826 - val_auc: 0.8529 - val_loss: 0.5112\n","Epoch 24/100\n","\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6400 - auc: 0.6839 - loss: 0.6016\n","Epoch 24: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6401 - auc: 0.6841 - loss: 0.6015 - val_acc: 0.8406 - val_auc: 0.8529 - val_loss: 0.4545\n","Epoch 25/100\n","\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6486 - auc: 0.6942 - loss: 0.6004\n","Epoch 25: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6483 - auc: 0.6944 - loss: 0.6001 - val_acc: 0.8696 - val_auc: 0.8456 - val_loss: 0.4312\n","Epoch 26/100\n","\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6303 - auc: 0.7046 - loss: 0.5835\n","Epoch 26: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6305 - auc: 0.7043 - loss: 0.5836 - val_acc: 0.8406 - val_auc: 0.8529 - val_loss: 0.4886\n","Epoch 27/100\n","\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6429 - auc: 0.6634 - loss: 0.5974\n","Epoch 27: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6432 - auc: 0.6645 - loss: 0.5971 - val_acc: 0.7536 - val_auc: 0.8529 - val_loss: 0.5539\n","Epoch 28/100\n","\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6209 - auc: 0.6882 - loss: 0.6035\n","Epoch 28: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6214 - auc: 0.6886 - loss: 0.6029 - val_acc: 0.7536 - val_auc: 0.8529 - val_loss: 0.5195\n","Epoch 29/100\n","\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6292 - auc: 0.6928 - loss: 0.5983\n","Epoch 29: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6298 - auc: 0.6930 - loss: 0.5979 - val_acc: 0.8261 - val_auc: 0.8529 - val_loss: 0.4865\n","Epoch 30/100\n","\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6585 - auc: 0.7293 - loss: 0.5704\n","Epoch 30: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6580 - auc: 0.7286 - loss: 0.5707 - val_acc: 0.9275 - val_auc: 0.8456 - val_loss: 0.4109\n","Epoch 31/100\n","\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6543 - auc: 0.6917 - loss: 0.5891\n","Epoch 31: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6540 - auc: 0.6920 - loss: 0.5889 - val_acc: 0.7391 - val_auc: 0.8529 - val_loss: 0.5614\n","Epoch 32/100\n","\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6477 - auc: 0.7032 - loss: 0.5844\n","Epoch 32: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6478 - auc: 0.7033 - loss: 0.5843 - val_acc: 0.7971 - val_auc: 0.8529 - val_loss: 0.5080\n","Epoch 33/100\n","\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6032 - auc: 0.6674 - loss: 0.5959\n","Epoch 33: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6035 - auc: 0.6680 - loss: 0.5956 - val_acc: 0.8116 - val_auc: 0.8529 - val_loss: 0.4969\n","Epoch 34/100\n","\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6569 - auc: 0.7121 - loss: 0.5749\n","Epoch 34: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6565 - auc: 0.7117 - loss: 0.5751 - val_acc: 0.7391 - val_auc: 0.8529 - val_loss: 0.5566\n","Epoch 35/100\n","\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6233 - auc: 0.6823 - loss: 0.5900\n","Epoch 35: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6237 - auc: 0.6826 - loss: 0.5898 - val_acc: 0.7536 - val_auc: 0.8529 - val_loss: 0.5334\n","Epoch 36/100\n","\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6581 - auc: 0.7044 - loss: 0.5742\n","Epoch 36: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6577 - auc: 0.7042 - loss: 0.5744 - val_acc: 0.8406 - val_auc: 0.8529 - val_loss: 0.4890\n","Epoch 37/100\n","\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6285 - auc: 0.6903 - loss: 0.5902\n","Epoch 37: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6285 - auc: 0.6904 - loss: 0.5902 - val_acc: 0.7536 - val_auc: 0.8529 - val_loss: 0.5302\n","Epoch 38/100\n","\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6156 - auc: 0.6756 - loss: 0.5841\n","Epoch 38: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6161 - auc: 0.6762 - loss: 0.5839 - val_acc: 0.8116 - val_auc: 0.8529 - val_loss: 0.4872\n","Epoch 39/100\n","\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6475 - auc: 0.6853 - loss: 0.5851\n","Epoch 39: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6481 - auc: 0.6863 - loss: 0.5846 - val_acc: 0.8551 - val_auc: 0.8529 - val_loss: 0.5017\n","Epoch 40/100\n","\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6586 - auc: 0.7204 - loss: 0.5679\n","Epoch 40: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6584 - auc: 0.7200 - loss: 0.5680 - val_acc: 0.8406 - val_auc: 0.8529 - val_loss: 0.4473\n","Epoch 41/100\n","\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6687 - auc: 0.7031 - loss: 0.5823\n","Epoch 41: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6685 - auc: 0.7032 - loss: 0.5822 - val_acc: 0.6957 - val_auc: 0.8529 - val_loss: 0.5588\n","Epoch 42/100\n","\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6456 - auc: 0.7050 - loss: 0.5564\n","Epoch 42: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6457 - auc: 0.7048 - loss: 0.5570 - val_acc: 0.8696 - val_auc: 0.8309 - val_loss: 0.4303\n","Epoch 43/100\n","\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6669 - auc: 0.7411 - loss: 0.5411\n","Epoch 43: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6665 - auc: 0.7404 - loss: 0.5418 - val_acc: 0.8551 - val_auc: 0.8529 - val_loss: 0.4849\n","Epoch 44/100\n","\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6617 - auc: 0.7226 - loss: 0.5528\n","Epoch 44: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6611 - auc: 0.7221 - loss: 0.5534 - val_acc: 0.8116 - val_auc: 0.8529 - val_loss: 0.5195\n","Epoch 45/100\n","\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6316 - auc: 0.7025 - loss: 0.5757\n","Epoch 45: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6319 - auc: 0.7031 - loss: 0.5753 - val_acc: 0.8551 - val_auc: 0.8529 - val_loss: 0.4511\n","Epoch 46/100\n","\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6346 - auc: 0.6721 - loss: 0.5749\n","Epoch 46: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6353 - auc: 0.6730 - loss: 0.5747 - val_acc: 0.8116 - val_auc: 0.8529 - val_loss: 0.5242\n","Epoch 47/100\n","\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6761 - auc: 0.7434 - loss: 0.5441\n","Epoch 47: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6755 - auc: 0.7426 - loss: 0.5448 - val_acc: 0.8696 - val_auc: 0.8162 - val_loss: 0.4621\n","Epoch 48/100\n","\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6571 - auc: 0.7109 - loss: 0.5727\n","Epoch 48: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6571 - auc: 0.7111 - loss: 0.5725 - val_acc: 0.8406 - val_auc: 0.8309 - val_loss: 0.4751\n","Epoch 49/100\n","\u001b[1m284/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6633 - auc: 0.7023 - loss: 0.5685\n","Epoch 49: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6639 - auc: 0.7030 - loss: 0.5685 - val_acc: 0.8406 - val_auc: 0.8456 - val_loss: 0.4689\n","Epoch 50/100\n","\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6127 - auc: 0.6691 - loss: 0.5933\n","Epoch 50: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6136 - auc: 0.6701 - loss: 0.5927 - val_acc: 0.8116 - val_auc: 0.8529 - val_loss: 0.5292\n","Epoch 51/100\n","\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6610 - auc: 0.7193 - loss: 0.5719\n","Epoch 51: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6611 - auc: 0.7194 - loss: 0.5717 - val_acc: 0.8551 - val_auc: 0.8235 - val_loss: 0.4540\n","Epoch 52/100\n","\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6623 - auc: 0.7064 - loss: 0.5674\n","Epoch 52: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6616 - auc: 0.7063 - loss: 0.5676 - val_acc: 0.8841 - val_auc: 0.7794 - val_loss: 0.4430\n","Epoch 53/100\n","\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6435 - auc: 0.7373 - loss: 0.5502\n","Epoch 53: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6435 - auc: 0.7367 - loss: 0.5505 - val_acc: 0.8116 - val_auc: 0.8456 - val_loss: 0.5528\n","Epoch 54/100\n","\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6466 - auc: 0.6898 - loss: 0.5705\n","Epoch 54: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6465 - auc: 0.6901 - loss: 0.5705 - val_acc: 0.8696 - val_auc: 0.7353 - val_loss: 0.4655\n","Epoch 55/100\n","\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6440 - auc: 0.6929 - loss: 0.5816\n","Epoch 55: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6444 - auc: 0.6934 - loss: 0.5813 - val_acc: 0.8841 - val_auc: 0.5074 - val_loss: 0.4683\n","Epoch 56/100\n","\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6509 - auc: 0.7445 - loss: 0.5496\n","Epoch 56: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6508 - auc: 0.7440 - loss: 0.5500 - val_acc: 0.8986 - val_auc: 0.7868 - val_loss: 0.4236\n","Epoch 57/100\n","\u001b[1m283/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6318 - auc: 0.7043 - loss: 0.5711\n","Epoch 57: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6325 - auc: 0.7051 - loss: 0.5707 - val_acc: 0.8406 - val_auc: 0.7426 - val_loss: 0.4946\n","Epoch 58/100\n","\u001b[1m291/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6471 - auc: 0.7009 - loss: 0.5743\n","Epoch 58: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6473 - auc: 0.7014 - loss: 0.5740 - val_acc: 0.8551 - val_auc: 0.7574 - val_loss: 0.4888\n","Epoch 59/100\n","\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6728 - auc: 0.7190 - loss: 0.5484\n","Epoch 59: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6727 - auc: 0.7190 - loss: 0.5485 - val_acc: 0.7536 - val_auc: 0.7794 - val_loss: 0.5558\n","Epoch 60/100\n","\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6243 - auc: 0.7071 - loss: 0.5778\n","Epoch 60: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6247 - auc: 0.7075 - loss: 0.5776 - val_acc: 0.8841 - val_auc: 0.7721 - val_loss: 0.4380\n","Epoch 61/100\n","\u001b[1m284/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6368 - auc: 0.7261 - loss: 0.5934\n","Epoch 61: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6384 - auc: 0.7270 - loss: 0.5915 - val_acc: 0.7101 - val_auc: 0.6765 - val_loss: 0.5481\n","Epoch 62/100\n","\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6412 - auc: 0.7126 - loss: 0.5718\n","Epoch 62: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6417 - auc: 0.7129 - loss: 0.5715 - val_acc: 0.8551 - val_auc: 0.8382 - val_loss: 0.4663\n","Epoch 63/100\n","\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6511 - auc: 0.7308 - loss: 0.5645\n","Epoch 63: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6515 - auc: 0.7310 - loss: 0.5644 - val_acc: 0.8406 - val_auc: 0.4191 - val_loss: 0.4829\n","Epoch 64/100\n","\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6303 - auc: 0.7131 - loss: 0.5636\n","Epoch 64: val_loss did not improve from 0.40864\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6308 - auc: 0.7135 - loss: 0.5635 - val_acc: 0.9275 - val_auc: 0.6838 - val_loss: 0.4299\n","Epoch 65/100\n","\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6454 - auc: 0.7450 - loss: 0.5512\n","Epoch 65: val_loss improved from 0.40864 to 0.36145, saving model to best_fold_07.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6455 - auc: 0.7448 - loss: 0.5513 - val_acc: 0.9420 - val_auc: 0.6544 - val_loss: 0.3615\n","Epoch 66/100\n","\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6605 - auc: 0.7368 - loss: 0.5512\n","Epoch 66: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6601 - auc: 0.7364 - loss: 0.5515 - val_acc: 0.8261 - val_auc: 0.6544 - val_loss: 0.4741\n","Epoch 67/100\n","\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6838 - auc: 0.7488 - loss: 0.5399\n","Epoch 67: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6832 - auc: 0.7481 - loss: 0.5405 - val_acc: 0.8116 - val_auc: 0.4118 - val_loss: 0.4978\n","Epoch 68/100\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6821 - auc: 0.7387 - loss: 0.5466\n","Epoch 68: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6821 - auc: 0.7388 - loss: 0.5467 - val_acc: 0.4058 - val_auc: 0.6397 - val_loss: 0.6206\n","Epoch 69/100\n","\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6677 - auc: 0.7370 - loss: 0.5506\n","Epoch 69: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6675 - auc: 0.7370 - loss: 0.5507 - val_acc: 0.8551 - val_auc: 0.5956 - val_loss: 0.4527\n","Epoch 70/100\n","\u001b[1m293/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6827 - auc: 0.7504 - loss: 0.5483\n","Epoch 70: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6824 - auc: 0.7503 - loss: 0.5484 - val_acc: 0.4928 - val_auc: 0.7721 - val_loss: 0.6067\n","Epoch 71/100\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6510 - auc: 0.7395 - loss: 0.5560\n","Epoch 71: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6510 - auc: 0.7395 - loss: 0.5560 - val_acc: 0.9275 - val_auc: 0.6838 - val_loss: 0.3969\n","Epoch 72/100\n","\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6345 - auc: 0.6884 - loss: 0.5978\n","Epoch 72: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6346 - auc: 0.6888 - loss: 0.5975 - val_acc: 0.8261 - val_auc: 0.8529 - val_loss: 0.5184\n","Epoch 73/100\n","\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6579 - auc: 0.7256 - loss: 0.5678\n","Epoch 73: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6579 - auc: 0.7259 - loss: 0.5676 - val_acc: 0.8696 - val_auc: 0.4632 - val_loss: 0.4533\n","Epoch 74/100\n","\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6747 - auc: 0.7496 - loss: 0.5381\n","Epoch 74: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6743 - auc: 0.7491 - loss: 0.5388 - val_acc: 0.8406 - val_auc: 0.8162 - val_loss: 0.4605\n","Epoch 75/100\n","\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6550 - auc: 0.7461 - loss: 0.5466\n","Epoch 75: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6553 - auc: 0.7459 - loss: 0.5468 - val_acc: 0.8696 - val_auc: 0.5221 - val_loss: 0.4552\n","Epoch 76/100\n","\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6522 - auc: 0.7490 - loss: 0.5459\n","Epoch 76: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6524 - auc: 0.7488 - loss: 0.5462 - val_acc: 0.9275 - val_auc: 0.8015 - val_loss: 0.3661\n","Epoch 77/100\n","\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6769 - auc: 0.7570 - loss: 0.5374\n","Epoch 77: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6766 - auc: 0.7562 - loss: 0.5381 - val_acc: 0.7826 - val_auc: 0.6618 - val_loss: 0.5057\n","Epoch 78/100\n","\u001b[1m292/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6836 - auc: 0.7514 - loss: 0.5489\n","Epoch 78: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6834 - auc: 0.7513 - loss: 0.5489 - val_acc: 0.7826 - val_auc: 0.4265 - val_loss: 0.4968\n","Epoch 79/100\n","\u001b[1m284/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6842 - auc: 0.7788 - loss: 0.5247\n","Epoch 79: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6830 - auc: 0.7773 - loss: 0.5259 - val_acc: 0.4493 - val_auc: 0.3750 - val_loss: 0.5985\n","Epoch 80/100\n","\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6544 - auc: 0.7238 - loss: 0.5611\n","Epoch 80: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6547 - auc: 0.7242 - loss: 0.5609 - val_acc: 0.9275 - val_auc: 0.5441 - val_loss: 0.4032\n","Epoch 81/100\n","\u001b[1m284/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6721 - auc: 0.7432 - loss: 0.5598\n","Epoch 81: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6713 - auc: 0.7433 - loss: 0.5594 - val_acc: 0.4348 - val_auc: 0.4559 - val_loss: 0.6026\n","Epoch 82/100\n","\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6744 - auc: 0.7515 - loss: 0.5374\n","Epoch 82: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6747 - auc: 0.7513 - loss: 0.5378 - val_acc: 0.8261 - val_auc: 0.6397 - val_loss: 0.4731\n","Epoch 83/100\n","\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6629 - auc: 0.7377 - loss: 0.5438\n","Epoch 83: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6630 - auc: 0.7378 - loss: 0.5439 - val_acc: 0.8986 - val_auc: 0.4559 - val_loss: 0.4420\n","Epoch 84/100\n","\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6636 - auc: 0.7423 - loss: 0.5478\n","Epoch 84: val_loss did not improve from 0.36145\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6636 - auc: 0.7422 - loss: 0.5478 - val_acc: 0.7971 - val_auc: 0.8088 - val_loss: 0.5285\n","Epoch 85/100\n","\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6760 - auc: 0.7575 - loss: 0.5483\n","Epoch 85: val_loss improved from 0.36145 to 0.33024, saving model to best_fold_07.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6760 - auc: 0.7573 - loss: 0.5482 - val_acc: 0.9420 - val_auc: 0.6397 - val_loss: 0.3302\n","Epoch 86/100\n","\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6806 - auc: 0.7673 - loss: 0.5399\n","Epoch 86: val_loss did not improve from 0.33024\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6804 - auc: 0.7666 - loss: 0.5402 - val_acc: 0.8986 - val_auc: 0.4118 - val_loss: 0.4483\n","Epoch 87/100\n","\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6730 - auc: 0.7541 - loss: 0.5461\n","Epoch 87: val_loss did not improve from 0.33024\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6729 - auc: 0.7540 - loss: 0.5461 - val_acc: 0.6667 - val_auc: 0.5221 - val_loss: 0.5313\n","Epoch 88/100\n","\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6742 - auc: 0.7480 - loss: 0.5386\n","Epoch 88: val_loss did not improve from 0.33024\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6741 - auc: 0.7480 - loss: 0.5386 - val_acc: 0.9130 - val_auc: 0.4485 - val_loss: 0.4326\n","Epoch 89/100\n","\u001b[1m289/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6711 - auc: 0.7105 - loss: 0.5579\n","Epoch 89: val_loss did not improve from 0.33024\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6714 - auc: 0.7116 - loss: 0.5575 - val_acc: 0.7391 - val_auc: 0.8088 - val_loss: 0.5488\n","Epoch 90/100\n","\u001b[1m296/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6927 - auc: 0.7628 - loss: 0.5298\n","Epoch 90: val_loss did not improve from 0.33024\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6927 - auc: 0.7627 - loss: 0.5300 - val_acc: 0.8116 - val_auc: 0.8088 - val_loss: 0.5013\n","Epoch 91/100\n","\u001b[1m285/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6518 - auc: 0.7229 - loss: 0.5725\n","Epoch 91: val_loss did not improve from 0.33024\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6527 - auc: 0.7245 - loss: 0.5709 - val_acc: 0.8406 - val_auc: 0.8529 - val_loss: 0.4347\n","Epoch 92/100\n","\u001b[1m288/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6653 - auc: 0.7480 - loss: 0.5467\n","Epoch 92: val_loss did not improve from 0.33024\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6655 - auc: 0.7481 - loss: 0.5467 - val_acc: 0.8261 - val_auc: 0.5956 - val_loss: 0.4803\n","Epoch 93/100\n","\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7009 - auc: 0.7671 - loss: 0.5222\n","Epoch 93: val_loss did not improve from 0.33024\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7003 - auc: 0.7666 - loss: 0.5228 - val_acc: 0.8986 - val_auc: 0.4338 - val_loss: 0.4368\n","Epoch 94/100\n","\u001b[1m290/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6768 - auc: 0.7691 - loss: 0.5265\n","Epoch 94: val_loss did not improve from 0.33024\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6766 - auc: 0.7687 - loss: 0.5269 - val_acc: 0.8261 - val_auc: 0.7647 - val_loss: 0.4811\n","Epoch 95/100\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6917 - auc: 0.7537 - loss: 0.5321\n","Epoch 95: val_loss did not improve from 0.33024\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6916 - auc: 0.7536 - loss: 0.5321 - val_acc: 0.8551 - val_auc: 0.7574 - val_loss: 0.4392\n","Epoch 96/100\n","\u001b[1m287/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6755 - auc: 0.7728 - loss: 0.5184\n","Epoch 96: val_loss did not improve from 0.33024\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6755 - auc: 0.7722 - loss: 0.5191 - val_acc: 0.7826 - val_auc: 0.5074 - val_loss: 0.5111\n","Epoch 97/100\n","\u001b[1m286/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6881 - auc: 0.7406 - loss: 0.5491\n","Epoch 97: val_loss did not improve from 0.33024\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6878 - auc: 0.7409 - loss: 0.5488 - val_acc: 0.7681 - val_auc: 0.6985 - val_loss: 0.5174\n","Epoch 98/100\n","\u001b[1m295/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6682 - auc: 0.7430 - loss: 0.5517\n","Epoch 98: val_loss did not improve from 0.33024\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6682 - auc: 0.7431 - loss: 0.5516 - val_acc: 0.8116 - val_auc: 0.7868 - val_loss: 0.4975\n","Epoch 99/100\n","\u001b[1m284/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7081 - auc: 0.7822 - loss: 0.5139\n","Epoch 99: val_loss did not improve from 0.33024\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.7070 - auc: 0.7811 - loss: 0.5149 - val_acc: 0.6377 - val_auc: 0.3603 - val_loss: 0.5702\n","Epoch 100/100\n","\u001b[1m294/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6984 - auc: 0.7697 - loss: 0.5406\n","Epoch 100: val_loss did not improve from 0.33024\n","\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.6982 - auc: 0.7695 - loss: 0.5406 - val_acc: 0.8406 - val_auc: 0.7426 - val_loss: 0.4455\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Fold 7 | TEST ACC=0.6167 | TEST AUC=0.2089 | n=240\n","Confusion matrix:\n"," [[148  41]\n"," [ 51   0]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0      0.744     0.783     0.763       189\n","           1      0.000     0.000     0.000        51\n","\n","    accuracy                          0.617       240\n","   macro avg      0.372     0.392     0.381       240\n","weighted avg      0.586     0.617     0.601       240\n","\n","\n","Per-fold TEST ACC: [0.676, 0.5809, 0.4173, 0.6286, 0.7851, 0.5314, 0.6167]\n","Per-fold TEST AUC: [0.7264, 0.501, 0.6511, 0.6492, 0.3673, 0.5246, 0.2089]\n","\n","Mean TEST ACC: 0.6051 ± 0.1065\n","Mean TEST AUC: 0.5184 ± 0.1677\n","\n","Saved TEST-only per-fold metrics to cv7_img_fold_metrics.csv\n"]}]},{"cell_type":"code","source":["fold_test_aucs"],"metadata":{"id":"yUSkVV9BpHSa","executionInfo":{"status":"ok","timestamp":1760665429689,"user_tz":300,"elapsed":15,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"82975ac7-2097-4b6c-d3c6-bc9a25b08498"},"id":"yUSkVV9BpHSa","execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7263681592039801,\n"," 0.5010416666666667,\n"," 0.6511281396338867,\n"," 0.6491666666666667,\n"," 0.3673267326732673,\n"," 0.5246485473289597,\n"," 0.2089428363938168]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["fold_test_accs"],"metadata":{"id":"KUgcBvQhpHVE","executionInfo":{"status":"ok","timestamp":1760665441591,"user_tz":300,"elapsed":58,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"04eeb876-e639-4c83-fcdb-d438949986ab"},"id":"KUgcBvQhpHVE","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.6759581881533101,\n"," 0.5808823529411765,\n"," 0.4172661870503597,\n"," 0.6285714285714286,\n"," 0.7851239669421488,\n"," 0.5314009661835749,\n"," 0.6166666666666667]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":[],"metadata":{"id":"IrWZ5cUFpHXs","executionInfo":{"status":"aborted","timestamp":1760664384660,"user_tz":300,"elapsed":286227,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"IrWZ5cUFpHXs","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sPOzCNAug4NW","executionInfo":{"status":"aborted","timestamp":1760664384681,"user_tz":300,"elapsed":286247,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"sPOzCNAug4NW","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xxOkMiS4g4SL","executionInfo":{"status":"aborted","timestamp":1760664384686,"user_tz":300,"elapsed":286252,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"id":"xxOkMiS4g4SL","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"3wJQznZz-oll","metadata":{"id":"3wJQznZz-oll","executionInfo":{"status":"aborted","timestamp":1760664384689,"user_tz":300,"elapsed":286231,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"Gr4rUSqY-o79","metadata":{"id":"Gr4rUSqY-o79","executionInfo":{"status":"aborted","timestamp":1760664384690,"user_tz":300,"elapsed":286232,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ksQMstdc-o-3","metadata":{"id":"ksQMstdc-o-3","executionInfo":{"status":"aborted","timestamp":1760664384691,"user_tz":300,"elapsed":286232,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"JSdB6j-a-pDF","metadata":{"id":"JSdB6j-a-pDF","executionInfo":{"status":"aborted","timestamp":1760664384692,"user_tz":300,"elapsed":286233,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"U7ouQnxD-pF_","metadata":{"id":"U7ouQnxD-pF_","executionInfo":{"status":"aborted","timestamp":1760664384693,"user_tz":300,"elapsed":286234,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"WnjxgEPK-pIJ","metadata":{"id":"WnjxgEPK-pIJ","executionInfo":{"status":"aborted","timestamp":1760664384694,"user_tz":300,"elapsed":286234,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"j28g8Lqp-pKy","metadata":{"id":"j28g8Lqp-pKy","executionInfo":{"status":"aborted","timestamp":1760664384695,"user_tz":300,"elapsed":286235,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"DJbv-4-G-pMn","metadata":{"id":"DJbv-4-G-pMn","executionInfo":{"status":"aborted","timestamp":1760664384696,"user_tz":300,"elapsed":286236,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"Cxtz-1Fo-pPP","metadata":{"id":"Cxtz-1Fo-pPP","executionInfo":{"status":"aborted","timestamp":1760664384697,"user_tz":300,"elapsed":286237,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"JinSNJgh-pRf","metadata":{"id":"JinSNJgh-pRf","executionInfo":{"status":"aborted","timestamp":1760664384697,"user_tz":300,"elapsed":286237,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ywg21ljv-pcL","metadata":{"id":"ywg21ljv-pcL","executionInfo":{"status":"aborted","timestamp":1760664384702,"user_tz":300,"elapsed":286242,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"Jl01Xhpa-pfL","metadata":{"id":"Jl01Xhpa-pfL","executionInfo":{"status":"aborted","timestamp":1760664384704,"user_tz":300,"elapsed":286243,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ErNrKHRm-pg_","metadata":{"id":"ErNrKHRm-pg_","executionInfo":{"status":"aborted","timestamp":1760664384705,"user_tz":300,"elapsed":286244,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"IElgvqQj-pit","metadata":{"id":"IElgvqQj-pit","executionInfo":{"status":"aborted","timestamp":1760664384706,"user_tz":300,"elapsed":286245,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"-TADzyG9-pnO","metadata":{"id":"-TADzyG9-pnO","executionInfo":{"status":"aborted","timestamp":1760664384707,"user_tz":300,"elapsed":286246,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"miiDblbz-ppC","metadata":{"id":"miiDblbz-ppC","executionInfo":{"status":"aborted","timestamp":1760664384708,"user_tz":300,"elapsed":286247,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"Bnp7fHxm-pqu","metadata":{"id":"Bnp7fHxm-pqu","executionInfo":{"status":"aborted","timestamp":1760664384709,"user_tz":300,"elapsed":286248,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"UiQbsLv47Xu-","metadata":{"id":"UiQbsLv47Xu-","executionInfo":{"status":"aborted","timestamp":1760664384710,"user_tz":300,"elapsed":286248,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"hhAiYZZVGIsM","metadata":{"id":"hhAiYZZVGIsM","executionInfo":{"status":"aborted","timestamp":1760664384710,"user_tz":300,"elapsed":286248,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"EWQ7UG7zGIuj","metadata":{"id":"EWQ7UG7zGIuj","executionInfo":{"status":"aborted","timestamp":1760664384711,"user_tz":300,"elapsed":286249,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"hUObArfBGIw5","metadata":{"id":"hUObArfBGIw5","executionInfo":{"status":"aborted","timestamp":1760664384712,"user_tz":300,"elapsed":286250,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ln5ftwRAGI0C","metadata":{"id":"ln5ftwRAGI0C","executionInfo":{"status":"aborted","timestamp":1760664384713,"user_tz":300,"elapsed":286251,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"jgczkpH8GI2s","metadata":{"id":"jgczkpH8GI2s","executionInfo":{"status":"aborted","timestamp":1760664384714,"user_tz":300,"elapsed":286252,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"CFxtsYm4DJxo","metadata":{"id":"CFxtsYm4DJxo","executionInfo":{"status":"aborted","timestamp":1760664384718,"user_tz":300,"elapsed":286256,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"zIo_rXgnDJzw","metadata":{"id":"zIo_rXgnDJzw","executionInfo":{"status":"aborted","timestamp":1760664384723,"user_tz":300,"elapsed":286260,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"N4iBf4B0DJ14","metadata":{"id":"N4iBf4B0DJ14","executionInfo":{"status":"aborted","timestamp":1760664384724,"user_tz":300,"elapsed":286261,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"mGuWgjhCDJ5y","metadata":{"id":"mGuWgjhCDJ5y","executionInfo":{"status":"aborted","timestamp":1760664384725,"user_tz":300,"elapsed":286262,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"mtPQw2LIDJ8A","metadata":{"id":"mtPQw2LIDJ8A","executionInfo":{"status":"aborted","timestamp":1760664384726,"user_tz":300,"elapsed":286263,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"VRIqcx7HDJ9m","metadata":{"id":"VRIqcx7HDJ9m","executionInfo":{"status":"aborted","timestamp":1760664384734,"user_tz":300,"elapsed":286271,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"HfhdGuLEDJ_u","metadata":{"id":"HfhdGuLEDJ_u","executionInfo":{"status":"aborted","timestamp":1760664384736,"user_tz":300,"elapsed":286273,"user":{"displayName":"Haiyang Tang","userId":"10844064189374017810"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"virtual ENV","language":"python","name":"environment_instance"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":5}